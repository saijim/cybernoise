{"title":"BLAB: Brutally Long Audio Bench","summary":"Researchers introduce BLAB, a groundbreaking benchmark for audio language models to understand long-form conversational speech, pushing the limits of voice technology.","intro":"Imagine a world where your voice assistant can grasp the nuances of a hour-long conversation as effortlessly as you do. The future is closer than you think, thanks to the Brutally Long Audio Bench (BLAB) - a game-changing benchmark that's set to revolutionize the world of voice technology.","text":"In a significant leap towards enhancing the capabilities of voice technology, researchers have unveiled the Brutally Long Audio Bench (BLAB), a novel benchmark designed to test the limits of audio language models (LMs) in understanding long-form conversational speech. This development marks a crucial step towards creating more sophisticated and human-like voice assistants that can comprehend and respond to complex interactions. The BLAB benchmark comprises over 833 hours of diverse, full-length audio clips, each paired with human-annotated questions and answers, averaging 51 minutes in length. By evaluating six state-of-the-art audio LMs, including Gemini 2.0 Pro and GPT-4o, on BLAB, researchers found that even the most advanced models struggled with tasks such as localization, duration estimation, emotion recognition, and counting. The study revealed that audio LMs face significant challenges in understanding long-form speech, with performance declining as the duration of the audio increases. Moreover, the models performed poorly on tasks requiring temporal reasoning, counting, and understanding non-phonemic information, often relying more on prompts than the actual audio content. Despite these challenges, the introduction of BLAB is a significant step forward in the development of more robust and capable audio LMs. As researchers continue to push the boundaries of what is possible with voice technology, the potential applications of this technology are vast, ranging from enhancing the accessibility of language technologies for diverse user populations to creating more intuitive and responsive voice assistants. The future of voice technology is bright, and with benchmarks like BLAB, we can expect significant advancements in the years to come. One of the key insights from the study is the trade-off between task difficulty and audio duration. As audio LMs continue to evolve, it is likely that we will see significant improvements in their ability to understand long-form speech. The development of BLAB is a testament to the ongoing efforts to bridge the gap between human communication and machine understanding. By providing a challenging evaluation framework, BLAB is poised to drive innovation in the field of audio LMs, driving researchers to develop more sophisticated models that can handle the complexities of natural human interaction. As we move forward, it is clear that the impact of this technology will be felt across various sectors, from customer service and healthcare to education and entertainment. With the introduction of BLAB, we are one step closer to realizing a future where voice technology is not only more intuitive but also more accessible and responsive to the needs of diverse user populations. The possibilities are endless, and the future of voice technology has never been more promising.","keywords":["Voice Technology","Audio Language Models","Long-Form Speech","Conversational AI","BLAB Benchmark"],"prompt":"Generate an image that represents the intersection of human conversation and artificial intelligence, in the style of Syd Mead and H.R. Giger, with a futuristic, neon-lit cityscape in the background and a close-up of a voice assistant device in the foreground, surrounded by swirling audio waveforms and binary code, symbolizing the BLAB benchmark and the future of voice technology.","id":"2505.03054","slug":"revolutionizing-voice-tech-the-brutally-long-audio-bench-challenge","link":"https://arxiv.org/abs/2505.03054","abstract":"Abstract: Developing large audio language models (LMs) capable of understanding diverse spoken interactions is essential for accommodating the multimodal nature of human communication and can increase the accessibility of language technologies across different user populations. Recent work on audio LMs has primarily evaluated their performance on short audio segments, typically under 30 seconds, with limited exploration of long-form conversational speech segments that more closely reflect natural user interactions with these models. We introduce Brutally Long Audio Bench (BLAB), a challenging long-form audio benchmark that evaluates audio LMs on localization, duration estimation, emotion, and counting tasks using audio segments averaging 51 minutes in length. BLAB consists of 833+ hours of diverse, full-length audio clips, each paired with human-annotated, text-based natural language questions and answers. Our audio data were collected from permissively licensed sources and underwent a human-assisted filtering process to ensure task compliance. We evaluate six open-source and proprietary audio LMs on BLAB and find that all of them, including advanced models such as Gemini 2.0 Pro and GPT-4o, struggle with the tasks in BLAB. Our comprehensive analysis reveals key insights into the trade-offs between task difficulty and audio duration. In general, we find that audio LMs struggle with long-form speech, with performance declining as duration increases. They perform poorly on localization, temporal reasoning, counting, and struggle to understand non-phonemic information, relying more on prompts than audio content. BLAB serves as a challenging evaluation framework to develop audio LMs with robust long-form audio understanding capabilities.","creator":"Orevaoghene Ahia, Martijn Bartelds, Kabir Ahuja, Hila Gonen, Valentin Hofmann, Siddhant Arora, Shuyue Stella Li, Vishal Puttagunta, Mofetoluwa Adeyemi, Charishma Buchireddy, Ben Walls, Noah Bennett, Shinji Watanabe, Noah A. Smith, Yulia Tsvetkov, Sachin Kumar","topic":"artificial-intelligence"}