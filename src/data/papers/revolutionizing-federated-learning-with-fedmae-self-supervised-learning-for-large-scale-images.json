{"title":"Revolutionizing Federated Learning with FedMAE: Self-Supervised Learning for Large-Scale Images","summary":"FedMAE utilizes one-block masked autoencoders to pre-train lightweight client devices and build a multi-block ViT backbone for improved downstream tasks in federated learning.","intro":"Are you worried about your personal data privacy but still want to contribute to the development of AI? Look no further than FedMAE, the latest federated learning framework that utilizes self-supervised learning to protect user privacy while improving the performance of downstream tasks. By pre-training one-block masked autoencoders on local client devices, FedMAE achieves superior results with large-scale images. Say goodbye to high labeling costs and limited computing resources with FedMAE!","keywords":["Federated Learning","Self-Supervised Learning","Masked AutoEncoder","Large-Scale Images","Privacy"],"prompt":"a futuristic smartphone with a lock-shield displayed on top, representing the idea of privacy and security in the federated learning framework.","link":"http://arxiv.org/abs/2303.11339","id":"9a8727f458bdf074116bc52adee7ed09","slug":"revolutionizing-federated-learning-with-fedmae-self-supervised-learning-for-large-scale-images","imageSlug":"an-image-of-a-futuristic-smartphone-with-a-lock-shield-displayed-on-top-representing-the-idea-of-privacy-and-security-in-the-federated-learning-framework","creator":"Nan Yang, Xuanyu Chen, Charles Z. Liu, Dong Yuan, Wei Bao, Lizhen Cui"}