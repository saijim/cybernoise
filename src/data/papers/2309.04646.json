{"title":"Vietnamese AI Chatbots Just Got Smarter!","summary":"Your favourite AI chatbots are now even more skilled, competent and responsive, particularly in the Vietnamese language, thanks to revolutionary methods in training large language models!","intro":"Yes, that's right folks! Your beloved AI companions are no longer just regurgitators of bland, programmed responses. They have now stepped up their game, and are ready to provide you with accurate, detailed, and relevant interactions, all in the beautiful Vietnamese language! How you ask? Read on to find out how science is making this stunning transformation possible.","text":"You've probably heard of the marvels of large language models (LLMs) like GPT-4, PaLM, and LLaMa. These tech wonderkids are taking the world by storm, flexing their prowess at a variety of tasks that involve the nitty-gritty of human language. But don't get too comfy, because what's about to come is going to top everything. Let's dive right into it!\n\nSo imagine you're chatting with your AI assistant, and it is not just blandly responding back but actually following your instructions. It responds to you the way a human would. Sounds dreamy, right? Well, that's no longer dreamland folks! Recent advancements in instruction tuning have made it possible for these AI language models to follow user's instructions and produce human-like responses.\n\nNow, here comes the hitch - training and implementing these LLMs is a costly venture. Moreover, there's a scarcity of pretrained LLMs and instruction-tune datasets for Vietnamese. And that's where our heroes, the ingenious folks at the cutting edge of AI research, come in!\n\nThey decided to hitch a ride on open-source projects that have large-scale instruction-following datasets to make instruction tuned chatbots more accessible. Leveraging resources from projects like Alpaca, GPT4All, and Chat-Doctor, they were able to cover general and specific medical domains.\n\nBut wait, isn't this the first time someone's doing this for Vietnamese? Absolutely! These are its pioneers. They then applied a technique called Low-Rank Adaptation (LoRA) on two open LLMs: Bloomz (Multilingual) and GPTJ-6B (Vietnamese). This resulted in four fantastically fine-tuned models â€“ Bloomz-Chat, Bloomz-Doctor, GPTJ-Chat, and GPTJ-Doctor.\n\nTo ensure they were on the right track, they decided to assess their methodology in a detailed fashion. They used GPT-4, another top-notch automated tool, to gauge the effectiveness of the responses these new models generated. And guess what? Despite the low-cost setup, their method showed a whopping 20-30% improvement over the original models!\n\nHold on to your seats ladies and gentlemen, because the era of smarter, more efficient, and even more engaging AI chatbots have arrived! And let us tell you, these models are ready to amaze you with their capabilities.","keywords":["AI","Chatbot","Vietnamese","Large language models","Advanced Tuning"],"prompt":"Draw a futuristic neon AI chatbot speaking Vietnamese","link":"http://arxiv.org/abs/2309.04646","id":"2309.04646","slug":"vietnamese-ai-chatbots-just-got-smarter","creator":"Vu-Thuan Doan, Quoc-Truong Truong, Duc-Vu Nguyen, Vinh-Tiep Nguyen, Thuy-Ngan Nguyen Luu","topic":"artificial-intelligence"}