{"title":"Efficacy of AI RAG Tools for Complex Information Extraction and Data Annotation Tasks: A Case Study Using Banks Public Disclosures","summary":"A groundbreaking study reveals that AI-powered retrieval tools can speed up complex financial data analysis by 10x and boost accuracy—especially when humans work alongside AI like teammates, not just followers.","intro":"Imagine sifting through thousands of dense, confusing bank reports—each packed with legal jargon, inconsistent formats, and hidden risks. Now, picture an AI assistant that doesn’t just find answers, but thinks with you, double-checks facts, and speeds up the work by 10 times. That’s not science fiction—it’s what’s happening right now in the world of financial analysis. And the best part? It’s not replacing humans. It’s turning them into super-powered analysts. In a real-world test on global bank disclosures, researchers found that when humans and AI team up the right way, they save over 268 hours per project—time that could be spent building better policies, smarter investments, or even just taking a well-earned break.","text":"In the fast-paced world of global finance, one of the toughest jobs is making sense of mountains of public disclosures from major banks—what we call “GSIBs,” or Global Systemically Important Banks. These documents are massive, messy, and full of inconsistencies. They’re like digital puzzle boxes: each page might contain vital data, but only if you know where to look and how to interpret it. For years, analysts have done this work by hand—reading, highlighting, categorizing, and cross-referencing. It’s slow, error-prone, and exhausting. But now, a new wave of AI tools is changing the game—and not just a little. Enter Retrieval-Augmented Generation (RAG), a smart AI system that doesn’t just spit out answers. It searches through massive document libraries, finds relevant snippets, and generates clear, accurate summaries—just like a super-smart research assistant who never gets tired.\n\nA recent study, published on arXiv (2507.21360v1), tested how well these AI tools work in real life. Researchers set up a realistic challenge: analyze thousands of pages of bank disclosures using complex, multi-part rules. They compared three approaches: humans working alone (the old way), humans using AI in a passive, “naive” mode (just accepting the first answer), and humans working interactively with the AI—asking follow-up questions, verifying facts, and guiding the tool like a partner.\n\nThe results? Mind-blowing. In the interactive AI condition, task speed increased by up to 10 times compared to the human-only method. Accuracy didn’t just stay the same—it improved, especially for tricky, nuanced questions. The AI didn’t make mistakes; it helped humans avoid them. And when the researchers projected the results to a full-scale project, the time saved? A staggering 268 hours—enough to complete an entire year’s worth of analysis in just a few weeks.\n\nBut here’s the real game-changer: success wasn’t just about the AI. It was about how well humans knew how to use it. The study found that analysts with better “AI literacy”—those who understood how to ask good questions, challenge answers, and guide the tool—performed even better. This isn’t about replacing people with robots. It’s about empowering people with tools that amplify their skills.\n\nThis isn’t just about banks. The same principles apply to healthcare (analyzing patient records), legal work (reviewing contracts), education (grading essays), and even journalism (verifying sources). The future isn’t AI vs. humans—it’s AI + humans, working together like a dream team. The AI handles the grunt work: finding data, organizing facts, spotting patterns. The human brings judgment, ethics, context, and creativity. Together, they’re unstoppable.\n\nAnd the best part? These tools are getting smarter, faster, and easier to use every day. No coding required. No PhD in machine learning. Just a willingness to learn and collaborate. As we move deeper into the digital age, the most valuable skill won’t be memorizing facts—it’ll be knowing how to work with smart tools to unlock knowledge faster and better than ever before.\n\nSo, the next time you face a mountain of complex documents, don’t panic. Don’t go it alone. Grab your AI partner. Ask the right questions. Let the machine do the heavy lifting. And in just hours—maybe even minutes—you’ll have clarity where there was chaos. That’s not just progress. That’s a revolution. And it’s already happening, right now, in boardrooms, labs, and research hubs around the world.","keywords":["AI collaboration","financial analysis","RAG technology","data annotation","future of work"],"prompt":"Futuristic cyberpunk-style illustration of a diverse team of analysts in neon-lit data hubs, working with glowing AI assistants that project holographic data streams and real-time insights. The scene blends sleek, organic architecture with digital overlays of bank reports, neural network patterns, and floating icons. Inspired by the art of Syd Mead, Blade Runner 2049, and the vibrant digital aesthetics of Beeple. Soft ambient lighting, high contrast, cinematic depth, cybernetic harmony between humans and AI.","id":"2507.21360","slug":"ai-superpowers-how-smart-tools-are-saving-analysts-268-hours-a-year-on-bank-reports","link":"https://arxiv.org/abs/2507.21360","abstract":"arXiv:2507.21360v1 Announce Type: cross Abstract: We utilize a within-subjects design with randomized task assignments to understand the effectiveness of using an AI retrieval augmented generation (RAG) tool to assist analysts with an information extraction and data annotation task. We replicate an existing, challenging real-world annotation task with complex multi-part criteria on a set of thousands of pages of public disclosure documents from global systemically important banks (GSIBs) with heterogeneous and incomplete information content. We test two treatment conditions. First, a \"naive\" AI use condition in which annotators use only the tool and must accept the first answer they are given. And second, an \"interactive\" AI treatment condition where annotators use the tool interactively, and use their judgement to follow-up with additional information if necessary. Compared to the human-only baseline, the use of the AI tool accelerated task execution by up to a factor of 10 and enhanced task accuracy, particularly in the interactive condition. We find that when extrapolated to the full task, these methods could save up to 268 hours compared to the human-only approach. Additionally, our findings suggest that annotator skill, not just with the subject matter domain, but also with AI tools, is a factor in both the accuracy and speed of task performance.","creator":"Nicholas Botti (Federal Reserve Board), Flora Haberkorn (Federal Reserve Board), Charlotte Hoopes (Federal Reserve Board), Shaun Khan (Federal Reserve Board)","topic":"economics"}