[{"name":"Artificial Intelligence","feed":[{"id":"2311.16109","slug":"transfer-learning-between-motor-imagery-datasets-using-deep-learning-validation-of-framework-and-comparison-of-datasets-arxiv-2311-16109v1-cs-cv","title":"Transfer Learning between Motor Imagery Datasets using Deep Learning -- Validation of Framework and Comparison of Datasets.","link":"http://arxiv.org/abs/2311.16109","abstract":"We present a simple deep learning-based framework commonly used in computer vision and demonstrate its effectiveness for cross-dataset transfer learning in mental imagery decoding tasks that are common in the field of Brain-Computer Interfaces (BCI). We investigate, on a large selection of 12 motor-imagery datasets, which ones are well suited for transfer, both as donors and as receivers. Challenges. Deep learning models typically require long training times and are data-hungry, which impedes their use for BCI systems that have to minimize the recording time for (training) examples and are subject to constraints induced by experiments involving human subjects. A solution to both issues is transfer learning, but it comes with its own challenge, i.e., substantial data distribution shifts between datasets, subjects and even between subsequent sessions of the same subject. Approach. For every pair of pre-training (donor) and test (receiver) dataset, we first train a model on the donor before training merely an additional new linear classification layer based on a few receiver trials. Performance of this transfer approach is then tested on other trials of the receiver dataset. Significance. First, we lower the threshold to use transfer learning between motor imagery datasets: the overall framework is extremely simple and nevertheless obtains decent classification scores. Second, we demonstrate that deep learning models are a good option for motor imagery cross-dataset transfer both for the reasons outlined in the first point and because the framework presented is viable in online scenarios. Finally, analysing which datasets are best suited for transfer learning can be used as a reference for future researchers to determine which to use for pre-training or benchmarking.","creator":"Pierre Guetschel, Michael Tangermann"},{"id":"2311.16111","slug":"deep-explainability-spin-geometrical-neural-meta-structures-arxiv-2311-16111v1-q-bio-nc","title":"Deep Explainability: Spin-Geometrical Neural Meta-Structures.","link":"http://arxiv.org/abs/2311.16111","abstract":"We face up to the challenge of explainability in multimodal artificial intelligence. At the nexus of neuroscience-inspired and quantum computing, interpretable and transparent spin-geometrical meta-architectures for early fusion of large-scale, heterogeneous, graph-structured data are envisioned, harnessing recent evidence for relativistic quantum neural coding of (co-)behavioral states in the self-organizing brain, under competitive, multidimensional dynamics. The designs draw on a self-dual classical description - via special Clifford-Lipschitz operations - of spinorial quantum states within registers of at most 16 qubits for efficient encoding of exponentially large neural structures. Formally 'trained', Lorentz neural architectures with precisely one lateral layer of exclusively inhibitory interneurons accounting for anti-modalities, as well as their co-architectures with intra-layer connections are highlighted. In principle, the approach accommodates the fusion of up to 16 time-invariant interconnected (anti-)modalities and the explicit recognition of underlying multidimensional patterns. Comprehensive insights are expected to be gained through applications to multimodal big data, under real-world scenarios.","creator":"Sofia Karamintziou, Georgios Meditskos, Dimos Ntioudis, Thanassis Mavropoulos, Stefanos Vrochidis, Ioannis (Yiannis) Kompatsiaris"},{"id":"2311.16112","slug":"co-learning-synaptic-delays-weights-and-adaptation-in-spiking-neural-networks-arxiv-2311-16112v1-cs-ne","title":"Co-learning synaptic delays, weights and adaptation in spiking neural networks.","link":"http://arxiv.org/abs/2311.16112","abstract":"Spiking neural networks (SNN) distinguish themselves from artificial neural networks (ANN) because of their inherent temporal processing and spike-based computations, enabling a power-efficient implementation in neuromorphic hardware. In this paper, we demonstrate that data processing with spiking neurons can be enhanced by co-learning the connection weights with two other biologically inspired neuronal features: 1) a set of parameters describing neuronal adaptation processes and 2) synaptic propagation delays. The former allows the spiking neuron to learn how to specifically react to incoming spikes based on its past. The trained adaptation parameters result in neuronal heterogeneity, which is found in the brain and also leads to a greater variety in available spike patterns. The latter enables to learn to explicitly correlate patterns that are temporally distanced. Synaptic delays reflect the time an action potential requires to travel from one neuron to another. We show that each of the co-learned features separately leads to an improvement over the baseline SNN and that the combination of both leads to state-of-the-art SNN results on all speech recognition datasets investigated with a simple 2-hidden layer feed-forward network. Our SNN outperforms the ANN on the neuromorpic datasets (Spiking Heidelberg Digits and Spiking Speech Commands), even with fewer trainable parameters. On the 35-class Google Speech Commands dataset, our SNN also outperforms a GRU of similar size. Our work presents brain-inspired improvements to SNN that enable them to excel over an equivalent ANN of similar size on tasks with rich temporal dynamics.","creator":"Lucas Deckers, Laurens Van Damme, Ing Jyh Tsang, Werner Van Leekwijck, Steven Latr&#xe9;"},{"id":"2311.16114","slug":"learning-noise-robust-joint-representation-for-multimodal-emotion-recognition-under-realistic-incomplete-data-scenarios-arxiv-2311-16114v1-cs-cv","title":"Learning Noise-Robust Joint Representation for Multimodal Emotion Recognition under Realistic Incomplete Data Scenarios.","link":"http://arxiv.org/abs/2311.16114","abstract":"Multimodal emotion recognition (MER) in practical scenarios presents a significant challenge due to the presence of incomplete data, such as missing or noisy data. Traditional methods often discard missing data or replace it with a zero vector, neglecting the availability issue of noisy data. Consequently, these approaches are not fully applicable to realistic scenarios, where both missing and noisy data are prevalent. To address this problem, we propose a novel noise-robust MER model, named NMER, which effectively learns robust multimodal joint representations from incomplete data containing noise. Our approach incorporates two key components. First, we introduce a noise scheduler that adjusts the type and level of noise in the training data, emulating the characteristics of incomplete data in realistic scenarios. Second, we employ a Variational AutoEncoder (VAE)-based NMER model to generate robust multimodal joint representations from the noisy data, leveraging the modality invariant feature. The experimental results on the benchmark dataset IEMOCAP indicate the proposed NMER outperforms state-of-the-art MER systems. The ablation results also confirm the effectiveness of the VAE structure. We release our code at \\href{https://github.com/WooyoohL/Noise-robust_MER.","creator":"Qi Fan (1), Haolin Zuo (1), Rui Liu (1), Zheng Lian (2), Guanglai Gao (1) ((1) Inner Mongolia University, Hohhot, China, (2) Institute of Automation, Chinese Academy of Sciences, Beijing, China)"},{"id":"2311.16115","slug":"ai-and-democracy-s-digital-identity-crisis-arxiv-2311-16115v1-cs-cr","title":"AI and Democracy's Digital Identity Crisis.","link":"http://arxiv.org/abs/2311.16115","abstract":"AI-enabled tools have become sophisticated enough to allow a small number of individuals to run disinformation campaigns of an unprecedented scale. Privacy-preserving identity attestations can drastically reduce instances of impersonation and make disinformation easy to identify and potentially hinder. By understanding how identity attestations are positioned across the spectrum of decentralization, we can gain a better understanding of the costs and benefits of various attestations. In this paper, we discuss attestation types, including governmental, biometric, federated, and web of trust-based, and include examples such as e-Estonia, China's social credit system, Worldcoin, OAuth, X (formerly Twitter), Gitcoin Passport, and EAS. We believe that the most resilient systems create an identity that evolves and is connected to a network of similarly evolving identities that verify one another. In this type of system, each entity contributes its respective credibility to the attestation process, creating a larger, more comprehensive set of attestations. We believe these systems could be the best approach to authenticating identity and protecting against some of the threats to democracy that AI can pose in the hands of malicious actors. However, governments will likely attempt to mitigate these risks by implementing centralized identity authentication systems; these centralized systems could themselves pose risks to the democratic processes they are built to defend. We therefore recommend that policymakers support the development of standards-setting organizations for identity, provide legal clarity for builders of decentralized tooling, and fund research critical to effective identity authentication systems.","creator":"Shrey Jain, Connor Spelliscy, Samuel Vance-Law, Scott Moore"},{"id":"2311.16119","slug":"ignore-this-title-and-hackaprompt-exposing-systemic-vulnerabilities-of-llms-through-a-global-scale-prompt-hacking-competition-arxiv-2311-16119v1-cs-cr","title":"Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition.","link":"http://arxiv.org/abs/2311.16119","abstract":"Large Language Models (LLMs) are increasingly being deployed in interactive contexts that involve direct user engagement, such as chatbots and writing assistants. These deployments are increasingly plagued by prompt injection and jailbreaking (collectively, prompt hacking), in which models are manipulated to ignore their original instructions and instead follow potentially malicious ones. Although widely acknowledged as a significant security threat, there is a dearth of large-scale resources and quantitative studies on prompt hacking. To address this lacuna, we launch a global prompt hacking competition, which allows for free-form human input attacks. We elicit 600K+ adversarial prompts against three state-of-the-art LLMs. We describe the dataset, which empirically verifies that current LLMs can indeed be manipulated via prompt hacking. We also present a comprehensive taxonomical ontology of the types of adversarial prompts.","creator":"Sander Schulhoff, Jeremy Pinto, Anaum Khan, Louis-Fran&#xe7;ois Bouchard, Chenglei Si, Svetlina Anati, Valen Tagliabue, Anson Liu Kost, Christopher Carnahan, Jordan Boyd-Graber"},{"id":"2311.16122","slug":"semantic-generative-augmentations-for-few-shot-counting-arxiv-2311-16122v1-cs-cv","title":"Semantic Generative Augmentations for Few-Shot Counting.","link":"http://arxiv.org/abs/2311.16122","abstract":"With the availability of powerful text-to-image diffusion models, recent works have explored the use of synthetic data to improve image classification performances. These works show that it can effectively augment or even replace real data. In this work, we investigate how synthetic data can benefit few-shot class-agnostic counting. This requires to generate images that correspond to a given input number of objects. However, text-to-image models struggle to grasp the notion of count. We propose to rely on a double conditioning of Stable Diffusion with both a prompt and a density map in order to augment a training dataset for few-shot counting. Due to the small dataset size, the fine-tuned model tends to generate images close to the training images. We propose to enhance the diversity of synthesized images by exchanging captions between images thus creating unseen configurations of object types and spatial layout. Our experiments show that our diversified generation strategy significantly improves the counting accuracy of two recent and performing few-shot counting models on FSC147 and CARPK.","creator":"Perla Doubinsky (CEDRIC - VERTIGO, CNAM), Nicolas Audebert (CEDRIC - VERTIGO, CNAM), Michel Crucianu (CEDRIC - VERTIGO), Herv&#xe9; Le Borgne (CEA)"},{"id":"2311.16124","slug":"diffattack-evasion-attacks-against-diffusion-based-adversarial-purification-arxiv-2311-16124v1-cs-cr","title":"DiffAttack: Evasion Attacks Against Diffusion-Based Adversarial Purification.","link":"http://arxiv.org/abs/2311.16124","abstract":"Diffusion-based purification defenses leverage diffusion models to remove crafted perturbations of adversarial examples and achieve state-of-the-art robustness. Recent studies show that even advanced attacks cannot break such defenses effectively, since the purification process induces an extremely deep computational graph which poses the potential problem of gradient obfuscation, high memory cost, and unbounded randomness. In this paper, we propose a unified framework DiffAttack to perform effective and efficient attacks against diffusion-based purification defenses, including both DDPM and score-based approaches. In particular, we propose a deviated-reconstruction loss at intermediate diffusion steps to induce inaccurate density gradient estimation to tackle the problem of vanishing/exploding gradients. We also provide a segment-wise forwarding-backwarding algorithm, which leads to memory-efficient gradient backpropagation. We validate the attack effectiveness of DiffAttack compared with existing adaptive attacks on CIFAR-10 and ImageNet. We show that DiffAttack decreases the robust accuracy of models compared with SOTA attacks by over 20% on CIFAR-10 under $\\ell_\\infty$ attack $(\\epsilon=8/255)$, and over 10% on ImageNet under $\\ell_\\infty$ attack $(\\epsilon=4/255)$. We conduct a series of ablations studies, and we find 1) DiffAttack with the deviated-reconstruction loss added over uniformly sampled time steps is more effective than that added over only initial/final steps, and 2) diffusion-based purification with a moderate diffusion length is more robust under DiffAttack.","creator":"Mintong Kang, Dawn Song, Bo Li"},{"id":"2311.16133","slug":"effective-quantization-for-diffusion-models-on-cpus-arxiv-2311-16133v1-cs-cv","title":"Effective Quantization for Diffusion Models on CPUs.","link":"http://arxiv.org/abs/2311.16133","abstract":"Diffusion models have gained popularity for generating images from textual descriptions. Nonetheless, the substantial need for computational resources continues to present a noteworthy challenge, contributing to time-consuming processes. Quantization, a technique employed to compress deep learning models for enhanced efficiency, presents challenges when applied to diffusion models. These models are notably more sensitive to quantization compared to other model types, potentially resulting in a degradation of image quality. In this paper, we introduce a novel approach to quantize the diffusion models by leveraging both quantization-aware training and distillation. Our results show the quantized models can maintain the high image quality while demonstrating the inference efficiency on CPUs.","creator":"Hanwen Chang, Haihao Shen, Yiyang Cai, Xinyu Ye, Zhenzhong Xu, Wenhua Cheng, Kaokao Lv, Weiwei Zhang, Yintong Lu, Heng Guo"},{"id":"2311.16136","slug":"eraser-machine-unlearning-in-mlaas-via-an-inference-serving-aware-approach-arxiv-2311-16136v1-cs-cr","title":"ERASER: Machine Unlearning in MLaaS via an Inference Serving-Aware Approach.","link":"http://arxiv.org/abs/2311.16136","abstract":"Over the past few years, Machine Learning-as-a-Service (MLaaS) has received a surging demand for supporting Machine Learning-driven services to offer revolutionized user experience across diverse application areas. MLaaS provides inference service with low inference latency to application users based on an ML model trained using a dataset collected from numerous individual data owners. Recently, for the sake of data owners' privacy and to comply with the \"right to be forgotten (RTBF)\" as enacted by data protection legislation, many machine unlearning methods have been proposed to remove data owners' data from trained models upon their unlearning requests. However, despite their promising efficiency, almost all existing machine unlearning methods handle unlearning requests in a manner that is independent of inference requests, which unfortunately introduces new security and privacy vulnerabilities for machine unlearning in MLaaS. In this paper, we propose the ERASER framework for machinE unleaRning in MLaAS via an inferencE seRving-aware approach. ERASER proposes a novel certified inference consistency mechanism that reduces inference latency by selectively postponing unlearning execution incurred by unlearning requests from data owners, while strictly adhering to the RTBF principle. ERASER offers three groups of design choices to allow for tailor-made variants that best suit the specific environments and preferences of different MLaaS systems. Extensive empirical evaluations across various settings confirm ERASER's effectiveness, e.g., it can effectively save up to 99% of inference latency and 31% of computation overhead over the inference-oblivion baseline.","creator":"Yuke Hu, Jian Lou, Jiaqi Liu, Feng Lin, Zhan Qin, Kui Ren"},{"id":"2311.16137","slug":"a-graph-to-text-approach-to-knowledge-grounded-response-generation-in-human-robot-interaction-arxiv-2311-16137v1-cs-ro","title":"A Graph-to-Text Approach to Knowledge-Grounded Response Generation in Human-Robot Interaction.","link":"http://arxiv.org/abs/2311.16137","abstract":"Knowledge graphs are often used to represent structured information in a flexible and efficient manner, but their use in situated dialogue remains under-explored. This paper presents a novel conversational model for human--robot interaction that rests upon a graph-based representation of the dialogue state. The knowledge graph representing the dialogue state is continuously updated with new observations from the robot sensors, including linguistic, situated and multimodal inputs, and is further enriched by other modules, in particular for spatial understanding. The neural conversational model employed to respond to user utterances relies on a simple but effective graph-to-text mechanism that traverses the dialogue state graph and converts the traversals into a natural language form. This conversion of the state graph into text is performed using a set of parameterized functions, and the values for those parameters are optimized based on a small set of Wizard-of-Oz interactions. After this conversion, the text representation of the dialogue state graph is included as part of the prompt of a large language model used to decode the agent response. The proposed approach is empirically evaluated through a user study with a humanoid robot that acts as conversation partner to evaluate the impact of the graph-to-text mechanism on the response generation. After moving a robot along a tour of an indoor environment, participants interacted with the robot using spoken dialogue and evaluated how well the robot was able to answer questions about what the robot observed during the tour. User scores show a statistically significant improvement in the perceived factuality of the robot responses when the graph-to-text approach is employed, compared to a baseline using inputs structured as semantic triples.","creator":"Nicholas Thomas Walker, Stefan Ultes, Pierre Lison"},{"id":"2311.16138","slug":"after-stroke-arm-paresis-detection-using-kinematic-data-arxiv-2311-16138v1-cs-cv","title":"After-Stroke Arm Paresis Detection using Kinematic Data.","link":"http://arxiv.org/abs/2311.16138","abstract":"This paper presents an approach for detecting unilateral arm paralysis/weakness using kinematic data. Our method employs temporal convolution networks and recurrent neural networks, guided by knowledge distillation, where we use inertial measurement units attached to the body to capture kinematic information such as acceleration, rotation, and flexion of body joints during an action. This information is then analyzed to recognize body actions and patterns. Our proposed network achieves a high paretic detection accuracy of 97.99\\%, with an action classification accuracy of 77.69\\%, through knowledge sharing. Furthermore, by incorporating causal reasoning, we can gain additional insights into the patient's condition, such as their Fugl-Meyer assessment score or impairment level based on the machine learning result. Overall, our approach demonstrates the potential of using kinematic data and machine learning for detecting arm paralysis/weakness. The results suggest that our method could be a useful tool for clinicians and healthcare professionals working with patients with this condition.","creator":"Kenneth Lai, Mohammed Almekhlafi, Svetlana Yanushkevich"},{"id":"2311.16140","slug":"adapting-segment-anything-model-sam-through-prompt-based-learning-for-enhanced-protein-identification-in-cryo-em-micrographs-arxiv-2311-16140v1-cs-cv","title":"Adapting Segment Anything Model (SAM) through Prompt-based Learning for Enhanced Protein Identification in Cryo-EM Micrographs.","link":"http://arxiv.org/abs/2311.16140","abstract":"Cryo-electron microscopy (cryo-EM) remains pivotal in structural biology, yet the task of protein particle picking, integral for 3D protein structure construction, is laden with manual inefficiencies. While recent AI tools such as Topaz and crYOLO are advancing the field, they do not fully address the challenges of cryo-EM images, including low contrast, complex shapes, and heterogeneous conformations. This study explored prompt-based learning to adapt the state-of-the-art image segmentation foundation model Segment Anything Model (SAM) for cryo-EM. This focus was driven by the desire to optimize model performance with a small number of labeled data without altering pre-trained parameters, aiming for a balance between adaptability and foundational knowledge retention. Through trials with three prompt-based learning strategies, namely head prompt, prefix prompt, and encoder prompt, we observed enhanced performance and reduced computational requirements compared to the fine-tuning approach. This work not only highlights the potential of prompting SAM in protein identification from cryo-EM micrographs but also suggests its broader promise in biomedical image segmentation and object detection.","creator":"Fei He, Zhiyuan Yang, Mingyue Gao, Biplab Poudel, Newgin Sam Ebin Sam Dhas, Rajan Gyawali, Ashwin Dhakal, Jianlin Cheng, Dong Xu"},{"id":"2311.16141","slug":"brain-inspired-efficient-pruning-exploiting-criticality-in-spiking-neural-networks-arxiv-2311-16141v1-cs-ne","title":"Brain-Inspired Efficient Pruning: Exploiting Criticality in Spiking Neural Networks.","link":"http://arxiv.org/abs/2311.16141","abstract":"Spiking Neural Networks (SNNs) have been an attractive option for deployment on devices with limited computing resources and lower power consumption because of the event-driven computing characteristic. As such devices have limited computing and storage resources, pruning for SNNs has been widely focused recently. However, the binary and non-differentiable property of spike signals make pruning deep SNNs challenging, so existing methods require high time overhead to make pruning decisions. In this paper, inspired by critical brain hypothesis in neuroscience, we design a regeneration mechanism based on criticality to efficiently obtain the critical pruned networks. Firstly, we propose a low-cost metric for the criticality of pruning structures. Then we re-rank the pruned structures after pruning and regenerate those with higher criticality. We evaluate our method using VGG-16 and ResNet-19 for both unstructured pruning and structured pruning. Our method achieves higher performance compared to current state-of-the-art (SOTA) method with the same time overhead. We also achieve comparable performances (even better on VGG-16) compared to the SOTA method with 11.3x and 15.5x acceleration. Moreover, we investigate underlying mechanism of our method and find that it efficiently selects potential structures, learns the consistent feature representations and reduces the overfitting during the recovery phase.","creator":"Shuo Chen, Boxiao Liu, Haihang You"},{"id":"2311.16143","slug":"ransomware-detection-and-classification-using-machine-learning-arxiv-2311-16143v1-cs-cr","title":"Ransomware Detection and Classification using Machine Learning.","link":"http://arxiv.org/abs/2311.16143","abstract":"Vicious assaults, malware, and various ransomware pose a cybersecurity threat, causing considerable damage to computer structures, servers, and mobile and web apps across various industries and businesses. These safety concerns are important and must be addressed immediately. Ransomware detection and classification are critical for guaranteeing rapid reaction and prevention. This study uses the XGBoost classifier and Random Forest (RF) algorithms to detect and classify ransomware attacks. This approach involves analyzing the behaviour of ransomware and extracting relevant features that can help distinguish between different ransomware families. The models are evaluated on a dataset of ransomware attacks and demonstrate their effectiveness in accurately detecting and classifying ransomware. The results show that the XGBoost classifier, Random Forest Classifiers, can effectively detect and classify different ransomware attacks with high accuracy, thereby providing a valuable tool for enhancing cybersecurity.","creator":"Kavitha Kunku, ANK Zaman, Kaushik Roy"},{"id":"2311.16146","slug":"emulators-in-jinsp-arxiv-2311-16146v1-cs-ni","title":"Emulators in JINSP.","link":"http://arxiv.org/abs/2311.16146","abstract":"JINSP(Jiutian Intelligence Network Simulation Platform) describes a series of basic emulators and their combinations, such as the simulation of the protocol stack for dynamic users in a real environment, which is composed of user behavior simulation, base station simulation, and terminal simulation. It is applied in specific business scenarios, such as multi-target antenna optimization, compression feedback, and so on. This paper provides detailed descriptions of each emulator and its combination based on this foundation, including the implementation process of the emulator, integration with the platform, experimental results, and other aspects.","creator":"Lei Zhao, Miaomiao Zhang, Lv Zhe"},{"id":"2311.16153","slug":"identifying-and-mitigating-vulnerabilities-in-llm-integrated-applications-arxiv-2311-16153v1-cs-cr","title":"Identifying and Mitigating Vulnerabilities in LLM-Integrated Applications.","link":"http://arxiv.org/abs/2311.16153","abstract":"Large language models (LLMs) are increasingly deployed as the service backend for LLM-integrated applications such as code completion and AI-powered search. LLM-integrated applications serve as middleware to refine users' queries with domain-specific knowledge to better inform LLMs and enhance the responses. Despite numerous opportunities and benefits, LLM-integrated applications also introduce new attack surfaces. Understanding, minimizing, and eliminating these emerging attack surfaces is a new area of research. In this work, we consider a setup where the user and LLM interact via an LLM-integrated application in the middle. We focus on the communication rounds that begin with user's queries and end with LLM-integrated application returning responses to the queries, powered by LLMs at the service backend. For this query-response protocol, we identify potential vulnerabilities that can originate from the malicious application developer or from an outsider threat initiator that is able to control the database access, manipulate and poison data that are high-risk for the user. Successful exploits of the identified vulnerabilities result in the users receiving responses tailored to the intent of a threat initiator. We assess such threats against LLM-integrated applications empowered by OpenAI GPT-3.5 and GPT-4. Our empirical results show that the threats can effectively bypass the restrictions and moderation policies of OpenAI, resulting in users receiving responses that contain bias, toxic content, privacy risk, and disinformation. To mitigate those threats, we identify and define four key properties, namely integrity, source identification, attack detectability, and utility preservation, that need to be satisfied by a safe LLM-integrated application. Based on these properties, we develop a lightweight, threat-agnostic defense that mitigates both insider and outsider threats.","creator":"Fengqing Jiang, Zhangchen Xu, Luyao Niu, Boxin Wang, Jinyuan Jia, Bo Li, Radha Poovendran"},{"id":"2311.16158","slug":"carbnn-a-novel-active-transfer-learning-neural-network-to-build-de-novo-metal-organic-frameworks-mofs-for-carbon-capture-arxiv-2311-16158v1-cs-lg","title":"CarbNN: A Novel Active Transfer Learning Neural Network To Build De Novo Metal Organic Frameworks (MOFs) for Carbon Capture.","link":"http://arxiv.org/abs/2311.16158","abstract":"Over the past decade, climate change has become an increasing problem with one of the major contributing factors being carbon dioxide (CO2) emissions; almost 51% of total US carbon emissions are from factories. Current materials used in CO2 capture are lacking either in efficiency, sustainability, or cost.  Electrocatalysis of CO2 is a new approach where CO2 can be reduced and the components used industrially as fuel, saving transportation costs, creating financial incentives. Metal Organic Frameworks (MOFs) are crystals made of organo-metals that adsorb, filter, and electrocatalyze CO2. The current available MOFs for capture &amp; electrocatalysis are expensive to manufacture and inefficient at capture. The goal therefore is to computationally design a MOF that can adsorb CO2 and catalyze carbon monoxide &amp; oxygen with low cost.  A novel active transfer learning neural network was developed, utilizing transfer learning due to limited available data on 15 MOFs. Using the Cambridge Structural Database with 10,000 MOFs, the model used incremental mutations to fit a trained fitness hyper-heuristic function. Eventually, a Selenium MOF (C18MgO25Se11Sn20Zn5) was converged on. Through analysis of predictions &amp; literature, the converged MOF was shown to be more effective &amp; more synthetically accessible than existing MOFs, showing the model had an understanding of effective electrocatalytic structures in the material space. This novel network can be implemented for other gas separations and catalysis applications that have limited training accessible datasets.","creator":"Neel Redkar"},{"id":"2311.16161","slug":"vision-encoder-decoder-models-for-ai-coaching-arxiv-2311-16161v1-cs-cv","title":"Vision Encoder-Decoder Models for AI Coaching.","link":"http://arxiv.org/abs/2311.16161","abstract":"This research paper introduces an innovative AI coaching approach by integrating vision-encoder-decoder models. The feasibility of this method is demonstrated using a Vision Transformer as the encoder and GPT-2 as the decoder, achieving a seamless integration of visual input and textual interaction. Departing from conventional practices of employing distinct models for image recognition and text-based coaching, our integrated architecture directly processes input images, enabling natural question-and-answer dialogues with the AI coach. This unique strategy simplifies model architecture while enhancing the overall user experience in human-AI interactions. We showcase sample results to demonstrate the capability of the model. The results underscore the methodology's potential as a promising paradigm for creating efficient AI coach models in various domains involving visual inputs. Importantly, this potential holds true regardless of the particular visual encoder or text decoder chosen. Additionally, we conducted experiments with different sizes of GPT-2 to assess the impact on AI coach performance, providing valuable insights into the scalability and versatility of our proposed methodology.","creator":"Jyothi S Nayak, Afifah Khan Mohammed Ajmal Khan, Chirag Manjeshwar, Imadh Ajaz Banday"},{"id":"2311.16162","slug":"leveraging-artificial-intelligence-technology-for-mapping-research-to-sustainable-development-goals-a-case-study-arxiv-2311-16162v1-cs-dl","title":"Leveraging Artificial Intelligence Technology for Mapping Research to Sustainable Development Goals: A Case Study.","link":"http://arxiv.org/abs/2311.16162","abstract":"The number of publications related to the Sustainable Development Goals (SDGs) continues to grow. These publications cover a diverse spectrum of research, from humanities and social sciences to engineering and health. Given the imperative of funding bodies to monitor outcomes and impacts, linking publications to relevant SDGs is critical but remains time-consuming and difficult given the breadth and complexity of the SDGs. A publication may relate to several goals (interconnection feature of goals), and therefore require multidisciplinary knowledge to tag accurately. Machine learning approaches are promising and have proven particularly valuable for tasks such as manual data labeling and text classification. In this study, we employed over 82,000 publications from an Australian university as a case study. We utilized a similarity measure to map these publications onto Sustainable Development Goals (SDGs). Additionally, we leveraged the OpenAI GPT model to conduct the same task, facilitating a comparative analysis between the two approaches. Experimental results show that about 82.89% of the results obtained by the similarity measure overlap (at least one tag) with the outputs of the GPT model. The adopted model (similarity measure) can complement GPT model for SDG classification. Furthermore, deep learning methods, which include the similarity measure used here, are more accessible and trusted for dealing with sensitive data without the use of commercial AI services or the deployment of expensive computing resources to operate large language models. Our study demonstrates how a crafted combination of the two methods can achieve reliable results for mapping research to the SDGs.","creator":"Hui Yin, Amir Aryani, Gavin Lambert, Marcus White, Luis Salvador-Carulla, Shazia Sadiq, Elvira Sojli, Jennifer Boddy, Greg Murray, Wing Wah Tham"},{"id":"2311.16167","slug":"mmpde-net-and-moving-sampling-physics-informed-neural-networks-based-on-moving-mesh-method-arxiv-2311-16167v1-math-na","title":"MMPDE-Net and Moving Sampling Physics-informed Neural Networks Based On Moving Mesh Method.","link":"http://arxiv.org/abs/2311.16167","abstract":"In this work, we propose an end-to-end adaptive sampling neural network (MMPDE-Net) based on the moving mesh PDE method, which can adaptively generate new coordinates of sampling points by solving the moving mesh PDE. This model focuses on improving the efficiency of individual sampling points. Moreover, we have developed an iterative algorithm based on MMPDE-Net, which makes the sampling points more precise and controllable. Since MMPDE-Net is a framework independent of the deep learning solver, we combine it with PINN to propose MS-PINN and demonstrate its effectiveness by performing error analysis under the assumptions given in this paper. Meanwhile, we demonstrate the performance improvement of MS-PINN compared to PINN through numerical experiments on four typical examples to verify the effectiveness of our method.","creator":"Yu Yang, Qihong Yang, Yangtao Deng, Qiaolin He"},{"id":"2311.16171","slug":"multi-agent-learning-of-efficient-fulfilment-and-routing-strategies-in-e-commerce-arxiv-2311-16171v1-cs-ai","title":"Multi-Agent Learning of Efficient Fulfilment and Routing Strategies in E-Commerce.","link":"http://arxiv.org/abs/2311.16171","abstract":"This paper presents an integrated algorithmic framework for minimising product delivery costs in e-commerce (known as the cost-to-serve or C2S). One of the major challenges in e-commerce is the large volume of spatio-temporally diverse orders from multiple customers, each of which has to be fulfilled from one of several warehouses using a fleet of vehicles. This results in two levels of decision-making: (i) selection of a fulfillment node for each order (including the option of deferral to a future time), and then (ii) routing of vehicles (each of which can carry multiple orders originating from the same warehouse). We propose an approach that combines graph neural networks and reinforcement learning to train the node selection and vehicle routing agents. We include real-world constraints such as warehouse inventory capacity, vehicle characteristics such as travel times, service times, carrying capacity, and customer constraints including time windows for delivery. The complexity of this problem arises from the fact that outcomes (rewards) are driven both by the fulfillment node mapping as well as the routing algorithms, and are spatio-temporally distributed. Our experiments show that this algorithmic pipeline outperforms pure heuristic policies.","creator":"Omkar Shelke, Pranavi Pathakota, Anandsingh Chauhan, Harshad Khadilkar, Hardik Meisheri, Balaraman Ravindran"},{"id":"2311.16172","slug":"evolutionary-machine-learning-and-games-arxiv-2311-16172v1-cs-ne","title":"Evolutionary Machine Learning and Games.","link":"http://arxiv.org/abs/2311.16172","abstract":"Evolutionary machine learning (EML) has been applied to games in multiple ways, and for multiple different purposes. Importantly, AI research in games is not only about playing games; it is also about generating game content, modeling players, and many other applications. Many of these applications pose interesting problems for EML. We will structure this chapter on EML for games based on whether evolution is used to augment machine learning (ML) or ML is used to augment evolution. For completeness, we also briefly discuss the usage of ML and evolution separately in games.","creator":"Julian Togelius, Ahmed Khalifa, Sam Earle, Michael Cerny Green, Lisa Soros"},{"id":"2311.16173","slug":"conditions-for-length-generalization-in-learning-reasoning-skills-arxiv-2311-16173v1-cs-ai","title":"Conditions for Length Generalization in Learning Reasoning Skills.","link":"http://arxiv.org/abs/2311.16173","abstract":"Reasoning is a fundamental capability of AI agents. Recently, large language models (LLMs) have shown remarkable abilities to perform reasoning tasks. However, numerous evaluations of the reasoning capabilities of LLMs have also showed some limitations. An outstanding limitation is length generalization, meaning that when trained on reasoning problems of smaller lengths or sizes, the resulting models struggle with problems of larger sizes or lengths. This potentially indicates some theoretical limitations of generalization in learning reasoning skills. These evaluations and their observations motivated us to perform a theoretical study of the length generalization problem. This work focused on reasoning tasks that can be formulated as Markov dynamic processes (MDPs) and/or directed acyclic graphs (DAGs). It identifies and proves conditions that decide whether the length generalization problem can be solved or not for a reasoning task in a particular representation. Experiments are also conducted to verify the theoretical results.","creator":"Changnan Xiao, Bing Liu"},{"id":"2311.16176","slug":"shortcut-bias-mitigation-via-ensemble-diversity-using-diffusion-probabilistic-models-arxiv-2311-16176v1-cs-lg","title":"Shortcut Bias Mitigation via Ensemble Diversity Using Diffusion Probabilistic Models.","link":"http://arxiv.org/abs/2311.16176","abstract":"Spurious correlations in the data, where multiple cues are predictive of the target labels, often lead to a phenomenon known as simplicity bias, where a model relies on erroneous, easy-to-learn cues while ignoring reliable ones. In this work, we propose an ensemble diversification framework exploiting Diffusion Probabilistic Models (DPMs) for shortcut bias mitigation. We show that at particular training intervals, DPMs can generate images with novel feature combinations, even when trained on images displaying correlated input features. We leverage this crucial property to generate synthetic counterfactuals to increase model diversity via ensemble disagreement. We show that DPM-guided diversification is sufficient to remove dependence on primary shortcut cues, without a need for additional supervised signals. We further empirically quantify its efficacy on several diversification objectives, and finally show improved generalization and diversification performance on par with prior work that relies on auxiliary data collection.","creator":"Luca Scimeca, Alexander Rubinstein, Damien Teney, Seong Joon Oh, Armand Mihai Nicolicioiu, Yoshua Bengio"},{"id":"2311.16179","slug":"next-gen-traffic-surveillance-ai-assisted-mobile-traffic-violation-detection-system-arxiv-2311-16179v1-cs-cv","title":"Next-gen traffic surveillance: AI-assisted mobile traffic violation detection system.","link":"http://arxiv.org/abs/2311.16179","abstract":"Road traffic accidents pose a significant global public health concern, leading to injuries, fatalities, and vehicle damage. Approximately 1,3 million people lose their lives daily due to traffic accidents [World Health Organization, 2022]. Addressing this issue requires accurate traffic law violation detection systems to ensure adherence to regulations. The integration of Artificial Intelligence algorithms, leveraging machine learning and computer vision, has facilitated the development of precise traffic rule enforcement. This paper illustrates how computer vision and machine learning enable the creation of robust algorithms for detecting various traffic violations. Our model, capable of identifying six common traffic infractions, detects red light violations, illegal use of breakdown lanes, violations of vehicle following distance, breaches of marked crosswalk laws, illegal parking, and parking on marked crosswalks. Utilizing online traffic footage and a self-mounted on-dash camera, we apply the YOLOv5 algorithm's detection module to identify traffic agents such as cars, pedestrians, and traffic signs, and the strongSORT algorithm for continuous interframe tracking. Six discrete algorithms analyze agents' behavior and trajectory to detect violations. Subsequently, an Identification Module extracts vehicle ID information, such as the license plate, to generate violation notices sent to relevant authorities.","creator":"Dila Dede, Mehmet Ali Sars&#x131;l, Ata Shaker, Olgu Alt&#x131;nta&#x15f;, Onur Ergen"},{"id":"2311.16180","slug":"aiming-to-minimize-alcohol-impaired-road-fatalities-utilizing-fairness-aware-and-domain-knowledge-infused-artificial-intelligence-arxiv-2311-16180v1-cs-lg","title":"Aiming to Minimize Alcohol-Impaired Road Fatalities: Utilizing Fairness-Aware and Domain Knowledge-Infused Artificial Intelligence.","link":"http://arxiv.org/abs/2311.16180","abstract":"Approximately 30% of all traffic fatalities in the United States are attributed to alcohol-impaired driving. This means that, despite stringent laws against this offense in every state, the frequency of drunk driving accidents is alarming, resulting in approximately one person being killed every 45 minutes. The process of charging individuals with Driving Under the Influence (DUI) is intricate and can sometimes be subjective, involving multiple stages such as observing the vehicle in motion, interacting with the driver, and conducting Standardized Field Sobriety Tests (SFSTs). Biases have been observed through racial profiling, leading to some groups and geographical areas facing fewer DUI tests, resulting in many actual DUI incidents going undetected, ultimately leading to a higher number of fatalities. To tackle this issue, our research introduces an Artificial Intelligence-based predictor that is both fairness-aware and incorporates domain knowledge to analyze DUI-related fatalities in different geographic locations. Through this model, we gain intriguing insights into the interplay between various demographic groups, including age, race, and income. By utilizing the provided information to allocate policing resources in a more equitable and efficient manner, there is potential to reduce DUI-related fatalities and have a significant impact on road safety.","creator":"Tejas Venkateswaran, Sheikh Rabiul Islam, Md Golam Moula Mehedi Hasan, Mohiuddin Ahmed"},{"id":"2311.16185","slug":"enhancing-sentiment-analysis-results-through-outlier-detection-optimization-arxiv-2311-16185v1-cs-lg","title":"Enhancing Sentiment Analysis Results through Outlier Detection Optimization.","link":"http://arxiv.org/abs/2311.16185","abstract":"When dealing with text data containing subjective labels like speaker emotions, inaccuracies or discrepancies among labelers are not uncommon. Such discrepancies can significantly affect the performance of machine learning algorithms. This study investigates the potential of identifying and addressing outliers in text data with subjective labels, aiming to enhance classification outcomes. We utilized the Deep SVDD algorithm, a one-class classification method, to detect outliers in nine text-based emotion and sentiment analysis datasets. By employing both a small-sized language model (DistilBERT base model with 66 million parameters) and non-deep learning machine learning algorithms (decision tree, KNN, Logistic Regression, and LDA) as the classifier, our findings suggest that the removal of outliers can lead to enhanced results in most cases. Additionally, as outliers in such datasets are not necessarily unlearnable, we experienced utilizing a large language model -- DeBERTa v3 large with 131 million parameters, which can capture very complex patterns in data. We continued to observe performance enhancements across multiple datasets.","creator":"Yuetian Chen, Mei Si"},{"id":"2311.16191","slug":"mace-a-multi-pattern-accommodated-and-efficient-anomaly-detection-method-in-the-frequency-domain-arxiv-2311-16191v1-cs-lg","title":"MACE: A Multi-pattern Accommodated and Efficient Anomaly Detection Method in the Frequency Domain.","link":"http://arxiv.org/abs/2311.16191","abstract":"Anomaly detection significantly enhances the robustness of cloud systems. While neural network-based methods have recently demonstrated strong advantages, they encounter practical challenges in cloud environments: the contradiction between the impracticality of maintaining a unique model for each service and the limited ability of dealing with diverse normal patterns by a unified model, as well as issues with handling heavy traffic in real time and short-term anomaly detection sensitivity. Thus, we propose MACE, a Multi-pattern Accommodated and efficient Anomaly detection method in the frequency domain for time series anomaly detection. There are three novel characteristics of it: (i) a pattern extraction mechanism excelling at handling diverse normal patterns, which enables the model to identify anomalies by examining the correlation between the data sample and its service normal pattern, instead of solely focusing on the data sample itself; (ii) a dualistic convolution mechanism that amplifies short-term anomalies in the time domain and hinders the reconstruction of anomalies in the frequency domain, which enlarges the reconstruction error disparity between anomaly and normality and facilitates anomaly detection; (iii) leveraging the sparsity and parallelism of frequency domain to enhance model efficiency. We theoretically and experimentally prove that using a strategically selected subset of Fourier bases can not only reduce computational overhead but is also profit to distinguish anomalies, compared to using the complete spectrum. Moreover, extensive experiments demonstrate MACE's effectiveness in handling diverse normal patterns with a unified model and it achieves state-of-the-art performance with high efficiency. \\end{abstract}","creator":"Feiyi Chen, Yingying zhang, Zhen Qin, Lunting Fan, Renhe Jiang, Yuxuan Liang, Qingsong Wen, Shuiguang Deng"},{"id":"2311.16192","slug":"utilizing-multiple-inputs-autoregressive-models-for-bearing-remaining-useful-life-prediction-arxiv-2311-16192v1-cs-lg","title":"Utilizing Multiple Inputs Autoregressive Models for Bearing Remaining Useful Life Prediction.","link":"http://arxiv.org/abs/2311.16192","abstract":"Accurate prediction of the Remaining Useful Life (RUL) of rolling bearings is crucial in industrial production, yet existing models often struggle with limited generalization capabilities due to their inability to fully process all vibration signal patterns. We introduce a novel multi-input autoregressive model to address this challenge in RUL prediction for bearings. Our approach uniquely integrates vibration signals with previously predicted Health Indicator (HI) values, employing feature fusion to output current window HI values. Through autoregressive iterations, the model attains a global receptive field, effectively overcoming the limitations in generalization. Furthermore, we innovatively incorporate a segmentation method and multiple training iterations to mitigate error accumulation in autoregressive models. Empirical evaluation on the PMH2012 dataset demonstrates that our model, compared to other backbone networks using similar autoregressive approaches, achieves significantly lower Root Mean Square Error (RMSE) and Score. Notably, it outperforms traditional autoregressive models that use label values as inputs and non-autoregressive networks, showing superior generalization abilities with a marked lead in RMSE and Score metrics.","creator":"Junliang Wang, Qinghua Zhang, Guanhua Zhu, Guoxi Sun"},{"id":"2311.16193","slug":"students-interest-in-knowledge-acquisition-in-artificial-intelligence-arxiv-2311-16193v1-cs-cy","title":"Students' interest in knowledge acquisition in Artificial Intelligence.","link":"http://arxiv.org/abs/2311.16193","abstract":"Some students' expectations and points of view related to the Artificial Intelligence course are explored and analyzed in this study. We anonymous collected answers from 58 undergraduate students out of 200 enrolled in the Computer Science specialization. The answers were analysed and interpreted using thematic analysis to find out their interests and attractive and unattractive aspects related to the Artificial Intelligence study topic. We concluded that students are interested in Artificial Intelligence due to its trendiness, applicability, their passion and interest in the subject, the potential for future growth, and high salaries. However, the students' expectations were mainly related to achieving medium knowledge in the Artificial Intelligence field, and men seem to be more interested in acquiring high-level skills than women. The most common part that wasn't enjoyed by the students was the mathematical aspect used in Artificial Intelligence. Some of them (a small group) were also aware of the Artificial Intelligence potential which could be used in an unethical manner for negative purposes. Our study also provides a short comparison to the Databases course, in which students were not that passionate or interested in achieving medium knowledge, their interest was related to DB usage and basic information.","creator":"Manuela-Andreea Petrescu, Emilia-Loredana Pop, Tudor-Dan Mihoc"},{"id":"2311.16195","slug":"a-foundational-framework-and-methodology-for-personalized-early-and-timely-diagnosis-arxiv-2311-16195v1-cs-lg","title":"A Foundational Framework and Methodology for Personalized Early and Timely Diagnosis.","link":"http://arxiv.org/abs/2311.16195","abstract":"Early diagnosis of diseases holds the potential for deep transformation in healthcare by enabling better treatment options, improving long-term survival and quality of life, and reducing overall cost. With the advent of medical big data, advances in diagnostic tests as well as in machine learning and statistics, early or timely diagnosis seems within reach. Early diagnosis research often neglects the potential for optimizing individual diagnostic paths. To enable personalized early diagnosis, a foundational framework is needed that delineates the diagnosis process and systematically identifies the time-dependent value of various diagnostic tests for an individual patient given their unique characteristics. Here, we propose the first foundational framework for early and timely diagnosis. It builds on decision-theoretic approaches to outline the diagnosis process and integrates machine learning and statistical methodology for estimating the optimal personalized diagnostic path. To describe the proposed framework as well as possibly other frameworks, we provide essential definitions.  The development of a foundational framework is necessary for several reasons: 1) formalism provides clarity for the development of decision support tools; 2) observed information can be complemented with estimates of the future patient trajectory; 3) the net benefit of counterfactual diagnostic paths and associated uncertainties can be modeled for individuals 4) 'early' and 'timely' diagnosis can be clearly defined; 5) a mechanism emerges for assessing the value of technologies in terms of their impact on personalized early diagnosis, resulting health outcomes and incurred costs.  Finally, we hope that this foundational framework will unlock the long-awaited potential of timely diagnosis and intervention, leading to improved outcomes for patients and higher cost-effectiveness for healthcare systems.","creator":"Tim Schubert, Richard W Peck, Alexander Gimson, Camelia Davtyan, Mihaela van der Schaar"},{"id":"2311.16196","slug":"variational-exploration-module-vem-a-cloud-native-optimization-and-validation-tool-for-geospatial-modeling-and-ai-workflows-arxiv-2311-16196v1-cs-se","title":"Variational Exploration Module VEM: A Cloud-Native Optimization and Validation Tool for Geospatial Modeling and AI Workflows.","link":"http://arxiv.org/abs/2311.16196","abstract":"Geospatial observations combined with computational models have become key to understanding the physical systems of our environment and enable the design of best practices to reduce societal harm. Cloud-based deployments help to scale up these modeling and AI workflows. Yet, for practitioners to make robust conclusions, model tuning and testing is crucial, a resource intensive process which involves the variation of model input variables. We have developed the Variational Exploration Module which facilitates the optimization and validation of modeling workflows deployed in the cloud by orchestrating workflow executions and using Bayesian and machine learning-based methods to analyze model behavior. User configurations allow the combination of diverse sampling strategies in multi-agent environments. The flexibility and robustness of the model-agnostic module is demonstrated using real-world applications.","creator":"Julian Kuehnert (1), Hiwot Tadesse (1), Chris Dearden (2), Rosie Lickorish (3), Paolo Fraccaro (3), Anne Jones (3), Blair Edwards (3), Sekou L. Remy (1), Peter Melling (4), Tim Culmer (4) ((1) IBM Research, Nairobi, Kenya, (2) STFC Hartree Centre, Warrington, UK, (3) IBM Research, Daresbury, UK, (4) Riskaware Ltd., Bristol, UK)"},{"id":"2311.16197","slug":"generation-of-patient-specific-cardiac-chamber-models-using-generative-neural-networks-under-a-bayesian-framework-for-electroanatomical-mapping-arxiv-2311-16197v1-eess-iv","title":"Generation of patient specific cardiac chamber models using generative neural networks under a Bayesian framework for electroanatomical mapping.","link":"http://arxiv.org/abs/2311.16197","abstract":"Electroanatomical mapping is a technique used in cardiology to create a detailed 3D map of the electrical activity in the heart. It is useful for diagnosis, treatment planning and real time guidance in cardiac ablation procedures to treat arrhythmias like atrial fibrillation. A probabilistic machine learning model trained on a library of CT/MRI scans of the heart can be used during electroanatomical mapping to generate a patient-specific 3D model of the chamber being mapped. The use of probabilistic machine learning models under a Bayesian framework provides a way to quantify uncertainty in results and provide a natural framework of interpretability of the model. Here we introduce a Bayesian approach to surface reconstruction of cardiac chamber models from a sparse 3D point cloud data acquired during electroanatomical mapping. We show how probabilistic graphical models trained on segmented CT/MRI data can be used to generate cardiac chamber models from few acquired locations thereby reducing procedure time and x-ray exposure. We show how they provide insight into what the neural network learns from the segmented CT/MRI images used to train the network, which provides explainability to the resulting cardiac chamber models generated by the model.","creator":"Sunil Mathew, Jasbir Sra, Daniel B. Rowe"},{"id":"2311.16201","slug":"pre-trained-language-models-do-not-help-auto-regressive-text-to-image-generation-arxiv-2311-16201v1-cs-cv","title":"Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation.","link":"http://arxiv.org/abs/2311.16201","abstract":"Recent advances in image tokenizers, such as VQ-VAE, have enabled text-to-image generation using auto-regressive methods, similar to language modeling. However, these methods have yet to leverage pre-trained language models, despite their adaptability to various downstream tasks. In this work, we explore this gap by adapting a pre-trained language model for auto-regressive text-to-image generation, and find that pre-trained language models offer limited help. We provide a two-fold explanation by analyzing tokens from each modality. First, we demonstrate that image tokens possess significantly different semantics compared to text tokens, rendering pre-trained language models no more effective in modeling them than randomly initialized ones. Second, the text tokens in the image-text datasets are too simple compared to normal language model pre-training data, which causes the catastrophic degradation of language models' capability.","creator":"Yuhui Zhang, Brandon McKinzie, Zhe Gan, Vaishaal Shankar, Alexander Toshev"},{"id":"2311.16203","slug":"chattraffc-text-to-traffic-generation-via-diffusion-model-arxiv-2311-16203v1-cs-lg","title":"ChatTraffc: Text-to-Traffic Generation via Diffusion Model.","link":"http://arxiv.org/abs/2311.16203","abstract":"Traffic prediction is one of the most significant foundations in Intelligent Transportation Systems (ITS). Traditional traffic prediction methods rely only on historical traffic data to predict traffic trends and face two main challenges. 1) insensitivity to unusual events. 2) poor performance in long-term prediction. In this work, we explore how generative models combined with text describing the traffic system can be applied for traffic generation and name the task Text-to-Traffic Generation (TTG). The key challenge of the TTG task is how to associate text with the spatial structure of the road network and traffic data for generating traffic situations. To this end, we propose ChatTraffic, the first diffusion model for text-to-traffic generation. To guarantee the consistency between synthetic and real data, we augment a diffusion model with the Graph Convolutional Network (GCN) to extract spatial correlations of traffic data. In addition, we construct a large dataset containing text-traffic pairs for the TTG task. We benchmarked our model qualitatively and quantitatively on the released dataset. The experimental results indicate that ChatTraffic can generate realistic traffic situations from the text. Our code and dataset are available at https://github.com/ChyaZhang/ChatTraffic.","creator":"Chengyang Zhang, Yong Zhang, Qitan Shao, Bo Li, Yisheng Lv, Xinglin Piao, Baocai Yin"},{"id":"2311.16204","slug":"planning-for-the-efficient-updating-of-mutual-fund-portfolios-arxiv-2311-16204v1-q-fin-pm","title":"Planning for the Efficient Updating of Mutual Fund Portfolios.","link":"http://arxiv.org/abs/2311.16204","abstract":"Once there is a decision of rebalancing or updating a portfolio of funds, the process of changing the current portfolio to the target one, involves a set of transactions that are susceptible of being optimized. This is particularly relevant when managers have to handle the implications of different types of instruments. In this work we present linear programming and heuristic search approaches that produce plans for executing the update. The evaluation of our proposals shows cost improvements over the compared based strategy. The models can be easily extended to other realistic scenarios in which a holistic portfolio management is required","creator":"Tom&#xe1;s de la Rosa"},{"id":"2311.16206","slug":"continual-instruction-tuning-for-large-multimodal-models-arxiv-2311-16206v1-cs-lg","title":"Continual Instruction Tuning for Large Multimodal Models.","link":"http://arxiv.org/abs/2311.16206","abstract":"Instruction tuning is now a widely adopted approach to aligning large multimodal models (LMMs) to follow human intent. It unifies the data format of vision-language tasks, enabling multi-task joint training. However, vision-language tasks are constantly being created in practice. Instead of always re-training LMMs when new tasks arrive, continual learning offers flexibility for models to continually and efficiently exploit the evolving data. This work aims to explore the following two questions: 1) Do LMMs still suffer from catastrophic forgetting in continual instruction tuning? 2) Are the existing three classes of continual learning methods still applicable to the continual instruction tuning of LMMs? An extensive study is conducted to address the above questions. First, we establish the first benchmark in this setting and reveal that catastrophic forgetting is still observed when continually instruction-tuning LMMs. However, the multi-task joint instruction tuning can facilitate the model's continual learning ability and mitigate forgetting. Second, we integrate and adapt classic continual learning methods to our context, demonstrating the efficacy of data replay and model expansion strategies across diverse scenarios. In contrast, regularization-based methods only perform well on models that have been jointly instruction-tuned on multiple tasks. Third, we delve into the correlation and forgetting dynamics between vision-language task pairs and propose task-similarity-informed regularization and model expansion methods for continual instruction tuning of LMMs. Experimental results show that our approach consistently boosts the model's performance.","creator":"Jinghan He, Haiyun Guo, Ming Tang, Jinqiao Wang"},{"id":"2311.16208","slug":"instructmol-multi-modal-integration-for-building-a-versatile-and-reliable-molecular-assistant-in-drug-discovery-arxiv-2311-16208v1-q-bio-bm","title":"InstructMol: Multi-Modal Integration for Building a Versatile and Reliable Molecular Assistant in Drug Discovery.","link":"http://arxiv.org/abs/2311.16208","abstract":"The rapid evolution of artificial intelligence in drug discovery encounters challenges with generalization and extensive training, yet Large Language Models (LLMs) offer promise in reshaping interactions with complex molecular data. Our novel contribution, InstructMol, a multi-modal LLM, effectively aligns molecular structures with natural language via an instruction-tuning approach, utilizing a two-stage training strategy that adeptly combines limited domain-specific data with molecular and textual information. InstructMol showcases substantial performance improvements in drug discovery-related molecular tasks, surpassing leading LLMs and significantly reducing the gap with specialized models, thereby establishing a robust foundation for a versatile and dependable drug discovery assistant.","creator":"He Cao, Zijing Liu, Xingyu Lu, Yuan Yao, Yu Li"},{"id":"2311.16254","slug":"removing-nsfw-concepts-from-vision-and-language-models-for-text-to-image-retrieval-and-generation-arxiv-2311-16254v1-cs-cv","title":"Removing NSFW Concepts from Vision-and-Language Models for Text-to-Image Retrieval and Generation.","link":"http://arxiv.org/abs/2311.16254","abstract":"Vision-and-Language models such as CLIP have demonstrated remarkable effectiveness across a wide range of tasks. However, these models are typically trained on web-scale data, which can introduce inappropriate content and lead to the development of unsafe and biased behavior. This, in turn, hampers their applicability in sensitive and trustworthy contexts and could raise significant concern in their adoption. To overcome these limitations, we introduce a methodology to make Vision-and-Language models safer by removing their sensitivity to not-safe-for-work concepts. We show how this can be done by distilling from a large language model which converts between safe and unsafe sentences and which is fine-tuned starting from just 100 manually-curated pairs. We conduct extensive experiments on the resulting embedding space for both retrieval and text-to-image generation, where we show that our model can also be properly employed with pre-trained image generators. Our source code and trained models are available at: https://github.com/aimagelab/safe-clip.","creator":"Samuele Poppi, Tobia Poppi, Federico Cocchi, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara"},{"id":"2311.16261","slug":"relvae-generative-pretraining-for-few-shot-visual-relationship-detection-arxiv-2311-16261v1-cs-cv","title":"RelVAE: Generative Pretraining for few-shot Visual Relationship Detection.","link":"http://arxiv.org/abs/2311.16261","abstract":"Visual relations are complex, multimodal concepts that play an important role in the way humans perceive the world. As a result of their complexity, high-quality, diverse and large scale datasets for visual relations are still absent. In an attempt to overcome this data barrier, we choose to focus on the problem of few-shot Visual Relationship Detection (VRD), a setting that has been so far neglected by the community. In this work we present the first pretraining method for few-shot predicate classification that does not require any annotated relations. We achieve this by introducing a generative model that is able to capture the variation of semantic, visual and spatial information of relations inside a latent space and later exploiting its representations in order to achieve efficient few-shot classification. We construct few-shot training splits and show quantitative experiments on VG200 and VRD datasets where our model outperforms the baselines. Lastly we attempt to interpret the decisions of the model by conducting various qualitative experiments.","creator":"Sotiris Karapiperis, Markos Diomataris, Vassilis Pitsikalis"},{"id":"2311.16277","slug":"a-graph-neural-network-based-qubo-formulated-hamiltonian-inspired-loss-function-for-combinatorial-optimization-using-reinforcement-learning-arxiv-2311-16277v1-cs-lg","title":"A Graph Neural Network-Based QUBO-Formulated Hamiltonian-Inspired Loss Function for Combinatorial Optimization using Reinforcement Learning.","link":"http://arxiv.org/abs/2311.16277","abstract":"Quadratic Unconstrained Binary Optimization (QUBO) is a generic technique to model various NP-hard Combinatorial Optimization problems (CO) in the form of binary variables. Ising Hamiltonian is used to model the energy function of a system. QUBO to Ising Hamiltonian is regarded as a technique to solve various canonical optimization problems through quantum optimization algorithms. Recently, PI-GNN, a generic framework, has been proposed to address CO problems over graphs based on Graph Neural Network (GNN) architecture. They introduced a generic QUBO-formulated Hamiltonian-inspired loss function that was directly optimized using GNN. PI-GNN is highly scalable but there lies a noticeable decrease in the number of satisfied constraints when compared to problem-specific algorithms and becomes more pronounced with increased graph densities. Here, We identify a behavioral pattern related to it and devise strategies to improve its performance. Another group of literature uses Reinforcement learning (RL) to solve the aforementioned NP-hard problems using problem-specific reward functions. In this work, we also focus on creating a bridge between the RL-based solutions and the QUBO-formulated Hamiltonian. We formulate and empirically evaluate the compatibility of the QUBO-formulated Hamiltonian as the generic reward function in the RL-based paradigm in the form of rewards. Furthermore, we also introduce a novel Monty Carlo Tree Search-based strategy with GNN where we apply a guided search through manual perturbation of node labels during training. We empirically evaluated our methods and observed up to 44% improvement in the number of constraint violations compared to the PI-GNN.","creator":"Redwan Ahmed Rizvee, Raheeb Hasan, Md. Mosaddek Khan"},{"id":"2311.16312","slug":"domain-specific-deep-learning-feature-extractor-for-diabetic-foot-ulcer-detection-arxiv-2311-16312v1-cs-cv","title":"Domain-Specific Deep Learning Feature Extractor for Diabetic Foot Ulcer Detection.","link":"http://arxiv.org/abs/2311.16312","abstract":"Diabetic Foot Ulcer (DFU) is a condition requiring constant monitoring and evaluations for treatment. DFU patient population is on the rise and will soon outpace the available health resources. Autonomous monitoring and evaluation of DFU wounds is a much-needed area in health care. In this paper, we evaluate and identify the most accurate feature extractor that is the core basis for developing a deep-learning wound detection network. For the evaluation, we used mAP and F1-score on the publicly available DFU2020 dataset. A combination of UNet and EfficientNetb3 feature extractor resulted in the best evaluation among the 14 networks compared. UNet and Efficientnetb3 can be used as the classifier in the development of a comprehensive DFU domain-specific autonomous wound detection pipeline.","creator":"Reza Basiri, Milos R. Popovic, Shehroz S. Khan"},{"id":"2311.16338","slug":"releasing-the-craqan-coreference-resolution-in-question-answering-an-open-source-dataset-and-dataset-creation-methodology-using-instruction-following-models-arxiv-2311-16338v1-cs-cl","title":"Releasing the CRaQAn (Coreference Resolution in Question-Answering): An open-source dataset and dataset creation methodology using instruction-following models.","link":"http://arxiv.org/abs/2311.16338","abstract":"Instruction-following language models demand robust methodologies for information retrieval to augment instructions for question-answering applications. A primary challenge is the resolution of coreferences in the context of chunking strategies for long documents. The critical barrier to experimentation of handling coreferences is a lack of open source datasets, specifically in question-answering tasks that require coreference resolution. In this work we present our Coreference Resolution in Question-Answering (CRaQAn) dataset, an open-source dataset that caters to the nuanced information retrieval requirements of coreference resolution in question-answering tasks by providing over 250 question-answer pairs containing coreferences. To develop this dataset, we developed a novel approach for creating high-quality datasets using an instruction-following model (GPT-4) and a Recursive Criticism and Improvement Loop.","creator":"Rob Grzywinski, Joshua D&#x27;Arcy, Rob Naidoff, Ashish Shukla, Alex Browne, Ren Gibbons, Brinnae Bent"},{"id":"2311.16339","slug":"reward-shaping-for-improved-learning-in-real-time-strategy-game-play-arxiv-2311-16339v1-cs-lg","title":"Reward Shaping for Improved Learning in Real-time Strategy Game Play.","link":"http://arxiv.org/abs/2311.16339","abstract":"We investigate the effect of reward shaping in improving the performance of reinforcement learning in the context of the real-time strategy, capture-the-flag game. The game is characterized by sparse rewards that are associated with infrequently occurring events such as grabbing or capturing the flag, or tagging the opposing player. We show that appropriately designed reward shaping functions applied to different game events can significantly improve the player's performance and training times of the player's learning algorithm. We have validated our reward shaping functions within a simulated environment for playing a marine capture-the-flag game between two players. Our experimental results demonstrate that reward shaping can be used as an effective means to understand the importance of different sub-tasks during game-play towards winning the game, to encode a secondary objective functions such as energy efficiency into a player's game-playing behavior, and, to improve learning generalizable policies that can perform well against different skill levels of the opponent.","creator":"John Kliem, Prithviraj Dasgupta"},{"id":"2311.16353","slug":"improving-denoising-diffusion-probabilistic-models-via-exploiting-shared-representations-arxiv-2311-16353v1-cs-lg","title":"Improving Denoising Diffusion Probabilistic Models via Exploiting Shared Representations.","link":"http://arxiv.org/abs/2311.16353","abstract":"In this work, we address the challenge of multi-task image generation with limited data for denoising diffusion probabilistic models (DDPM), a class of generative models that produce high-quality images by reversing a noisy diffusion process. We propose a novel method, SR-DDPM, that leverages representation-based techniques from few-shot learning to effectively learn from fewer samples across different tasks. Our method consists of a core meta architecture with shared parameters, i.e., task-specific layers with exclusive parameters. By exploiting the similarity between diverse data distributions, our method can scale to multiple tasks without compromising the image quality. We evaluate our method on standard image datasets and show that it outperforms both unconditional and conditional DDPM in terms of FID and SSIM metrics.","creator":"Delaram Pirhayatifard, Mohammad Taha Toghani, Guha Balakrishnan, C&#xe9;sar A. Uribe"},{"id":"2311.16392","slug":"multi-defender-security-games-with-schedules-arxiv-2311-16392v1-cs-gt","title":"Multi-defender Security Games with Schedules.","link":"http://arxiv.org/abs/2311.16392","abstract":"Stackelberg Security Games are often used to model strategic interactions in high-stakes security settings. The majority of existing models focus on single-defender settings where a single entity assumes command of all security assets. However, many realistic scenarios feature multiple heterogeneous defenders with their own interests and priorities embedded in a more complex system. Furthermore, defenders rarely choose targets to protect. Instead, they have a multitude of defensive resources or schedules at its disposal, each with different protective capabilities. In this paper, we study security games featuring multiple defenders and schedules simultaneously. We show that unlike prior work on multi-defender security games, the introduction of schedules can cause non-existence of equilibrium even under rather restricted environments. We prove that under the mild restriction that any subset of a schedule is also a schedule, non-existence of equilibrium is not only avoided, but can be computed in polynomial time in games with two defenders. Under additional assumptions, our algorithm can be extended to games with more than two defenders and its computation scaled up in special classes of games with compactly represented schedules such as those used in patrolling applications. Experimental results suggest that our methods scale gracefully with game size, making our algorithms amongst the few that can tackle multiple heterogeneous defenders.","creator":"Zimeng Song, Chun Kai Ling, Fei Fang"},{"id":"2311.16424","slug":"manifold-preserving-guided-diffusion-arxiv-2311-16424v1-cs-lg","title":"Manifold Preserving Guided Diffusion.","link":"http://arxiv.org/abs/2311.16424","abstract":"Despite the recent advancements, conditional image generation still faces challenges of cost, generalizability, and the need for task-specific training. In this paper, we propose Manifold Preserving Guided Diffusion (MPGD), a training-free conditional generation framework that leverages pretrained diffusion models and off-the-shelf neural networks with minimal additional inference cost for a broad range of tasks. Specifically, we leverage the manifold hypothesis to refine the guided diffusion steps and introduce a shortcut algorithm in the process. We then propose two methods for on-manifold training-free guidance using pre-trained autoencoders and demonstrate that our shortcut inherently preserves the manifolds when applied to latent diffusion models. Our experiments show that MPGD is efficient and effective for solving a variety of conditional generation applications in low-compute settings, and can consistently offer up to 3.8x speed-ups with the same number of diffusion steps while maintaining high sample quality compared to the baselines.","creator":"Yutong He, Naoki Murata, Chieh-Hsin Lai, Yuhta Takida, Toshimitsu Uesaka, Dongjun Kim, Wei-Hsiang Liao, Yuki Mitsufuji, J. Zico Kolter, Ruslan Salakhutdinov, Stefano Ermon"},{"id":"2311.16432","slug":"text-driven-image-editing-via-learnable-regions-arxiv-2311-16432v1-cs-cv","title":"Text-Driven Image Editing via Learnable Regions.","link":"http://arxiv.org/abs/2311.16432","abstract":"Language has emerged as a natural interface for image editing. In this paper, we introduce a method for region-based image editing driven by textual prompts, without the need for user-provided masks or sketches. Specifically, our approach leverages an existing pretrained text-to-image model and introduces a bounding box generator to find the edit regions that are aligned with the textual prompts. We show that this simple approach enables flexible editing that is compatible with current image generation models, and is able to handle complex prompts featuring multiple objects, complex sentences or long paragraphs. We conduct an extensive user study to compare our method against state-of-the-art methods. Experiments demonstrate the competitive performance of our method in manipulating images with high fidelity and realism that align with the language descriptions provided. Our project webpage: https://yuanze-lin.me/LearnableRegions_page.","creator":"Yuanze Lin, Yi-Wen Chen, Yi-Hsuan Tsai, Lu Jiang, Ming-Hsuan Yang"},{"id":"2311.16450","slug":"typhoon-intensity-prediction-with-vision-transformer-arxiv-2311-16450v1-cs-cv","title":"Typhoon Intensity Prediction with Vision Transformer.","link":"http://arxiv.org/abs/2311.16450","abstract":"Predicting typhoon intensity accurately across space and time is crucial for issuing timely disaster warnings and facilitating emergency response. This has vast potential for minimizing life losses and property damages as well as reducing economic and environmental impacts. Leveraging satellite imagery for scenario analysis is effective but also introduces additional challenges due to the complex relations among clouds and the highly dynamic context. Existing deep learning methods in this domain rely on convolutional neural networks (CNNs), which suffer from limited per-layer receptive fields. This limitation hinders their ability to capture long-range dependencies and global contextual knowledge during inference. In response, we introduce a novel approach, namely \"Typhoon Intensity Transformer\" (Tint), which leverages self-attention mechanisms with global receptive fields per layer. Tint adopts a sequence-to-sequence feature representation learning perspective. It begins by cutting a given satellite image into a sequence of patches and recursively employs self-attention operations to extract both local and global contextual relations between all patch pairs simultaneously, thereby enhancing per-patch feature representation learning. Extensive experiments on a publicly available typhoon benchmark validate the efficacy of Tint in comparison with both state-of-the-art deep learning and conventional meteorological methods. Our code is available at https://github.com/chen-huanxin/Tint.","creator":"Huanxin Chen, Pengshuai Yin, Huichou Huang, Qingyao Wu, Ruirui Liu, Xiatian Zhu"},{"id":"2311.16464","slug":"bridging-the-gap-a-unified-video-comprehension-framework-for-moment-retrieval-and-highlight-detection-arxiv-2311-16464v1-cs-cv","title":"Bridging the Gap: A Unified Video Comprehension Framework for Moment Retrieval and Highlight Detection.","link":"http://arxiv.org/abs/2311.16464","abstract":"Video Moment Retrieval (MR) and Highlight Detection (HD) have attracted significant attention due to the growing demand for video analysis. Recent approaches treat MR and HD as similar video grounding problems and address them together with transformer-based architecture. However, we observe that the emphasis of MR and HD differs, with one necessitating the perception of local relationships and the other prioritizing the understanding of global contexts. Consequently, the lack of task-specific design will inevitably lead to limitations in associating the intrinsic specialty of two tasks. To tackle the issue, we propose a Unified Video COMprehension framework (UVCOM) to bridge the gap and jointly solve MR and HD effectively. By performing progressive integration on intra and inter-modality across multi-granularity, UVCOM achieves the comprehensive understanding in processing a video. Moreover, we present multi-aspect contrastive learning to consolidate the local relation modeling and global knowledge accumulation via well aligned multi-modal space. Extensive experiments on QVHighlights, Charades-STA, TACoS , YouTube Highlights and TVSum datasets demonstrate the effectiveness and rationality of UVCOM which outperforms the state-of-the-art methods by a remarkable margin.","creator":"Yicheng Xiao, Zhuoyan Luo, Yong Liu, Yue Ma, Hengwei Bian, Yatai Ji, Yujiu Yang, Xiu Li"},{"id":"2311.16466","slug":"enhancing-human-persuasion-with-large-language-models-arxiv-2311-16466v1-cs-hc","title":"Enhancing Human Persuasion With Large Language Models.","link":"http://arxiv.org/abs/2311.16466","abstract":"Although large language models (LLMs) are reshaping various aspects of human life, our current understanding of their impacts remains somewhat constrained. Here we investigate the impact of LLMs on human communication, in the context of consumer complaints in the financial industry. Employing an AI detection tool on more than 780K complaints gathered by the Consumer Financial Protection Bureau (CFPB), we find evidence of LLM usage in the writing of complaints - shortly after the release of ChatGPT. Our analyses reveal that LLM usage is positively correlated with the likelihood of obtaining desirable outcomes (i.e., offer of relief from financial firms) and suggest that this positive correlation may be partly due to the linguistic features improved by LLMs. We test this conjecture with a preregistered experiment, which reveals results consistent with those from observational studies: Consumer complaints written with ChatGPT for improved linguistic qualities were more likely to receive hypothetical relief offers than the original consumer complaints, demonstrating the LLM's ability to enhance message persuasiveness in human communication. Being some of the earliest empirical evidence on LLM usage for enhancing persuasion, our results highlight the transformative potential of LLMs in human communication.","creator":"Minkyu Shin, Jin Kim"},{"id":"2311.16476","slug":"lans-a-layout-aware-neural-solver-for-plane-geometry-problem-arxiv-2311-16476v1-cs-cv","title":"LANS: A Layout-Aware Neural Solver for Plane Geometry Problem.","link":"http://arxiv.org/abs/2311.16476","abstract":"Geometry problem solving (GPS) is a challenging mathematical reasoning task requiring multi-modal understanding, fusion and reasoning. Existing neural solvers take GPS as a vision-language task but be short in the representation of geometry diagrams which carry rich and complex layout information. In this paper, we propose a layout-aware neural solver named LANS, integrated with two new modules: multimodal layout-aware pre-trained language model (MLA-PLM) and layout-aware fusion attention (LA-FA). MLA-PLM adopts structural and semantic pre-training (SSP) to implement global relationship modeling, and point matching pre-training (PMP) to achieve alignment between visual points and textual points. LA-FA employs a layout-aware attention mask to realize point-guided cross-modal fusion for further boosting layout awareness of LANS. Extensive experiments on datasets Geometry3K and PGPS9K validate the effectiveness of the layout-aware modules and superior problem solving performance of our LANS solver, over existing symbolic solvers and neural solvers. The code will make public available soon.","creator":"Ming-Liang Zhang, Zhong-Zhi Li, Fei Yin, Cheng-Lin Liu"},{"id":"2311.16480","slug":"mi-gen-multiple-instance-generation-of-pathology-reports-for-gigapixel-whole-slide-images-arxiv-2311-16480v1-cs-cv","title":"MI-Gen: Multiple Instance Generation of Pathology Reports for Gigapixel Whole-Slide Images.","link":"http://arxiv.org/abs/2311.16480","abstract":"Whole slide images are the foundation of digital pathology for the diagnosis and treatment of carcinomas. Writing pathology reports is laborious and error-prone for inexperienced pathologists. To reduce the workload and improve clinical automation, we investigate how to generate pathology reports given whole slide images. On the data end, we curated the largest WSI-text dataset (TCGA-PathoText). In specific, we collected nearly 10000 high-quality WSI-text pairs for visual-language models by recognizing and cleaning pathology reports which narrate diagnostic slides in TCGA. On the model end, we propose the multiple instance generative model (MI-Gen) which can produce pathology reports for gigapixel WSIs. We benchmark our model on the largest subset of TCGA-PathoText. Experimental results show our model can generate pathology reports which contain multiple clinical clues. Furthermore, WSI-text prediction can be seen as an approach of visual-language pre-training, which enables our model to be transferred to downstream diagnostic tasks like carcinoma grading and phenotyping. We observe that simple semantic extraction from the pathology reports can achieve the best performance (0.838 of F1 score) on BRCA subtyping without adding extra parameters or tricky fine-tuning. Our collected dataset and related code will all be publicly available.","creator":"Pingyi Chen, Honglin Li, Chenglu Zhu, Sunyi Zheng, Lin Yang"},{"id":"2311.16488","slug":"efficient-multimodal-diffusion-models-using-joint-data-infilling-with-partially-shared-u-net-arxiv-2311-16488v1-cs-cv","title":"Efficient Multimodal Diffusion Models Using Joint Data Infilling with Partially Shared U-Net.","link":"http://arxiv.org/abs/2311.16488","abstract":"Recently, diffusion models have been used successfully to fit distributions for cross-modal data translation and multimodal data generation. However, these methods rely on extensive scaling, overlooking the inefficiency and interference between modalities. We develop Partially Shared U-Net (PS-U-Net) architecture which is an efficient multimodal diffusion model that allows text and image inputs to pass through dedicated layers and skip-connections for preserving modality-specific fine-grained details. Inspired by image inpainting, we also propose a new efficient multimodal sampling method that introduces new scenarios for conditional generation while only requiring a simple joint distribution to be learned. Our empirical exploration of the MS-COCO dataset demonstrates that our method generates multimodal text and image data with higher quality compared to existing multimodal diffusion models while having a comparable size, faster training, faster multimodal sampling, and more flexible generation.","creator":"Zizhao Hu, Shaochong Jia, Mohammad Rostami"},{"id":"2311.16502","slug":"mmmu-a-massive-multi-discipline-multimodal-understanding-and-reasoning-benchmark-for-expert-agi-arxiv-2311-16502v1-cs-cl","title":"MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI.","link":"http://arxiv.org/abs/2311.16502","abstract":"We introduce MMMU: a new benchmark designed to evaluate multimodal models on massive multi-discipline tasks demanding college-level subject knowledge and deliberate reasoning. MMMU includes 11.5K meticulously collected multimodal questions from college exams, quizzes, and textbooks, covering six core disciplines: Art &amp; Design, Business, Science, Health &amp; Medicine, Humanities &amp; Social Science, and Tech &amp; Engineering. These questions span 30 subjects and 183 subfields, comprising 30 highly heterogeneous image types, such as charts, diagrams, maps, tables, music sheets, and chemical structures. Unlike existing benchmarks, MMMU focuses on advanced perception and reasoning with domain-specific knowledge, challenging models to perform tasks akin to those faced by experts. Our evaluation of 14 open-source LMMs and the proprietary GPT-4V(ision) highlights the substantial challenges posed by MMMU. Even the advanced GPT-4V only achieves a 56% accuracy, indicating significant room for improvement. We believe MMMU will stimulate the community to build next-generation multimodal foundation models towards expert artificial general intelligence.","creator":"Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, Wenhu Chen"},{"id":"2311.16503","slug":"tfmq-dm-temporal-feature-maintenance-quantization-for-diffusion-models-arxiv-2311-16503v1-cs-cv","title":"TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models.","link":"http://arxiv.org/abs/2311.16503","abstract":"The Diffusion model, a prevalent framework for image generation, encounters significant challenges in terms of broad applicability due to its extended inference times and substantial memory requirements. Efficient Post-training Quantization (PTQ) is pivotal for addressing these issues in traditional models. Different from traditional models, diffusion models heavily depend on the time-step $t$ to achieve satisfactory multi-round denoising. Usually, $t$ from the finite set $\\{1, \\ldots, T\\}$ is encoded to a temporal feature by a few modules totally irrespective of the sampling data. However, existing PTQ methods do not optimize these modules separately. They adopt inappropriate reconstruction targets and complex calibration methods, resulting in a severe disturbance of the temporal feature and denoising trajectory, as well as a low compression efficiency. To solve these, we propose a Temporal Feature Maintenance Quantization (TFMQ) framework building upon a Temporal Information Block which is just related to the time-step $t$ and unrelated to the sampling data. Powered by the pioneering block design, we devise temporal information aware reconstruction (TIAR) and finite set calibration (FSC) to align the full-precision temporal features in a limited time. Equipped with the framework, we can maintain the most temporal information and ensure the end-to-end generation quality. Extensive experiments on various datasets and diffusion models prove our state-of-the-art results. Remarkably, our quantization approach, for the first time, achieves model performance nearly on par with the full-precision model under 4-bit weight quantization. Additionally, our method incurs almost no extra computational cost and accelerates quantization time by $2.0 \\times$ on LSUN-Bedrooms $256 \\times 256$ compared to previous works.","creator":"Yushi Huang, Ruihao Gong, Jing Liu, Tianlong Chen, Xianglong Liu"},{"id":"2311.16512","slug":"coser-bridging-image-and-language-for-cognitive-super-resolution-arxiv-2311-16512v1-cs-cv","title":"CoSeR: Bridging Image and Language for Cognitive Super-Resolution.","link":"http://arxiv.org/abs/2311.16512","abstract":"Existing super-resolution (SR) models primarily focus on restoring local texture details, often neglecting the global semantic information within the scene. This oversight can lead to the omission of crucial semantic details or the introduction of inaccurate textures during the recovery process. In our work, we introduce the Cognitive Super-Resolution (CoSeR) framework, empowering SR models with the capacity to comprehend low-resolution images. We achieve this by marrying image appearance and language understanding to generate a cognitive embedding, which not only activates prior information from large text-to-image diffusion models but also facilitates the generation of high-quality reference images to optimize the SR process. To further improve image fidelity, we propose a novel condition injection scheme called \"All-in-Attention\", consolidating all conditional information into a single module. Consequently, our method successfully restores semantically correct and photorealistic details, demonstrating state-of-the-art performance across multiple benchmarks.","creator":"Haoze Sun, Wenbo Li, Jianzhuang Liu, Haoyu Chen, Renjing Pei, Xueyi Zou, Youliang Yan, Yujiu Yang"},{"id":"2311.16514","slug":"video-anomaly-detection-via-spatio-temporal-pseudo-anomaly-generation-a-unified-approach-arxiv-2311-16514v1-cs-cv","title":"Video Anomaly Detection via Spatio-Temporal Pseudo-Anomaly Generation : A Unified Approach.","link":"http://arxiv.org/abs/2311.16514","abstract":"Video Anomaly Detection (VAD) is an open-set recognition task, which is usually formulated as a one-class classification (OCC) problem, where training data is comprised of videos with normal instances while test data contains both normal and anomalous instances. Recent works have investigated the creation of pseudo-anomalies (PAs) using only the normal data and making strong assumptions about real-world anomalies with regards to abnormality of objects and speed of motion to inject prior information about anomalies in an autoencoder (AE) based reconstruction model during training. This work proposes a novel method for generating generic spatio-temporal PAs by inpainting a masked out region of an image using a pre-trained Latent Diffusion Model and further perturbing the optical flow using mixup to emulate spatio-temporal distortions in the data. In addition, we present a simple unified framework to detect real-world anomalies under the OCC setting by learning three types of anomaly indicators, namely reconstruction quality, temporal irregularity and semantic inconsistency. Extensive experiments on four VAD benchmark datasets namely Ped2, Avenue, ShanghaiTech and UBnormal demonstrate that our method performs on par with other existing state-of-the-art PAs generation and reconstruction based methods under the OCC setting. Our analysis also examines the transferability and generalisation of PAs across these datasets, offering valuable insights by identifying real-world anomalies through PAs.","creator":"Ayush K. Rai, Tarun Krishna, Feiyan Hu, Alexandru Drimbarean, Kevin McGuinness, Alan F. Smeaton, Noel E. O&#x27;Connor"},{"id":"2311.16515","slug":"word-for-person-zero-shot-composed-person-retrieval-arxiv-2311-16515v1-cs-cv","title":"Word for Person: Zero-shot Composed Person Retrieval.","link":"http://arxiv.org/abs/2311.16515","abstract":"Searching for specific person has great security value and social benefits, and it often involves a combination of visual and textual information. Conventional person retrieval methods, whether image-based or text-based, usually fall short in effectively harnessing both types of information, leading to the loss of accuracy. In this paper, a whole new task called Composed Person Retrieval (CPR) is proposed to jointly utilize both image and text information for target person retrieval. However, the supervised CPR must depend on very costly manual annotation dataset, while there are currently no available resources. To mitigate this issue, we firstly introduce the Zero-shot Composed Person Retrieval (ZS-CPR), which leverages existing domain-related data to resolve the CPR problem without reliance on expensive annotations. Secondly, to learn ZS-CPR model, we propose a two-stage learning framework, Word4Per, where a lightweight Textual Inversion Network (TINet) and a text-based person retrieval model based on fine-tuned Contrastive Language-Image Pre-training (CLIP) network are learned without utilizing any CPR data. Thirdly, a finely annotated Image-Text Composed Person Retrieval dataset (ITCPR) is built as the benchmark to assess the performance of the proposed Word4Per framework. Extensive experiments under both Rank-1 and mAP demonstrate the effectiveness of Word4Per for the ZS-CPR task, surpassing the comparative methods by over 10%. The code and ITCPR dataset will be publicly available at https://github.com/Delong-liu-bupt/Word4Per.","creator":"Delong Liu, Haiwen Li, Zhicheng Zhao, Fei Su, Hongying Meng"},{"id":"2311.16534","slug":"graph-prompt-learning-a-comprehensive-survey-and-beyond-arxiv-2311-16534v1-cs-ai","title":"Graph Prompt Learning: A Comprehensive Survey and Beyond.","link":"http://arxiv.org/abs/2311.16534","abstract":"Artificial General Intelligence (AGI) has revolutionized numerous fields, yet its integration with graph data, a cornerstone in our interconnected world, remains nascent. This paper presents a pioneering survey on the emerging domain of graph prompts in AGI, addressing key challenges and opportunities in harnessing graph data for AGI applications. Despite substantial advancements in AGI across natural language processing and computer vision, the application to graph data is relatively underexplored. This survey critically evaluates the current landscape of AGI in handling graph data, highlighting the distinct challenges in cross-modality, cross-domain, and cross-task applications specific to graphs. Our work is the first to propose a unified framework for understanding graph prompt learning, offering clarity on prompt tokens, token structures, and insertion patterns in the graph domain. We delve into the intrinsic properties of graph prompts, exploring their flexibility, expressiveness, and interplay with existing graph models. A comprehensive taxonomy categorizes over 100 works in this field, aligning them with pre-training tasks across node-level, edge-level, and graph-level objectives. Additionally, we present, ProG, a Python library, and an accompanying website, to support and advance research in graph prompting. The survey culminates in a discussion of current challenges and future directions, offering a roadmap for research in graph prompting within AGI. Through this comprehensive analysis, we aim to catalyze further exploration and practical applications of AGI in graph data, underlining its potential to reshape AGI fields and beyond. ProG and the website can be accessed by \\url{https://github.com/WxxShirley/Awesome-Graph-Prompt}, and \\url{https://github.com/sheldonresearch/ProG}, respectively.","creator":"Xiangguo Sun, Jiawen Zhang, Xixi Wu, Hong Cheng, Yun Xiong, Jia Li"},{"id":"2311.16594","slug":"monitor-placement-for-fault-localization-in-deep-neural-network-accelerators-arxiv-2311-16594v1-cs-ar","title":"Monitor Placement for Fault Localization in Deep Neural Network Accelerators.","link":"http://arxiv.org/abs/2311.16594","abstract":"Systolic arrays are a prominent choice for deep neural network (DNN) accelerators because they offer parallelism and efficient data reuse. Improving the reliability of DNN accelerators is crucial as hardware faults can degrade the accuracy of DNN inferencing. Systolic arrays make use of a large number of processing elements (PEs) for parallel processing, but when one PE is faulty, the error propagates and affects the outcomes of downstream PEs. Due to the large number of PEs, the cost associated with implementing hardware-based runtime monitoring of every single PE is infeasible. We present a solution to optimize the placement of hardware monitors within systolic arrays. We first prove that $2N-1$ monitors are needed to localize a single faulty PE and we also derive the monitor placement. We show that a second placement optimization problem, which minimizes the set of candidate faulty PEs for a given number of monitors, is NP-hard. Therefore, we propose a heuristic approach to balance the reliability and hardware resource utilization in DNN accelerators when number of monitors is limited. Experimental evaluation shows that to localize a single faulty PE, an area overhead of only 0.33% is incurred for a $256\\times 256$ systolic array.","creator":"Wei-Kai Liu, Benjamin Tan, Krishnendu Chakrabarty"},{"id":"2311.16602","slug":"gsp-kalmannet-tracking-graph-signals-via-neural-aided-kalman-filtering-arxiv-2311-16602v1-eess-sp","title":"GSP-KalmanNet: Tracking Graph Signals via Neural-Aided Kalman Filtering.","link":"http://arxiv.org/abs/2311.16602","abstract":"Dynamic systems of graph signals are encountered in various applications, including social networks, power grids, and transportation. While such systems can often be described as state space (SS) models, tracking graph signals via conventional tools based on the Kalman filter (KF) and its variants is typically challenging. This is due to the nonlinearity, high dimensionality, irregularity of the domain, and complex modeling associated with real-world dynamic systems of graph signals. In this work, we study the tracking of graph signals using a hybrid model-based/data-driven approach. We develop the GSP-KalmanNet, which tracks the hidden graphical states from the graphical measurements by jointly leveraging graph signal processing (GSP) tools and deep learning (DL) techniques. The derivations of the GSP-KalmanNet are based on extending the KF to exploit the inherent graph structure via graph frequency domain filtering, which considerably simplifies the computational complexity entailed in processing high-dimensional signals and increases the robustness to small topology changes. Then, we use data to learn the Kalman gain following the recently proposed KalmanNet framework, which copes with partial and approximated modeling, without forcing a specific model over the noise statistics. Our empirical results demonstrate that the proposed GSP-KalmanNet achieves enhanced accuracy and run time performance as well as improved robustness to model misspecifications compared with both model-based and data-driven benchmarks.","creator":"Itay Buchnik, Guy Sagi, Nimrod Leinwand, Yuval Loya, Nir Shlezinger, Tirza Routtenberg"},{"id":"2311.16605","slug":"lastgl-an-industrial-framework-for-large-scale-temporal-graph-learning-arxiv-2311-16605v1-cs-lg","title":"LasTGL: An Industrial Framework for Large-Scale Temporal Graph Learning.","link":"http://arxiv.org/abs/2311.16605","abstract":"Over the past few years, graph neural networks (GNNs) have become powerful and practical tools for learning on (static) graph-structure data. However, many real-world applications, such as social networks and e-commerce, involve temporal graphs where nodes and edges are dynamically evolving. Temporal graph neural networks (TGNNs) have progressively emerged as an extension of GNNs to address time-evolving graphs and have gradually become a trending research topic in both academics and industry. Advancing research in such an emerging field requires new tools to compose TGNN models and unify their different schemes in dealing with temporal graphs. To facilitate research and application in temporal graph learning, we introduce LasTGL, an industrial framework that integrates unified and extensible implementations of common temporal graph learning algorithms for various advanced tasks. The purpose of LasTGL is to provide the essential building blocks for solving temporal graph learning tasks, focusing on the guiding principles of user-friendliness and quick prototyping on which PyTorch is based. In particular, LasTGL provides comprehensive temporal graph datasets, TGNN models and utilities along with well-documented tutorials, making it suitable for both absolute beginners and expert deep learning practitioners alike.","creator":"Jintang Li, Jiawang Dan, Ruofan Wu, Jing Zhou, Sheng Tian, Yunfei Liu, Baokun Wang, Changhua Meng, Weiqiang Wang, Yuchang Zhu, Liang Chen, Zibin Zheng"},{"id":"2311.16644","slug":"finnish-5th-and-6th-graders-misconceptions-about-artificial-intelligence-arxiv-2311-16644v1-cs-cy","title":"Finnish 5th and 6th graders' misconceptions about Artificial Intelligence.","link":"http://arxiv.org/abs/2311.16644","abstract":"Research on children's initial conceptions of AI is in an emerging state, which, from a constructivist viewpoint, challenges the development of pedagogically sound AI-literacy curricula, methods, and materials. To contribute to resolving this need in the present paper, qualitative survey data from 195 children were analyzed abductively to answer the following three research questions: What kind of misconceptions do Finnish 5th and 6th graders' have about the essence AI?; 2) How do these misconceptions relate to common misconception types?; and 3) How profound are these misconceptions? As a result, three misconception categories were identified: 1) Non-technological AI, in which AI was conceptualized as peoples' cognitive processes (factual misconception); 2) Anthropomorphic AI, in which AI was conceptualized as a human-like entity (vernacular, non-scientific, and conceptual misconception); and 3) AI as a machine with a pre-installed intelligence or knowledge (factual misconception). Majority of the children evaluated their AI-knowledge low, which implies that the misconceptions are more superficial than profound. The findings suggest that context-specific linguistic features can contribute to students' AI misconceptions. Implications for future research and AI literacy education are discussed.","creator":"Pekka Mertala, Janne Fagerlund"},{"id":"2311.16666","slug":"multimodal-learning-for-predicting-molecular-properties-a-framework-based-on-image-and-graph-structures-arxiv-2311-16666v1-cs-lg","title":"MultiModal-Learning for Predicting Molecular Properties: A Framework Based on Image and Graph Structures.","link":"http://arxiv.org/abs/2311.16666","abstract":"The quest for accurate prediction of drug molecule properties poses a fundamental challenge in the realm of Artificial Intelligence Drug Discovery (AIDD). An effective representation of drug molecules emerges as a pivotal component in this pursuit. Contemporary leading-edge research predominantly resorts to self-supervised learning (SSL) techniques to extract meaningful structural representations from large-scale, unlabeled molecular data, subsequently fine-tuning these representations for an array of downstream tasks. However, an inherent shortcoming of these studies lies in their singular reliance on one modality of molecular information, such as molecule image or SMILES representations, thus neglecting the potential complementarity of various molecular modalities. In response to this limitation, we propose MolIG, a novel MultiModaL molecular pre-training framework for predicting molecular properties based on Image and Graph structures. MolIG model innovatively leverages the coherence and correlation between molecule graph and molecule image to execute self-supervised tasks, effectively amalgamating the strengths of both molecular representation forms. This holistic approach allows for the capture of pivotal molecular structural characteristics and high-level semantic information. Upon completion of pre-training, Graph Neural Network (GNN) Encoder is used for the prediction of downstream tasks. In comparison to advanced baseline models, MolIG exhibits enhanced performance in downstream tasks pertaining to molecular property prediction within benchmark groups such as MoleculeNet Benchmark Group and ADMET Benchmark Group.","creator":"Zhuoyuan Wang, Jiacong Mi, Shan Lu, Jieyue He"},{"id":"2311.16671","slug":"splitnerf-split-sum-approximation-neural-field-for-joint-geometry-illumination-and-material-estimation-arxiv-2311-16671v1-cs-cv","title":"SplitNeRF: Split Sum Approximation Neural Field for Joint Geometry, Illumination, and Material Estimation.","link":"http://arxiv.org/abs/2311.16671","abstract":"We present a novel approach for digitizing real-world objects by estimating their geometry, material properties, and environmental lighting from a set of posed images with fixed lighting. Our method incorporates into Neural Radiance Field (NeRF) pipelines the split sum approximation used with image-based lighting for real-time physical-based rendering. We propose modeling the scene's lighting with a single scene-specific MLP representing pre-integrated image-based lighting at arbitrary resolutions. We achieve accurate modeling of pre-integrated lighting by exploiting a novel regularizer based on efficient Monte Carlo sampling. Additionally, we propose a new method of supervising self-occlusion predictions by exploiting a similar regularizer based on Monte Carlo sampling. Experimental results demonstrate the efficiency and effectiveness of our approach in estimating scene geometry, material properties, and lighting. Our method is capable of attaining state-of-the-art relighting quality after only ${\\sim}1$ hour of training in a single NVIDIA A100 GPU.","creator":"Jesus Zarzar, Bernard Ghanem"},{"id":"2311.16673","slug":"large-language-models-meet-computer-vision-a-brief-survey-arxiv-2311-16673v1-cs-cv","title":"Large Language Models Meet Computer Vision: A Brief Survey.","link":"http://arxiv.org/abs/2311.16673","abstract":"Recently, the intersection of Large Language Models (LLMs) and Computer Vision (CV) has emerged as a pivotal area of research, driving significant advancements in the field of Artificial Intelligence (AI). As transformers have become the backbone of many state-of-the-art models in both Natural Language Processing (NLP) and CV, understanding their evolution and potential enhancements is crucial. This survey paper delves into the latest progressions in the domain of transformers and their subsequent successors, emphasizing their potential to revolutionize Vision Transformers (ViTs) and LLMs. This survey also presents a comparative analysis, juxtaposing the performance metrics of several leading paid and open-source LLMs, shedding light on their strengths and areas of improvement as well as a literature review on how LLMs are being used to tackle vision related tasks. Furthermore, the survey presents a comprehensive collection of datasets employed to train LLMs, offering insights into the diverse data available to achieve high performance in various pre-training and downstream tasks of LLMs. The survey is concluded by highlighting open directions in the field, suggesting potential venues for future research and development. This survey aims to underscores the profound intersection of LLMs on CV, leading to a new era of integrated and advanced AI models.","creator":"Raby Hamadi"},{"id":"2311.16680","slug":"roso-improving-robotic-policy-inference-via-synthetic-observations-arxiv-2311-16680v1-cs-ro","title":"ROSO: Improving Robotic Policy Inference via Synthetic Observations.","link":"http://arxiv.org/abs/2311.16680","abstract":"In this paper, we propose the use of generative artificial intelligence (AI) to improve zero-shot performance of a pre-trained policy by altering observations during inference. Modern robotic systems, powered by advanced neural networks, have demonstrated remarkable capabilities on pre-trained tasks. However, generalizing and adapting to new objects and environments is challenging, and fine-tuning visuomotor policies is time-consuming. To overcome these issues we propose Robotic Policy Inference via Synthetic Observations (ROSO). ROSO uses stable diffusion to pre-process a robot's observation of novel objects during inference time to fit within its distribution of observations of the pre-trained policies. This novel paradigm allows us to transfer learned knowledge from known tasks to previously unseen scenarios, enhancing the robot's adaptability without requiring lengthy fine-tuning. Our experiments show that incorporating generative AI into robotic inference significantly improves successful outcomes, finishing up to 57% of tasks otherwise unsuccessful with the pre-trained policy.","creator":"Yusuke Miyashita, Dimitris Gahtidis, Colin La, Jeremy Rabinowicz, Juxi Leitner"},{"id":"2311.16681","slug":"understanding-the-extra-ordinary-validating-deep-model-decisions-with-prototypical-concept-based-explanations-arxiv-2311-16681v1-cs-cv","title":"Understanding the (Extra-)Ordinary: Validating Deep Model Decisions with Prototypical Concept-based Explanations.","link":"http://arxiv.org/abs/2311.16681","abstract":"Ensuring both transparency and safety is critical when deploying Deep Neural Networks (DNNs) in high-risk applications, such as medicine. The field of explainable AI (XAI) has proposed various methods to comprehend the decision-making processes of opaque DNNs. However, only few XAI methods are suitable of ensuring safety in practice as they heavily rely on repeated labor-intensive and possibly biased human assessment. In this work, we present a novel post-hoc concept-based XAI framework that conveys besides instance-wise (local) also class-wise (global) decision-making strategies via prototypes. What sets our approach apart is the combination of local and global strategies, enabling a clearer understanding of the (dis-)similarities in model decisions compared to the expected (prototypical) concept use, ultimately reducing the dependence on human long-term assessment. Quantifying the deviation from prototypical behavior not only allows to associate predictions with specific model sub-strategies but also to detect outlier behavior. As such, our approach constitutes an intuitive and explainable tool for model validation. We demonstrate the effectiveness of our approach in identifying out-of-distribution samples, spurious model behavior and data quality issues across three datasets (ImageNet, CUB-200, and CIFAR-10) utilizing VGG, ResNet, and EfficientNet architectures. Code is available on https://github.com/maxdreyer/pcx.","creator":"Maximilian Dreyer, Reduan Achtibat, Wojciech Samek, Sebastian Lapuschkin"},{"id":"2311.16683","slug":"hyper-relational-knowledge-graph-neural-network-for-next-poi-arxiv-2311-16683v1-cs-ai","title":"Hyper-Relational Knowledge Graph Neural Network for Next POI.","link":"http://arxiv.org/abs/2311.16683","abstract":"With the advancement of mobile technology, Point of Interest (POI) recommendation systems in Location-based Social Networks (LBSN) have brought numerous benefits to both users and companies. Many existing works employ Knowledge Graph (KG) to alleviate the data sparsity issue in LBSN. These approaches primarily focus on modeling the pair-wise relations in LBSN to enrich the semantics and thereby relieve the data sparsity issue. However, existing approaches seldom consider the hyper-relations in LBSN, such as the mobility relation (a 3-ary relation: user-POI-time). This makes the model hard to exploit the semantics accurately. In addition, prior works overlook the rich structural information inherent in KG, which consists of higher-order relations and can further alleviate the impact of data sparsity.To this end, we propose a Hyper-Relational Knowledge Graph Neural Network (HKGNN) model. In HKGNN, a Hyper-Relational Knowledge Graph (HKG) that models the LBSN data is constructed to maintain and exploit the rich semantics of hyper-relations. Then we proposed a Hypergraph Neural Network to utilize the structural information of HKG in a cohesive way. In addition, a self-attention network is used to leverage sequential information and make personalized recommendations. Furthermore, side information, essential in reducing data sparsity by providing background knowledge of POIs, is not fully utilized in current methods. In light of this, we extended the current dataset with available side information to further lessen the impact of data sparsity. Results of experiments on four real-world LBSN datasets demonstrate the effectiveness of our approach compared to existing state-of-the-art methods.","creator":"Jixiao Zhang, Yongkang Li, Ruotong Zou, Jingyuan Zhang, Zipei Fan, Xuan Song"},{"id":"2311.16700","slug":"rethinking-intermediate-layers-design-in-knowledge-distillation-for-kidney-and-liver-tumor-segmentation-arxiv-2311-16700v1-cs-cv","title":"Rethinking Intermediate Layers design in Knowledge Distillation for Kidney and Liver Tumor Segmentation.","link":"http://arxiv.org/abs/2311.16700","abstract":"Knowledge distillation(KD) has demonstrated remarkable success across various domains, but its application to medical imaging tasks, such as kidney and liver tumor segmentation, has encountered challenges. Many existing KD methods are not specifically tailored for these tasks. Moreover, prevalent KD methods often lack a careful consideration of what and from where to distill knowledge from the teacher to the student. This oversight may lead to issues like the accumulation of training bias within shallower student layers, potentially compromising the effectiveness of KD. To address these challenges, we propose Hierarchical Layer-selective Feedback Distillation (HLFD). HLFD strategically distills knowledge from a combination of middle layers to earlier layers and transfers final layer knowledge to intermediate layers at both the feature and pixel levels. This design allows the model to learn higher-quality representations from earlier layers, resulting in a robust and compact student model. Extensive quantitative evaluations reveal that HLFD outperforms existing methods by a significant margin. For example, in the kidney segmentation task, HLFD surpasses the student model (without KD) by over 10pp, significantly improving its focus on tumor-specific features. From a qualitative standpoint, the student model trained using HLFD excels at suppressing irrelevant information and can focus sharply on tumor-specific details, which opens a new pathway for more efficient and accurate diagnostic tools.","creator":"Vandan Gorade, Sparsh Mittal, Debesh Jha, Ulas Bagci"},{"id":"2311.16711","slug":"ledits-limitless-image-editing-using-text-to-image-models-arxiv-2311-16711v1-cs-cv","title":"LEDITS++: Limitless Image Editing using Text-to-Image Models.","link":"http://arxiv.org/abs/2311.16711","abstract":"Text-to-image diffusion models have recently received increasing interest for their astonishing ability to produce high-fidelity images from solely text inputs. Subsequent research efforts aim to exploit and apply their capabilities to real image editing. However, existing image-to-image methods are often inefficient, imprecise, and of limited versatility. They either require time-consuming fine-tuning, deviate unnecessarily strongly from the input image, and/or lack support for multiple, simultaneous edits. To address these issues, we introduce LEDITS++, an efficient yet versatile and precise textual image manipulation technique. LEDITS++'s novel inversion approach requires no tuning nor optimization and produces high-fidelity results with a few diffusion steps. Second, our methodology supports multiple simultaneous edits and is architecture-agnostic. Third, we use a novel implicit masking technique that limits changes to relevant image regions. We propose the novel TEdBench++ benchmark as part of our exhaustive evaluation. Our results demonstrate the capabilities of LEDITS++ and its improvements over previous methods. The project page is available at https://leditsplusplus-project.static.hf.space .","creator":"Manuel Brack, Felix Friedrich, Katharina Kornmeier, Linoy Tsaban, Patrick Schramowski, Kristian Kersting, Apolin&#xe1;rio Passos"},{"id":"2311.16716","slug":"graph-pre-training-and-prompt-learning-for-recommendation-arxiv-2311-16716v1-cs-ir","title":"Graph Pre-training and Prompt Learning for Recommendation.","link":"http://arxiv.org/abs/2311.16716","abstract":"GNN-based recommenders have excelled in modeling intricate user-item interactions through multi-hop message passing. However, existing methods often overlook the dynamic nature of evolving user-item interactions, which impedes the adaption to changing user preferences and distribution shifts in newly arriving data. Thus, their scalability and performances in real-world dynamic environments are limited. In this study, we propose GraphPL, a framework that incorporates parameter-efficient and dynamic graph pre-training with prompt learning. This novel combination empowers GNNs to effectively capture both long-term user preferences and short-term behavior dynamics, enabling the delivery of accurate and timely recommendations. Our GraphPL framework addresses the challenge of evolving user preferences by seamlessly integrating a temporal prompt mechanism and a graph-structural prompt learning mechanism into the pre-trained GNN model. The temporal prompt mechanism encodes time information on user-item interaction, allowing the model to naturally capture temporal context, while the graph-structural prompt learning mechanism enables the transfer of pre-trained knowledge to adapt to behavior dynamics without the need for continuous incremental training. We further bring in a dynamic evaluation setting for recommendation to mimic real-world dynamic scenarios and bridge the offline-online gap to a better level. Our extensive experiments including a large-scale industrial deployment showcases the lightweight plug-in scalability of our GraphPL when integrated with various state-of-the-art recommenders, emphasizing the advantages of GraphPL in terms of effectiveness, robustness and efficiency.","creator":"Yuhao Yang, Lianghao Xia, Da Luo, Kangyi Lin, Chao Huang"},{"id":"2311.16733","slug":"llms-for-science-usage-for-code-generation-and-data-analysis-arxiv-2311-16733v1-cs-se","title":"LLMs for Science: Usage for Code Generation and Data Analysis.","link":"http://arxiv.org/abs/2311.16733","abstract":"Large language models (LLMs) have been touted to enable increased productivity in many areas of today's work life. Scientific research as an area of work is no exception: the potential of LLM-based tools to assist in the daily work of scientists has become a highly discussed topic across disciplines. However, we are only at the very onset of this subject of study. It is still unclear how the potential of LLMs will materialise in research practice. With this study, we give first empirical evidence on the use of LLMs in the research process. We have investigated a set of use cases for LLM-based tools in scientific research, and conducted a first study to assess to which degree current tools are helpful. In this paper we report specifically on use cases related to software engineering, such as generating application code and developing scripts for data analytics. While we studied seemingly simple use cases, results across tools differ significantly. Our results highlight the promise of LLM-based tools in general, yet we also observe various issues, particularly regarding the integrity of the output these tools provide.","creator":"Mohamed Nejjar, Luca Zacharias, Fabian Stiehle, Ingo Weber"},{"id":"2311.16754","slug":"towards-full-scene-domain-generalization-in-multi-agent-collaborative-bird-s-eye-view-segmentation-for-connected-and-autonomous-driving-arxiv-2311-16754v1-cs-cv","title":"Towards Full-scene Domain Generalization in Multi-agent Collaborative Bird's Eye View Segmentation for Connected and Autonomous Driving.","link":"http://arxiv.org/abs/2311.16754","abstract":"Collaborative perception has recently gained significant attention in autonomous driving, improving perception quality by enabling the exchange of additional information among vehicles. However, deploying collaborative perception systems can lead to domain shifts due to diverse environmental conditions and data heterogeneity among connected and autonomous vehicles (CAVs). To address these challenges, we propose a unified domain generalization framework applicable in both training and inference stages of collaborative perception. In the training phase, we introduce an Amplitude Augmentation (AmpAug) method to augment low-frequency image variations, broadening the model's ability to learn across various domains. We also employ a meta-consistency training scheme to simulate domain shifts, optimizing the model with a carefully designed consistency loss to encourage domain-invariant representations. In the inference phase, we introduce an intra-system domain alignment mechanism to reduce or potentially eliminate the domain discrepancy among CAVs prior to inference. Comprehensive experiments substantiate the effectiveness of our method in comparison with the existing state-of-the-art works. Code will be released at https://github.com/DG-CAVs/DG-CoPerception.git.","creator":"Senkang Hu, Zhengru Fang, Xianhao Chen, Yuguang Fang, Sam Kwong"},{"id":"2311.16769","slug":"equilibrium-in-the-computing-continuum-through-active-inference-arxiv-2311-16769v1-cs-dc","title":"Equilibrium in the Computing Continuum through Active Inference.","link":"http://arxiv.org/abs/2311.16769","abstract":"Computing Continuum (CC) systems are challenged to ensure the intricate requirements of each computational tier. Given the system's scale, the Service Level Objectives (SLOs) which are expressed as these requirements, must be broken down into smaller parts that can be decentralized. We present our framework for collaborative edge intelligence enabling individual edge devices to (1) develop a causal understanding of how to enforce their SLOs, and (2) transfer knowledge to speed up the onboarding of heterogeneous devices. Through collaboration, they (3) increase the scope of SLO fulfillment. We implemented the framework and evaluated a use case in which a CC system is responsible for ensuring Quality of Service (QoS) and Quality of Experience (QoE) during video streaming. Our results showed that edge devices required only ten training rounds to ensure four SLOs; furthermore, the underlying causal structures were also rationally explainable. The addition of new types of devices can be done a posteriori, the framework allowed them to reuse existing models, even though the device type had been unknown. Finally, rebalancing the load within a device cluster allowed individual edge devices to recover their SLO compliance after a network failure from 22% to 89%.","creator":"Boris Sedlak, Victor Casamayor Pujol, Praveen Kumar Donta, Schahram Dustdar"},{"id":"2111.01566","slug":"strategyproof-and-proportionally-fair-facility-location-arxiv-2111-01566v3-cs-gt-updated","title":"Strategyproof and Proportionally Fair Facility Location.","link":"http://arxiv.org/abs/2111.01566","abstract":"We focus on a simple, one-dimensional collective decision problem (often referred to as the facility location problem) and explore issues of strategyproofness and proportionality-based fairness. We introduce and analyze a hierarchy of proportionality-based fairness axioms of varying strength: Individual Fair Share (IFS), Unanimous Fair Share (UFS), Proportionality (as in Freeman et al, 2021), and Proportional Fairness (PF). For each axiom, we characterize the family of mechanisms that satisfy the axiom and strategyproofness. We show that imposing strategyproofness renders many of the axioms to be equivalent: the family of mechanisms that satisfy proportionality, unanimity, and strategyproofness is equivalent to the family of mechanisms that satisfy UFS and strategyproofness, which, in turn, is equivalent to the family of mechanisms that satisfy PF and strategyproofness. Furthermore, there is a unique such mechanism: the Uniform Phantom mechanism, which is studied in Freeman et al. (2021). We also characterize the outcomes of the Uniform Phantom mechanism as the unique (pure) equilibrium outcome for any mechanism that satisfies continuity, strict monotonicity, and UFS. Finally, we analyze the approximation guarantees, in terms of optimal social welfare and minimum total cost, obtained by mechanisms that are strategyproof and satisfy each proportionality-based fairness axiom. We show that the Uniform Phantom mechanism provides the best approximation of the optimal social welfare (and also minimum total cost) among all mechanisms that satisfy UFS.","creator":"Haris Aziz, Alexander Lam, Barton E. Lee, Toby Walsh"},{"id":"2112.03002","slug":"graphprompt-graph-based-prompt-templates-for-biomedical-synonym-prediction-arxiv-2112-03002v2-cs-cl-updated","title":"GraphPrompt: Graph-Based Prompt Templates for Biomedical Synonym Prediction.","link":"http://arxiv.org/abs/2112.03002","abstract":"In the expansion of biomedical dataset, the same category may be labeled with different terms, thus being tedious and onerous to curate these terms. Therefore, automatically mapping synonymous terms onto the ontologies is desirable, which we name as biomedical synonym prediction task. Unlike biomedical concept normalization (BCN), no clues from context can be used to enhance synonym prediction, making it essential to extract graph features from ontology. We introduce an expert-curated dataset OBO-syn encompassing 70 different types of concepts and 2 million curated concept-term pairs for evaluating synonym prediction methods. We find BCN methods perform weakly on this task for not making full use of graph information. Therefore, we propose GraphPrompt, a prompt-based learning approach that creates prompt templates according to the graphs. GraphPrompt obtained 37.2\\% and 28.5\\% improvement on zero-shot and few-shot settings respectively, indicating the effectiveness of these graph-based prompt templates. We envision that our method GraphPrompt and OBO-syn dataset can be broadly applied to graph-based NLP tasks, and serve as the basis for analyzing diverse and accumulating biomedical data. All the data and codes are avalible at: https://github.com/HanwenXuTHU/GraphPrompt","creator":"Hanwen Xu, Jiayou Zhang, Zhirui Wang, Shizhuo Zhang, Megh Manoj Bhalerao, Yucong Liu, Dawei Zhu, Sheng Wang"},{"id":"2201.05760","slug":"big-data-analytics-for-network-level-short-term-travel-time-prediction-with-hierarchical-lstm-arxiv-2201-05760v3-cs-lg-updated","title":"Big Data Analytics for Network Level Short-Term Travel Time Prediction with Hierarchical LSTM.","link":"http://arxiv.org/abs/2201.05760","abstract":"The travel time data collected from widespread traffic monitoring sensors necessitate big data analytic tools for querying, visualization, and identifying meaningful traffic patterns. This paper utilizes a large-scale travel time dataset from Caltrans Performance Measurement System (PeMS) system that is an overflow for traditional data processing and modeling tools. To overcome the challenges of the massive amount of data, the big data analytic engines Apache Spark and Apache MXNet are applied for data wrangling and modeling. Seasonality and autocorrelation were performed to explore and visualize the trend of time-varying data. Inspired by the success of the hierarchical architecture for many Artificial Intelligent (AI) tasks, we consolidate the cell and hidden states passed from low-level to the high-level LSTM with an attention pooling similar to how the human perception system operates. The designed hierarchical LSTM model can consider the dependencies at different time scales to capture the spatial-temporal correlations of network-level travel time. Another self-attention module is then devised to connect LSTM extracted features to the fully connected layers, predicting travel time for all corridors instead of a single link/route. The comparison results show that the Hierarchical LSTM with Attention (HierLSTMat) model gives the best prediction results at 30-minute and 45-min horizons and can successfully forecast unusual congestion. The efficiency gained from big data analytic tools was evaluated by comparing them with popular data science and deep learning frameworks.","creator":"Tianya T. Zhang"},{"id":"2206.02541","slug":"pcpt-and-acpt-copyright-protection-and-traceability-scheme-for-dnn-models-arxiv-2206-02541v2-cs-cr-updated","title":"PCPT and ACPT: Copyright Protection and Traceability Scheme for DNN Models.","link":"http://arxiv.org/abs/2206.02541","abstract":"Deep neural networks (DNNs) have achieved tremendous success in artificial intelligence (AI) fields. However, DNN models can be easily illegally copied, redistributed, or abused by criminals, seriously damaging the interests of model inventors. The copyright protection of DNN models by neural network watermarking has been studied, but the establishment of a traceability mechanism for determining the authorized users of a leaked model is a new problem driven by the demand for AI services. Because the existing traceability mechanisms are used for models without watermarks, a small number of false-positives are generated. Existing black-box active protection schemes have loose authorization control and are vulnerable to forgery attacks. Therefore, based on the idea of black-box neural network watermarking with the video framing and image perceptual hash algorithm, a passive copyright protection and traceability framework PCPT is proposed that uses an additional class of DNN models, improving the existing traceability mechanism that yields a small number of false-positives. Based on an authorization control strategy and image perceptual hash algorithm, a DNN model active copyright protection and traceability framework ACPT is proposed. This framework uses the authorization control center constructed by the detector and verifier. This approach realizes stricter authorization control, which establishes a strong connection between users and model owners, improves the framework security, and supports traceability verification.","creator":"Xuefeng Fan, Dahao Fu, Hangyu Gui, Xinpeng Zhang, Xiaoyi Zhou"},{"id":"2206.11792","slug":"two-dimensional-total-absorption-spectroscopy-with-conditional-generative-adversarial-networks-arxiv-2206-11792v2-nucl-ex-updated","title":"Two-dimensional total absorption spectroscopy with conditional generative adversarial networks.","link":"http://arxiv.org/abs/2206.11792","abstract":"We explore the use of machine learning techniques to remove the response of large volume $\\gamma$-ray detectors from experimental spectra. Segmented $\\gamma$-ray total absorption spectrometers (TAS) allow for the simultaneous measurement of individual $\\gamma$-ray energy (E$_\\gamma$) and total excitation energy (E$_x$). Analysis of TAS detector data is complicated by the fact that the E$_x$ and E$_\\gamma$ quantities are correlated, and therefore, techniques that simply unfold using E$_x$ and E$_\\gamma$ response functions independently are not as accurate. In this work, we investigate the use of conditional generative adversarial networks (cGANs) to simultaneously unfold $E_{x}$ and $E_{\\gamma}$ data in TAS detectors. Specifically, we employ a \\texttt{Pix2Pix} cGAN, a generative modeling technique based on recent advances in deep learning, to treat \\rawmatrix~ matrix unfolding as an image-to-image translation problem. We present results for simulated and experimental matrices of single-$\\gamma$ and double-$\\gamma$ decay cascades. Our model demonstrates characterization capabilities within detector resolution limits for upwards of 93% of simulated test cases.","creator":"Cade Dembski, Michelle P. Kuchera, Sean Liddick, Raghu Ramanujan, Artemis Spyrou"},{"id":"2210.02804","slug":"just-cloze-a-novel-framework-for-evaluating-the-factual-consistency-faster-in-abstractive-summarization-arxiv-2210-02804v2-cs-cl-updated","title":"Just ClozE! A Novel Framework for Evaluating the Factual Consistency Faster in Abstractive Summarization.","link":"http://arxiv.org/abs/2210.02804","abstract":"The issue of factual consistency in abstractive summarization has received extensive attention in recent years, and the evaluation of factual consistency between summary and document has become an important and urgent task. Most of the current evaluation metrics are adopted from the question answering (QA) or natural language inference (NLI) task. However, the application of QA-based metrics is extremely time-consuming in practice while NLI-based metrics are lack of interpretability. In this paper, we propose a cloze-based evaluation framework called ClozE and show the great potential of the cloze-based metric. It inherits strong interpretability from QA, while maintaining the speed of NLI- level reasoning. We demonstrate that ClozE can reduce the evaluation time by nearly 96% relative to QA-based metrics while retaining their interpretability and performance through experiments on six human-annotated datasets and a meta-evaluation benchmark GO FIGURE (Gabriel et al., 2021). Finally, we discuss three important facets of ClozE in practice, which further shows better overall performance of ClozE compared to other metrics.","creator":"Yiyang Li, Lei Li, Marina Litvak, Natalia Vanetik, Dingxin Hu, Yuze Li, Yanquan Zhou"},{"id":"2211.05228","slug":"fixed-frustratingly-easy-domain-generalization-with-mixup-arxiv-2211-05228v2-cs-cv-updated","title":"FIXED: Frustratingly Easy Domain Generalization with Mixup.","link":"http://arxiv.org/abs/2211.05228","abstract":"Domain generalization (DG) aims to learn a generalizable model from multiple training domains such that it can perform well on unseen target domains. A popular strategy is to augment training data to benefit generalization through methods such as Mixup~\\cite{zhang2018mixup}. While the vanilla Mixup can be directly applied, theoretical and empirical investigations uncover several shortcomings that limit its performance. Firstly, Mixup cannot effectively identify the domain and class information that can be used for learning invariant representations. Secondly, Mixup may introduce synthetic noisy data points via random interpolation, which lowers its discrimination capability. Based on the analysis, we propose a simple yet effective enhancement for Mixup-based DG, namely domain-invariant Feature mIXup (FIX). It learns domain-invariant representations for Mixup. To further enhance discrimination, we leverage existing techniques to enlarge margins among classes to further propose the domain-invariant Feature MIXup with Enhanced Discrimination (FIXED) approach. We present theoretical insights about guarantees on its effectiveness. Extensive experiments on seven public datasets across two modalities including image classification (Digits-DG, PACS, Office-Home) and time series (DSADS, PAMAP2, UCI-HAR, and USC-HAD) demonstrate that our approach significantly outperforms nine state-of-the-art related methods, beating the best performing baseline by 6.5\\% on average in terms of test accuracy. Code is available at: https://github.com/jindongwang/transferlearning/tree/master/code/deep/fixed.","creator":"Wang Lu, Jindong Wang, Han Yu, Lei Huang, Xiang Zhang, Yiqiang Chen, Xing Xie"},{"id":"2211.13131","slug":"fetril-feature-translation-for-exemplar-free-class-incremental-learning-arxiv-2211-13131v2-cs-cv-updated","title":"FeTrIL: Feature Translation for Exemplar-Free Class-Incremental Learning.","link":"http://arxiv.org/abs/2211.13131","abstract":"Exemplar-free class-incremental learning is very challenging due to the negative effect of catastrophic forgetting. A balance between stability and plasticity of the incremental process is needed in order to obtain good accuracy for past as well as new classes. Existing exemplar-free class-incremental methods focus either on successive fine tuning of the model, thus favoring plasticity, or on using a feature extractor fixed after the initial incremental state, thus favoring stability. We introduce a method which combines a fixed feature extractor and a pseudo-features generator to improve the stability-plasticity balance. The generator uses a simple yet effective geometric translation of new class features to create representations of past classes, made of pseudo-features. The translation of features only requires the storage of the centroid representations of past classes to produce their pseudo-features. Actual features of new classes and pseudo-features of past classes are fed into a linear classifier which is trained incrementally to discriminate between all classes. The incremental process is much faster with the proposed method compared to mainstream ones which update the entire deep model. Experiments are performed with three challenging datasets, and different incremental settings. A comparison with ten existing methods shows that our method outperforms the others in most cases.","creator":"Gr&#xe9;goire Petit, Adrian Popescu, Hugo Schindler, David Picard, Bertrand Delezoide"},{"id":"2212.09744","slug":"dsi-updating-transformer-memory-with-new-documents-arxiv-2212-09744v2-cs-cl-updated","title":"DSI++: Updating Transformer Memory with New Documents.","link":"http://arxiv.org/abs/2212.09744","abstract":"Differentiable Search Indices (DSIs) encode a corpus of documents in model parameters and use the same model to answer user queries directly. Despite the strong performance of DSI models, deploying them in situations where the corpus changes over time is computationally expensive because reindexing the corpus requires re-training the model. In this work, we introduce DSI++, a continual learning challenge for DSI to incrementally index new documents while being able to answer queries related to both previously and newly indexed documents. Across different model scales and document identifier representations, we show that continual indexing of new documents leads to considerable forgetting of previously indexed documents. We also hypothesize and verify that the model experiences forgetting events during training, leading to unstable learning. To mitigate these issues, we investigate two approaches. The first focuses on modifying the training dynamics. Flatter minima implicitly alleviate forgetting, so we optimize for flatter loss basins and show that the model stably memorizes more documents ($+12\\%$). Next, we introduce a generative memory to sample pseudo-queries for documents and supplement them during continual indexing to prevent forgetting for the retrieval task. Extensive experiments on novel continual indexing benchmarks based on Natural Questions (NQ) and MS MARCO demonstrate that our proposed solution mitigates forgetting significantly. Concretely, it improves the average Hits@10 by $+21.1\\%$ over competitive baselines for NQ and requires $6$ times fewer model updates compared to re-training the DSI model for incrementally indexing five corpora in a sequence.","creator":"Sanket Vaibhav Mehta, Jai Gupta, Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Jinfeng Rao, Marc Najork, Emma Strubell, Donald Metzler"},{"id":"2302.04023","slug":"a-multitask-multilingual-multimodal-evaluation-of-chatgpt-on-reasoning-hallucination-and-interactivity-arxiv-2302-04023v4-cs-cl-updated","title":"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity.","link":"http://arxiv.org/abs/2302.04023","abstract":"This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets. We carry out an extensive technical evaluation of ChatGPT using 23 data sets covering 8 different common NLP application tasks. We evaluate the multitask, multilingual and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset. We find that ChatGPT outperforms LLMs with zero-shot learning on most tasks and even outperforms fine-tuned models on some tasks. We find that it is better at understanding non-Latin script languages than generating them. It is able to generate multimodal content from textual prompts, via an intermediate code generation step. Moreover, we find that ChatGPT is 63.41% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner. It is, for example, better at deductive than inductive reasoning. ChatGPT suffers from hallucination problems like other LLMs and it generates more extrinsic hallucinations from its parametric memory as it does not have access to an external knowledge base. Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++ on machine translation, in a multi-turn \"prompt engineering\" fashion. We also release codebase for evaluation set extraction.","creator":"Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, Pascale Fung"},{"id":"2303.01345","slug":"planet-clothpick-effective-fabric-flattening-based-on-latent-dynamic-planning-arxiv-2303-01345v2-cs-ro-updated","title":"PlaNet-ClothPick: Effective Fabric Flattening Based on Latent Dynamic Planning.","link":"http://arxiv.org/abs/2303.01345","abstract":"Why do Recurrent State Space Models such as PlaNet fail at cloth manipulation tasks? Recent work has attributed this to the blurry prediction of the observation, which makes it difficult to plan directly in the latent space. This paper explores the reasons behind this by applying PlaNet in the pick-and-place fabric-flattening domain. We find that the sharp discontinuity of the transition function on the contour of the fabric makes it difficult to learn an accurate latent dynamic model, causing the MPC planner to produce pick actions slightly outside of the article. By limiting picking space on the cloth mask and training on specially engineered trajectories, our mesh-free PlaNet-ClothPick surpasses visual planning and policy learning methods on principal metrics in simulation, achieving similar performance as state-of-the-art mesh-based planning approaches. Notably, our model exhibits a faster action inference and requires fewer transitional model parameters than the state-of-the-art robotic systems in this domain. Other supplementary materials are available at: https://sites.google.com/view/planet-clothpick.","creator":"Halid Abdulrahim Kadi, Kasim Terzic"},{"id":"2303.01928","slug":"fairshap-a-data-re-weighting-approach-for-algorithmic-fairness-based-on-shapley-values-arxiv-2303-01928v3-cs-lg-updated","title":"FairShap: A Data Re-weighting Approach for Algorithmic Fairness based on Shapley Values.","link":"http://arxiv.org/abs/2303.01928","abstract":"Algorithmic fairness is of utmost societal importance, yet the current trend in large-scale machine learning models requires training with massive datasets that are frequently biased. In this context, pre-processing methods that focus on modeling and correcting bias in the data emerge as valuable approaches. In this paper, we propose FairShap, a novel instance-level data re-weighting method for fair algorithmic decision-making through data valuation by means of Shapley Values. FairShap is model-agnostic and easily interpretable, as it measures the contribution of each training data point to a predefined fairness metric. We empirically validate FairShap on several state-of-the-art datasets of different nature, with a variety of training scenarios and models and show how it yields fairer models with similar levels of accuracy than the baselines. We illustrate FairShap's interpretability by means of histograms and latent space visualizations. Moreover, we perform a utility-fairness study, and ablation and runtime experiments to illustrate the impact of the size of the reference dataset and FairShap's computational cost depending on the size of the dataset and the number of features. We believe that FairShap represents a promising direction in interpretable and model-agnostic approaches to algorithmic fairness that yield competitive accuracy even when only biased datasets are available.","creator":"Adrian Arnaiz-Rodriguez, Nuria Oliver"},{"id":"2303.09373","slug":"mapseg-unified-unsupervised-domain-adaptation-for-heterogeneous-medical-image-segmentation-based-on-3d-masked-autoencoding-and-pseudo-labeling-arxiv-2303-09373v2-cs-cv-updated","title":"MAPSeg: Unified Unsupervised Domain Adaptation for Heterogeneous Medical Image Segmentation Based on 3D Masked Autoencoding and Pseudo-Labeling.","link":"http://arxiv.org/abs/2303.09373","abstract":"Robust segmentation is critical for deriving quantitative measures from large-scale, multi-center, and longitudinal medical scans. Manually annotating medical scans, however, is expensive and labor-intensive and may not always be available in every domain. Unsupervised domain adaptation (UDA) is a well-studied technique that alleviates this label-scarcity problem by leveraging available labels from another domain. In this study, we introduce Masked Autoencoding and Pseudo-Labeling Segmentation (MAPSeg), a $\\textbf{unified}$ UDA framework with great versatility and superior performance for heterogeneous and volumetric medical image segmentation. To the best of our knowledge, this is the first study that systematically reviews and develops a framework to tackle four different domain shifts in medical image segmentation. More importantly, MAPSeg is the first framework that can be applied to $\\textbf{centralized}$, $\\textbf{federated}$, and $\\textbf{test-time}$ UDA while maintaining comparable performance. We compare MAPSeg with previous state-of-the-art methods on a private infant brain MRI dataset and a public cardiac CT-MRI dataset, and MAPSeg outperforms others by a large margin (10.5 Dice improvement on the private MRI dataset and 5.7 on the public CT-MRI dataset). MAPSeg poses great practical value and can be applied to real-world problems. Our code and pretrained model will be available later.","creator":"Xuzhe Zhang, Yuhao Wu, Elsa Angelini, Ang Li, Jia Guo, Jerod M. Rasmussen, Thomas G. O&#x27;Connor, Pathik D. Wadhwa, Andrea Parolin Jackowski, Hai Li, Jonathan Posner, Andrew F. Laine, Yun Wang"},{"id":"2303.11712","slug":"efficiently-explaining-csps-with-unsatisfiable-subset-optimization-extended-algorithms-and-examples-arxiv-2303-11712v3-cs-ai-updated","title":"Efficiently Explaining CSPs with Unsatisfiable Subset Optimization (extended algorithms and examples).","link":"http://arxiv.org/abs/2303.11712","abstract":"We build on a recently proposed method for stepwise explaining solutions of Constraint Satisfaction Problems (CSP) in a human-understandable way. An explanation here is a sequence of simple inference steps where simplicity is quantified using a cost function. The algorithms for explanation generation rely on extracting Minimal Unsatisfiable Subsets (MUS) of a derived unsatisfiable formula, exploiting a one-to-one correspondence between so-called non-redundant explanations and MUSs. However, MUS extraction algorithms do not provide any guarantee of subset minimality or optimality with respect to a given cost function. Therefore, we build on these formal foundations and tackle the main points of improvement, namely how to generate explanations efficiently that are provably optimal (with respect to the given cost metric). For that, we developed (1) a hitting set-based algorithm for finding the optimal constrained unsatisfiable subsets; (2) a method for re-using relevant information over multiple algorithm calls; and (3) methods exploiting domain-specific information to speed up the explanation sequence generation. We experimentally validated our algorithms on a large number of CSP problems. We found that our algorithms outperform the MUS approach in terms of explanation quality and computational time (on average up to 56 % faster than a standard MUS approach).","creator":"Emilio Gamba, Bart Bogaerts, Tias Guns"},{"id":"2303.18158","slug":"constrained-optimization-of-rank-one-functions-with-indicator-variables-arxiv-2303-18158v2-math-oc-updated","title":"Constrained Optimization of Rank-One Functions with Indicator Variables.","link":"http://arxiv.org/abs/2303.18158","abstract":"Optimization problems involving minimization of a rank-one convex function over constraints modeling restrictions on the support of the decision variables emerge in various machine learning applications. These problems are often modeled with indicator variables for identifying the support of the continuous variables. In this paper we investigate compact extended formulations for such problems through perspective reformulation techniques. In contrast to the majority of previous work that relies on support function arguments and disjunctive programming techniques to provide convex hull results, we propose a constructive approach that exploits a hidden conic structure induced by perspective functions. To this end, we first establish a convex hull result for a general conic mixed-binary set in which each conic constraint involves a linear function of independent continuous variables and a set of binary variables. We then demonstrate that extended representations of sets associated with epigraphs of rank-one convex functions over constraints modeling indicator relations naturally admit such a conic representation. This enables us to systematically give perspective formulations for the convex hull descriptions of these sets with nonlinear separable or non-separable objective functions, sign constraints on continuous variables, and combinatorial constraints on indicator variables. We illustrate the efficacy of our results on sparse nonnegative logistic regression problems.","creator":"Soroosh Shafiee, Fatma K&#x131;l&#x131;n&#xe7;-Karzan"},{"id":"2304.12479","slug":"agi-artificial-general-intelligence-for-education-arxiv-2304-12479v4-cs-ai-updated","title":"AGI: Artificial General Intelligence for Education.","link":"http://arxiv.org/abs/2304.12479","abstract":"Artificial general intelligence (AGI) has gained global recognition as a future technology due to the emergence of breakthrough large language models and chatbots such as GPT-4 and ChatGPT, respectively. Compared to conventional AI models, typically designed for a limited range of tasks, demand significant amounts of domain-specific data for training and may not always consider intricate interpersonal dynamics in education. AGI, driven by the recent large pre-trained models, represents a significant leap in the capability of machines to perform tasks that require human-level intelligence, such as reasoning, problem-solving, decision-making, and even understanding human emotions and social interactions. This position paper reviews AGI's key concepts, capabilities, scope, and potential within future education, including achieving future educational goals, designing pedagogy and curriculum, and performing assessments. It highlights that AGI can significantly improve intelligent tutoring systems, educational assessment, and evaluation procedures. AGI systems can adapt to individual student needs, offering tailored learning experiences. They can also provide comprehensive feedback on student performance and dynamically adjust teaching methods based on student progress. The paper emphasizes that AGI's capabilities extend to understanding human emotions and social interactions, which are critical in educational settings. The paper discusses that ethical issues in education with AGI include data bias, fairness, and privacy and emphasizes the need for codes of conduct to ensure responsible AGI use in academic settings like homework, teaching, and recruitment. We also conclude that the development of AGI necessitates interdisciplinary collaborations between educators and AI engineers to advance research and application efforts.","creator":"Ehsan Latif, Gengchen Mai, Matthew Nyaaba, Xuansheng Wu, Ninghao Liu, Guoyu Lu, Sheng Li, Tianming Liu, Xiaoming Zhai"},{"id":"2305.08415","slug":"marsellus-a-heterogeneous-risc-v-ai-iot-end-node-soc-with-2-to-8b-dnn-acceleration-and-30-boost-adaptive-body-biasing-arxiv-2305-08415v3-cs-ar-updated","title":"Marsellus: A Heterogeneous RISC-V AI-IoT End-Node SoC with 2-to-8b DNN Acceleration and 30%-Boost Adaptive Body Biasing.","link":"http://arxiv.org/abs/2305.08415","abstract":"Emerging Artificial Intelligence-enabled Internet-of-Things (AI-IoT) System-on-a-Chip (SoC) for augmented reality, personalized healthcare, and nano-robotics need to run many diverse tasks within a power envelope of a few tens of mW over a wide range of operating conditions: compute-intensive but strongly quantized Deep Neural Network (DNN) inference, as well as signal processing and control requiring high-precision floating-point. We present Marsellus, an all-digital heterogeneous SoC for AI-IoT end-nodes fabricated in GlobalFoundries 22nm FDX that combines 1) a general-purpose cluster of 16 RISC-V Digital Signal Processing (DSP) cores attuned for the execution of a diverse range of workloads exploiting 4-bit and 2-bit arithmetic extensions (XpulpNN), combined with fused MAC&amp;LOAD operations and floating-point support; 2) a 2-8bit Reconfigurable Binary Engine (RBE) to accelerate 3x3 and 1x1 (pointwise) convolutions in DNNs; 3) a set of On-Chip Monitoring (OCM) blocks connected to an Adaptive Body Biasing (ABB) generator and a hardware control loop, enabling on-the-fly adaptation of transistor threshold voltages. Marsellus achieves up to 180 Gop/s or 3.32 Top/s/W on 2-bit precision arithmetic in software, and up to 637 Gop/s or 12.4 Top/s/W on hardware-accelerated DNN layers.","creator":"Francesco Conti, Gianna Paulin, Angelo Garofalo, Davide Rossi, Alfio Di Mauro, Georg Rutishauser, Gianmarco Ottavi, Manuel Eggimann, Hayate Okuhara, Luca Benini"},{"id":"2305.14561","slug":"negative-feedback-training-a-novel-concept-to-improve-robustness-of-nvcim-dnn-accelerators-arxiv-2305-14561v2-cs-lg-updated","title":"Negative Feedback Training: A Novel Concept to Improve Robustness of NVCIM DNN Accelerators.","link":"http://arxiv.org/abs/2305.14561","abstract":"Compute-in-memory (CIM) accelerators built upon non-volatile memory (NVM) devices excel in energy efficiency and latency when performing Deep Neural Network (DNN) inference, thanks to their in-situ data processing capability. However, the stochastic nature and intrinsic variations of NVM devices often result in performance degradation in DNN inference. Introducing these non-ideal device behaviors during DNN training enhances robustness, but drawbacks include limited accuracy improvement, reduced prediction confidence, and convergence issues. This arises from a mismatch between the deterministic training and non-deterministic device variations, as such training, though considering variations, relies solely on the model's final output. In this work, we draw inspiration from the control theory and propose a novel training concept: Negative Feedback Training (NFT) leveraging the multi-scale noisy information captured from network. We develop two specific NFT instances, Oriented Variational Forward (OVF) and Intermediate Representation Snapshot (IRS). Extensive experiments show that our methods outperform existing state-of-the-art methods with up to a 46.71% improvement in inference accuracy while reducing epistemic uncertainty, boosting output confidence, and improving convergence probability. Their effectiveness highlights the generality and practicality of our NFT concept in enhancing DNN robustness against device variations.","creator":"Yifan Qin, Zheyu Yan, Wujie Wen, Xiaobo Sharon Hu, Yiyu Shi"},{"id":"2305.14726","slug":"in-context-demonstration-selection-with-cross-entropy-difference-arxiv-2305-14726v2-cs-cl-updated","title":"In-Context Demonstration Selection with Cross Entropy Difference.","link":"http://arxiv.org/abs/2305.14726","abstract":"Large language models (LLMs) can use in-context demonstrations to improve performance on zero-shot tasks. However, selecting the best in-context examples is challenging because model performance can vary widely depending on the selected examples. We present a cross-entropy difference (CED) method for selecting in-context demonstrations. Our method is based on the observation that the effectiveness of in-context demonstrations negatively correlates with the perplexity of the test example by a language model that was finetuned on that demonstration. We utilize parameter efficient finetuning to train small models on training data that are used for computing the cross-entropy difference between a test example and every candidate in-context demonstration. This metric is used to rank and select in-context demonstrations independently for each test input. We evaluate our method on a mix-domain dataset that combines 8 benchmarks, representing 4 text generation tasks, showing that CED for in-context demonstration selection can improve performance for a variety of LLMs.","creator":"Dan Iter, Reid Pryzant, Ruochen Xu, Shuohang Wang, Yang Liu, Yichong Xu, Chenguang Zhu"},{"id":"2305.16378","slug":"sim-suction-learning-a-suction-grasp-policy-for-cluttered-environments-using-a-synthetic-benchmark-arxiv-2305-16378v2-cs-ro-updated","title":"Sim-Suction: Learning a Suction Grasp Policy for Cluttered Environments Using a Synthetic Benchmark.","link":"http://arxiv.org/abs/2305.16378","abstract":"This paper presents Sim-Suction, a robust object-aware suction grasp policy for mobile manipulation platforms with dynamic camera viewpoints, designed to pick up unknown objects from cluttered environments. Suction grasp policies typically employ data-driven approaches, necessitating large-scale, accurately-annotated suction grasp datasets. However, the generation of suction grasp datasets in cluttered environments remains underexplored, leaving uncertainties about the relationship between the object of interest and its surroundings. To address this, we propose a benchmark synthetic dataset, Sim-Suction-Dataset, comprising 500 cluttered environments with 3.2 million annotated suction grasp poses. The efficient Sim-Suction-Dataset generation process provides novel insights by combining analytical models with dynamic physical simulations to create fast and accurate suction grasp pose annotations. We introduce Sim-Suction-Pointnet to generate robust 6D suction grasp poses by learning point-wise affordances from the Sim-Suction-Dataset, leveraging the synergy of zero-shot text-to-segmentation. Real-world experiments for picking up all objects demonstrate that Sim-Suction-Pointnet achieves success rates of 96.76%, 94.23%, and 92.39% on cluttered level 1 objects (prismatic shape), cluttered level 2 objects (more complex geometry), and cluttered mixed objects, respectively. The Sim-Suction policies outperform state-of-the-art benchmarks tested by approximately 21% in cluttered mixed scenes.","creator":"Juncheng Li, David J. Cappelleri"},{"id":"2305.18228","slug":"sr-ood-out-of-distribution-detection-via-sample-repairing-arxiv-2305-18228v2-cs-lg-updated","title":"SR-OOD: Out-of-Distribution Detection via Sample Repairing.","link":"http://arxiv.org/abs/2305.18228","abstract":"Out-of-distribution (OOD) detection is a crucial task for ensuring the reliability and robustness of machine learning models. Recent works have shown that generative models often assign high confidence scores to OOD samples, indicating that they fail to capture the semantic information of the data. To tackle this problem, we take advantage of sample repairing and propose a novel OOD detection framework, namely SR-OOD. Our framework leverages the idea that repairing an OOD sample can reveal its semantic inconsistency with the in-distribution data. Specifically, our framework consists of two components: a sample repairing module and a detection module. The sample repairing module applies erosion to an input sample and uses a generative adversarial network to repair it. The detection module then determines whether the input sample is OOD using a distance metric. Our framework does not require any additional data or label information for detection, making it applicable to various scenarios. We conduct extensive experiments on three image datasets: CIFAR-10, CelebA, and Pokemon. The results demonstrate that our approach achieves superior performance over the state-of-the-art generative methods in OOD detection.","creator":"Rui Sun, Andi Zhang, Haiming Zhang, Jinke Ren, Yao Zhu, Ruimao Zhang, Shuguang Cui, Zhen Li"},{"id":"2305.18766","slug":"hifa-high-fidelity-text-to-3d-generation-with-advanced-diffusion-guidance-arxiv-2305-18766v3-cs-cv-updated","title":"HiFA: High-fidelity Text-to-3D Generation with Advanced Diffusion Guidance.","link":"http://arxiv.org/abs/2305.18766","abstract":"The advancements in automatic text-to-3D generation have been remarkable. Most existing methods use pre-trained text-to-image diffusion models to optimize 3D representations like Neural Radiance Fields (NeRFs) via latent-space denoising score matching. Yet, these methods often result in artifacts and inconsistencies across different views due to their suboptimal optimization approaches and limited understanding of 3D geometry. Moreover, the inherent constraints of NeRFs in rendering crisp geometry and stable textures usually lead to a two-stage optimization to attain high-resolution details. This work proposes holistic sampling and smoothing approaches to achieve high-quality text-to-3D generation, all in a single-stage optimization. We compute denoising scores in the text-to-image diffusion model's latent and image spaces. Instead of randomly sampling timesteps (also referred to as noise levels in denoising score matching), we introduce a novel timestep annealing approach that progressively reduces the sampled timestep throughout optimization. To generate high-quality renderings in a single-stage optimization, we propose regularization for the variance of z-coordinates along NeRF rays. To address texture flickering issues in NeRFs, we introduce a kernel smoothing technique that refines importance sampling weights coarse-to-fine, ensuring accurate and thorough sampling in high-density regions. Extensive experiments demonstrate the superiority of our method over previous approaches, enabling the generation of highly detailed and view-consistent 3D assets through a single-stage training process.","creator":"Junzhe Zhu, Peiye Zhuang"},{"id":"2306.07745","slug":"kernelized-reinforcement-learning-with-order-optimal-regret-bounds-arxiv-2306-07745v2-cs-lg-updated","title":"Kernelized Reinforcement Learning with Order Optimal Regret Bounds.","link":"http://arxiv.org/abs/2306.07745","abstract":"Reinforcement learning (RL) has shown empirical success in various real world settings with complex models and large state-action spaces. The existing analytical results, however, typically focus on settings with a small number of state-actions or simple models such as linearly modeled state-action value functions. To derive RL policies that efficiently handle large state-action spaces with more general value functions, some recent works have considered nonlinear function approximation using kernel ridge regression. We propose $\\pi$-KRVI, an optimistic modification of least-squares value iteration, when the state-action value function is represented by a reproducing kernel Hilbert space (RKHS). We prove the first order-optimal regret guarantees under a general setting. Our results show a significant polynomial in the number of episodes improvement over the state of the art. In particular, with highly non-smooth kernels (such as Neural Tangent kernel or some Mat\\'ern kernels) the existing results lead to trivial (superlinear in the number of episodes) regret bounds. We show a sublinear regret bound that is order optimal in the case of Mat\\'ern kernels where a lower bound on regret is known.","creator":"Sattar Vakili, Julia Olkhovskaya"},{"id":"2306.11363","slug":"masked-diffusion-models-are-fast-distribution-learners-arxiv-2306-11363v4-cs-cv-updated","title":"Masked Diffusion Models Are Fast Distribution Learners.","link":"http://arxiv.org/abs/2306.11363","abstract":"Diffusion model has emerged as the \\emph{de-facto} model for image generation, yet the heavy training overhead hinders its broader adoption in the research community. We observe that diffusion models are commonly trained to learn all fine-grained visual information from scratch. This paradigm may cause unnecessary training costs hence requiring in-depth investigation. In this work, we show that it suffices to train a strong diffusion model by first pre-training the model to learn some primer distribution that loosely characterizes the unknown real image distribution. Then the pre-trained model can be fine-tuned for various generation tasks efficiently. In the pre-training stage, we propose to mask a high proportion (e.g., up to 90\\%) of input images to approximately represent the primer distribution and introduce a masked denoising score matching objective to train a model to denoise visible areas. In subsequent fine-tuning stage, we efficiently train diffusion model without masking. Utilizing the two-stage training framework, we achieves significant training acceleration and a new FID score record of 6.27 on CelebA-HQ $256 \\times 256$ for ViT-based diffusion models. The generalizability of a pre-trained model further helps building models that perform better than ones trained from scratch on different downstream datasets. For instance, a diffusion model pre-trained on VGGFace2 attains a 46\\% quality improvement when fine-tuned on a different dataset that contains only 3000 images. Our code is available at \\url{https://github.com/jiachenlei/maskdm}.","creator":"Jiachen Lei, Qinglong Wang, Peng Cheng, Zhongjie Ba, Zhan Qin, Zhibo Wang, Zhenguang Liu, Kui Ren"},{"id":"2306.15943","slug":"no-transfers-required-integrating-last-mile-with-public-transit-using-opti-mile-arxiv-2306-15943v2-cs-cy-updated","title":"No Transfers Required: Integrating Last Mile with Public Transit Using Opti-Mile.","link":"http://arxiv.org/abs/2306.15943","abstract":"Public transit is a popular mode of transit due to its affordability, despite the inconveniences due to the necessity of transfers required to reach most areas. For example, in the bus and metro network of New Delhi, only 30% of stops can be directly accessed from any starting point, thus requiring transfers for most commutes. Additionally, last-mile services like rickshaws, tuk-tuks or shuttles are commonly used as feeders to the nearest public transit access points, which further adds to the complexity and inefficiency of a journey. Ultimately, users often face a tradeoff between coverage and transfers to reach their destination, regardless of the mode of transit or the use of last-mile services. To address the problem of limited accessibility and inefficiency due to transfers in public transit systems, we propose ``opti-mile,\" a novel trip planning approach that combines last-mile services with public transit such that no transfers are required. Opti-mile allows users to customise trip parameters such as maximum walking distance, and acceptable fare range. We analyse the transit network of New Delhi, evaluating the efficiency, feasibility and advantages of opti-mile for optimal multi-modal trips between randomly selected source-destination pairs. We demonstrate that opti-mile trips lead to a 10% reduction in distance travelled for 18% increase in price compared to traditional shortest paths. We also show that opti-mile trips provide better coverage of the city than public transit, without a significant fare increase.","creator":"Raashid Altaf, Pravesh Biyani"},{"id":"2307.00154","slug":"stitched-vits-are-flexible-vision-backbones-arxiv-2307-00154v2-cs-cv-updated","title":"Stitched ViTs are Flexible Vision Backbones.","link":"http://arxiv.org/abs/2307.00154","abstract":"Large pretrained plain vision Transformers (ViTs) have been the workhorse for many downstream tasks. However, existing works utilizing off-the-shelf ViTs are inefficient in terms of training and deployment, because adopting ViTs with individual sizes requires separate trainings and is restricted by fixed performance-efficiency trade-offs. In this paper, we are inspired by stitchable neural networks (SN-Net), which is a new framework that cheaply produces a single model that covers rich subnetworks by stitching pretrained model families, supporting diverse performance-efficiency trade-offs at runtime. Building upon this foundation, we introduce SN-Netv2, a systematically improved model stitching framework to facilitate downstream task adaptation. Specifically, we first propose a two-way stitching scheme to enlarge the stitching space. We then design a resource-constrained sampling strategy that takes into account the underlying FLOPs distributions in the space for better sampling. Finally, we observe that learning stitching layers as a low-rank update plays an essential role on downstream tasks to stabilize training and ensure a good Pareto frontier. With extensive experiments on ImageNet-1K, ADE20K, COCO-Stuff-10K and NYUv2, SN-Netv2 demonstrates superior performance over SN-Netv1 on downstream dense predictions and shows strong ability as a flexible vision backbone, achieving great advantages in both training efficiency and deployment flexibility. Code is available at https://github.com/ziplab/SN-Netv2.","creator":"Zizheng Pan, Jing Liu, Haoyu He, Jianfei Cai, Bohan Zhuang"},{"id":"2307.12226","slug":"geometry-aware-adaptation-for-pretrained-models-arxiv-2307-12226v2-cs-lg-updated","title":"Geometry-Aware Adaptation for Pretrained Models.","link":"http://arxiv.org/abs/2307.12226","abstract":"Machine learning models -- including prominent zero-shot models -- are often trained on datasets whose labels are only a small proportion of a larger label space. Such spaces are commonly equipped with a metric that relates the labels via distances between them. We propose a simple approach to exploit this information to adapt the trained model to reliably predict new classes -- or, in the case of zero-shot prediction, to improve its performance -- without any additional training. Our technique is a drop-in replacement of the standard prediction rule, swapping argmax with the Fr\\'echet mean. We provide a comprehensive theoretical analysis for this approach, studying (i) learning-theoretic results trading off label space diameter, sample complexity, and model dimension, (ii) characterizations of the full range of scenarios in which it is possible to predict any unobserved class, and (iii) an optimal active learning-like next class selection procedure to obtain optimal training classes for when it is not possible to predict the entire range of unobserved classes. Empirically, using easily-available external metrics, our proposed approach, Loki, gains up to 29.7% relative improvement over SimCLR on ImageNet and scales to hundreds of thousands of classes. When no such metric is available, Loki can use self-derived metrics from class embeddings and obtains a 10.5% improvement on pretrained zero-shot models such as CLIP.","creator":"Nicholas Roberts, Xintong Li, Dyah Adila, Sonia Cromp, Tzu-Heng Huang, Jitian Zhao, Frederic Sala"},{"id":"2307.12689","slug":"addressing-the-impact-of-localized-training-data-in-graph-neural-networks-arxiv-2307-12689v2-cs-lg-updated","title":"Addressing the Impact of Localized Training Data in Graph Neural Networks.","link":"http://arxiv.org/abs/2307.12689","abstract":"Graph Neural Networks (GNNs) have achieved notable success in learning from graph-structured data, owing to their ability to capture intricate dependencies and relationships between nodes. They excel in various applications, including semi-supervised node classification, link prediction, and graph generation. However, it is important to acknowledge that the majority of state-of-the-art GNN models are built upon the assumption of an in-distribution setting, which hinders their performance on real-world graphs with dynamic structures. In this article, we aim to assess the impact of training GNNs on localized subsets of the graph. Such restricted training data may lead to a model that performs well in the specific region it was trained on but fails to generalize and make accurate predictions for the entire graph. In the context of graph-based semi-supervised learning (SSL), resource constraints often lead to scenarios where the dataset is large, but only a portion of it can be labeled, affecting the model's performance. This limitation affects tasks like anomaly detection or spam detection when labeling processes are biased or influenced by human subjectivity. To tackle the challenges posed by localized training data, we approach the problem as an out-of-distribution (OOD) data issue by by aligning the distributions between the training data, which represents a small portion of labeled data, and the graph inference process that involves making predictions for the entire graph. We propose a regularization method to minimize distributional discrepancies between localized training data and graph inference, improving model performance on OOD data. Extensive tests on popular GNN models show significant performance improvement on three citation GNN benchmark datasets. The regularization approach effectively enhances model adaptation and generalization, overcoming challenges posed by OOD data.","creator":"Akansha A"},{"id":"2307.16769","slug":"2-level-reinforcement-learning-for-ships-on-inland-waterways-arxiv-2307-16769v2-cs-sy-updated","title":"2-Level Reinforcement Learning for Ships on Inland Waterways.","link":"http://arxiv.org/abs/2307.16769","abstract":"This paper proposes a realistic modularized framework for controlling autonomous surface vehicles (ASVs) on inland waterways (IWs) based on deep reinforcement learning (DRL). The framework comprises two levels: a high-level local path planning (LPP) unit and a low-level path following (PF) unit, each consisting of a DRL agent. The LPP agent is responsible for planning a path under consideration of nearby vessels, traffic rules, and the geometry of the waterway. We thereby transfer a recently proposed spatial-temporal recurrent neural network architecture to continuous action spaces. The LPP agent improves operational safety in comparison to a state-of-the-art artificial potential field method by increasing the minimum distance to other vessels by 65% on average. The PF agent performs low-level actuator control while accounting for shallow water influences and the environmental forces winds, waves, and currents. Compared with a proportional-integral-derivative (PID) controller, the PF agent yields only 61% of the mean cross-track error while significantly reducing control effort in terms of the required absolute rudder angle. Lastly, both agents are jointly validated in simulation, employing the lower Elbe in northern Germany as an example case and using real automatic identification system (AIS) trajectories to model the behavior of other ships.","creator":"Martin Waltz, Niklas Paulig, Ostap Okhrin"},{"id":"2308.12532","slug":"fedsol-stabilized-orthogonal-learning-in-federated-learning-arxiv-2308-12532v3-cs-lg-updated","title":"FedSOL: Stabilized Orthogonal Learning in Federated Learning.","link":"http://arxiv.org/abs/2308.12532","abstract":"Federated Learning (FL) aggregates locally trained models from individual clients to construct a global model. While FL enables learning a model with data privacy, it often suffers from significant performance degradation when client data distributions are heterogeneous. Many previous FL algorithms have addressed this issue by introducing various proximal restrictions. These restrictions aim to encourage global alignment by constraining the deviation of local learning from the global objective. However, they inherently limit local learning by interfering with the original local objectives. Recently, an alternative approach has emerged to improve local learning generality. By obtaining local models within a smooth loss landscape, this approach mitigates conflicts among different local objectives of the clients. Yet, it does not ensure stable global alignment, as local learning does not take the global objective into account. In this study, we propose Federated Stability on Learning (FedSoL), which combines both the concepts of global alignment and local generality. In FedSoL, the local learning seeks a parameter region robust against proximal perturbations. This strategy introduces an implicit proximal restriction effect in local learning while maintaining the original local objective for parameter update. Our experiments show that FedSoL consistently achieves state-of-the-art performance on various setups.","creator":"Gihun Lee, Minchan Jeong, Sangmook Kim, Jaehoon Oh, Se-Young Yun"},{"id":"2308.14610","slug":"polarrec-radio-interferometric-data-reconstruction-with-polar-coordinate-representation-arxiv-2308-14610v2-astro-ph-im-updated","title":"PolarRec: Radio Interferometric Data Reconstruction with Polar Coordinate Representation.","link":"http://arxiv.org/abs/2308.14610","abstract":"In radio astronomy, visibility data, which are measurements of wave signals from radio telescopes, are transformed into images for observation of distant celestial objects. However, these resultant images usually contain both real sources and artifacts, due to signal sparsity and other factors. One way to obtain cleaner images is to reconstruct samples into dense forms before imaging. Unfortunately, existing reconstruction methods often miss some components of visibility in frequency domain, so blurred object edges and persistent artifacts remain in the images. Furthermore, the computation overhead is high on irregular visibility samples due to the data skew. To address these problems, we propose PolarRec, a transformer-encoder-conditioned reconstruction pipeline with visibility samples converted into the polar coordinate representation. This representation matches the way in which radio telescopes observe a celestial area as the Earth rotates. As a result, visibility samples distribute in the polar system more uniformly than in the Cartesian space. Therefore, we propose to use radial distance in the loss function, to help reconstruct complete visibility effectively. Also, we group visibility samples by their polar angles and propose a group-based encoding scheme to improve the efficiency. Our experiments demonstrate that PolarRec markedly improves imaging results by faithfully reconstructing all frequency components in the visibility domain while significantly reducing the computation cost in visibility data encoding. We believe this high-quality and high-efficiency imaging of PolarRec will better facilitate astronomers to conduct their research.","creator":"Ruoqi Wang, Zhuoyang Chen, Jiayi Zhu, Qiong Luo, Feng Wang"},{"id":"2308.15568","slug":"over-squashing-in-graph-neural-networks-a-comprehensive-survey-arxiv-2308-15568v5-cs-ai-updated","title":"Over-Squashing in Graph Neural Networks: A Comprehensive survey.","link":"http://arxiv.org/abs/2308.15568","abstract":"Graph Neural Networks (GNNs) revolutionize machine learning for graph-structured data, effectively capturing complex relationships. They disseminate information through interconnected nodes, but long-range interactions face challenges known as \"over-squashing\". This survey delves into the challenge of over-squashing in Graph Neural Networks (GNNs), where long-range information dissemination is hindered, impacting tasks reliant on intricate long-distance interactions. It comprehensively explores the causes, consequences, and mitigation strategies for over-squashing. Various methodologies are reviewed, including graph rewiring, novel normalization, spectral analysis, and curvature-based strategies, with a focus on their trade-offs and effectiveness. The survey also discusses the interplay between over-squashing and other GNN limitations, such as over-smoothing, and provides a taxonomy of models designed to address these issues in node and graph-level tasks. Benchmark datasets for performance evaluation are also detailed, making this survey a valuable resource for researchers and practitioners in the GNN field.","creator":"Singh Akansha"},{"id":"2309.01291","slug":"generative-social-choice-arxiv-2309-01291v2-cs-gt-updated","title":"Generative Social Choice.","link":"http://arxiv.org/abs/2309.01291","abstract":"Traditionally, social choice theory has only been applicable to choices among a few predetermined alternatives but not to more complex decisions such as collectively selecting a textual statement. We introduce generative social choice, a framework that combines the mathematical rigor of social choice theory with the capability of large language models to generate text and extrapolate preferences. This framework divides the design of AI-augmented democratic processes into two components: first, proving that the process satisfies rigorous representation guarantees when given access to oracle queries; second, empirically validating that these queries can be approximately implemented using a large language model. We apply this framework to the problem of generating a slate of statements that is representative of opinions expressed as free-form text; specifically, we develop a democratic process with representation guarantees and use this process to represent the opinions of participants in a survey about chatbot personalization. We find that 93 out of 100 participants feel \"mostly\" or \"perfectly\" represented by the slate of five statements we extracted.","creator":"Sara Fish, Paul G&#xf6;lz, David C. Parkes, Ariel D. Procaccia, Gili Rusak, Itai Shapira, Manuel W&#xfc;thrich"},{"id":"2309.02705","slug":"certifying-llm-safety-against-adversarial-prompting-arxiv-2309-02705v2-cs-cl-updated","title":"Certifying LLM Safety against Adversarial Prompting.","link":"http://arxiv.org/abs/2309.02705","abstract":"Large language models (LLMs) released for public use incorporate guardrails to ensure their output is safe, often referred to as \"model alignment.\" An aligned language model should decline a user's request to produce harmful content. However, such safety measures are vulnerable to adversarial attacks, which add maliciously designed token sequences to a harmful prompt to bypass the model's safety guards. In this work, we introduce erase-and-check, the first framework to defend against adversarial prompts with verifiable safety guarantees. We defend against three attack modes: i) adversarial suffix, which appends an adversarial sequence at the end of the prompt; ii) adversarial insertion, where the adversarial sequence is inserted anywhere in the middle of the prompt; and iii) adversarial infusion, where adversarial tokens are inserted at arbitrary positions in the prompt, not necessarily as a contiguous block. Our experimental results demonstrate that this procedure can obtain strong certified safety guarantees on harmful prompts while maintaining good empirical performance on safe prompts. For example, against adversarial suffixes of length 20, it certifiably detects 92% of harmful prompts and labels 94% of safe prompts correctly using the open-source language model Llama 2 as the safety filter. We further improve the filter's performance, in terms of accuracy and speed, by replacing Llama 2 with a DistilBERT safety classifier fine-tuned on safe and harmful prompts. Additionally, we propose two efficient empirical defenses: i) RandEC, a randomized version of erase-and-check that evaluates the safety filter on a small subset of the erased subsequences, and ii) GradEC, a gradient-based version that optimizes the erased tokens to remove the adversarial sequence. The code for our experiments is available at https://github.com/aounon/certified-llm-safety.","creator":"Aounon Kumar, Chirag Agarwal, Suraj Srinivas, Aaron Jiaxun Li, Soheil Feizi, Himabindu Lakkaraju"},{"id":"2309.09919","slug":"plug-in-the-safety-chip-enforcing-constraints-for-llm-driven-robot-agents-arxiv-2309-09919v3-cs-ro-updated","title":"Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot Agents.","link":"http://arxiv.org/abs/2309.09919","abstract":"Recent advancements in large language models (LLMs) have enabled a new research domain, LLM agents, for solving robotics and planning tasks by leveraging the world knowledge and general reasoning abilities of LLMs obtained during pretraining. However, while considerable effort has been made to teach the robot the \"dos,\" the \"don'ts\" received relatively less attention. We argue that, for any practical usage, it is as crucial to teach the robot the \"don'ts\": conveying explicit instructions about prohibited actions, assessing the robot's comprehension of these restrictions, and, most importantly, ensuring compliance. Moreover, verifiable safe operation is essential for deployments that satisfy worldwide standards such as ISO 61508, which defines standards for safely deploying robots in industrial factory environments worldwide. Aiming at deploying the LLM agents in a collaborative environment, we propose a queryable safety constraint module based on linear temporal logic (LTL) that simultaneously enables natural language (NL) to temporal constraints encoding, safety violation reasoning and explaining, and unsafe action pruning. To demonstrate the effectiveness of our system, we conducted experiments in VirtualHome environment and on a real robot. The experimental results show that our system strictly adheres to the safety constraints and scales well with complex safety constraints, highlighting its potential for practical utility.","creator":"Ziyi Yang, Shreyas S. Raman, Ankit Shah, Stefanie Tellex"},{"id":"2309.10399","slug":"exploiting-causality-signals-in-medical-images-a-pilot-study-with-empirical-results-arxiv-2309-10399v2-cs-cv-updated","title":"Exploiting Causality Signals in Medical Images: A Pilot Study with Empirical Results.","link":"http://arxiv.org/abs/2309.10399","abstract":"We present a novel technique to discover and exploit weak causal signals directly from images via neural networks for classification purposes. This way, we model how the presence of a feature in one part of the image affects the appearance of another feature in a different part of the image. Our method consists of a convolutional neural network backbone and a causality-factors extractor module, which computes weights to enhance each feature map according to its causal influence in the scene. We developed different architecture variants and empirically evaluated all of our models on two public datasets of prostate MRI images and breast histopathology slides for cancer diagnosis. To confirm our quantitative results, we conduct ablation studies and investigate the explainability of our models via class activation maps. Our findings show that our lightweight block extracts meaningful information and improves the overall classification, together with producing more robust predictions that focus on relevant parts of the image. That is crucial in medical imaging, where accurate and reliable classifications are essential for effective diagnosis and treatment planning.","creator":"Gianluca Carloni, Sara Colantonio"},{"id":"2309.11087","slug":"embed-search-align-dna-sequence-alignment-using-transformer-models-arxiv-2309-11087v2-q-bio-gn-updated","title":"Embed-Search-Align: DNA Sequence Alignment using Transformer Models.","link":"http://arxiv.org/abs/2309.11087","abstract":"DNA sequence alignment involves assigning short DNA reads to the most probable locations on an extensive reference genome. This process is crucial for various genomic analyses, including variant calling, transcriptomics, and epigenomics. Conventional methods, refined over decades, tackle this challenge in two steps: genome indexing followed by efficient search to locate likely positions for given reads. Building on the success of Large Language Models (LLM) in encoding text into embeddings, where the distance metric captures semantic similarity, recent efforts have explored whether the same Transformer architecture can produce numerical representations for DNA sequences. Such models have shown early promise in tasks involving classification of short DNA sequences, such as the detection of coding vs non-coding regions, as well as the identification of enhancer and promoter sequences. Performance at sequence classification tasks does not, however, translate to sequence alignment, where it is necessary to conduct a genome-wide search to successfully align every read. We address this open problem by framing it as an Embed-Search-Align task. In this framework, a novel encoder model DNA-ESA generates representations of reads and fragments of the reference, which are projected into a shared vector space where the read-fragment distance is used as surrogate for alignment. In particular, DNA-ESA introduces: (1) Contrastive loss for self-supervised training of DNA sequence representations, facilitating rich sequence-level embeddings, and (2) a DNA vector store to enable search across fragments on a global scale. DNA-ESA is &gt;97% accurate when aligning 250-length reads onto a human reference genome of 3 gigabases (single-haploid), far exceeds the performance of 6 recent DNA-Transformer model baselines and shows task transfer across chromosomes and species.","creator":"Pavan Holur, K. C. Enevoldsen, Lajoyce Mboning, Thalia Georgiou, Louis-S. Bouchard, Matteo Pellegrini, Vwani Roychowdhury"},{"id":"2309.11526","slug":"likelihood-based-sensor-calibration-using-affine-transformation-arxiv-2309-11526v2-cs-lg-updated","title":"Likelihood-based Sensor Calibration using Affine Transformation.","link":"http://arxiv.org/abs/2309.11526","abstract":"An important task in the field of sensor technology is the efficient implementation of adaptation procedures of measurements from one sensor to another sensor of identical design. One idea is to use the estimation of an affine transformation between different systems, which can be improved by the knowledge of experts. This paper presents an improved solution from Glacier Research that was published back in 1973. The results demonstrate the adaptability of this solution for various applications, including software calibration of sensors, implementation of expert-based adaptation, and paving the way for future advancements such as distributed learning methods. One idea here is to use the knowledge of experts for estimating an affine transformation between different systems. We evaluate our research with simulations and also with real measured data of a multi-sensor board with 8 identical sensors. Both data set and evaluation script are provided for download. The results show an improvement for both the simulation and the experiments with real data.","creator":"R&#xfc;diger Machhamer, Lejla Begic Fazlic, Eray Guven, David Junk, Gunes Karabulut Kurt, Stefan Naumann, Stephan Didas, Klaus-Uwe Gollmer, Ralph Bergmann, Ingo J. Timm, Guido Dartmann"},{"id":"2309.13411","slug":"towards-attributions-of-input-variables-in-a-coalition-arxiv-2309-13411v2-cs-lg-updated","title":"Towards Attributions of Input Variables in a Coalition.","link":"http://arxiv.org/abs/2309.13411","abstract":"This paper aims to develop a new attribution method to explain the conflict between individual variables' attributions and their coalition's attribution from a fully new perspective. First, we find that the Shapley value can be reformulated as the allocation of Harsanyi interactions encoded by the AI model. Second, based the re-alloction of interactions, we extend the Shapley value to the attribution of coalitions. Third we ective. We derive the fundamental mechanism behind the conflict. This conflict come from the interaction containing partial variables in their coalition.","creator":"Xinhao Zheng, Huiqi Deng, Bo Fan, Quanshi Zhang"},{"id":"2309.13607","slug":"mm-nerf-multimodal-guided-3d-multi-style-transfer-of-neural-radiance-field-arxiv-2309-13607v2-cs-cv-updated","title":"MM-NeRF: Multimodal-Guided 3D Multi-Style Transfer of Neural Radiance Field.","link":"http://arxiv.org/abs/2309.13607","abstract":"3D style transfer aims to generate stylized views of 3D scenes with specified styles, which requires high-quality generating and keeping multi-view consistency. Existing methods still suffer the challenges of high-quality stylization with texture details and stylization with multimodal guidance. In this paper, we reveal that the common training method of stylization with NeRF, which generates stylized multi-view supervision by 2D style transfer models, causes the same object in supervision to show various states (color tone, details, etc.) in different views, leading NeRF to tend to smooth the texture details, further resulting in low-quality rendering for 3D multi-style transfer. To tackle these problems, we propose a novel Multimodal-guided 3D Multi-style transfer of NeRF, termed MM-NeRF. First, MM-NeRF projects multimodal guidance into a unified space to keep the multimodal styles consistency and extracts multimodal features to guide the 3D stylization. Second, a novel multi-head learning scheme is proposed to relieve the difficulty of learning multi-style transfer, and a multi-view style consistent loss is proposed to track the inconsistency of multi-view supervision data. Finally, a novel incremental learning mechanism to generalize MM-NeRF to any new style with small costs. Extensive experiments on several real-world datasets show that MM-NeRF achieves high-quality 3D multi-style stylization with multimodal guidance, and keeps multi-view consistency and style consistency between multimodal guidance. Codes will be released.","creator":"Zijiang Yang, Zhongwei Qiu, Chang Xu, Dongmei Fu"},{"id":"2309.13620","slug":"pris-practical-robust-invertible-network-for-image-steganography-arxiv-2309-13620v2-cs-cv-updated","title":"PRIS: Practical robust invertible network for image steganography.","link":"http://arxiv.org/abs/2309.13620","abstract":"Image steganography is a technique of hiding secret information inside another image, so that the secret is not visible to human eyes and can be recovered when needed. Most of the existing image steganography methods have low hiding robustness when the container images affected by distortion. Such as Gaussian noise and lossy compression. This paper proposed PRIS to improve the robustness of image steganography, it based on invertible neural networks, and put two enhance modules before and after the extraction process with a 3-step training strategy. Moreover, rounding error is considered which is always ignored by existing methods, but actually it is unavoidable in practical. A gradient approximation function (GAF) is also proposed to overcome the undifferentiable issue of rounding distortion. Experimental results show that our PRIS outperforms the state-of-the-art robust image steganography method in both robustness and practicability. Codes are available at https://github.com/yanghangAI/PRIS, demonstration of our model in practical at this http URL","creator":"Hang Yang, Yitian Xu, Xuhua Liu, Xiaodong Ma"},{"id":"2309.14053","slug":"revisiting-lars-for-large-batch-training-generalization-of-neural-networks-arxiv-2309-14053v2-cs-lg-updated","title":"Revisiting LARS for Large Batch Training Generalization of Neural Networks.","link":"http://arxiv.org/abs/2309.14053","abstract":"LARS and LAMB have emerged as prominent techniques in Large Batch Learning (LBL) to ensure training stability in AI. Convergence stability is a challenge in LBL, where the AI agent usually gets trapped in the sharp minimizer. To address this challenge, warm-up is an efficient technique, but it lacks a strong theoretical foundation. Specifically, the warm-up process often reduces gradients in the early phase, inadvertently preventing the agent from escaping the sharp minimizer early on. In light of this situation, we conduct empirical experiments to analyze the behaviors of LARS and LAMB with and without a warm-up strategy. Our analyses give a comprehensive insight into the behaviors of LARS, LAMB, and the necessity of a warm-up technique in LBL, including an explanation of their failure in many cases. Building upon these insights, we propose a novel algorithm called Time Varying LARS (TVLARS), which facilitates robust training in the initial phase without the need for warm-up. A configurable sigmoid-like function is employed in TVLARS to replace the warm-up process to enhance training stability. Moreover, TVLARS stimulates gradient exploration in the early phase, thus allowing it to surpass the sharp minimizes early on and gradually transition to LARS and achieving robustness of LARS in the latter phases. Extensive experimental evaluations reveal that TVLARS consistently outperforms LARS and LAMB in most cases, with improvements of up to 2% in classification scenarios. Notably, in every case of self-supervised learning, TVLARS dominates LARS and LAMB with performance improvements of up to 10%.","creator":"Khoi Do, Duong Nguyen, Hoa Nguyen, Long Tran-Thanh, Quoc-Viet Pham"},{"id":"2309.16064","slug":"masked-autoencoders-are-scalable-learners-of-cellular-morphology-arxiv-2309-16064v2-cs-cv-updated","title":"Masked Autoencoders are Scalable Learners of Cellular Morphology.","link":"http://arxiv.org/abs/2309.16064","abstract":"Inferring biological relationships from cellular phenotypes in high-content microscopy screens provides significant opportunity and challenge in biological research. Prior results have shown that deep vision models can capture biological signal better than hand-crafted features. This work explores how self-supervised deep learning approaches scale when training larger models on larger microscopy datasets. Our results show that both CNN- and ViT-based masked autoencoders significantly outperform weakly supervised baselines. At the high-end of our scale, a ViT-L/8 trained on over 3.5-billion unique crops sampled from 93-million microscopy images achieves relative improvements as high as 28% over our best weakly supervised baseline at inferring known biological relationships curated from public databases. Relevant code and select models released with this work can be found at: https://github.com/recursionpharma/maes_microscopy.","creator":"Oren Kraus, Kian Kenyon-Dean, Saber Saberian, Maryam Fallah, Peter McLean, Jess Leung, Vasudev Sharma, Ayla Khan, Jia Balakrishnan, Safiye Celik, Maciej Sypetkowski, Chi Vicky Cheng, Kristen Morse, Maureen Makes, Ben Mabey, Berton Earnshaw"},{"id":"2310.01837","slug":"extending-cam-based-xai-methods-for-remote-sensing-imagery-segmentation-arxiv-2310-01837v2-cs-cv-updated","title":"Extending CAM-based XAI methods for Remote Sensing Imagery Segmentation.","link":"http://arxiv.org/abs/2310.01837","abstract":"Current AI-based methods do not provide comprehensible physical interpretations of the utilized data, extracted features, and predictions/inference operations. As a result, deep learning models trained using high-resolution satellite imagery lack transparency and explainability and can be merely seen as a black box, which limits their wide-level adoption. Experts need help understanding the complex behavior of AI models and the underlying decision-making process. The explainable artificial intelligence (XAI) field is an emerging field providing means for robust, practical, and trustworthy deployment of AI models. Several XAI techniques have been proposed for image classification tasks, whereas the interpretation of image segmentation remains largely unexplored. This paper offers to bridge this gap by adapting the recent XAI classification algorithms and making them usable for muti-class image segmentation, where we mainly focus on buildings' segmentation from high-resolution satellite images. To benchmark and compare the performance of the proposed approaches, we introduce a new XAI evaluation methodology and metric based on \"Entropy\" to measure the model uncertainty. Conventional XAI evaluation methods rely mainly on feeding area-of-interest regions from the image back to the pre-trained (utility) model and then calculating the average change in the probability of the target class. Those evaluation metrics lack the needed robustness, and we show that using Entropy to monitor the model uncertainty in segmenting the pixels within the target class is more suitable. We hope this work will pave the way for additional XAI research for image segmentation and applications in the remote sensing discipline.","creator":"Abdul Karim Gizzini, Mustafa Shukor, Ali J. Ghandour"},{"id":"2310.02071","slug":"towards-end-to-end-embodied-decision-making-via-multi-modal-large-language-model-explorations-with-gpt4-vision-and-beyond-arxiv-2310-02071v4-cs-ai-updated","title":"Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond.","link":"http://arxiv.org/abs/2310.02071","abstract":"In this study, we explore the potential of Multimodal Large Language Models (MLLMs) in improving embodied decision-making processes for agents. While Large Language Models (LLMs) have been widely used due to their advanced reasoning skills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual understanding and reasoning capabilities. We investigate whether state-of-the-art MLLMs can handle embodied decision-making in an end-to-end manner and whether collaborations between LLMs and MLLMs can enhance decision-making. To address these questions, we introduce a new benchmark called PCA-EVAL, which evaluates embodied decision-making from the perspectives of Perception, Cognition, and Action. Additionally, we propose HOLMES, a multi-agent cooperation framework that allows LLMs to leverage MLLMs and APIs to gather multimodal information for informed decision-making. We compare end-to-end embodied decision-making and HOLMES on our benchmark and find that the GPT4-Vision model demonstrates strong end-to-end embodied decision-making abilities, outperforming GPT4-HOLMES in terms of average decision accuracy (+3%). However, this performance is exclusive to the latest GPT4-Vision model, surpassing the open-source state-of-the-art MLLM by 26%. Our results indicate that powerful MLLMs like GPT4-Vision hold promise for decision-making in embodied agents, offering new avenues for MLLM research. Code and data are open at https://github.com/pkunlp-icler/PCA-EVAL/.","creator":"Liang Chen, Yichi Zhang, Shuhuai Ren, Haozhe Zhao, Zefan Cai, Yuchi Wang, Peiyi Wang, Tianyu Liu, Baobao Chang"},{"id":"2310.03059","slug":"point-peft-parameter-efficient-fine-tuning-for-3d-pre-trained-models-arxiv-2310-03059v3-cs-cv-updated","title":"Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models.","link":"http://arxiv.org/abs/2310.03059","abstract":"The popularity of pre-trained large models has revolutionized downstream tasks across diverse fields, such as language, vision, and multi-modality. To minimize the adaption cost for downstream tasks, many Parameter-Efficient Fine-Tuning (PEFT) techniques are proposed for language and 2D image pre-trained models. However, the specialized PEFT method for 3D pre-trained models is still under-explored. To this end, we introduce Point-PEFT, a novel framework for adapting point cloud pre-trained models with minimal learnable parameters. Specifically, for a pre-trained 3D model, we freeze most of its parameters, and only tune the newly added PEFT modules on downstream tasks, which consist of a Point-prior Prompt and a Geometry-aware Adapter. The Point-prior Prompt adopts a set of learnable prompt tokens, for which we propose to construct a memory bank with domain-specific knowledge, and utilize a parameter-free attention to enhance the prompt tokens. The Geometry-aware Adapter aims to aggregate point cloud features within spatial neighborhoods to capture fine-grained geometric information through local interactions. Extensive experiments indicate that our Point-PEFT can achieve better performance than the full fine-tuning on various downstream tasks, while using only 5% of the trainable parameters, demonstrating the efficiency and effectiveness of our approach. Code will be released at https://github.com/Even-JK/PEFT-3D.","creator":"Ivan Tang, Ray Zhang, Zoey Guo, Dong Wang, Zhigang Wang, Bin Zhao, Xuelong Li"},{"id":"2310.03211","slug":"on-the-performance-of-multimodal-language-models-arxiv-2310-03211v2-cs-cl-updated","title":"On the Performance of Multimodal Language Models.","link":"http://arxiv.org/abs/2310.03211","abstract":"Instruction-tuned large language models (LLMs) have demonstrated promising zero-shot generalization capabilities across various downstream tasks. Recent research has introduced multimodal capabilities to LLMs by integrating independently pretrained vision encoders through model grafting. These multimodal variants undergo instruction tuning, similar to LLMs, enabling effective zero-shot generalization for multimodal tasks. This study conducts a comparative analysis of different multimodal instruction tuning approaches and evaluates their performance across a range of tasks, including complex reasoning, conversation, image captioning, multiple-choice questions (MCQs), and binary classification. Through rigorous benchmarking and ablation experiments, we reveal key insights for guiding architectural choices when incorporating multimodal capabilities into LLMs. However, current approaches have limitations; they do not sufficiently address the need for a diverse multimodal instruction dataset, which is crucial for enhancing task generalization. Additionally, they overlook issues related to truthfulness and factuality when generating responses. These findings illuminate current methodological constraints in adapting language models for image comprehension and provide valuable guidance for researchers and practitioners seeking to harness multimodal versions of LLMs.","creator":"Utsav Garg, Erhan Bas"},{"id":"2310.04438","slug":"a-brief-history-of-prompt-leveraging-language-models-through-advanced-prompting-arxiv-2310-04438v2-cs-cl-updated","title":"A Brief History of Prompt: Leveraging Language Models. (Through Advanced Prompting).","link":"http://arxiv.org/abs/2310.04438","abstract":"This paper presents a comprehensive exploration of the evolution of prompt engineering and generation in the field of natural language processing (NLP). Starting from the early language models and information retrieval systems, we trace the key developments that have shaped prompt engineering over the years. The introduction of attention mechanisms in 2015 revolutionized language understanding, leading to advancements in controllability and context-awareness. Subsequent breakthroughs in reinforcement learning techniques further enhanced prompt engineering, addressing issues like exposure bias and biases in generated text. We examine the significant contributions in 2018 and 2019, focusing on fine-tuning strategies, control codes, and template-based generation. The paper also discusses the growing importance of fairness, human-AI collaboration, and low-resource adaptation. In 2020 and 2021, contextual prompting and transfer learning gained prominence, while 2022 and 2023 witnessed the emergence of advanced techniques like unsupervised pre-training and novel reward shaping. Throughout the paper, we reference specific research studies that exemplify the impact of various developments on prompt engineering. The journey of prompt engineering continues, with ethical considerations being paramount for the responsible and inclusive future of AI systems.","creator":"Golam Md Muktadir"},{"id":"2310.04486","slug":"t-rep-representation-learning-for-time-series-using-time-embeddings-arxiv-2310-04486v2-cs-lg-updated","title":"T-Rep: Representation Learning for Time Series using Time-Embeddings.","link":"http://arxiv.org/abs/2310.04486","abstract":"Multivariate time series present challenges to standard machine learning techniques, as they are often unlabeled, high dimensional, noisy, and contain missing data. To address this, we propose T-Rep, a self-supervised method to learn time series representations at a timestep granularity. T-Rep learns vector embeddings of time alongside its feature extractor, to extract temporal features such as trend, periodicity, or distribution shifts from the signal. These time-embeddings are leveraged in pretext tasks, to incorporate smooth and fine-grained temporal dependencies in the representations, as well as reinforce robustness to missing data. We evaluate T-Rep on downstream classification, forecasting, and anomaly detection tasks. It is compared to existing self-supervised algorithms for time series, which it outperforms in all three tasks. We test T-Rep in missing data regimes, where it proves more resilient than its counterparts. Finally, we provide latent space visualisation experiments, highlighting the interpretability of the learned representations.","creator":"Archibald Fraikin, Adrien Bennetot, St&#xe9;phanie Allassonni&#xe8;re"},{"id":"2310.05898","slug":"lion-secretly-solves-constrained-optimization-as-lyapunov-predicts-arxiv-2310-05898v4-cs-lg-updated","title":"Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts.","link":"http://arxiv.org/abs/2310.05898","abstract":"Lion (Evolved Sign Momentum), a new optimizer discovered through program search, has shown promising results in training large AI models. It performs comparably or favorably to AdamW but with greater memory efficiency. As we can expect from the results of a random search program, Lion incorporates elements from several existing algorithms, including signed momentum, decoupled weight decay, Polak, and Nesterov momentum, but does not fit into any existing category of theoretically grounded optimizers. Thus, even though Lion appears to perform well as a general-purpose optimizer for a wide range of tasks, its theoretical basis remains uncertain. This lack of theoretical clarity limits opportunities to further enhance and expand Lion's efficacy.  This work aims to demystify Lion. Based on both continuous-time and discrete-time analysis, we demonstrate that Lion is a theoretically novel and principled approach for minimizing a general loss function $f(x)$ while enforcing a bound constraint $\\|x\\|_\\infty \\leq 1/\\lambda$. Lion achieves this through the incorporation of decoupled weight decay, where $\\lambda$ represents the weight decay coefficient. Our analysis is made possible by the development of a new Lyapunov function for the Lion updates. It applies to a broader family of Lion-$\\kappa$ algorithms, where the $\\text{sign}(\\cdot)$ operator in Lion is replaced by the subgradient of a convex function $\\kappa$, leading to the solution of a general composite optimization problem of $\\min_x f(x) + \\kappa^*(x)$. Our findings provide valuable insights into the dynamics of Lion and pave the way for further improvements and extensions of Lion-related algorithms.","creator":"Lizhang Chen, Bo Liu, Kaizhao Liang, Qiang Liu"},{"id":"2310.08559","slug":"phenomenal-yet-puzzling-testing-inductive-reasoning-capabilities-of-language-models-with-hypothesis-refinement-arxiv-2310-08559v2-cs-cl-updated","title":"Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement.","link":"http://arxiv.org/abs/2310.08559","abstract":"The ability to derive underlying principles from a handful of observations and then generalize to novel situations -- known as inductive reasoning -- is central to human intelligence. Prior work suggests that language models (LMs) often fall short on inductive reasoning, despite achieving impressive success on research benchmarks. In this work, we conduct a systematic study of the inductive reasoning capabilities of LMs through iterative hypothesis refinement, a technique that more closely mirrors the human inductive process than standard input-output prompting. Iterative hypothesis refinement employs a three-step process: proposing, selecting, and refining hypotheses in the form of textual rules. By examining the intermediate rules, we observe that LMs are phenomenal hypothesis proposers (i.e., generating candidate rules), and when coupled with a (task-specific) symbolic interpreter that is able to systematically filter the proposed set of rules, this hybrid approach achieves strong results across inductive reasoning benchmarks that require inducing causal relations, language-like instructions, and symbolic concepts. However, they also behave as puzzling inductive reasoners, showing notable performance gaps between rule induction (i.e., identifying plausible rules) and rule application (i.e., applying proposed rules to instances), suggesting that LMs are proposing hypotheses without being able to actually apply the rules. Through empirical and human analyses, we further reveal several discrepancies between the inductive reasoning processes of LMs and humans, shedding light on both the potentials and limitations of using LMs in inductive reasoning tasks.","creator":"Linlu Qiu, Liwei Jiang, Ximing Lu, Melanie Sclar, Valentina Pyatkin, Chandra Bhagavatula, Bailin Wang, Yoon Kim, Yejin Choi, Nouha Dziri, Xiang Ren"},{"id":"2310.08659","slug":"loftq-lora-fine-tuning-aware-quantization-for-large-language-models-arxiv-2310-08659v4-cs-cl-updated","title":"LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models.","link":"http://arxiv.org/abs/2310.08659","abstract":"Quantization is an indispensable technique for serving Large Language Models (LLMs) and has recently found its way into LoRA fine-tuning. In this work we focus on the scenario where quantization and LoRA fine-tuning are applied together on a pre-trained model. In such cases it is common to observe a consistent gap in the performance on downstream tasks between full fine-tuning and quantization plus LoRA fine-tuning approach. In response, we propose LoftQ (LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that simultaneously quantizes an LLM and finds a proper low-rank initialization for LoRA fine-tuning. Such an initialization alleviates the discrepancy between the quantized and full-precision model and significantly improves generalization in downstream tasks. We evaluate our method on natural language understanding, question answering, summarization, and natural language generation tasks. Experiments show that our method is highly effective and outperforms existing quantization methods, especially in the challenging 2-bit and 2/4-bit mixed precision regimes. The code is available on https://github.com/yxli2123/LoftQ.","creator":"Yixiao Li, Yifan Yu, Chen Liang, Pengcheng He, Nikos Karampatziakis, Weizhu Chen, Tuo Zhao"},{"id":"2310.08992","slug":"codechain-towards-modular-code-generation-through-chain-of-self-revisions-with-representative-sub-modules-arxiv-2310-08992v2-cs-ai-updated","title":"CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules.","link":"http://arxiv.org/abs/2310.08992","abstract":"Large Language Models (LLMs) have already become quite proficient at solving simpler programming tasks like those in HumanEval or MBPP benchmarks. However, solving more complex and competitive programming tasks is still quite challenging for these models - possibly due to their tendency to generate solutions as monolithic code blocks instead of decomposing them into logical sub-tasks and sub-modules. On the other hand, experienced programmers instinctively write modularized code with abstraction for solving complex tasks, often reusing previously developed modules. To address this gap, we propose CodeChain, a novel framework for inference that elicits modularized code generation through a chain of self-revisions, each being guided by some representative sub-modules generated in previous iterations. Concretely, CodeChain first instructs the LLM to generate modularized codes through chain-of-thought prompting. Then it applies a chain of self-revisions by iterating the two steps: 1) extracting and clustering the generated sub-modules and selecting the cluster representatives as the more generic and re-usable implementations, and 2) augmenting the original chain-of-thought prompt with these selected module-implementations and instructing the LLM to re-generate new modularized solutions. We find that by naturally encouraging the LLM to reuse the previously developed and verified sub-modules, CodeChain can significantly boost both modularity as well as correctness of the generated solutions, achieving relative pass@1 improvements of 35% on APPS and 76% on CodeContests. It is shown to be effective on both OpenAI LLMs as well as open-sourced LLMs like WizardCoder. We also conduct comprehensive ablation studies with different methods of prompting, number of clusters, model sizes, program qualities, etc., to provide useful insights that underpin CodeChain's success.","creator":"Hung Le, Hailin Chen, Amrita Saha, Akash Gokul, Doyen Sahoo, Shafiq Joty"},{"id":"2310.09843","slug":"cocoformer-a-controllable-feature-rich-polyphonic-music-generation-method-arxiv-2310-09843v2-cs-sd-updated","title":"CoCoFormer: A controllable feature-rich polyphonic music generation method.","link":"http://arxiv.org/abs/2310.09843","abstract":"This paper explores the modeling method of polyphonic music sequence. Due to the great potential of Transformer models in music generation, controllable music generation is receiving more attention. In the task of polyphonic music, current controllable generation research focuses on controlling the generation of chords, but lacks precise adjustment for the controllable generation of choral music textures. This paper proposed Condition Choir Transformer (CoCoFormer) which controls the output of the model by controlling the chord and rhythm inputs at a fine-grained level. In this paper, the self-supervised method improves the loss function and performs joint training through conditional control input and unconditional input training. In order to alleviate the lack of diversity on generated samples caused by the teacher forcing training, this paper added an adversarial training method. CoCoFormer enhances model performance with explicit and implicit inputs to chords and rhythms. In this paper, the experiments proves that CoCoFormer has reached the current better level than current models. On the premise of specifying the polyphonic music texture, the same melody can also be generated in a variety of ways.","creator":"Jiuyang Zhou, Tengfei Niu, Hong Zhu, Xingping Wang"},{"id":"2310.11676","slug":"prem-a-simple-yet-effective-approach-for-node-level-graph-anomaly-detection-arxiv-2310-11676v3-cs-lg-updated","title":"PREM: A Simple Yet Effective Approach for Node-Level Graph Anomaly Detection.","link":"http://arxiv.org/abs/2310.11676","abstract":"Node-level graph anomaly detection (GAD) plays a critical role in identifying anomalous nodes from graph-structured data in various domains such as medicine, social networks, and e-commerce. However, challenges have arisen due to the diversity of anomalies and the dearth of labeled data. Existing methodologies - reconstruction-based and contrastive learning - while effective, often suffer from efficiency issues, stemming from their complex objectives and elaborate modules. To improve the efficiency of GAD, we introduce a simple method termed PREprocessing and Matching (PREM for short). Our approach streamlines GAD, reducing time and memory consumption while maintaining powerful anomaly detection capabilities. Comprising two modules - a pre-processing module and an ego-neighbor matching module - PREM eliminates the necessity for message-passing propagation during training, and employs a simple contrastive loss, leading to considerable reductions in training time and memory usage. Moreover, through rigorous evaluations of five real-world datasets, our method demonstrated robustness and effectiveness. Notably, when validated on the ACM dataset, PREM achieved a 5% improvement in AUC, a 9-fold increase in training speed, and sharply reduce memory usage compared to the most efficient baseline.","creator":"Junjun Pan, Yixin Liu, Yizhen Zheng, Shirui Pan"},{"id":"2310.14714","slug":"batteryml-an-open-source-platform-for-machine-learning-on-battery-degradation-arxiv-2310-14714v2-cs-lg-updated","title":"BatteryML:An Open-source platform for Machine Learning on Battery Degradation.","link":"http://arxiv.org/abs/2310.14714","abstract":"Battery degradation remains a pivotal concern in the energy storage domain, with machine learning emerging as a potent tool to drive forward insights and solutions. However, this intersection of electrochemical science and machine learning poses complex challenges. Machine learning experts often grapple with the intricacies of battery science, while battery researchers face hurdles in adapting intricate models tailored to specific datasets. Beyond this, a cohesive standard for battery degradation modeling, inclusive of data formats and evaluative benchmarks, is conspicuously absent. Recognizing these impediments, we present BatteryML - a one-step, all-encompass, and open-source platform designed to unify data preprocessing, feature extraction, and the implementation of both traditional and state-of-the-art models. This streamlined approach promises to enhance the practicality and efficiency of research applications. BatteryML seeks to fill this void, fostering an environment where experts from diverse specializations can collaboratively contribute, thus elevating the collective understanding and advancement of battery research.The code for our project is publicly available on GitHub at https://github.com/microsoft/BatteryML.","creator":"Han Zhang, Xiaofan Gui, Shun Zheng, Ziheng Lu, Yuqi Li, Jiang Bian"},{"id":"2310.17025","slug":"netfound-foundation-model-for-network-security-arxiv-2310-17025v2-cs-ni-updated","title":"netFound: Foundation Model for Network Security.","link":"http://arxiv.org/abs/2310.17025","abstract":"In ML for network security, traditional workflows rely on high-quality labeled data and manual feature engineering, but limited datasets and human expertise hinder feature selection, leading to models struggling to capture crucial relationships and generalize effectively. Inspired by recent advancements in ML application domains like GPT-4 and Vision Transformers, we have developed netFound, a foundational model for network security. This model undergoes pre-training using self-supervised algorithms applied to readily available unlabeled network packet traces. netFound's design incorporates hierarchical and multi-modal attributes of network traffic, effectively capturing hidden networking contexts, including application logic, communication protocols, and network conditions.  With this pre-trained foundation in place, we can fine-tune netFound for a wide array of downstream tasks, even when dealing with low-quality, limited, and noisy labeled data. Our experiments demonstrate netFound's superiority over existing state-of-the-art ML-based solutions across three distinct network downstream tasks: traffic classification, network intrusion detection, and APT detection. Furthermore, we emphasize netFound's robustness against noisy and missing labels, as well as its ability to generalize across temporal variations and diverse network environments. Finally, through a series of ablation studies, we provide comprehensive insights into how our design choices enable netFound to more effectively capture hidden networking contexts, further solidifying its performance and utility in network security applications.","creator":"Satyandra Guthula, Navya Battula, Roman Beltiukov, Wenbo Guo, Arpit Gupta"},{"id":"2310.17639","slug":"in-context-learning-dynamics-with-random-binary-sequences-arxiv-2310-17639v2-cs-ai-updated","title":"In-Context Learning Dynamics with Random Binary Sequences.","link":"http://arxiv.org/abs/2310.17639","abstract":"Large language models (LLMs) trained on huge corpora of text datasets demonstrate intriguing capabilities, achieving state-of-the-art performance on tasks they were not explicitly trained for. The precise nature of LLM capabilities is often mysterious, and different prompts can elicit different capabilities through in-context learning. We propose a framework that enables us to analyze in-context learning dynamics to understand latent concepts underlying LLMs' behavioral patterns. This provides a more nuanced understanding than success-or-failure evaluation benchmarks, but does not require observing internal activations as a mechanistic interpretation of circuits would. Inspired by the cognitive science of human randomness perception, we use random binary sequences as context and study dynamics of in-context learning by manipulating properties of context data, such as sequence length. In the latest GPT-3.5+ models, we find emergent abilities to generate seemingly random numbers and learn basic formal languages, with striking in-context learning dynamics where model outputs transition sharply from seemingly random behaviors to deterministic repetition.","creator":"Eric J. Bigelow, Ekdeep Singh Lubana, Robert P. Dick, Hidenori Tanaka, Tomer D. Ullman"},{"id":"2310.18021","slug":"formalgeo-the-first-step-toward-human-like-imo-level-geometric-automated-reasoning-arxiv-2310-18021v3-cs-ai-updated","title":"FormalGeo: The First Step Toward Human-like IMO-level Geometric Automated Reasoning.","link":"http://arxiv.org/abs/2310.18021","abstract":"This is the first paper in a series of work we have accomplished over the past three years. In this paper, we have constructed a complete and compatible formal plane geometry system. This will serve as a crucial bridge between IMO-level plane geometry challenges and readable AI automated reasoning. Within this formal framework, we have been able to seamlessly integrate modern AI models with our formal system. AI is now capable of providing deductive reasoning solutions to IMO-level plane geometry problems, just like handling other natural languages, and these proofs are readable, traceable, and verifiable. We propose the geometry formalization theory (GFT) to guide the development of the geometry formal system. Based on the GFT, we have established the FormalGeo, which consists of 88 geometric predicates and 196 theorems. It can represent, validate, and solve IMO-level geometry problems. we also have crafted the FGPS (formal geometry problem solver) in Python. It serves as both an interactive assistant for verifying problem-solving processes and an automated problem solver. We've annotated the formalgeo7k and formalgeo-imo datasets. The former contains 6,891 (expand to 133,818 through data augmentation) geometry problems, while the latter includes 18 (expand to 2,627 and continuously increasing) IMO-level challenging geometry problems. All annotated problems include detailed formal language descriptions and solutions. Implementation of the formal system and experiments validate the correctness and utility of the GFT. The backward depth-first search method only yields a 2.42% problem-solving failure rate, and we can incorporate deep learning techniques to achieve lower one. The source code of FGPS and datasets are available at https://github.com/BitSecret/FGPS.","creator":"Xiaokai Zhang, Na Zhu, Yiming He, Jia Zou, Qike Huang, Xiaoxiao Jin, Yanjun Guo, Chenyang Mao, Zhe Zhu, Dengfeng Yue, Fangzhen Zhu, Yang Li, Yifan Wang, Yiwen Huang, Runan Wang, Cheng Qin, Zhenbing Zeng, Shaorong Xie, Xiangfeng Luo, Tuo Leng"},{"id":"2310.20246","slug":"breaking-language-barriers-in-multilingual-mathematical-reasoning-insights-and-observations-arxiv-2310-20246v4-cs-cl-updated","title":"Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations.","link":"http://arxiv.org/abs/2310.20246","abstract":"Existing research predominantly focuses on developing powerful language learning models (LLMs) for mathematical reasoning within monolingual languages, with few explorations in preserving efficacy in a multilingual context. To bridge this gap, this paper pioneers exploring and training powerful Multilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we construct the first multilingual math reasoning instruction dataset, MGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue of training data scarcity in xMR tasks. Based on the collected dataset, we propose different training strategies to build powerful xMR LLMs, named MathOctopus, notably outperform conventional open-source LLMs and exhibit superiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B reaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond remarkable results, we unearth several pivotal observations and insights from extensive experiments: (1) When extending the rejection sampling strategy to the multilingual context, it proves effective for model performances, albeit limited. (2) Employing parallel corpora for math Supervised Fine-Tuning (SFT) across multiple languages not only significantly enhances model performance multilingually but also elevates their monolingual performance. This indicates that crafting multilingual corpora can be regarded as a vital strategy for enhancing model performance in a specific language, especially in mathematical reasoning tasks. For instance, MathOctopus-7B improves its counterparts that trained on English from 42.2% to 50.8% on GSM8K testset.","creator":"Nuo Chen, Zinan Zheng, Ning Wu, Ming Gong, Yangqiu Song, Dongmei Zhang, Jia Li"},{"id":"2310.20323","slug":"semanticboost-elevating-motion-generation-with-augmented-textual-cues-arxiv-2310-20323v2-cs-cv-updated","title":"SemanticBoost: Elevating Motion Generation with Augmented Textual Cues.","link":"http://arxiv.org/abs/2310.20323","abstract":"Current techniques face difficulties in generating motions from intricate semantic descriptions, primarily due to insufficient semantic annotations in datasets and weak contextual understanding. To address these issues, we present SemanticBoost, a novel framework that tackles both challenges simultaneously. Our framework comprises a Semantic Enhancement module and a Context-Attuned Motion Denoiser (CAMD). The Semantic Enhancement module extracts supplementary semantics from motion data, enriching the dataset's textual description and ensuring precise alignment between text and motion data without depending on large language models. On the other hand, the CAMD approach provides an all-encompassing solution for generating high-quality, semantically consistent motion sequences by effectively capturing context information and aligning the generated motion with the given textual descriptions. Distinct from existing methods, our approach can synthesize accurate orientational movements, combined motions based on specific body part descriptions, and motions generated from complex, extended sentences. Our experimental results demonstrate that SemanticBoost, as a diffusion-based method, outperforms auto-regressive-based techniques, achieving cutting-edge performance on the Humanml3D dataset while maintaining realistic and smooth motion generation quality.","creator":"Xin He, Shaoli Huang, Xiaohang Zhan, Chao Weng, Ying Shan"},{"id":"2311.05332","slug":"on-the-road-with-gpt-4v-ision-early-explorations-of-visual-language-model-on-autonomous-driving-arxiv-2311-05332v2-cs-cv-updated","title":"On the Road with GPT-4V(ision): Early Explorations of Visual-Language Model on Autonomous Driving.","link":"http://arxiv.org/abs/2311.05332","abstract":"The pursuit of autonomous driving technology hinges on the sophisticated integration of perception, decision-making, and control systems. Traditional approaches, both data-driven and rule-based, have been hindered by their inability to grasp the nuance of complex driving environments and the intentions of other road users. This has been a significant bottleneck, particularly in the development of common sense reasoning and nuanced scene understanding necessary for safe and reliable autonomous driving. The advent of Visual Language Models (VLM) represents a novel frontier in realizing fully autonomous vehicle driving. This report provides an exhaustive evaluation of the latest state-of-the-art VLM, GPT-4V(ision), and its application in autonomous driving scenarios. We explore the model's abilities to understand and reason about driving scenes, make decisions, and ultimately act in the capacity of a driver. Our comprehensive tests span from basic scene recognition to complex causal reasoning and real-time decision-making under varying conditions. Our findings reveal that GPT-4V demonstrates superior performance in scene understanding and causal reasoning compared to existing autonomous systems. It showcases the potential to handle out-of-distribution scenarios, recognize intentions, and make informed decisions in real driving contexts. However, challenges remain, particularly in direction discernment, traffic light recognition, vision grounding, and spatial reasoning tasks. These limitations underscore the need for further research and development. Project is now available on GitHub for interested parties to access and utilize: \\url{https://github.com/PJLab-ADG/GPT4V-AD-Exploration}","creator":"Licheng Wen, Xuemeng Yang, Daocheng Fu, Xiaofeng Wang, Pinlong Cai, Xin Li, Tao Ma, Yingxuan Li, Linran Xu, Dengke Shang, Zheng Zhu, Shaoyan Sun, Yeqi Bai, Xinyu Cai, Min Dou, Shuanglu Hu, Botian Shi, Yu Qiao"},{"id":"2311.06864","slug":"understanding-practices-around-computational-news-discovery-tools-in-the-domain-of-science-journalism-arxiv-2311-06864v2-cs-hc-updated","title":"Understanding Practices around Computational News Discovery Tools in the Domain of Science Journalism.","link":"http://arxiv.org/abs/2311.06864","abstract":"Science and technology journalists today face challenges in finding newsworthy leads due to increased workloads, reduced resources, and expanding scientific publishing ecosystems. Given this context, we explore computational methods to aid these journalists' news discovery in terms of time-efficiency and agency. In particular, we prototyped three computational information subsidies into an interactive tool that we used as a probe to better understand how such a tool may offer utility or more broadly shape the practices of professional science journalists. Our findings highlight central considerations around science journalists' agency, context, and responsibilities that such tools can influence and could account for in design. Based on this, we suggest design opportunities for greater and longer-term user agency; incorporating contextual, personal and collaborative notions of newsworthiness; and leveraging flexible interfaces and generative models. Overall, our findings contribute a richer view of the sociotechnical system around computational news discovery tools, and suggest ways to improve such tools to better support the practices of science journalists.","creator":"Sachita Nishal, Jasmine Sinchai, Nicholas Diakopoulos"},{"id":"2311.08379","slug":"scheming-ais-will-ais-fake-alignment-during-training-in-order-to-get-power-arxiv-2311-08379v3-cs-cy-updated","title":"Scheming AIs: Will AIs fake alignment during training in order to get power?.","link":"http://arxiv.org/abs/2311.08379","abstract":"This report examines whether advanced AIs that perform well in training will be doing so in order to gain power later -- a behavior I call \"scheming\" (also sometimes called \"deceptive alignment\"). I conclude that scheming is a disturbingly plausible outcome of using baseline machine learning methods to train goal-directed AIs sophisticated enough to scheme (my subjective probability on such an outcome, given these conditions, is roughly 25%). In particular: if performing well in training is a good strategy for gaining power (as I think it might well be), then a very wide variety of goals would motivate scheming -- and hence, good training performance. This makes it plausible that training might either land on such a goal naturally and then reinforce it, or actively push a model's motivations towards such a goal as an easy way of improving performance. What's more, because schemers pretend to be aligned on tests designed to reveal their motivations, it may be quite difficult to tell whether this has occurred. However, I also think there are reasons for comfort. In particular: scheming may not actually be such a good strategy for gaining power; various selection pressures in training might work against schemer-like goals (for example, relative to non-schemers, schemers need to engage in extra instrumental reasoning, which might harm their training performance); and we may be able to increase such pressures intentionally. The report discusses these and a wide variety of other considerations in detail, and it suggests an array of empirical research directions for probing the topic further.","creator":"Joe Carlsmith"},{"id":"2311.09312","slug":"h-packer-holographic-rotationally-equivariant-convolutional-neural-network-for-protein-side-chain-packing-arxiv-2311-09312v2-q-bio-bm-updated","title":"H-Packer: Holographic Rotationally Equivariant Convolutional Neural Network for Protein Side-Chain Packing.","link":"http://arxiv.org/abs/2311.09312","abstract":"Accurately modeling protein 3D structure is essential for the design of functional proteins. An important sub-task of structure modeling is protein side-chain packing: predicting the conformation of side-chains (rotamers) given the protein's backbone structure and amino-acid sequence. Conventional approaches for this task rely on expensive sampling procedures over hand-crafted energy functions and rotamer libraries. Recently, several deep learning methods have been developed to tackle the problem in a data-driven way, albeit with vastly different formulations (from image-to-image translation to directly predicting atomic coordinates). Here, we frame the problem as a joint regression over the side-chains' true degrees of freedom: the dihedral $\\chi$ angles. We carefully study possible objective functions for this task, while accounting for the underlying symmetries of the task. We propose Holographic Packer (H-Packer), a novel two-stage algorithm for side-chain packing built on top of two light-weight rotationally equivariant neural networks. We evaluate our method on CASP13 and CASP14 targets. H-Packer is computationally efficient and shows favorable performance against conventional physics-based algorithms and is competitive against alternative deep learning solutions.","creator":"Gian Marco Visani, William Galvin, Michael Neal Pun, Armita Nourmohammad"},{"id":"2311.09790","slug":"breaking-boundaries-balancing-performance-and-robustness-in-deep-wireless-traffic-forecasting-arxiv-2311-09790v3-cs-lg-updated","title":"Breaking Boundaries: Balancing Performance and Robustness in Deep Wireless Traffic Forecasting.","link":"http://arxiv.org/abs/2311.09790","abstract":"Balancing the trade-off between accuracy and robustness is a long-standing challenge in time series forecasting. While most of existing robust algorithms have achieved certain suboptimal performance on clean data, sustaining the same performance level in the presence of data perturbations remains extremely hard. In this paper, we study a wide array of perturbation scenarios and propose novel defense mechanisms against adversarial attacks using real-world telecom data. We compare our strategy against two existing adversarial training algorithms under a range of maximal allowed perturbations, defined using $\\ell_{\\infty}$-norm, $\\in [0.1,0.4]$. Our findings reveal that our hybrid strategy, which is composed of a classifier to detect adversarial examples, a denoiser to eliminate noise from the perturbed data samples, and a standard forecaster, achieves the best performance on both clean and perturbed data. Our optimal model can retain up to $92.02\\%$ the performance of the original forecasting model in terms of Mean Squared Error (MSE) on clean data, while being more robust than the standard adversarially trained models on perturbed data. Its MSE is 2.71$\\times$ and 2.51$\\times$ lower than those of comparing methods on normal and perturbed data, respectively. In addition, the components of our models can be trained in parallel, resulting in better computational efficiency. Our results indicate that we can optimally balance the trade-off between the performance and robustness of forecasting models by improving the classifier and denoiser, even in the presence of sophisticated and destructive poisoning attacks.","creator":"Romain Ilbert, Thai V. Hoang, Zonghua Zhang, Themis Palpanas"},{"id":"2311.10776","slug":"towards-an-automatic-ai-agent-for-reaction-condition-recommendation-in-chemical-synthesis-arxiv-2311-10776v2-cs-ir-updated","title":"Towards an Automatic AI Agent for Reaction Condition Recommendation in Chemical Synthesis.","link":"http://arxiv.org/abs/2311.10776","abstract":"Artificial intelligence (AI) for reaction condition optimization has become an important topic in the pharmaceutical industry, given that a data-driven AI model can assist drug discovery and accelerate reaction design. However, existing AI models lack the chemical insights and real-time knowledge acquisition abilities of experienced human chemists. This paper proposes a Large Language Model (LLM) empowered AI agent to bridge this gap. We put forth a novel three-phase paradigm and applied advanced intelligence-enhancement methods like in-context learning and multi-LLM debate so that the AI agent can borrow human insight and update its knowledge by searching the latest chemical literature. Additionally, we introduce a novel Coarse-label Contrastive Learning (CCL) based chemical fingerprint that greatly enhances the agent's performance in optimizing the reaction condition. With the above efforts, the proposed AI agent can autonomously generate the optimal reaction condition recommendation without any human interaction. Further, the agent is highly professional in terms of chemical reactions. It demonstrates close-to-human performance and strong generalization capability in both dry-lab and wet-lab experiments. As the first attempt in the chemical AI agent, this work goes a step further in the field of \"AI for chemistry\" and opens up new possibilities for computer-aided synthesis planning.","creator":"Kexin Chen, Junyou Li, Kunyi Wang, Yuyang Du, Jiahui Yu, Jiamin Lu, Lanqing Li, Jiezhong Qiu, Qun Fang, Pheng Ann Heng, Guangyong Chen"},{"id":"2311.12089","slug":"explaining-deep-learning-models-for-age-related-gait-classification-based-on-time-series-acceleration-arxiv-2311-12089v2-cs-lg-updated","title":"Explaining Deep Learning Models for Age-related Gait Classification based on time series acceleration.","link":"http://arxiv.org/abs/2311.12089","abstract":"Gait analysis holds significant importance in monitoring daily health, particularly among older adults. Advancements in sensor technology enable the capture of movement in real-life environments and generate big data. Machine learning, notably deep learning (DL), shows promise to use these big data in gait analysis. However, the inherent black-box nature of these models poses challenges for their clinical application. This study aims to enhance transparency in DL-based gait classification for aged-related gait patterns using Explainable Artificial Intelligence, such as SHAP.  A total of 244 subjects, comprising 129 adults and 115 older adults (age&gt;65), were included. They performed a 3-minute walking task while accelerometers were affixed to the lumbar segment L3. DL models, convolutional neural network (CNN) and gated recurrent unit (GRU), were trained using 1-stride and 8-stride accelerations, respectively, to classify adult and older adult groups. SHAP was employed to explain the models' predictions.  CNN achieved a satisfactory performance with an accuracy of 81.4% and an AUC of 0.89, and GRU demonstrated promising results with an accuracy of 84.5% and an AUC of 0.94. SHAP analysis revealed that both CNN and GRU assigned higher SHAP values to the data from vertical and walking directions, particularly emphasizing data around heel contact, spanning from the terminal swing to loading response phases. Furthermore, SHAP values indicated that GRU did not treat every stride equally.  CNN accurately distinguished between adults and older adults based on the characteristics of a single stride's data. GRU achieved accurate classification by considering the relationships and subtle differences between strides. In both models, data around heel contact emerged as most critical, suggesting differences in acceleration and deceleration patterns during walking between different age groups.","creator":"Xiaoping Zheng, Bert Otten, Michiel F Reneman, Claudine JC Lamoth"},{"id":"2311.12824","slug":"comparative-analysis-of-shear-strength-prediction-models-for-reinforced-concrete-slab-column-connections-arxiv-2311-12824v2-cs-ne-updated","title":"Comparative Analysis of Shear Strength Prediction Models for Reinforced Concrete Slab-Column Connections.","link":"http://arxiv.org/abs/2311.12824","abstract":"This research aims at comparative analysis of shear strength prediction at slab-column connection, unifying machine learning, design codes and Finite Element Analysis. Current design codes (CDCs) of ACI 318-19 (ACI), Eurocode 2 (EC2), Compressive Force Path (CFP) method, Feed Forward Neural Network (FNN) based Artificial Neural Network (ANN), PSO-based FNN (PSOFNN), and BAT algorithm-based BATFNN are used. The study is complemented with FEA of slab for validating the experimental results and machine learning predictions.In the case of hybrid models of PSOFNN and BATFNN, mean square error is used as an objective function to obtain the optimized values of the weights, that are used by Feed Forward Neural Network to perform predictions on the slab data. Seven different models of PSOFNN, BATFNN, and FNN are trained on this data and the results exhibited that PSOFNN is the best model overall. PSOFNN has the best results for SCS=1 with highest value of R as 99.37% and lowest of MSE, and MAE values of 0.0275%, and 1.214% respectively which are better than the best FNN model for SCS=4 having the values of R, MSE, and MAE as 97.464%, 0.0492%, and 1.43%, respectively.","creator":"Sarmed Wahab, Nasim Shakouri Mahmoudabadi, Sarmad Waqas, Nouman Herl, Muhammad Iqbal, Khurshid Alam, Afaq Ahmad"},{"id":"2311.13148","slug":"building-the-future-of-responsible-ai-a-reference-architecture-for-designing-large-language-model-based-agents-arxiv-2311-13148v2-cs-ai-updated","title":"Building the Future of Responsible AI: A Reference Architecture for Designing Large Language Model based Agents.","link":"http://arxiv.org/abs/2311.13148","abstract":"Large language models (LLMs) have been widely recognised as transformative artificial generative intelligence (AGI) technologies due to their capabilities to understand and generate content, including plans with reasoning capabilities. Foundation model based agents derive their autonomy from the capabilities of foundation models, which enable them to autonomously break down a given goal into a set of manageable tasks and orchestrate task execution to meet the goal. Despite the huge efforts put into building foundation model based autonomous agents, the architecture design of the agents has not yet been systematically explored. Also, while there are significant benefits of using autonomous agents for planning and execution, there are serious considerations regarding responsible AI related software quality attributes, such as security and accountability. Therefore, this paper presents a pattern-oriented reference architecture that serves as architecture design guidance and enables responsible-AI-by-design when designing foundation model based autonomous agents. We evaluate the completeness and utility of the proposed reference architecture by mapping it to the architecture of two real-world agents.","creator":"Qinghua Lu, Liming Zhu, Xiwei Xu, Zhenchang Xing, Stefan Harrer, Jon Whittle"},{"id":"2311.14552","slug":"griffon-spelling-out-all-object-locations-at-any-granularity-with-large-language-models-arxiv-2311-14552v2-cs-cv-updated","title":"Griffon: Spelling out All Object Locations at Any Granularity with Large Language Models.","link":"http://arxiv.org/abs/2311.14552","abstract":"Replicating the innate human ability to detect all objects based on free-form texts at any granularity remains a formidable challenge for Vision-Language models. Current Large Vision Language Models (LVLMs) are predominantly constrained to grounding a single, pre-existing object, relying solely on data from Referring Expression Comprehension tasks. The limitation leads to a compromise in model design, necessitating the introduction of visual expert models or the integration of customized head structures. Beyond these constraints, our research delves into the untapped potential of LVLMs and uncover their inherent capability for basic object perception, allowing them to accurately identify and locate objects of interest. Building on this insight, we introduce a novel language-prompted localization dataset designed to fully unleash the capabilities of LVLMs in integrating fine-grained object perception with precise location awareness. More importantly, we present $\\textbf{Griffon}$, a purely LVLM-based baseline, which does not require the introduction of any special tokens, expert models, or additional detection modules. It simply maintains a consistent structure with popular LVLMs by unifying data formats across various localization-related scenarios and is trained end-to-end through a well-designed pipeline. Comprehensive experiments demonstrate that $\\textbf{Griffon}$ not only achieves state-of-the-art performance on the fine-grained RefCOCO series but also approaches the capabilities of the expert model Faster RCNN on the detection benchmark MSCOCO.","creator":"Yufei Zhan, Yousong Zhu, Zhiyang Chen, Fan Yang, Ming Tang, Jinqiao Wang"},{"id":"2311.15243","slug":"id-like-prompt-learning-for-few-shot-out-of-distribution-detection-arxiv-2311-15243v2-cs-cv-updated","title":"ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection.","link":"http://arxiv.org/abs/2311.15243","abstract":"Out-of-distribution (OOD) detection methods often exploit auxiliary outliers to train model identifying OOD samples, especially discovering challenging outliers from auxiliary outliers dataset to improve OOD detection. However, they may still face limitations in effectively distinguishing between the most challenging OOD samples that are much like in-distribution (ID) data, i.e., ID-like samples. To this end, we propose a novel OOD detection framework that discovers ID-like outliers using CLIP from the vicinity space of the ID samples, thus helping to identify these most challenging OOD samples. Then a prompt learning framework is proposed that utilizes the identified ID-like outliers to further leverage the capabilities of CLIP for OOD detection. Benefiting from the powerful CLIP, we only need a small number of ID samples to learn the prompts of the model without exposing other auxiliary outlier datasets. By focusing on the most challenging ID-like OOD samples and elegantly exploiting the capabilities of CLIP, our method achieves superior few-shot learning performance on various real-world image datasets (e.g., in 4-shot OOD detection on the ImageNet-1k dataset, our method reduces the average FPR95 by 12.16% and improves the average AUROC by 2.76%, compared to state-of-the-art methods).","creator":"Yichen Bai, Zongbo Han, Changqing Zhang, Bing Cao, Xiaoheng Jiang, Qinghua Hu"},{"id":"2311.15951","slug":"replay-across-experiments-a-natural-extension-of-off-policy-rl-arxiv-2311-15951v2-cs-lg-updated","title":"Replay across Experiments: A Natural Extension of Off-Policy RL.","link":"http://arxiv.org/abs/2311.15951","abstract":"Replaying data is a principal mechanism underlying the stability and data efficiency of off-policy reinforcement learning (RL). We present an effective yet simple framework to extend the use of replays across multiple experiments, minimally adapting the RL workflow for sizeable improvements in controller performance and research iteration times. At its core, Replay Across Experiments (RaE) involves reusing experience from previous experiments to improve exploration and bootstrap learning while reducing required changes to a minimum in comparison to prior work. We empirically show benefits across a number of RL algorithms and challenging control domains spanning both locomotion and manipulation, including hard exploration tasks from egocentric vision. Through comprehensive ablations, we demonstrate robustness to the quality and amount of data available and various hyperparameter choices. Finally, we discuss how our approach can be applied more broadly across research life cycles and can increase resilience by reloading data across random seeds or hyperparameter variations.","creator":"Dhruva Tirumala, Thomas Lampe, Jose Enrique Chen, Tuomas Haarnoja, Sandy Huang, Guy Lever, Ben Moran, Tim Hertweck, Leonard Hasenclever, Martin Riedmiller, Nicolas Heess, Markus Wulfmeier"},{"id":"2311.16103","slug":"video-bench-a-comprehensive-benchmark-and-toolkit-for-evaluating-video-based-large-language-models-arxiv-2311-16103v2-cs-cv-updated","title":"Video-Bench: A Comprehensive Benchmark and Toolkit for Evaluating Video-based Large Language Models.","link":"http://arxiv.org/abs/2311.16103","abstract":"Video-based large language models (Video-LLMs) have been recently introduced, targeting both fundamental improvements in perception and comprehension, and a diverse range of user inquiries. In pursuit of the ultimate goal of achieving artificial general intelligence, a truly intelligent Video-LLM model should not only see and understand the surroundings, but also possess human-level commonsense, and make well-informed decisions for the users. To guide the development of such a model, the establishment of a robust and comprehensive evaluation system becomes crucial. To this end, this paper proposes \\textit{Video-Bench}, a new comprehensive benchmark along with a toolkit specifically designed for evaluating Video-LLMs. The benchmark comprises 10 meticulously crafted tasks, evaluating the capabilities of Video-LLMs across three distinct levels: Video-exclusive Understanding, Prior Knowledge-based Question-Answering, and Comprehension and Decision-making. In addition, we introduce an automatic toolkit tailored to process model outputs for various tasks, facilitating the calculation of metrics and generating convenient final scores. We evaluate 8 representative Video-LLMs using \\textit{Video-Bench}. The findings reveal that current Video-LLMs still fall considerably short of achieving human-like comprehension and analysis of real-world videos, offering valuable insights for future research directions. The benchmark and toolkit are available at: \\url{https://github.com/PKU-YuanGroup/Video-Bench}.","creator":"Munan Ning, Bin Zhu, Yujia Xie, Bin Lin, Jiaxi Cui, Lu Yuan, Dongdong Chen, Li Yuan"},{"id":"2311.10328","slug":"transonet-automatic-segmentation-of-vasculature-in-computed-tomographic-angiograms-using-deep-learning-arxiv-2311-10328v1-eess-iv-cross-listed","title":"TransONet: Automatic Segmentation of Vasculature in Computed Tomographic Angiograms Using Deep Learning.","link":"http://arxiv.org/abs/2311.10328","abstract":"Pathological alterations in the human vascular system underlie many chronic diseases, such as atherosclerosis and aneurysms. However, manually analyzing diagnostic images of the vascular system, such as computed tomographic angiograms (CTAs) is a time-consuming and tedious process. To address this issue, we propose a deep learning model to segment the vascular system in CTA images of patients undergoing surgery for peripheral arterial disease (PAD). Our study focused on accurately segmenting the vascular system (1) from the descending thoracic aorta to the iliac bifurcation and (2) from the descending thoracic aorta to the knees in CTA images using deep learning techniques. Our approach achieved average Dice accuracies of 93.5% and 80.64% in test dataset for (1) and (2), respectively, highlighting its high accuracy and potential clinical utility. These findings demonstrate the use of deep learning techniques as a valuable tool for medical professionals to analyze the health of the vascular system efficiently and accurately. Please visit the GitHub page for this paper at https://github.com/pip-alireza/TransOnet.","creator":"Alireza Bagheri Rajeoni, Breanna Pederson, Ali Firooz, Hamed Abdollahi, Andrew K. Smith, Daniel G. Clair, Susan M. Lessner, Homayoun Valafar"}]},{"name":"Plant Biology","feed":[{"id":"2023.11.29.569170v1","slug":"assessment-of-photosynthetic-activity-in-dense-microalgae-cultures-using-oxygen-production","title":"Assessment of photosynthetic activity in dense microalgae cultures using oxygen production","link":"http://biorxiv.org/cgi/content/short/2023.11.29.569170v1?rss=1","abstract":"Microalgae are photosynthetic microorganisms playing a pivotal role in primary production in aquatic ecosystems, sustaining the entry of carbon in the biosphere. Microalgae have also been recognized as sustainable source of biomass to complement crops. For this objective they are cultivated in photobioreactors or ponds at high cell density to maximize biomass productivity and lower the cost of downstream processes. Photosynthesis depends on light availability, that is often not constant over time. In nature, sunlight fluctuates over diurnal cycles and weather conditions. In high-density microalgae cultures of photobioreactors outdoors, on top of natural variations, microalgae are subjected to further complexity in light exposure. Because of the high-density cells experience self-shading effects that heavily limit light availability in most of the mass culture volume. This limitation strongly affects biomass productivity of industrial microalgae cultivation plants with important implication on economic feasibility. Understanding how photosynthesis responds to cell density is informative to assess functionality in the inhomogeneous light environment of industrial photobioreactors. In this work we exploited a high-sensitivity Clark electrode to measure microalgae photosynthesis and compare cultures with different densities, using Nannochloropsis as model organism. We observed that cell density has a substantial impact on photosynthetic activity, and demonstrated the reduction of the cell's light-absorption capacity by genetic modification is a valuable strategy to increase photosynthetic functionality of dense microalgae cultures.","creator":"Vera-Vives, A. M., Michelberger, T., Morosinotto, T., Perin, G."},{"id":"2023.11.28.569066v1","slug":"morphometrics-and-phylogenomics-of-coca-erythroxylum-spp-illuminate-its-reticulate-evolution-with-implications-for-taxonomy","title":"Morphometrics and phylogenomics of coca (Erythroxylum spp.) illuminate its reticulate evolution, with implications for taxonomy","link":"http://biorxiv.org/cgi/content/short/2023.11.28.569066v1?rss=1","abstract":"South American coca (Erythroxylum coca and E. novogranatense) has been a keystone crop for many Andean and Amazonian communities for at least 8,000 years. However, over the last half century, global demand for cocaine has placed this plant in the centre of armed conflict, deforestation, and explosive growth of illegal economies. While national and international agencies progress from a war-on-drugs policy model towards locally appropriate, data-informed strategies to tackle coca plantations, monitoring their expansion and composition remains essential. The principal means to identify coca plants is leaf morphology, yet the extent to which it is reflected in taxonomy is uncertain. Here, we analyse the consistency of the current naming system of coca and its four closest wild relatives (the coca clade), using morphometrics, phylogenomics, and population genomics. We include the name-bearing type specimens of cocas closest wild relatives E. gracilipes and E. cataractarum. Morphometrics of 342 digitized herbarium specimens show that leaf shape and size fail to reliably discriminate between species and varieties. However, the rounder and more obovate leaves of certain coca varieties could be associated with domestication syndrome of this crop. Our phylogenomic data indicate gene flow involving monophyletic clades of E. gracilipes and the E. coca clade. These results further clarify the evolution of coca and support a taxonomic framework wherein E. gracilipes is retained as a single species. Our findings have implications for the development of cost-effective genotyping methods to effectively discriminate varieties of cultural significance from high-yielding cultivars fuelling the lucrative cocaine market.","creator":"Przelomska, N., Diaz, R., Avila, F. A., Ballen, G. A., Cortes-B, R., Kistler, L., Chitwood, D. H., Charitonidou, M., Renner, S. S., Perez-Escobar, O. A., Antonelli, A."},{"id":"2023.11.28.568964v1","slug":"performance-of-chrysanthemum-cultivars-under-agro-climatic-condition-of-chhattisgarh-plains","title":"Performance of Chrysanthemum Cultivars under Agro-climatic condition of Chhattisgarh plains","link":"http://biorxiv.org/cgi/content/short/2023.11.28.568964v1?rss=1","abstract":"Chrysanthemum is the second largest flower after rose in the global ornamental plants market; It is third in terms of cut flower and ranks fifth in global floriculture trading. Therefore, floricultural study of chrysanthemum has gained widespread attention recently. As the state of Chhattisgarh is rising as a floral hub, we are propelled to determine suitable cultivars of chrysanthemum for different characters in Chhattisgarh plains. To this end, we conducted an experiment based on Randomized Block Design (under field condition) during the year 2016-2017, with seven cultivars of Chrysanthemum namely Pusa Sona, Pusa Arunodaya, Pusa Kesari, Pusa Chitraksha, Pusa Aditya, Mother Teresa, and White Prolific. Our results indicate that Pusa Sona exhibits the early bud appearance (32.80 days), early flowering (60.27 days), maximum number of flowers per plant (137.80), and maximum number of branches per plant (19.73). Further, maximum plant height (49.47 cm) and plant spread (32.63 cm) were observed in Pusa Chitraksha. While Pusa Kesari recorded maximum flower diameter (7.00 cm) and maximum weight of flowers per plant (177.50 g), the maximum flowering duration (59.40 days) was noted under Pusa Aditya. We are certain that these novel findings would help decision making of floriculturists significantly regarding chrysanthemum plantation.","creator":"Bhoi, M."},{"id":"2023.11.28.569014v1","slug":"nuclear-gsh-import-precedes-coordinated-cell-cycle-changes-during-regeneration","title":"Nuclear GSH import precedes coordinated cell cycle changes during regeneration","link":"http://biorxiv.org/cgi/content/short/2023.11.28.569014v1?rss=1","abstract":"Arabidopsis root tip regeneration requires cell division and cellular reprogramming. Here, we present new datasets that describe the cell cycle in Arabidopsis roots that maintain developmental context and cell-type resolution and provide an expanded set of cell cycle phase transcriptional markers. Using these data, we provide in vivo confirmation of a longstanding model in plants that glutathione (GSH) and reactive oxygen species (ROS) vary in a cell cycle dependent manner. We then demonstrate using long term time lapse imaging that cells in G1 phase undergo a transient peak of GSH prior to a tissue-wide coordinated entry into S phase. This coordinated S phase entry precedes a period of fast divisions, which we show appears to potentiate cellular reprogramming during regeneration. Taken together, this work demonstrates a role for GSH in coordinating cell cycle regulation and cellular reprogramming during regeneration.","creator":"Lee, L. R., Guillotin, B., Hutchison, C., Desvoyes, B., Gutierrez, C., Birnbaum, K. D."},{"id":"2023.11.27.568936v1","slug":"virus-induced-gene-silencing-vigs-as-a-tool-for-functional-genetic-analysis-in-passion-fruit-plants","title":"Virus-induced gene silencing (VIGS) as a tool for functional genetic analysis in passion fruit plants","link":"http://biorxiv.org/cgi/content/short/2023.11.27.568936v1?rss=1","abstract":"Passion fruit (Passiflora edulis) is grown perennially in sub-tropical and tropical areas. Its fruits contain multiple vitamins and antioxidants, and thus are consumed increasingly in drinks and foods. However, the functions and regulations of genes that are engaged in the biosynthesis of the health-promoting compounds in passion fruits remain largely unknown. Its whole genome sequence has just been published recently. Virus-induced gene silencing (VIGS) is a reverse genetics tool for analyzing gene function. Here, we engineered telosma mosaic virus (TelMV), a potyvirus infecting passion fruit, into a VIGS vector by inserting the Gateway-compatible recombination sites. The newly constructed TelMV-VIGS virus successfully expressed foreign protein and induced systemic infection in both Nicotiana benthamiana and P. edulis plants. Intriguingly, TelMV-VIGS vector containing different fragments of green fluorescent protein (GFP) gene induced systemic gene silencing on the GFP-transgenic N. benthamiana plants (16c). When the phytoene desaturase (PDS) gene, an endogenous gene in passion fruit, was engineered into the vector, it triggered the silencing of PePDS, as evidenced by the reduced mRNA levels and photobleached phenotype. We reported the first development of VIGS vector in passion fruit, as the first step in our endeavor of discovering horticulturally important genes for improving passion fruit production and quality.","creator":"Wang, X., Shen, W., Cui, H., Dai, Z."},{"id":"2023.11.27.568951v1","slug":"microfluidic-device-for-simple-diagnosis-of-plant-growth-condition-by-detecting-mirnas-from-filtered-plant-extracts","title":"Microfluidic device for simple diagnosis of plant growth condition by detecting miRNAs from filtered plant extracts","link":"http://biorxiv.org/cgi/content/short/2023.11.27.568951v1?rss=1","abstract":"Plants are exposed to a variety of environmental stress and starvation of inorganic phosphorus can be a major constraint in crop production. In plants, in response to phosphate deficiency in soil, miR399, a type of microRNA (miRNA), is upregulated. By detecting miR399, the early diagnosis of phosphorus deficiency stress in plants can be accomplished. However, general miRNA detection methods require complicated experimental manipulations. Therefore, simple and rapid miRNA detection methods are required for early plant nutritional diagnosis. For the simple detection of miR399, microfluidic technology is suitable for point-of-care applications because of its ability to detect target molecules in small amounts in a short time and with simple manipulation. In this study, we developed a microfluidic device to detect miRNAs from filtered plant extracts for the easy diagnosis of plant growth conditions. To fabricate the microfluidic device, verification of the amine-terminated glass as the basis of the device and the DNA probe immobilization method on the glass was conducted. In this device, the target miRNAs were detected by fluorescence of sandwich hybridization in a microfluidic channel. For plant stress diagnostics using a microfluidic device, we developed a protocol for miRNA detection by validating the sample preparation buffer, filtering, and signal amplification. Using this system, endogenous sly-miR399 in tomatoes, which is expressed in response to phosphorus deficiency, was detected before the appearance of stress symptoms. This early diagnosis system of plant growth conditions has a potential to improve food production and sustainability through cultivation management.","creator":"Kawakatsu, Y., Okada, R., Hara, M., Tsutsui, H., Yanagisawa, N., Higashiyama, T., Arima, A., Baba, Y., Kurotani, K.-i., Notaguchi, M."},{"id":"2023.11.28.568332v1","slug":"stress-knowledge-map-a-knowledge-graph-resource-for-systems-biology-analysis-of-plant-stress-responses","title":"Stress Knowledge Map: A knowledge graph resource for systems biology analysis of plant stress responses","link":"http://biorxiv.org/cgi/content/short/2023.11.28.568332v1?rss=1","abstract":"Stress Knowledge Map (SKM, https://skm.nib.si) is a publicly available resource containing two complementary knowledge graphs describing current knowledge of biochemical, signalling, and regulatory molecular interactions in plants: a highly curated model of plant stress signalling (PSS, 543 reactions) and a large comprehensive knowledge network (CKN, 488,390 interactions). Both were constructed by domain experts through systematic curation of diverse literature and database resources. SKM provides a single entrypoint for plant stress response investigations and the related growth tradeoffs. SKM provides interactive exploration of current knowledge. PSS is also formulated as qualitative and quantitative models for systems biology, and thus represents a starting point of a plant digital twin. Here, we describe the features of SKM and show, through two case studies, how it can be used for complex analyses, including systematic hypothesis generation, design of validation experiments, or to gain new insights into experimental observations in plant biology.","creator":"Bleker, C., Ramsak, Z., Bittner, A., Podpecan, V., Zagorscak, M., Wurzinger, B., Baebler, S., Petek, M., Kriznik, M., van Dieren, A., Gruber, J., Afjehi-Sadat, L., Zupanic, A., Teige, M., Vothknecht, U. C., Gruden, K."},{"id":"2023.11.28.568962v1","slug":"pollen-production-pollen-viability-and-autofertility-in-faba-bean-vicia-faba-l-and-their-relationship-with-realized-paternal-success","title":"Pollen production, pollen viability and autofertility in faba bean (Vicia faba L.) and their relationship with realized paternal success","link":"http://biorxiv.org/cgi/content/short/2023.11.28.568962v1?rss=1","abstract":"In animal-pollinated plants, pollen dispersal depends on several plant and animal characteristics which may influence a plant's paternal success. Different paternal success influences the genetic contribution of a genotype to the next generation. In breeding of partially allogamous faba bean (Vicia faba L.), synthetic populations are developed where equal contributions of genotypes to the next generation are desired to reduce inbreeding. Since direct assessments of paternity are elaborate and costly, we studied whether components of plant fitness such as pollen production and pollen viability can be used as estimates for paternity. In a field experiment and a caged outdoor pot experiment, a total of 18 genotypes (14 inbred lines, 4 F1 hybrids) of faba bean were evaluated for pollen production, pollen viability and autofertility. Pollen production was higher at the lower than at the upper inflorescences and we found mid-parent heterosis for this trait. The relative pollen viability was high (93 % to 97 % in pots, 88 % to 95 % in field) indicating that fertilization success is rather not limited by a low pollen quality. Only in the field, pollen of F1 hybrids was more viable than pollen of inbred lines. Autofertility ranged from 0 % to 98 %, with very marked average mid-parent heterosis for this trait. Autofertility did not seem to be related to either pollen production, pollen viability or paternal success. However, pollen production and pollen viability were highly correlated with paternal success. Hence, data on pollen production and viability might be useful in breeding of synthetic populations to choose parents with small differences in paternal successes, to reduce inbreeding and better exploit heterosis.","creator":"Bruenjes, L., Link, W."},{"id":"2023.11.27.568869v1","slug":"blue-spectral-quality-contributes-to-yield-and-ascorbic-acid-content-in-micro-tom-tomato-under-sole-source-lighting","title":"Blue spectral quality contributes to yield and ascorbic acid content in Micro Tom tomato under sole-source lighting","link":"http://biorxiv.org/cgi/content/short/2023.11.27.568869v1?rss=1","abstract":"There is an intricate relationship between the spectral composition of light, plant photosynthetic performance and biomass accumulation. The interaction between plants and the ambient light environment is not only crop-specific but also crucial for maximized yield and nutritional quality. The emergence of LED technology introduced a unique avenue for manipulating the light spectrum, offering new and continued possibilities for optimizing growth conditions. With a focus on tomato cultivation under sole-source lighting, we have investigated the impact of blue spectral quality (waveband composition) on growth and nutritional value of dwarf tomato. Notably, our study revealed that distinct wavebands of blue light (400 nm, 420 nm and 450 nm) can influence the net photosynthetic rate despite unaltered photochemical efficiency. Our research uncovered a correlation whereby shorter wavelengths of blue light increased leaf area, while longer blue wavelengths contributed to greater harvest indices. In addition, we identified a specific blue peak wavelength, 450 nm, that significantly affected chlorophyll composition in leaves and ascorbate levels in fruits. Through these findings, we call attention to the notion that blue spectral quality has a role in shaping both yield and nutritional attributes of dwarf tomato, such as  Micro Tom, under sole-source lighting. Overall, our research provides valuable insight into the nuanced interplay between light spectrum, plant physiology, and horticultural outcome.","creator":"Goldman, M. S., Kolmos, E."},{"id":"2023.11.27.568831v1","slug":"can-changes-in-ploidy-drive-the-evolution-to-allogamy-in-a-selfing-species-complex","title":"Can changes in ploidy drive the evolution to allogamy in a selfing species complex?","link":"http://biorxiv.org/cgi/content/short/2023.11.27.568831v1?rss=1","abstract":"O_LIThe evolution of mating systems in plants is central for understanding the rise of their diversity on Earth. The transition towards self-fertilization is a well-known example of convergent evolution although the opposite direction is expected to be forbidden according to evolutionary theories. We suggest that the ploidy level could promote changes in the reproductive strategies through its effect on traits related to pollination. C_LIO_LIWe performed controlled crosses on several populations from the polyploid Erysimum incanum species complex, described as predominantly selfing, to evaluate the inbreeding depression. Additionally, we measured mating traits such as floral size, herkogamy, anther exertion, the relative investment in male and female components (P:O ratio) and genetic diversity. C_LIO_LIWe described three ploidy levels in the complex - hexaploids were unknown until now. We found significant differences in the self-pollination success among ploidies and even among populations within the same ploidy. Inbreeding depression was present in higher ploidies, accompanied by bigger flowers with higher anther exposure, increased herkogamy and P:O and genetic diversity. C_LIO_LIThese findings suggest that ploidy could be promoting alternative reproductive strategies to selfing, driving mating system diversification within a selfing species, which has not been previously described in the wild. C_LI","creator":"Garcia-Munoz, A., Ferron, C., Vaca-Benito, C., Martinez-Gomez, M. N., Castro, S., Castro, M., Loureiro, J., Munoz-Pajares, A. J., Abdelaziz, M."},{"id":"2023.11.27.568843v1","slug":"colonization-of-bacillus-altitudinis-on-the-compatible-soybean-varieties-to-provide-seed-rot-resistance","title":"Colonization of Bacillus altitudinis on the Compatible Soybean Varieties to Provide Seed Rot Resistance","link":"http://biorxiv.org/cgi/content/short/2023.11.27.568843v1?rss=1","abstract":"Seed health is crucial for plant growth and agricultural productivity. Recent studies have illustrated the importance of plant microbiome in disease resistance, however, it remains unclear whether the seed microbiome confers seed rot resistance against fungal pathogens. In this study, the application of antibiotics on the seeds of eight soybean varieties showed that seed-associated bacteria were involved in the seed rot resistance caused by Calonectria ilicicola, but this resistance cannot be carried to withstand root rot. Using PacBio 16S rDNA full-length sequencing and microbiome analyses, the seed microbiome was shown to mainly dependent on the soybean variety, and there was no consistent community network associated with seed rot resistance across soybean varieties. Instead, the seed-associated Bacillus altitudinis was identified through the differential abundance analysis and culture-dependent isolation. Moreover, qPCR confirmed the persistence of B. altitudinis on apical shoots till 21 days post-inoculation, but not on roots by 9 days post-inoculation. The short-term colonization of B. altitudinis on roots may explain the absence of root rot resistance. Furthermore, seed treated with B. altitudinis restored seed rot resistance, but only in the compatible soybean varieties. For the incompatible soybean varieties, B. altitudinis showed lower bacterial density and provided no seed protection. Collectively, this study advances the insight of B. altitudinis conferring seed rot resistance. These findings highlight the potential of using seed-associated bacteria for seed protection and underscore the importance of considering bacterial compatibility with plant genotypes and tissues.","creator":"Wu, P.-H., Chang, H.-X."},{"id":"2023.11.26.568767v1","slug":"alternative-splicing-variants-of-arabidopsis-g-protein-subunit-agb1-function-in-plant-development-and-endoplasmic-reticulum-stress-response","title":"Alternative splicing variants of Arabidopsis G protein  subunit AGB1 function in plant development and endoplasmic reticulum stress response","link":"http://biorxiv.org/cgi/content/short/2023.11.26.568767v1?rss=1","abstract":"The Arabidopsis heterotrimeric G protein {beta} subunit, GTP BINDING PROTEIN BETA 1 (AGB1), has multiple functions in plant development and response to various environmental stimuli including endoplasmic reticulum (ER) stress. However, how the single gene produces the pleiotropic effect remains elusive. Here, we show that AGB1 has 4 alternative splice isoforms with isoform-specific features. AGB1.2 failed to rescue the agb1-3 mutant defects and thus was considered a non-functional isoform. Although AGB1.1 and AGB1.4 were both localized at the plasma membrane and the ER, AGB1.1 fully rescued the defects of agb1-3, and AGB1.4 only partially rescued the defects even though its transcript level was higher than that of AGB1.1. Intriguingly, AGB1.3 was localized at the nucleus and further enhanced the leaf-shape phenotype of agb1-3. The protein structure of AGB1.3 is unique because of the termination of translation in the 7th-WD40 motif by alternative splicing, which produced an incomplete propeller structure. AGB1.1 and AGB1.4 but not AGB1.3 interacted with the G{gamma} subunits, AGG1, AGG2, and AGG3, possibly because of the lack of the 7th-WD40 motif in AGB1.3. AGB1 may produce its multifaceted functions in plant development and ER stress tolerance via its alternative splice isoforms with distinct structural features and subcellular localization.","creator":"Cho, Y."},{"id":"2023.11.27.568785v1","slug":"genetically-clustered-antifungal-phytocytokines-and-receptor-proteins-function-together-to-trigger-plant-immune-signaling","title":"Genetically-clustered antifungal phytocytokines and receptor proteins function together to trigger plant immune signaling","link":"http://biorxiv.org/cgi/content/short/2023.11.27.568785v1?rss=1","abstract":"O_LIPhytocytokines regulate plant immunity via cell-surface receptors. Populus trichocarpa RUST INDUCED SECRETED PEPTIDE 1 (PtRISP1) exhibits an elicitor activity in poplar, as well as a direct antimicrobial activity against rust fungi. PtRISP1 gene directly clusters with a gene encoding a leucine-rich repeat receptor protein (LRR-RP), that we termed RISP- ASSOCIATED LRR-RP (PtRALR). C_LIO_LIIn this study, we used phylogenomics to characterize the RISP and RALR gene families, and functional assays to characterize RISP/RALR pairs. C_LIO_LIBoth RISP and RALR gene families specifically evolved in Salicaceae species (poplar and willow), and systematically cluster in the genomes. Two divergent RISPs, PtRISP1 and Salix purpurea RISP1 (SpRISP1), induced a reactive oxygen species (ROS) burst and mitogen- activated protein kinases (MAPKs) phosphorylation in Nicotiana benthamiana leaves expressing the respective clustered RALR. PtRISP1 triggers a rapid stomatal closure in poplar, and both PtRISP1 and SpRISP1 directly inhibit rust pathogen growth. C_LIO_LIAltogether, these results suggest that plants evolved phytocytokines with direct antimicrobial activities, and that the genes coding these phytocytokines co-evolved and physically cluster with their cognate receptors. C_LI","creator":"Lintz, J., Goto, Y., Bender, K. W., Bchini, R., Dubrulle, G., Cawston, E., Zipfel, C., Duplessis, S., PETRE, B."},{"id":"2023.11.24.568555v1","slug":"a-coordinated-switch-in-sucrose-and-callose-metabolism-enables-enhanced-symplastic-unloading-in-potato-tubers","title":"A coordinated switch in sucrose and callose metabolism enables enhanced symplastic unloading in potato tubers","link":"http://biorxiv.org/cgi/content/short/2023.11.24.568555v1?rss=1","abstract":"One of the early changes upon tuber induction is the switch from apoplastic to symplastic unloading. Whether and how this change in unloading mode contributes to sink-strength has remained unclear. In addition, developing tubers also change from energy to storage-based sucrose metabolism. Here we investigated the coordination between changes in unloading mode and sucrose metabolism and their relative role in tuber sink strength by looking into callose and sucrose metabolism gene expression combined with a model of apoplastic and symplastic unloading. Decreased callose deposition in tubers is driven by decreased callose synthase activity. Furthermore, changes in callose metabolism and sucrose metabolism are strongly correlated, indicating a well-coordinated developmental switch. Modelling indicates that symplastic unloading is not the most efficient unloading mode per se. Instead, it is the concurrent metabolic switch that provides the physiological conditions necessary to potentiate symplastic transport and thereby enhance tuber sink strength.","creator":"van den Herik, B., Bergonzi, S., Li, Y., Bachem, C. W. B., ten Tusscher, K. H."},{"id":"2023.11.24.568554v1","slug":"fertilizer-and-cultivar-affect-the-barley-rhizobiome-while-domestication-age-only-affects-growth-at-low-nutrient-levels","title":"Fertilizer and cultivar affect the barley rhizobiome, while domestication age only affects growth at low nutrient levels","link":"http://biorxiv.org/cgi/content/short/2023.11.24.568554v1?rss=1","abstract":"Modern plant breeding has provided barley cultivars that produce high yields when supplied with ample amounts of mineral fertilizer. This narrow selection criterion may have reduced key traits facilitating vital microbiome-plant interactions. Here, we investigated the performance of three old and four modern barley cultivars grown at different fertilizer regimes and assessed the root microbiome composition using 16s rRNA amplicon sequencing. The objectives were to investigate: i) nutrient availability effects on nutrient uptake and biomass production and, ii) how domestication age, cultivar, and fertilizer treatment affect the root microbiome. Without fertilizer, old cultivars outperformed modern ones in terms of biomass and had higher leaf concentration of nitrogen, potassium, sulphur, iron, zinc, and copper. This suggests that older barley cultivars retained the ability of their wild ancestor to collaborate with the soil microbiome resulting in improved nutrient acquisition in low-input systems. Interestingly, domestication age did not significantly affect the diversity of the rhizo-microbiome, which was instead dependent on individual cultivar and fertilizer treatment.  HighlightOlder barley cultivars outperform the modern ones in terms of biomass at low nutrient availability. However, the rhizo-microbial diversity depended on the individual cultivar and fertilizer regime.","creator":"Kindtler, N. L., Sheikh, S., Richardy, J., Krogh, E., Maccario, L., Vestergard, M., da Fonseca, R. R., Ekelund, F., Laursen, K. H."},{"id":"2023.11.26.568706v1","slug":"dynamic-floral-scent-profile-of-epiphyllum-oxypetalum-and-the-cytosolic-biosynthesis-of-trans-geraniol-through-mevalonate-pathway","title":"Dynamic floral scent profile of Epiphyllum oxypetalum and the cytosolic biosynthesis of trans-Geraniol through mevalonate pathway","link":"http://biorxiv.org/cgi/content/short/2023.11.26.568706v1?rss=1","abstract":"O_LIEpiphyllum oxypetalum, a renowned ornamental species in Cactaceae, unveils its attractive fragrance during its infrequent and rapid night blooming. However, the nature of this floral scent remains unexplored. C_LIO_LIEmploying GC-MS, transcriptome and biochemical assay, we systematically characterized the composition, emission dynamics and biosynthesis of E. oxypetalum floral scent. C_LIO_LIComposition of the floral scent was highly dynamic, with 72.54% trans-Geraniol, 12.96% benzyl alcohol and 3.75% methyl salicylate at full bloom. From 22:00 to 05:00 the following day, the strong scent was primarily released from petals and sepals. Proved by inhibitor assay, the precursors for the dominant scent volatile trans-Geraniol are derived from amyloplast degradation and mevalonate (MVA) pathway. Together with the cytosol-localized geraniol pyrophosphate synthase EoGDPS and geraniol synthase EoTPSa1, we proved an uncanonical cytoplasmic biosynthesis route for monoterpene volatiles in E. oxypetalum petal. C_LIO_LIOur study on the dynamic floral scent profile and its biosynthesis posed the first detailed analysis of cactus floral scent. These results laid foundation for novel perfume development and future inquiries on specialized pollination coevolution in Cactaceae. C_LI","creator":"Zhang, Y., Tian, Q., Zhang, Y., Xiao, H., Sun, Q., Li, T."},{"id":"2023.11.26.567847v1","slug":"characterization-of-tomato-canal-1-mutant-using-a-multi-omics-approach","title":"Characterization of tomato canal-1 mutant using a multi-omics approach","link":"http://biorxiv.org/cgi/content/short/2023.11.26.567847v1?rss=1","abstract":"The recently described canal-1 tomato mutant, which has a variegated leaf phenotype, has been shown to affect canalization of yield. The corresponding protein is orthologous to AtSCO2 - SNOWY COTYLEDON2, which has suggested roles in thylakoid biogenesis. Here we characterize the canal-1 mutant through a multi-omics approach, by comparing mutant to wild-type tissues. While white canal-1 leaves are devoid of chlorophyll, green leaves of the mutant appear wild-type-like, despite an impaired protein function. Transcriptomic data suggest that green mutant leaves compensate for this impaired protein function by upregulation of transcription of photosystem assembly and photosystem component genes, thereby allowing adequate photosystem establishment, which is reflected in their wild-type-like proteome. White canal-1 leaves, however, likely fail to reach a certain threshold enabling this overcompensation, and plastids get trapped in an undeveloped state, while additionally suffering from high light stress, indicated by the overexpression of ELIP homolog genes. The metabolic profile of white and to a lesser degree also green tissues revealed upregulation of amino acid levels, that was at least partially mediated by transcriptional and proteomic upregulation. These combined changes are indicative of a stress response and suggest that white tissues behave as carbon sinks. In summary, our work demonstrates the relevance of the SCO2 protein in both photosystem assembly and as a consequence in the canalization of yield.  Significance statementThe variegated canalized-1 tomato mutant was recently described and the underlying gene SCO2 suggested to be a yield canalization gene. Through a multi-omics approach we show that mutants require a transcriptional upregulation of photosystem components and assembly components, likely as overcompensation for partially impaired SCO2 function, to produce a wild type-like proteome and functional photosynthetic tissue Our data, furthermore, suggest that variation of green to white leaf area from plant to plant leads to the yield variation.","creator":"Ahchige, M. W., Fisher, J., Sokolowska, E., Lyall, R., Illing, N., Skirycz, A., Zamir, D., Alseekh, S., Fernie, A. R."},{"id":"2023.11.25.568661v1","slug":"bait-not-reward-co2-enriched-nepenthes-pitchers-secrete-toxic-nectar","title":"Bait, not reward: CO2-enriched Nepenthes pitchers secrete toxic nectar","link":"http://biorxiv.org/cgi/content/short/2023.11.25.568661v1?rss=1","abstract":"Nepenthes pitchers are leaf-evolved biological traps holding high levels of CO2 within them. Extrafloral nectar (EFN) secreted by Nepenthes pitchers has long been regarded as the major reward to the visiting arthropods, but its chemical constituents and their role in prey capture are least explored. Here we show that Nepenthes EFN is a toxic sugar mix devoid of key nitrogenous components (amino acids, proteins) and vitamin C. Fatty acids (cis-11-octadecenoic acid (C18:1), palmitic acid (C16:0), stearic acid (C18:0)) and their derivatives were detected in both N. khasiana peristome and lid EFNs. Both the nectars showed strong acetylcholinesterase (AChE) inhibition in vitro and in vivo. Bioactivity guided isolation revealed (+)-isoshinanolone, a naphthoquinone derivative, as the AChE inhibitor in Nepenthes EFNs. GC-headspace analysis showed the naphthoquinone, plumbagin, as the major volatile constituent in prey capturing regions of pitchers, along with the VOCs, (Z)-3-hexen-1-ol, 1-hexanol and acetoin. N. khasiana pitchers trap a wide spectrum of preys dominated by ants, whereas only limited herbivory was observed on its leaves and pitchers. Chemical (EFN, volatiles), gaseous (CO2), visual (colour, UV reflectance, fluorescence), physical (peristome geometry, surface microstructure, wettable surface-aquaplaning) and environmental (humidity, rain) factors effect prey capture in Nepenthes pitchers. These leaf-transformed traps with high growth rate and C:N ratio, reduced Rubisco activity, modified stomata, acidic pitcher fluid and absence of key nitrogenous metabolites are model systems displaying the effects of elevated CO2 within them. We testify that Nepenthes EFN is  a toxic sugar bait which hinders the neuronal activity and flight of visiting arthropods. These unique traps adopt various deceptive strategies for prey capture, and our discovery abolishes the notion of Nepenthes EFN as a  reward to the visiting ants and other arthropods.","creator":"Lathika, C. C., Sujatha, G. B., Thomas, G., Johnson, A. J., Viswanathan, G., Varghese, T. S., Mohamed, S., Shereefa, L. A., Baby, S."},{"id":"2023.11.24.568494v1","slug":"dynamics-of-evolution-in-irano-anatolian-and-caucasus-biodiversity-hotspots-evolutionary-radiation-and-its-drivers-in-gypsophila-caryophyllaceae","title":"Dynamics of evolution in Irano-Anatolian and Caucasus biodiversity hotspots: Evolutionary radiation and its drivers in Gypsophila (Caryophyllaceae)","link":"http://biorxiv.org/cgi/content/short/2023.11.24.568494v1?rss=1","abstract":"O_LIIrano-Anatolian and Caucasus biodiversity hotspots, characterized by a high degree of alpine endemism and extremely dynamic geographical history, are among the 36 globally defined biodiversity hotspots. However, the dynamics of evolution and the cofactors of diversification have not been investigated in these regions. C_LIO_LIWe explore the evolutionary dynamics of Gypsophila (Caryophylleae: Caryophyllaceae), a large and diverse genus with a high degree of endemism in the Irano-Anatolian and Caucasus biodiversity hotspots. We investigate the diversification rate and its biotic and abiotic cofactors within the Caryophylleae tribe, with a special focus on Gypsophila. C_LIO_LIWe identified a shift in the diversification rate of Gypsophila that started about 3 million years ago and was influenced by both biotic and abiotic forces. The results suggest that the diversity inside Gypsophila evolved due to evolutionary radiation that was triggered by both paleoenvironmental factors and acquiring morphological novelties. C_LIO_LIThe result of this study demonstrates a highly dynamic evolutionary history across the Caryophylleae clade and Gypsophila, which is consistent with the extensive fluctuation in the geological and climatological history of Irano-Anatolian and Caucasus biodiversity hotspots. This study significantly improves our understanding of the dynamics of evolution in the Irano-Anatolian and Caucasus biodiversity hotspots and the impact of environmental changes on the rate of diversification. C_LI","creator":"Madhani, H., Rabeler, R. K., Heubl, G., Madhani, N., Zarre, S."},{"id":"2023.11.25.568654v1","slug":"saga1-and-saga2-promote-starch-formation-around-proto-pyrenoids-in-arabidopsis-chloroplasts","title":"SAGA1 and SAGA2 promote starch formation around proto-pyrenoids in Arabidopsis chloroplasts","link":"http://biorxiv.org/cgi/content/short/2023.11.25.568654v1?rss=1","abstract":"The pyrenoid is a chloroplastic microcompartment in which most algae and some terrestrial plants condense the primary carboxylase, Rubisco (ribulose-1,5-bisphosphate carboxylase/oxygenase) as part of a CO2-concentrating mechanism that improves the efficiency of CO2 capture. Engineering a pyrenoid-based CO2-concentrating mechanism (pCCM) into C3 crop plants is a promising strategy to enhance yield capacities and resilience to the changing climate. Many pyrenoids are characterized by a sheath of starch plates that is proposed to act as a barrier to limit CO2 diffusion. Recently, we have reconstituted a phase-separated  proto-pyrenoid Rubisco matrix in the model C3 plant Arabidopsis thaliana using proteins from the alga with the most well studied pyrenoid, Chlamydomonas reinhardtii (1). Here we describe the impact of introducing the Chlamydomonas proteins StArch Granules Abnormal 1 (SAGA1) and SAGA2, which are associated with the regulation of pyrenoid starch biogenesis and morphology. We show that SAGA1 localizes to the proto-pyrenoid in engineered Arabidopsis plants, which results in the formation of atypical spherical starch granules enclosed within the proto-pyrenoid condensate and adjacent plate-like granules that partially cover the condensate, but without modifying the total amount of chloroplastic starch accrued. Additional expression of SAGA2 further increases the proportion of starch synthesised as adjacent plate-like granules that fully encircle the proto-pyrenoid. Our findings pave the way to assembling a diffusion barrier as part of a functional pCCM in vascular plants, whilst also advancing our understanding of the roles of SAGA1 and SAGA2 in starch sheath formation and opening novel avenues for engineering starch morphology.","creator":"Atkinson, N., Stringer, R., Mitchell, S. R., Seung, D., McCormick, A. J."},{"id":"2023.11.24.567652v1","slug":"bdnrt2a-and-bdnrt3-2-are-the-major-components-of-the-high-affinity-nitrate-transport-system-in-brachypodium-distachyon","title":"BdNRT2A and BdNRT3.2 are the major components of the High-Affinity nitrate Transport System in Brachypodium distachyon","link":"http://biorxiv.org/cgi/content/short/2023.11.24.567652v1?rss=1","abstract":"O_LIAn efficient nitrate uptake system contributes to the improvement of crop nitrogen use efficiency under low nitrogen availability. The High Affinity nitrate Transport System (HATS) in plants is active in low external nitrate and is mediated by a two-component system [high affinity transporters NRT2 associated to a partner protein NRT3 (NAR2)]. C_LIO_LIIn Brachypodium, the model plant for C3 cereals, we investigated the role of BdNRT2A and BdNRT3.2 through various experimental approaches including gene expression profiling, functional characterisation in heterologous system, intracellular localization by imaging, and reverse genetics via gene silencing. C_LIO_LIExpression of BdNRT2.A and BdNRT3.2 genes in response to nitrate availability fits with the characteristics of the HATS components. Co-expression of BdNRT2A and BdNRT3.2 is required for an effective nitrate transport in the heterologous expression system Xenopus oocytes. Functional interaction between BdNRT2A-GFP and BdNRT3.2-RFP fusion proteins has been observed at the plasma membrane in Arabidopsis protoplasts in transient expression experiments. BdNRT3.2 appeared to be necessary for the plasma membrane localization of BdNRT2A. 15Nitrate influx measurements with bdnrt2a mutants (two amiRNA mutants and one NaN3 induced mutant with a truncated NRT2A protein), confirmed that BdNRT2A is a major contributor of the HATS in Brachypodium. C_LIO_LIDirected mutagenesis in BdNRT2A of a conserved Ser residue (S461) specific to monocotyledons has been performed to mimic a non-phosphorylated S461A or a constitutively phosphorylated S461D, in order to evaluate its potential role in the BdNRT2A and BdNRT3.2 interaction leading to plasma membrane targeting. Interestingly, the phosphorylation status of S461 did not modify the interaction, suggesting on a more complex mechanism. C_LIO_LIIn conclusion, our data show that BdNRT2A and BdNRT3.2 are the main components of the nitrate HATS activity in Brachypodium (Bd21-3) and allow an optimal growth in low N conditions. C_LI","creator":"David, L. C., Gregoire, M., Berquin, P., Marmagne, A., Dalmais, M., Bendahmane, A., Miller, A. J., Krapp, A., Daniel-Vedele, F., Girin, T., FERRARIO-MERY, S."},{"id":"2023.11.24.568587v1","slug":"a-role-for-chloroplast-rna-binding-protein-cp29a-in-rbcl-expression-during-cold-acclimation","title":"A role for chloroplast RNA binding protein CP29A in rbcL expression during cold acclimation","link":"http://biorxiv.org/cgi/content/short/2023.11.24.568587v1?rss=1","abstract":"The chloroplast genome encodes key components of the photosynthetic light reaction machinery and the large subunit of the enzyme central for carbon fixation, RuBisCo. Plants constantly face the challenge of balancing light and dark reactions under varying environmental conditions. Nuclear RNA binding proteins (RBPs) play a crucial role in plant acclimation to these changes through post-transcriptional processes. Mutants of chloroplast gene expression factors often exhibit impaired chloroplast biogenesis, especially in cold conditions. Cold temperatures pose a challenge for plants as they slow down Calvin Cycle enzymes, potentially leading to a shortage of electron acceptors and oxidative damage from excess electrons in the thylakoid membrane. A well-known response of plants to this problem is to increase the production of RuBisCo and other Calvin Cycle enzymes in the cold. The chloroplast RNA binding protein CP29A targets rbcL mRNA and is essential for cold resistance in Arabidopsis thaliana. This effect is confined to the youngest leaf tissue and is linked to its role in enhancing the splicing of various chloroplast RNAs in cold conditions. In this study, we utilized enhanced cross-linking and immunoprecipitation (eCLIP) and RNA- Bind-N-Seq (RBNS) to investigate the RNA targets of CP29A, achieving nucleotide-resolution insights into protein-RNA interaction sites. We discovered that CP29A preferentially binds to mRNAs encoding subunits of photosystem II. Notably, one of the most confidently identified targets of CP29A is the 5-UTR of rbcL, where it interacts with a site downstream of the pentatricopeptide repeat protein MRL1, a crucial player in rbcL accumulation. Arabidopsis mutants lacking CP29A showed no significant rbcL changes, possibly due to CP29As restricted role in a limited number of cells at the base of leaves. In contrast, CRISPR mutants of tobacco NtCP29A exhibit photosynthetic deficiencies throughout the entire leaf blade, correlating with a substantial decrease in both rbcL mRNA and RbcL protein levels. Conclusively, our study establishes CP29A as a pioneer regulator in sustaining optimal RuBisCo expression during cold acclimation, highlighting its integral role in plant cold response mechanisms.","creator":"Lenzen, B., Roesch, F., Ruwe, H., Legen, J., Small, I. D., Schmitz-Linneweber, C."},{"id":"2023.11.23.568454v1","slug":"anatomical-insights-into-the-vascular-lay-out-of-the-barley-rachis-implications-for-transport-and-spikelet-connection","title":"Anatomical insights into the vascular lay-out of the barley rachis: implications for transport and spikelet connection","link":"http://biorxiv.org/cgi/content/short/2023.11.23.568454v1?rss=1","abstract":"Background and aimsVascular patterning is intimately related to plant form and function. However, morphologic a l studies on the vascular anatomy of cereal crops, and inflorescences in particular, are scarce despite their importance for grain yield determination. Here, using barley (Hordeum vulgare) as a model, we study the vascular anatomy of the spike-type inflorescence. Our goal is to clarify the relationship between rachis (spike axis) vasculature and spike size, the implications for transport capacity and its interaction with the spikelets.  MethodsWe employed serial transversal internode sections in multiple barley lines with different spike size, and investigated the internode diameter, vascular area and vein number size along the mature barley rachis. We then modeled the vascular dynamics along the main spike axis, and analyzed their relationship with spike size.  Key resultsInternode diameter and total vascular area have a clear positive correlation with spike size whereas vascular number is only weakly correlated. While the lateral periphery of the rachis contains large mature veins of constant diameter the central part is occupied by a staggered array of small immature veins. This underlines the importance of minimizing transport resistance and suggests that transport and distribution of nutrients are spatially separated. Spikelet-derived veins enter the rachis either in the central area, where they often merge with the immature rachis veins, or in the periphery where they do not merge with the large mature veins. An increase in floret fertility through the conversion of a two-rowed barley into an isogenic six-rowed line, as well a decrease in floret fertility due to enhanced pre-anthesis tip degeneration caused by the mutation tip sterile 2.b (tst2.b) significantly affected vein size, but had limited to no effects on vein number or rachis diameter. Comparative analysis of a wild barley accession suggests that the domestication of barley may have favored plants with enhanced rachis transport capacity.  ConclusionsThe rachis vasculature is the result of a two-step process involving an initial lay-out followed by size adjustment according to floret fertility/spike size. The functional processes of long distance transport and local supply to spikelets are spatially separated while a vascular continuity between rachis and spikelets appears non-essential.","creator":"Rutten, T., Thirulogachandar, V., Huang, Y., Shanmugaraj, N., Koppolu, R., Ortleb, S., Hensel, G., Kumlehn, J., Melzer, M., Schnurbusch, T."},{"id":"2023.11.23.568411v1","slug":"smerf6-promotes-the-expression-of-terpenoid-pathway-in-salvia-officinalis-and-improves-the-production-of-high-value-abietane-diterpenes-carnosol-and-carnosic-acid","title":"SmERF6 promotes the expression of terpenoid pathway in Salvia officinalis and improves the production of high value abietane diterpenes, carnosol and carnosic acid","link":"http://biorxiv.org/cgi/content/short/2023.11.23.568411v1?rss=1","abstract":"Carnosol (CO) and carnosic acid (CA) are pharmaceutically important diterpenes predominantly produced in members of Lamiaceae, Salvia officinalis, Salvia fruticosa and Rosmarinus officinalis. Nevertheless, availability of these compounds in plant system is very low.  With an effort to improve the in planta content of these diterpenes, SmERF6 (Salvia miltiorrhiza Ethylene Responsive Factor 6) transcription factor was expressed in S. officinalis heterologously. SmERF6 is known to bind at the promoter regions of Copalyl diphosphate synthase (CPS) and Kaurene synthase like (KSL) genes and improve ferruginol content, a common precursor for abietane diterpenes in Salvia genus.  Transient expression of SmERF6 exhibited the inter-specific activity in promoting differential accumulation of diterpenes in S. officinalis. Overexpression studies showed elevation in the levels of CO (10-folds) and CA (8-folds). Further, in infiltrated leaves levels of ferruginol (50%) and CA derivatives (rosmanol, epirosmanal, methyl carnosic acid) were significantly upregulated along with the other signature terpenes. While, knockdown of homologous ERF6 resulted in drastic reduction of the metabolite content.  Finally, stable transgenic lines of S. officinalis developed through in planta Agrobacterium mediated genetic transformation method accumulated higher levels of CO (4-folds) and CA (3-folds) as compared to wild plants.  Overall, the present study is the first report on improving the content of pharmaceutically important diterpenes in S. officinalis by overexpressing pathway specific transcription factor. The current results showed convincing evidence for the concept of improving the content of specialized metabolite(s) in medicinal plants by manipulating the expression of key transcription factors.","creator":"Revuru, B., Thashanamoorthi, G., Demiwal, P., Sircar, D., Ramalingam, S."},{"id":"2023.11.21.568194v1","slug":"genetic-adaptation-to-ammonium-sustains-wheat-grain-quality-and-alleviates-acclimation-to-co2-enrichment","title":"Genetic adaptation to ammonium sustains wheat grain quality and alleviates acclimation to CO2 enrichment","link":"http://biorxiv.org/cgi/content/short/2023.11.21.568194v1?rss=1","abstract":"Plants synthesize protein through assimilating inorganic nitrogen. Yet, the extent to which soil nitrogen sources alter crop responses to atmospheric CO2 remains uncertain. We assessed wheat (Triticum aestivum L.) biomass under CO2 enrichment in genotypes that demonstrated a preference for ammonium (NH4+) or nitrate (NO3-), and contrasting degrees of NH4+ tolerance. Nitrogen-form preference, but not NH4+ tolerance, correlated with CO responses. Notably, NH4+-preferring genotypes maintained higher biomass and sustained grain nitrogen concentrations, thus avoiding CO2 acclimation, the decline in biomass stimulation after prolonged exposure to CO2 enrichment. Furthermore, NH4+ nutrition accelerated flowering and increased spike biomass. Breeding for NH4+-adapted genotypes may not only improve climate resilience, but also potentially accelerate development and increase yield without any penalty on grain quality. Because wheat provides 20% of the protein and carbohydrate in the human diet, our study provided strategies to sustain food security under the atmospheric conditions anticipated in the future.  HighlightBreeding for NH4+-adapted genotypes may not only improve climate resilience, but also potentially accelerate development and increase yield without any penalty on grain quality under elevated CO2 atmospheres.","creator":"Kasemsap, P., Bloom, A. J."},{"id":"2023.11.23.568424v1","slug":"exploring-the-family-feud-a-fungal-endophyte-induces-local-cell-wall-mediated-resistance-in-wheat-roots-against-the-closely-related-take-all-pathogen","title":"Exploring the family feud: a fungal endophyte induces local cell wall-mediated resistance in wheat roots against the closely related \"take-all\" pathogen","link":"http://biorxiv.org/cgi/content/short/2023.11.23.568424v1?rss=1","abstract":"Take-all disease, caused by the soil-borne ascomycete fungus Gaeumannomyces tritici, is one of the most important root diseases of wheat in the UK and worldwide. The fungus invades the roots and destroys the vascular tissue, hindering the uptake of water and nutrients from the soil. Closely related non-pathogenic species in the Magnaporthaceae family, such as Gaeumannomyces hyphopodioides, occur naturally in arable and grassland soils and have previously been reported to reduce take-all disease in field studies. Here, we characterise the different infection structures produced by G. tritici and G. hyphopodioides and suggest an alternative role for previously described \"sub-epidermal vesicles\" (SEVs). We show that direct interaction between the two species is unlikely to play a significant role in take-all control, and instead demonstrate that take-all control is achieved via local host changes in response to prior G. hyphopodioides root colonisation. RNA sequencing revealed extensive host transcriptional reprogramming in G. hyphopodioides colonised tissues, characterised by a striking downregulation of key cell-wall related genes, including cellulose synthase (CESA), and xyloglucan endotransglucosylase/hydrolase (XTH) genes. In the absence of take-all resistant wheat cultivars and avirulent G. tritici strains, studying closely related G. hyphopodioides provides a much-needed avenue to elucidate take-all resistance mechanisms in wheat.","creator":"Chancellor, T., Smith, D. P., Chen, W., Clark, S. J., Venter, E., Halsey, K., McMillan, V., Canning, G., Hammond-Kosack, K. E., Palma-Guerrero, J."},{"id":"2023.11.22.568388v1","slug":"genome-sequence-and-cell-biological-toolbox-of-the-highly-regenerative-coenocytic-green-feather-alga-bryopsis","title":"Genome sequence and cell biological toolbox of the highly regenerative, coenocytic green feather alga Bryopsis","link":"http://biorxiv.org/cgi/content/short/2023.11.22.568388v1?rss=1","abstract":"Green feather algae (Bryopsidales) undergo a unique life cycle in which a single cell repeatedly executes nuclear division without cytokinesis, resulting in the development of a thallus (> 100 mm) with characteristic morphology called coenocyte. Bryopsis is a representative coenocytic alga that has exceptionally high regeneration ability: extruded cytoplasm aggregates rapidly in seawater, leading to the formation of protoplasts. However, the genetic basis of the unique cell biology of Bryopsis remains poorly understood. Here, we present a high-quality assembly and annotation of the nuclear genome of Bryopsis sp. (90.7 Mbp, 27 contigs, N50 = 6.7 Mbp, 14,034 protein-coding genes). Comparative genomic analyses indicate that the genes encoding BPL-1/Bryohealin, the aggregation-promoting lectin, are heavily duplicated in Bryopsis, whereas homologous genes are absent in other Ulvophycean algae, suggesting the basis of regeneration capability of Bryopsis. Bryopsis sp. possesses >30 kinesins but only a single myosin, which differs from other green algae that have multiple types of myosin genes. Consistent with this biased motor toolkit, we observed that the bidirectional motility of chloroplasts in the cytoplasm was dependent on microtubules but not actin in Bryopsis sp. Unexpectedly, most genes required for cytokinesis in plants are present in Bryopsis, including those in the SNARE or kinesin superfamily. Nevertheless, a kinesin crucial for cytokinesis initiation in plants (NACK/Kinesin-7II) is hardly expressed in the coenocytic part of the thallus, possibly underlying the lack of cytokinesis in this portion. The present genome sequence lays the foundation for experimental biology in coenocytic macroalgae.  Significance statementThe exceptionally coenocytic body and remarkable regeneration ability of Bryopsis have attracted biologists for years. However, molecular biological tools remain underdeveloped, partly due to the lack of genome information. Here, we report high-quality assembly and annotation of the genome, providing a crucial resource for experimental biology and genomics studies of Bryopsis. Furthermore, comparative genomic analysis reveals a unique gene repertoire that possibly underlies the highly regenerative coenocytic body.","creator":"Ochiai, K. K., Hanawa, D., Ogawa, H. A., Tanaka, H., Uesaka, K., Edzuka, T., Shirae-Kurabayashi, M., Toyoda, A., Itoh, T., Goshima, G."},{"id":"2023.11.22.568237v1","slug":"integrating-leaf-gas-exchange-and-chlorophyll-fluorescence-to-reveal-the-long-term-regulation-of-photosynthesis-in-situ","title":"Integrating leaf gas exchange and chlorophyll fluorescence to reveal the long-term regulation of photosynthesis in situ","link":"http://biorxiv.org/cgi/content/short/2023.11.22.568237v1?rss=1","abstract":"Understanding the diurnal and seasonal regulation of photosynthesis is an essential step in quantifying and modeling the impact of the environment on plant function. Although the dynamics of photosynthesis have been widely investigated in terms of CO2 exchange measurements, a more comprehensive view can be obtained when combining gas exchange and chlorophyll fluorescence (ChlF) measurements. However, such integrated measurements have been so far restricted to short term analysis using portable systems that combine IRGA and PAM-ChlF techniques. Here we introduce and demonstrate a new method for integrated, long-term and in situ measurements of leaf gas exchange and ChlF, based on an autonomous gas exchange system and a new miniature PAM- fluorometer. The method is used to simultaneously track the dynamics of the light and carbon reactions of photosynthesis at a 20-minute resolution in leaves of silver birch during summer time. The potential of the method is initially demonstrated using the ratio between electron transport and net assimilation (ETR/ANET). We successfully captured the diurnal patterns in the ETR/ANET during summer time, including a drastic increase in ETR/ANET upon a high-temperature period. We suggest that these measurements can provide valuable data to model and quantify the regulation of leaf photosynthesis in situ.  HighlightWe introduce new integrated measurements to help resolve the seasonal and diurnal dynamics of photosynthesis regulation by combining long-term simultaneous measurements of gas exchange and chlorophyll fluorescence in field conditions.","creator":"Oivukkamaki, J., Aalto, J., Pfundel, E. E., Tian, M., Zhang, C., Grebe, S., Salmon, Y., Holtta, T. S., Porcar-Castell, A."},{"id":"2023.11.21.568158v1","slug":"cooperativity-and-additivity-in-plant-enhancers","title":"Cooperativity and additivity in plant enhancers","link":"http://biorxiv.org/cgi/content/short/2023.11.21.568158v1?rss=1","abstract":"Enhancers are cis-regulatory elements that shape gene expression in response to numerous developmental and environmental cues. In animals, several models have been proposed to explain how enhancers integrate the activity of multiple transcription factors. However, it remains largely unknown how plant enhancers integrate transcription factor activity. Here, we use Plant STARR-seq to characterize three light-responsive plant enhancers--AB80, Cab-1, and rbcS-E9--derived from genes active in photosynthesis. Saturation mutagenesis reveals mutations, many of which cluster in short regions, that strongly reduce enhancer activity in the light, in the dark or in both conditions. When tested in the light, these mutation-sensitive regions do not function on their own; rather, cooperative interactions with other such regions are required for full activity. Epistatic interactions occur between mutations in adjacent mutation-sensitive regions, and the spacing and order of mutation-sensitive regions in synthetic enhancers affects enhancer activity. In contrast, when tested in the dark, mutation-sensitive regions act independently and additively in conferring enhancer activity. Taken together, this work demonstrates that plant enhancers show evidence for both cooperative and additive interactions among their functional elements. This knowledge can be harnessed to design strong, condition-specific synthetic enhancers.","creator":"Jores, T., Tonnies, J., Mueth, N. A., Romanowski, A., Fields, S., Cuperus, J., Queitsch, C."},{"id":"2023.11.21.568111v1","slug":"identification-of-a-highly-drought-resistant-pp7l-hda6-mutant","title":"Identification of a highly drought-resistant pp7l hda6 mutant","link":"http://biorxiv.org/cgi/content/short/2023.11.21.568111v1?rss=1","abstract":"Plants have evolved efficient strategies to cope with drought stress, including stomata closure, significant changes in nuclear gene expression, and epigenetic mechanisms. Previously, we identified Arabidopsis thaliana PROTEIN PHOSPHATASE7-LIKE (PP7L) as an extrachloroplastic protein that promotes chloroplast development and high light, and salt tolerance. Here, we demonstrate that the pp7l mutant can withstand prolonged periods of drought stress. Interestingly, chloroplast development in pp7l recovers under drought conditions, despite growth of the mutant is impaired under normal growth conditions. To assess the (post)transcriptional changes occurring in the pp7l mutant under different durations of drought exposure, we used long non-coding RNA-sequencing. Compared to the previously reported drought-responsive changes in the wild type, the drought-responsive changes detected in the pp7l mutant were negligible. Our analysis of data generated in this study and previously motivated us to create a pp7l hda6 mutant, which exhibits remarkable drought resistance. Notably, the growth penalty associated with pp7l was alleviated in the double mutant, ruling out a dwarf effect on the drought-tolerant trait of this genotype.","creator":"Xu, D., Leister, D., Kleine, T."}]},{"name":"Economics","feed":[{"id":"2311.16156","slug":"an-efficiency-analysis-of-spanish-airports-arxiv-2311-16156v1-econ-gn","title":"An efficiency analysis of Spanish airports.","link":"http://arxiv.org/abs/2311.16156","abstract":"Privatization and commercialization of airports in recent years are drawing a different picture in the aeronautical industry. Airport benchmarking shows the accommodation and performance of airports in the evolution of the market and the new requirements that they have to face. AENA manages a wide and heterogeneous network of airports. There are 46 airports divided into three categories and with particularities due to their geographical location or the competitive environment where they are located. This paper analyzes the technical efficiency and its determinants of the 39 commercial airports of the AENA network between the years 2011-2014. To do this, two benchmarking techniques, SFA and DEA, are used, with a two-stage analysis. The average efficiency of the network is between 75-79\\%. The results with the two techniques are similar with a correlation of 0.67. With regard to the commercial part of the network, AENA has a high margin for improvement because it is below the world and European average. AENA must focus on the development of the commercial area and the introduction of competition within the network to improve the technical efficiency of regional airports mainly.","creator":"Adrian Nerja"},{"id":"2311.16260","slug":"using-multiple-outcomes-to-improve-the-synthetic-control-method-arxiv-2311-16260v1-econ-em","title":"Using Multiple Outcomes to Improve the Synthetic Control Method.","link":"http://arxiv.org/abs/2311.16260","abstract":"When there are multiple outcome series of interest, Synthetic Control analyses typically proceed by estimating separate weights for each outcome. In this paper, we instead propose estimating a common set of weights across outcomes, by balancing either a vector of all outcomes or an index or average of them. Under a low-rank factor model, we show that these approaches lead to lower bias bounds than separate weights, and that averaging leads to further gains when the number of outcomes grows. We illustrate this via simulation and in a re-analysis of the impact of the Flint water crisis on educational outcomes.","creator":"Liyang Sun, Eli Ben-Michael, Avi Feller"},{"id":"2311.16333","slug":"from-reactive-to-proactive-volatility-modeling-with-hemisphere-neural-networks-arxiv-2311-16333v1-econ-em","title":"From Reactive to Proactive Volatility Modeling with Hemisphere Neural Networks.","link":"http://arxiv.org/abs/2311.16333","abstract":"We reinvigorate maximum likelihood estimation (MLE) for macroeconomic density forecasting through a novel neural network architecture with dedicated mean and variance hemispheres. Our architecture features several key ingredients making MLE work in this context. First, the hemispheres share a common core at the entrance of the network which accommodates for various forms of time variation in the error variance. Second, we introduce a volatility emphasis constraint that breaks mean/variance indeterminacy in this class of overparametrized nonlinear models. Third, we conduct a blocked out-of-bag reality check to curb overfitting in both conditional moments. Fourth, the algorithm utilizes standard deep learning software and thus handles large data sets - both computationally and statistically. Ergo, our Hemisphere Neural Network (HNN) provides proactive volatility forecasts based on leading indicators when it can, and reactive volatility based on the magnitude of previous prediction errors when it must. We evaluate point and density forecasts with an extensive out-of-sample experiment and benchmark against a suite of models ranging from classics to more modern machine learning-based offerings. In all cases, HNN fares well by consistently providing accurate mean/variance forecasts for all targets and horizons. Studying the resulting volatility paths reveals its versatility, while probabilistic forecasting evaluation metrics showcase its enviable reliability. Finally, we also demonstrate how this machinery can be merged with other structured deep learning models by revisiting Goulet Coulombe (2022)'s Neural Phillips Curve.","creator":"Philippe Goulet Coulombe, Mikael Frenette, Karin Klieber"},{"id":"2311.16370","slug":"climate-crops-and-postharvest-conflict-arxiv-2311-16370v1-econ-gn","title":"Climate, Crops, and Postharvest Conflict.","link":"http://arxiv.org/abs/2311.16370","abstract":"I present new evidence of the effects of climate shocks on political violence and social unrest. Using granular conflict and weather data covering the entire continent of Africa from 1997 to 2023, I find that exposure to El Ni\\~no events during the crop-growing season decreases political violence targeted at civilians during the early postharvest season. A moderate-strength El Ni\\~no event results in a three percent reduction in political violence with civilian targeting in croplands compared with the benchmark levels of this conflict evaluated at average cropland size and average growing-season exposure of local weather to El Ni\\~no shocks. Because this effect manifests itself only in cells with crop agriculture and only during the postharvest season supports the idea that agriculture is the key channel and rapacity is the key motive connecting climatic shocks and political violence. Reassuringly, the magnitude of the estimated effect increases substantially, in one instance more than doubles, when I use subsets of data that are better suited for unveiling the proposed mechanism. This study advances knowledge of the relationship between climate and conflict. And because El Ni\\~no events can be predicted several months in advance, these findings can contribute to creating a platform for early warning of political violence, specifically in predominantly agrarian societies in Africa.","creator":"David Ubilava"},{"id":"2311.16440","slug":"inference-for-low-rank-models-without-estimating-the-rank-arxiv-2311-16440v1-econ-em","title":"Inference for Low-rank Models without Estimating the Rank.","link":"http://arxiv.org/abs/2311.16440","abstract":"This paper studies the inference about linear functionals of high-dimensional low-rank matrices. While most existing inference methods would require consistent estimation of the true rank, our procedure is robust to rank misspecification, making it a promising approach in applications where rank estimation can be unreliable. We estimate the low-rank spaces using pre-specified weighting matrices, known as diversified projections. A novel statistical insight is that, unlike the usual statistical wisdom that overfitting mainly introduces additional variances, the over-estimated low-rank space also gives rise to a non-negligible bias due to an implicit ridge-type regularization. We develop a new inference procedure and show that the central limit theorem holds as long as the pre-specified rank is no smaller than the true rank. Empirically, we apply our method to the U.S. federal grants allocation data and test the existence of pork-barrel politics.","creator":"Jungjun Choi, Hyukjun Kwon, Yuan Liao"},{"id":"2311.16486","slug":"on-the-adaptation-of-causal-forests-to-manifold-data-arxiv-2311-16486v1-math-st","title":"On the adaptation of causal forests to manifold data.","link":"http://arxiv.org/abs/2311.16486","abstract":"Researchers often hold the belief that random forests are \"the cure to the world's ills\" (Bickel, 2010). But how exactly do they achieve this? Focused on the recently introduced causal forests (Athey and Imbens, 2016; Wager and Athey, 2018), this manuscript aims to contribute to an ongoing research trend towards answering this question, proving that causal forests can adapt to the unknown covariate manifold structure. In particular, our analysis shows that a causal forest estimator can achieve the optimal rate of convergence for estimating the conditional average treatment effect, with the covariate dimension automatically replaced by the manifold dimension. These findings align with analogous observations in the realm of deep learning and resonate with the insights presented in Peter Bickel's 2004 Rietz lecture.","creator":"Yiyi Huo, Yingying Fan, Fang Han"},{"id":"2311.16570","slug":"epistemic-limits-of-empirical-finance-causal-reductionism-and-self-reference-arxiv-2311-16570v1-q-fin-gn","title":"Epistemic Limits of Empirical Finance: Causal Reductionism and Self-Reference.","link":"http://arxiv.org/abs/2311.16570","abstract":"The clarion call for causal reduction in the study of capital markets is intensifying. However, in self-referencing and open systems such as capital markets, the idea of unidirectional causation (if applicable) may be limiting at best, and unstable or fallacious at worst. In this research, we critically assess the use of scientific deduction and causal inference within the study of empirical finance and econometrics. We then demonstrate the idea of competing causal chains using a toy model adapted from ecological predator/prey relationships. From this, we develop the alternative view that the study of empirical finance, and the risks contained therein, may be better appreciated once we admit that our current arsenal of quantitative finance tools may be limited to ex post causal inference under popular assumptions. Where these assumptions are challenged, for example in a recognizable reflexive context, the prescription of unidirectional causation proves deeply problematic.","creator":"Daniel Polakow, Tim Gebbie, Emlyn Flint"},{"id":"2311.17021","slug":"optimal-categorical-instrumental-variables-arxiv-2311-17021v1-econ-em","title":"Optimal Categorical Instrumental Variables.","link":"http://arxiv.org/abs/2311.17021","abstract":"This paper discusses estimation with a categorical instrumental variable in settings with potentially few observations per category. The proposed categorical instrumental variable estimator (CIV) leverages a regularization assumption that implies existence of a latent categorical variable with fixed finite support achieving the same first stage fit as the observed instrument. In asymptotic regimes that allow the number of observations per category to grow at arbitrary small polynomial rate with the sample size, I show that when the cardinality of the support of the optimal instrument is known, CIV is root-n asymptotically normal, achieves the same asymptotic variance as the oracle IV estimator that presumes knowledge of the optimal instrument, and is semiparametrically efficient under homoskedasticity. Under-specifying the number of support points reduces efficiency but maintains asymptotic normality.","creator":"Thomas Wiemann"},{"id":"1912.10488","slug":"efficient-and-convergent-sequential-pseudo-likelihood-estimation-of-dynamic-discrete-games-arxiv-1912-10488v4-econ-em-updated","title":"Efficient and Convergent Sequential Pseudo-Likelihood Estimation of Dynamic Discrete Games.","link":"http://arxiv.org/abs/1912.10488","abstract":"We propose a new sequential Efficient Pseudo-Likelihood (k-EPL) estimator for dynamic discrete choice games of incomplete information. k-EPL considers the joint behavior of multiple players simultaneously, as opposed to individual responses to other agents' equilibrium play. This, in addition to reframing the problem from conditional choice probability (CCP) space to value function space, yields a computationally tractable, stable, and efficient estimator. We show that each iteration in the k-EPL sequence is consistent and asymptotically efficient, so the first-order asymptotic properties do not vary across iterations. Furthermore, we show the sequence achieves higher-order equivalence to the finite-sample maximum likelihood estimator with iteration and that the sequence of estimators converges almost surely to the maximum likelihood estimator at a nearly-superlinear rate when the data are generated by any regular Markov perfect equilibrium, including equilibria that lead to inconsistency of other sequential estimators. When utility is linear in parameters, k-EPL iterations are computationally simple, only requiring that the researcher solve linear systems of equations to generate pseudo-regressors which are used in a static logit/probit regression. Monte Carlo simulations demonstrate the theoretical results and show k-EPL's good performance in finite samples in both small- and large-scale games, even when the game admits spurious equilibria in addition to one that generated the data. We apply the estimator to study the role of competition in the U.S. wholesale club industry.","creator":"Adam Dearing, Jason R. Blevins"},{"id":"2111.01566","slug":"strategyproof-and-proportionally-fair-facility-location-arxiv-2111-01566v3-cs-gt-updated","title":"Strategyproof and Proportionally Fair Facility Location.","link":"http://arxiv.org/abs/2111.01566","abstract":"We focus on a simple, one-dimensional collective decision problem (often referred to as the facility location problem) and explore issues of strategyproofness and proportionality-based fairness. We introduce and analyze a hierarchy of proportionality-based fairness axioms of varying strength: Individual Fair Share (IFS), Unanimous Fair Share (UFS), Proportionality (as in Freeman et al, 2021), and Proportional Fairness (PF). For each axiom, we characterize the family of mechanisms that satisfy the axiom and strategyproofness. We show that imposing strategyproofness renders many of the axioms to be equivalent: the family of mechanisms that satisfy proportionality, unanimity, and strategyproofness is equivalent to the family of mechanisms that satisfy UFS and strategyproofness, which, in turn, is equivalent to the family of mechanisms that satisfy PF and strategyproofness. Furthermore, there is a unique such mechanism: the Uniform Phantom mechanism, which is studied in Freeman et al. (2021). We also characterize the outcomes of the Uniform Phantom mechanism as the unique (pure) equilibrium outcome for any mechanism that satisfies continuity, strict monotonicity, and UFS. Finally, we analyze the approximation guarantees, in terms of optimal social welfare and minimum total cost, obtained by mechanisms that are strategyproof and satisfy each proportionality-based fairness axiom. We show that the Uniform Phantom mechanism provides the best approximation of the optimal social welfare (and also minimum total cost) among all mechanisms that satisfy UFS.","creator":"Haris Aziz, Alexander Lam, Barton E. Lee, Toby Walsh"},{"id":"2202.07150","slug":"asymptotics-of-cointegration-tests-for-high-dimensional-var-k-arxiv-2202-07150v4-econ-em-updated","title":"Asymptotics of Cointegration Tests for High-Dimensional VAR($k$).","link":"http://arxiv.org/abs/2202.07150","abstract":"The paper studies nonstationary high-dimensional vector autoregressions of order $k$, VAR($k$). Additional deterministic terms such as trend or seasonality are allowed. The number of time periods, $T$, and the number of coordinates, $N$, are assumed to be large and of the same order. Under this regime the first-order asymptotics of the Johansen likelihood ratio (LR), Pillai-Bartlett, and Hotelling-Lawley tests for cointegration are derived: the test statistics converge to nonrandom integrals. For more refined analysis, the paper proposes and analyzes a modification of the Johansen test. The new test for the absence of cointegration converges to the partial sum of the Airy$_1$ point process. Supporting Monte Carlo simulations indicate that the same behavior persists universally in many situations beyond those considered in our theorems.  The paper presents empirical implementations of the approach for the analysis of S$\\&amp;$P$100$ stocks and of cryptocurrencies. The latter example has a strong presence of multiple cointegrating relationships, while the results for the former are consistent with the null of no cointegration.","creator":"Anna Bykhovskaya, Vadim Gorin"},{"id":"2210.15914","slug":"the-role-of-immigrants-emigrants-and-locals-in-the-historical-formation-of-european-knowledge-agglomerations-arxiv-2210-15914v6-econ-gn-updated","title":"The Role of Immigrants, Emigrants, and Locals in the Historical Formation of European Knowledge Agglomerations.","link":"http://arxiv.org/abs/2210.15914","abstract":"Did migrants make Paris a Mecca for the arts and Vienna a beacon of classical music? Or was their rise a pure consequence of local actors? Here, we use data on more than 22,000 historical individuals born between the years 1000 and 2000 to estimate the contribution of famous immigrants, emigrants, and locals to the knowledge specializations of European regions. We find that the probability that a region develops or keeps specialization in an activity (based on the birth of famous physicists, painters, etc.) grows with both, the presence of immigrants with knowledge on that activity and immigrants with knowledge in related activities. In contrast, we do not find robust evidence that the presence of locals with related knowledge explains entries and/or exits. We address some endogeneity concerns using fixed-effects models considering any location-period-activity specific factors (e.g. the presence of a new university attracting scientists).","creator":"Philipp Koch, Viktor Stojkoski, C&#xe9;sar A. Hidalgo"},{"id":"2303.00208","slug":"a-myersonian-framework-for-optimal-liquidity-provision-in-automated-market-makers-arxiv-2303-00208v2-cs-gt-updated","title":"A Myersonian Framework for Optimal Liquidity Provision in Automated Market Makers.","link":"http://arxiv.org/abs/2303.00208","abstract":"In decentralized finance (\"DeFi\"), automated market makers (AMMs) enable traders to programmatically exchange one asset for another. Such trades are enabled by the assets deposited by liquidity providers (LPs). The goal of this paper is to characterize and interpret the optimal (i.e., profit-maximizing) strategy of a monopolist liquidity provider, as a function of that LP's beliefs about asset prices and trader behavior. We introduce a general framework for reasoning about AMMs based on a Bayesian-like belief inference framework, where LPs maintain an asset price estimate. In this model, the market maker (i.e., LP) chooses a demand curve that specifies the quantity of a risky asset to be held at each dollar price. Traders arrive sequentially and submit a price bid that can be interpreted as their estimate of the risky asset price; the AMM responds to this submitted bid with an allocation of the risky asset to the trader, a payment that the trader must pay, and a revised internal estimate for the true asset price. We define an incentive-compatible (IC) AMM as one in which a trader's optimal strategy is to submit its true estimate of the asset price, and characterize the IC AMMs as those with downward-sloping demand curves and payments defined by a formula familiar from Myerson's optimal auction theory. We generalize Myerson's virtual values, and characterize the profit-maximizing IC AMM. The optimal demand curve generally has a jump that can be interpreted as a \"bid-ask spread,\" which we show is caused by a combination of adverse selection risk (dominant when the degree of information asymmetry is large) and monopoly pricing (dominant when asymmetry is small). This work opens up new research directions into the study of automated exchange mechanisms from the lens of optimal auction theory and iterative belief inference, using tools of theoretical computer science in a novel way.","creator":"Jason Milionis, Ciamac C. Moallemi, Tim Roughgarden"},{"id":"2305.11523","slug":"ai-regulation-in-the-european-union-examining-non-state-actor-preferences-arxiv-2305-11523v2-econ-gn-updated","title":"AI Regulation in the European Union: Examining Non-State Actor Preferences.","link":"http://arxiv.org/abs/2305.11523","abstract":"As the development and use of artificial intelligence (AI) continues to grow, policymakers are increasingly grappling with the question of how to regulate this technology. The most far-reaching international initiative is the European Union (EU) AI Act, which aims to establish the first comprehensive, binding framework for regulating AI. In this article, we offer the first systematic analysis of non-state actor preferences toward international regulation of AI, focusing on the case of the EU AI Act. Theoretically, we develop an argument about the regulatory preferences of business actors and other non-state actors under varying conditions of AI sector competitiveness. Empirically, we test these expectations using data from public consultations on European AI regulation. Our findings are threefold. First, all types of non-state actors express concerns about AI and support regulation in some form. Second, there are nonetheless significant differences across actor types, with business actors being less concerned about the downsides of AI and more in favor of lax regulation than other non-state actors. Third, these differences are more pronounced in countries with stronger commercial AI sectors. Our findings shed new light on non-state actor preferences toward AI regulation and point to challenges for policymakers balancing competing interests in society.","creator":"Jonas Tallberg, Magnus Lundgren, Johannes Geith"},{"id":"2311.12878","slug":"adaptive-bayesian-learning-with-action-and-state-dependent-signal-variance-arxiv-2311-12878v2-stat-me-updated","title":"Adaptive Bayesian Learning with Action and State-Dependent Signal Variance.","link":"http://arxiv.org/abs/2311.12878","abstract":"This manuscript presents an advanced framework for Bayesian learning by incorporating action and state-dependent signal variances into decision-making models. This framework is pivotal in understanding complex data-feedback loops and decision-making processes in various economic systems. Through a series of examples, we demonstrate the versatility of this approach in different contexts, ranging from simple Bayesian updating in stable environments to complex models involving social learning and state-dependent uncertainties. The paper uniquely contributes to the understanding of the nuanced interplay between data, actions, outcomes, and the inherent uncertainty in economic models.","creator":"Kaiwen Hou"},{"id":"2311.14676","slug":"decoding-social-sentiment-in-dao-a-comparative-analysis-of-blockchain-governance-communities-arxiv-2311-14676v1-cs-cy-cross-listed","title":"Decoding Social Sentiment in DAO: A Comparative Analysis of Blockchain Governance Communities.","link":"http://arxiv.org/abs/2311.14676","abstract":"Blockchain technology is leading a revolutionary transformation across diverse industries, with effective governance standing as a critical determinant for the success and sustainability of blockchain projects. Community forums, pivotal in engaging decentralized autonomous organizations (DAOs), wield a substantial impact on blockchain governance decisions. Concurrently, Natural Language Processing (NLP), particularly sentiment analysis, provides powerful insights from textual data. While prior research has explored the potential of NLP tools in social media sentiment analysis, a gap persists in understanding the sentiment landscape of blockchain governance communities. The evolving discourse and sentiment dynamics on the forums of top DAOs remain largely unknown. This paper delves deep into the evolving discourse and sentiment dynamics on the public forums of leading DeFi projects -- Aave, Uniswap, Curve Dao, Aragon, Yearn.finance, Merit Circle, and Balancer -- placing a primary focus on discussions related to governance issues. Despite differing activity patterns, participants across these decentralized communities consistently express positive sentiments in their Discord discussions, indicating optimism towards governance decisions. Additionally, our research suggests a potential interplay between discussion intensity and sentiment dynamics, indicating that higher discussion volumes may contribute to more stable and positive emotions. The insights gained from this study are valuable for decision-makers in blockchain governance, underscoring the pivotal role of sentiment analysis in interpreting community emotions and its evolving impact on the landscape of blockchain governance. This research significantly contributes to the interdisciplinary exploration of the intersection of blockchain and society, with a specific emphasis on the decentralized blockchain governance ecosystem.","creator":"Yutong Quan, Xintong Wu, Wanlin Deng, Luyao Zhang"}]}]