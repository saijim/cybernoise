[{"name":"Artificial Intelligence","feed":[{"id":"2403.14077","slug":"can-chatgpt-detect-deepfakes-a-study-of-using-multimodal-large-language-models-for-media-forensics","title":"Can ChatGPT Detect DeepFakes? A Study of Using Multimodal Large Language Models for Media Forensics","link":"https://arxiv.org/abs/2403.14077","abstract":"Abstract: DeepFakes, which refer to AI-generated media content, have become an increasing concern due to their use as a means for disinformation. Detecting DeepFakes is currently solved with programmed machine learning algorithms. In this work, we investigate the capabilities of multimodal large language models (LLMs) in DeepFake detection. We conducted qualitative and quantitative experiments to demonstrate multimodal LLMs and show that they can expose AI-generated images through careful experimental design and prompt engineering. This is interesting, considering that LLMs are not inherently tailored for media forensic tasks, and the process does not require programming. We discuss the limitations of multimodal LLMs for these tasks and suggest possible improvements.","creator":"Shan Jia, Reilin Lyu, Kangran Zhao, Yize Chen, Zhiyuan Yan, Yan Ju, Chuanbo Hu, Xin Li, Baoyuan Wu, Siwei Lyu"},{"id":"2403.14100","slug":"causal-knowledge-engineering-a-case-study-from-covid-19","title":"Causal knowledge engineering: A case study from COVID-19","link":"https://arxiv.org/abs/2403.14100","abstract":"Abstract: COVID-19 appeared abruptly in early 2020, requiring a rapid response amid a context of great uncertainty. Good quality data and knowledge was initially lacking, and many early models had to be developed with causal assumptions and estimations built in to supplement limited data, often with no reliable approach for identifying, validating and documenting these causal assumptions. Our team embarked on a knowledge engineering process to develop a causal knowledge base consisting of several causal BNs for diverse aspects of COVID-19. The unique challenges of the setting lead to experiments with the elicitation approach, and what emerged was a knowledge engineering method we call Causal Knowledge Engineering (CKE). The CKE provides a structured approach for building a causal knowledge base that can support the development of a variety of application-specific models. Here we describe the CKE method, and use our COVID-19 work as a case study to provide a detailed discussion and analysis of the method.","creator":"Steven Mascaro, Yue Wu, Ross Pearson, Owen Woodberry, Jessica Ramsay, Tom Snelling, Ann E. Nicholson"},{"id":"2403.14102","slug":"dourn-improving-douzero-by-residual-neural-networks","title":"DouRN: Improving DouZero by Residual Neural Networks","link":"https://arxiv.org/abs/2403.14102","abstract":"Abstract: Deep reinforcement learning has made significant progress in games with imperfect information, but its performance in the card game Doudizhu (Chinese Poker/Fight the Landlord) remains unsatisfactory. Doudizhu is different from conventional games as it involves three players and combines elements of cooperation and confrontation, resulting in a large state and action space. In 2021, a Doudizhu program called DouZero\\cite{zha2021douzero} surpassed previous models without prior knowledge by utilizing traditional Monte Carlo methods and multilayer perceptrons. Building on this work, our study incorporates residual networks into the model, explores different architectural designs, and conducts multi-role testing. Our findings demonstrate that this model significantly improves the winning rate within the same training time. Additionally, we introduce a call scoring system to assist the agent in deciding whether to become a landlord. With these enhancements, our model consistently outperforms the existing version of DouZero and even experienced human players. \\footnote{The source code is available at \\url{https://github.com/Yingchaol/Douzero_Resnet.git.}","creator":"Yiquan Chen, Yingchao Lyu, Di Zhang"},{"id":"2403.14443","slug":"language-models-can-reduce-asymmetry-in-information-markets","title":"Language Models Can Reduce Asymmetry in Information Markets","link":"https://arxiv.org/abs/2403.14443","abstract":"Abstract: This work addresses the buyer's inspection paradox for information markets. The paradox is that buyers need to access information to determine its value, while sellers need to limit access to prevent theft. To study this, we introduce an open-source simulated digital marketplace where intelligent agents, powered by language models, buy and sell information on behalf of external participants. The central mechanism enabling this marketplace is the agents' dual capabilities: they not only have the capacity to assess the quality of privileged information but also come equipped with the ability to forget. This ability to induce amnesia allows vendors to grant temporary access to proprietary information, significantly reducing the risk of unauthorized retention while enabling agents to accurately gauge the information's relevance to specific queries or tasks. To perform well, agents must make rational decisions, strategically explore the marketplace through generated sub-queries, and synthesize answers from purchased information. Concretely, our experiments (a) uncover biases in language models leading to irrational behavior and evaluate techniques to mitigate these biases, (b) investigate how price affects demand in the context of informational goods, and (c) show that inspection and higher budgets both lead to higher quality outcomes.","creator":"Nasim Rahaman, Martin Weiss, Manuel W\\\"uthrich, Yoshua Bengio, Li Erran Li, Chris Pal, Bernhard Sch\\\"olkopf"},{"id":"2403.14566","slug":"a-survey-on-concept-based-approaches-for-model-improvement","title":"A survey on Concept-based Approaches For Model Improvement","link":"https://arxiv.org/abs/2403.14566","abstract":"Abstract: The focus of recent research has shifted from merely increasing the Deep Neural Networks (DNNs) performance in various tasks to DNNs, which are more interpretable to humans. The field of eXplainable Artificial Intelligence (XAI) has observed various techniques, including saliency-based and concept-based approaches. Concept-based approaches explain the model's decisions in simple human understandable terms called Concepts. Concepts are human interpretable units of data and are the thinking ground of humans. Explanations in terms of concepts enable detecting spurious correlations, inherent biases, or clever-hans. With the advent of concept-based explanations, there have been various concept representation methods and automatic concept discovery algorithms. Some recent methods use concepts for post-hoc model disentanglement evaluation, while others use them for ante-hoc training. The concept-based approaches are new, with many representations coming up, and there is very limited work on Concept-based Model improvement. We provide a systematic review and taxonomy of various concept representations and their discovery algorithms in DNNs, specifically in vision. We also provide details on concept-based model improvement literature, which is the first to survey concept-based model improvement methods.","creator":"Avani Gupta, P J Narayanan"},{"id":"2403.14589","slug":"react-meets-actre-autonomous-annotations-of-agent-trajectories-for-contrastive-self-training","title":"ReAct Meets ActRe: Autonomous Annotations of Agent Trajectories for Contrastive Self-Training","link":"https://arxiv.org/abs/2403.14589","abstract":"Abstract: Language agents have demonstrated autonomous decision-making abilities by reasoning with foundation models. Recently, efforts have been made to train language agents for performance improvement, with multi-step reasoning and action trajectories as the training data. However, collecting such trajectories still requires considerable human effort, by either artificial annotations or implementations of diverse prompting frameworks. In this work, we propose A$^3$T, a framework that enables the Autonomous Annotation of Agent Trajectories in the style of ReAct. The central role is an ActRe prompting agent, which explains the reason for an arbitrary action. When randomly sampling an external action, the ReAct-style agent could query the ActRe agent with the action to obtain its textual rationales. Novel trajectories are then synthesized by prepending the posterior reasoning from ActRe to the sampled action. In this way, the ReAct-style agent executes multiple trajectories for the failed tasks, and selects the successful ones to supplement its failed trajectory for contrastive self-training. Realized by policy gradient methods with binarized rewards, the contrastive self-training with accumulated trajectories facilitates a closed loop for multiple rounds of language agent self-improvement. We conduct experiments using QLoRA fine-tuning with the open-sourced Mistral-7B-Instruct-v0.2. In AlfWorld, the agent trained with A$^3$T obtains a 1-shot success rate of 96%, and 100% success with 4 iterative rounds. In WebShop, the 1-shot performance of the A$^3$T agent matches human average, and 4 rounds of iterative refinement lead to the performance approaching human experts. A$^3$T agents significantly outperform existing techniques, including prompting with GPT-4, advanced agent frameworks, and fully fine-tuned LLMs.","creator":"Zonghan Yang, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Yang Liu"},{"id":"2402.17128","slug":"oscar-object-state-captioning-and-state-change-representation","title":"OSCaR: Object State Captioning and State Change Representation","link":"https://arxiv.org/abs/2402.17128","abstract":"arXiv:2402.17128v3 Announce Type: cross  Abstract: The capability of intelligent models to extrapolate and comprehend changes in object states is a crucial yet demanding aspect of AI research, particularly through the lens of human interaction in real-world settings. This task involves describing complex visual environments, identifying active objects, and interpreting their changes as conveyed through language. Traditional methods, which isolate object captioning and state change detection, offer a limited view of dynamic environments. Moreover, relying on a small set of symbolic words to represent changes has restricted the expressiveness of the language. To address these challenges, in this paper, we introduce the Object State Captioning and State Change Representation (OSCaR) dataset and benchmark. OSCaR consists of 14,084 annotated video segments with nearly 1,000 unique objects from various egocentric video collections. It sets a new testbed for evaluating multimodal large language models (MLLMs). Our experiments demonstrate that while MLLMs show some skill, they lack a full understanding of object state changes. The benchmark includes a fine-tuned model that, despite initial capabilities, requires significant improvements in accuracy and generalization ability for effective understanding of these changes. Our code and dataset are available at https://github.com/nguyennm1024/OSCaR.","creator":"Nguyen Nguyen, Jing Bi, Ali Vosoughi, Yapeng Tian, Pooyan Fazli, Chenliang Xu"},{"id":"2403.13809","slug":"predicting-confinement-effect-of-carbon-fiber-reinforced-polymers-on-strength-of-concrete-using-metaheuristics-based-artificial-neural-networks","title":"Predicting Confinement Effect of Carbon Fiber Reinforced Polymers on Strength of Concrete using Metaheuristics-based Artificial Neural Networks","link":"https://arxiv.org/abs/2403.13809","abstract":"arXiv:2403.13809v1 Announce Type: cross  Abstract: This article deals with the study of predicting the confinement effect of carbon fiber reinforced polymers (CFRPs) on concrete cylinder strength using metaheuristics-based artificial neural networks. A detailed database of 708 CFRP confined concrete cylinders is developed from previously published research with information on 8 parameters including geometrical parameters like the diameter (d) and height (h) of a cylinder, unconfined compressive strength of concrete (fco'), thickness (nt), the elastic modulus of CFRP (Ef), unconfined concrete strain confined concrete strain and the ultimate compressive strength of confined concrete fcc'. Three metaheuristic models are implemented including particle swarm optimization (PSO), grey wolf optimizer (GWO), and bat algorithm (BA). These algorithms are trained on the data using an objective function of mean square error and their predicted results are validated against the experimental studies and finite element analysis. The study shows that the hybrid model of PSO predicted the strength of CFRP-confined concrete cylinders with maximum accuracy of 99.13% and GWO predicted the results with an accuracy of 98.17%. The high accuracy of axial compressive strength predictions demonstrated that these prediction models are a reliable solution to the empirical methods. The prediction models are especially suitable for avoiding full-scale time-consuming experimental tests that make the process quick and economical.","creator":"Sarmed Wahab, Mohamed Suleiman, Faisal Shabbir, Nasim Shakouri Mahmoudabadi, Sarmad Waqas, Nouman Herl, Afaq Ahmad"},{"id":"2403.13812","slug":"quantitative-analysis-of-ai-generated-texts-in-academic-research-a-study-of-ai-presence-in-arxiv-submissions-using-ai-detection-tool","title":"Quantitative Analysis of AI-Generated Texts in Academic Research: A Study of AI Presence in Arxiv Submissions using AI Detection Tool","link":"https://arxiv.org/abs/2403.13812","abstract":"arXiv:2403.13812v1 Announce Type: cross  Abstract: Many people are interested in ChatGPT since it has become a prominent AIGC model that provides high-quality responses in various contexts, such as software development and maintenance. Misuse of ChatGPT might cause significant issues, particularly in public safety and education, despite its immense potential. The majority of researchers choose to publish their work on Arxiv. The effectiveness and originality of future work depend on the ability to detect AI components in such contributions. To address this need, this study will analyze a method that can see purposely manufactured content that academic organizations use to post on Arxiv. For this study, a dataset was created using physics, mathematics, and computer science articles. Using the newly built dataset, the following step is to put originality.ai through its paces. The statistical analysis shows that Originality.ai is very accurate, with a rate of 98%.","creator":"Arslan Akram"},{"id":"2403.13825","slug":"deep-generative-models-for-ultra-high-granularity-particle-physics-detector-simulation-a-voyage-from-emulation-to-extrapolation","title":"Deep Generative Models for Ultra-High Granularity Particle Physics Detector Simulation: A Voyage From Emulation to Extrapolation","link":"https://arxiv.org/abs/2403.13825","abstract":"arXiv:2403.13825v1 Announce Type: cross  Abstract: Simulating ultra-high-granularity detector responses in Particle Physics represents a critical yet computationally demanding task. This thesis aims to overcome this challenge for the Pixel Vertex Detector (PXD) at the Belle II experiment, which features over 7.5M pixel channels-the highest spatial resolution detector simulation dataset ever analysed with generative models. This thesis starts off by a comprehensive and taxonomic review on generative models for simulating detector signatures. Then, it presents the Intra-Event Aware Generative Adversarial Network (IEA-GAN), a new geometry-aware generative model that introduces a relational attentive reasoning and Self-Supervised Learning to approximate an \"event\" in the detector. This study underscores the importance of intra-event correlation for downstream physics analyses. Building upon this, the work drifts towards a more generic approach and presents YonedaVAE, a Category Theory-inspired generative model that tackles the open problem of Out-of-Distribution (OOD) simulation. YonedaVAE introduces a learnable Yoneda embedding to capture the entirety of an event based on its sensor relationships, formulating a Category theoretical language for intra-event relational reasoning. This is complemented by introducing a Self-Supervised learnable prior for VAEs and an Adaptive Top-q sampling mechanism, enabling the model to sample point clouds with variable intra-category cardinality in a zero-shot manner. Variable Intra-event cardinality has not been approached before and is vital for simulating irregular detector geometries. Trained on an early experiment data, YonedaVAE can reach a reasonable OOD simulation precision of a later experiment with almost double luminosity. This study introduces, for the first time, the results of using deep generative models for ultra-high granularity detector simulation in Particle Physics.","creator":"Baran Hashemi"},{"id":"2403.13835","slug":"smart-automatically-scaling-down-language-models-with-accuracy-guarantees-for-reduced-processing-fees","title":"SMART: Automatically Scaling Down Language Models with Accuracy Guarantees for Reduced Processing Fees","link":"https://arxiv.org/abs/2403.13835","abstract":"arXiv:2403.13835v1 Announce Type: cross  Abstract: The advancement of Large Language Models (LLMs) has significantly boosted performance in natural language processing (NLP) tasks. However, the deployment of high-performance LLMs incurs substantial costs, primarily due to the increased number of parameters aimed at enhancing model performance. This has made the use of state-of-the-art LLMs more expensive for end-users. AI service providers, such as OpenAI and Anthropic, often offer multiple versions of LLMs with varying prices and performance. However, end-users still face challenges in choosing the appropriate LLM for their tasks that balance result quality with cost.   We introduce SMART, Scaling Models Adaptively for Reduced Token Fees, a novel LLM framework designed to minimize the inference costs of NLP tasks while ensuring sufficient result quality. It enables users to specify an accuracy constraint in terms of the equivalence of outputs to those of the most powerful LLM. SMART then generates results that deviate from the outputs of this LLM only with a probability below a user-defined threshold. SMART employs a profiling phase that evaluates the performance of multiple LLMs to identify those that meet the user-defined accuracy level. SMART optimizes the tradeoff between profiling overheads and the anticipated cost savings resulting from profiling. Moreover, our approach significantly reduces inference costs by strategically leveraging a mix of LLMs. Our experiments on three real-world datasets show that, based on OpenAI models, SMART achieves significant cost savings, up to 25.6x in comparison to GPT-4.","creator":"Saehan Jo, Immanuel Trummer"},{"id":"2403.13839","slug":"depyf-open-the-opaque-box-of-pytorch-compiler-for-machine-learning-researchers","title":"depyf: Open the Opaque Box of PyTorch Compiler for Machine Learning Researchers","link":"https://arxiv.org/abs/2403.13839","abstract":"arXiv:2403.13839v1 Announce Type: cross  Abstract: PyTorch \\texttt{2.x} introduces a compiler designed to accelerate deep learning programs. However, for machine learning researchers, adapting to the PyTorch compiler to full potential can be challenging. The compiler operates at the Python bytecode level, making it appear as an opaque box. To address this, we introduce \\texttt{depyf}, a tool designed to demystify the inner workings of the PyTorch compiler. \\texttt{depyf} decompiles bytecode generated by PyTorch back into equivalent source code, and establishes connections between in-memory code objects and their on-disk source code counterparts. This feature enables users to step through the source code line by line using debuggers, thus enhancing their understanding of the underlying processes. Notably, \\texttt{depyf} is non-intrusive and user-friendly, primarily relying on two convenient context managers for its core functionality. The project is \\href{https://github.com/thuml/depyf}{ openly available} and is recognized as a \\href{https://pytorch.org/ecosystem/}{PyTorch ecosystem project}.","creator":"Kaichao You, Runsheng Bai, Meng Cao, Jianmin Wang, Ion Stoica, Mingsheng Long"},{"id":"2403.13840","slug":"whose-side-are-you-on-investigating-the-political-stance-of-large-language-models","title":"Whose Side Are You On? Investigating the Political Stance of Large Language Models","link":"https://arxiv.org/abs/2403.13840","abstract":"arXiv:2403.13840v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have gained significant popularity for their application in various everyday tasks such as text generation, summarization, and information retrieval. As the widespread adoption of LLMs continues to surge, it becomes increasingly crucial to ensure that these models yield responses that are politically impartial, with the aim of preventing information bubbles, upholding fairness in representation, and mitigating confirmation bias. In this paper, we propose a quantitative framework and pipeline designed to systematically investigate the political orientation of LLMs. Our investigation delves into the political alignment of LLMs across a spectrum of eight polarizing topics, spanning from abortion to LGBTQ issues. Across topics, the results indicate that LLMs exhibit a tendency to provide responses that closely align with liberal or left-leaning perspectives rather than conservative or right-leaning ones when user queries include details pertaining to occupation, race, or political affiliation. The findings presented in this study not only reaffirm earlier observations regarding the left-leaning characteristics of LLMs but also surface particular attributes, such as occupation, that are particularly susceptible to such inclinations even when directly steered towards conservatism. As a recommendation to avoid these models providing politicised responses, users should be mindful when crafting queries, and exercise caution in selecting neutral prompt language.","creator":"Pagnarasmey Pit, Xingjun Ma, Mike Conway, Qingyu Chen, James Bailey, Henry Pit, Putrasmey Keo, Watey Diep, Yu-Gang Jiang"},{"id":"2403.13841","slug":"integrating-wearable-sensor-data-and-self-reported-diaries-for-personalized-affect-forecasting","title":"Integrating Wearable Sensor Data and Self-reported Diaries for Personalized Affect Forecasting","link":"https://arxiv.org/abs/2403.13841","abstract":"arXiv:2403.13841v1 Announce Type: cross  Abstract: Emotional states, as indicators of affect, are pivotal to overall health, making their accurate prediction before onset crucial. Current studies are primarily centered on immediate short-term affect detection using data from wearable and mobile devices. These studies typically focus on objective sensory measures, often neglecting other forms of self-reported information like diaries and notes. In this paper, we propose a multimodal deep learning model for affect status forecasting. This model combines a transformer encoder with a pre-trained language model, facilitating the integrated analysis of objective metrics and self-reported diaries. To validate our model, we conduct a longitudinal study, enrolling college students and monitoring them over a year, to collect an extensive dataset including physiological, environmental, sleep, metabolic, and physical activity parameters, alongside open-ended textual diaries provided by the participants. Our results demonstrate that the proposed model achieves predictive accuracy of 82.50% for positive affect and 82.76% for negative affect, a full week in advance. The effectiveness of our model is further elevated by its explainability.","creator":"Zhongqi Yang, Yuning Wang, Ken S. Yamashita, Maryam Sabah, Elahe Khatibi, Iman Azimi, Nikil Dutt, Jessica L. Borelli, Amir M. Rahmani"},{"id":"2403.13843","slug":"machine-learning-and-vision-transformers-for-thyroid-carcinoma-diagnosis-a-review","title":"Machine Learning and Vision Transformers for Thyroid Carcinoma Diagnosis: A review","link":"https://arxiv.org/abs/2403.13843","abstract":"arXiv:2403.13843v1 Announce Type: cross  Abstract: The growing interest in developing smart diagnostic systems to help medical experts process extensive data for treating incurable diseases has been notable. In particular, the challenge of identifying thyroid cancer (TC) has seen progress with the use of machine learning (ML) and big data analysis, incorporating transformers to evaluate TC prognosis and determine the risk of malignancy in individuals. This review article presents a summary of various studies on AIbased approaches, especially those employing transformers, for diagnosing TC. It introduces a new categorization system for these methods based on artifcial intelligence (AI) algorithms, the goals of the framework, and the computing environments used. Additionally, it scrutinizes and contrasts the available TC datasets by their features. The paper highlights the importance of AI instruments in aiding the diagnosis and treatment of TC through supervised, unsupervised, or mixed approaches, with a special focus on the ongoing importance of transformers in medical diagnostics and disease management. It further discusses the progress made and the continuing obstacles in this area. Lastly, it explores future directions and focuses within this research feld.","creator":"Yassine Habchi, Hamza Kheddar, Yassine Himeur, Abdelkrim Boukabou, Ammar Chouchane, Abdelmalik Ouamane, Shadi Atalla, Wathiq Mansoor"},{"id":"2403.13844","slug":"scheduled-knowledge-acquisition-on-lightweight-vector-symbolic-architectures-for-brain-computer-interfaces","title":"Scheduled Knowledge Acquisition on Lightweight Vector Symbolic Architectures for Brain-Computer Interfaces","link":"https://arxiv.org/abs/2403.13844","abstract":"arXiv:2403.13844v1 Announce Type: cross  Abstract: Brain-Computer interfaces (BCIs) are typically designed to be lightweight and responsive in real-time to provide users timely feedback. Classical feature engineering is computationally efficient but has low accuracy, whereas the recent neural networks (DNNs) improve accuracy but are computationally expensive and incur high latency. As a promising alternative, the low-dimensional computing (LDC) classifier based on vector symbolic architecture (VSA), achieves small model size yet higher accuracy than classical feature engineering methods. However, its accuracy still lags behind that of modern DNNs, making it challenging to process complex brain signals. To improve the accuracy of a small model, knowledge distillation is a popular method. However, maintaining a constant level of distillation between the teacher and student models may not be the best way for a growing student during its progressive learning stages. In this work, we propose a simple scheduled knowledge distillation method based on curriculum data order to enable the student to gradually build knowledge from the teacher model, controlled by an $\\alpha$ scheduler. Meanwhile, we employ the LDC/VSA as the student model to enhance the on-device inference efficiency for tiny BCI devices that demand low latency. The empirical results have demonstrated that our approach achieves better tradeoff between accuracy and hardware efficiency compared to other methods.","creator":"Yejia Liu, Shijin Duan, Xiaolin Xu, Shaolei Ren"},{"id":"2403.13845","slug":"learning-to-better-see-the-unseen-broad-deep-mixed-anti-forgetting-framework-for-incremental-zero-shot-fault-diagnosis","title":"Learning to better see the unseen: Broad-Deep Mixed Anti-Forgetting Framework for Incremental Zero-Shot Fault Diagnosis","link":"https://arxiv.org/abs/2403.13845","abstract":"arXiv:2403.13845v1 Announce Type: cross  Abstract: Zero-shot fault diagnosis (ZSFD) is capable of identifying unseen faults via predicting fault attributes labeled by human experts. We first recognize the demand of ZSFD to deal with continuous changes in industrial processes, i.e., the model's ability to adapt to new fault categories and attributes while avoiding forgetting the diagnosis ability learned previously. To overcome the issue that the existing ZSFD paradigm cannot learn from evolving streams of training data in industrial scenarios, the incremental ZSFD (IZSFD) paradigm is proposed for the first time, which incorporates category increment and attribute increment for both traditional ZSFD and generalized ZSFD paradigms. To achieve IZSFD, we present a broad-deep mixed anti-forgetting framework (BDMAFF) that aims to learn from new fault categories and attributes. To tackle the issue of forgetting, BDMAFF effectively accumulates previously acquired knowledge from two perspectives: features and attribute prototypes. The feature memory is established through a deep generative model that employs anti-forgetting training strategies, ensuring the generation quality of historical categories is supervised and maintained. The diagnosis model SEEs the UNSEEN faults with the help of generated samples from the generative model. The attribute prototype memory is established through a diagnosis model inspired by the broad learning system. Unlike traditional incremental learning algorithms, BDMAFF introduces a memory-driven iterative update strategy for the diagnosis model, which allows the model to learn new faults and attributes without requiring the storage of all historical training samples. The effectiveness of the proposed method is verified by a real hydraulic system and the Tennessee-Eastman benchmark process.","creator":"Jiancheng Zhao, Jiaqi Yue, Chunhui Zhao"},{"id":"2403.13846","slug":"a-clustering-method-with-graph-maximum-decoding-information","title":"A Clustering Method with Graph Maximum Decoding Information","link":"https://arxiv.org/abs/2403.13846","abstract":"arXiv:2403.13846v1 Announce Type: cross  Abstract: The clustering method based on graph models has garnered increased attention for its widespread applicability across various knowledge domains. Its adaptability to integrate seamlessly with other relevant applications endows the graph model-based clustering analysis with the ability to robustly extract \"natural associations\" or \"graph structures\" within datasets, facilitating the modelling of relationships between data points. Despite its efficacy, the current clustering method utilizing the graph-based model overlooks the uncertainty associated with random walk access between nodes and the embedded structural information in the data. To address this gap, we present a novel Clustering method for Maximizing Decoding Information within graph-based models, named CMDI. CMDI innovatively incorporates two-dimensional structural information theory into the clustering process, consisting of two phases: graph structure extraction and graph vertex partitioning. Within CMDI, graph partitioning is reformulated as an abstract clustering problem, leveraging maximum decoding information to minimize uncertainty associated with random visits to vertices. Empirical evaluations on three real-world datasets demonstrate that CMDI outperforms classical baseline methods, exhibiting a superior decoding information ratio (DI-R). Furthermore, CMDI showcases heightened efficiency, particularly when considering prior knowledge (PK). These findings underscore the effectiveness of CMDI in enhancing decoding information quality and computational efficiency, positioning it as a valuable tool in graph-based clustering analyses.","creator":"Xinrun Xu, Manying Lv, Yurong Wu, Zhanbiao Lian, Zhiming Ding, Jin Yan, Shan Jiang"},{"id":"2403.13847","slug":"optimal-transport-for-domain-adaptation-through-gaussian-mixture-models","title":"Optimal Transport for Domain Adaptation through Gaussian Mixture Models","link":"https://arxiv.org/abs/2403.13847","abstract":"arXiv:2403.13847v1 Announce Type: cross  Abstract: In this paper we explore domain adaptation through optimal transport. We propose a novel approach, where we model the data distributions through Gaussian mixture models. This strategy allows us to solve continuous optimal transport through an equivalent discrete problem. The optimal transport solution gives us a matching between source and target domain mixture components. From this matching, we can map data points between domains, or transfer the labels from the source domain components towards the target domain. We experiment with 2 domain adaptation benchmarks in fault diagnosis, showing that our methods have state-of-the-art performance.","creator":"Eduardo Fernandes Montesuma, Fred Maurice Ngol\\`e Mboula, Antoine Souloumiac"},{"id":"2403.13848","slug":"smooth-sensitivity-for-learning-differentially-private-yet-accurate-rule-lists","title":"Smooth Sensitivity for Learning Differentially-Private yet Accurate Rule Lists","link":"https://arxiv.org/abs/2403.13848","abstract":"arXiv:2403.13848v1 Announce Type: cross  Abstract: Differentially-private (DP) mechanisms can be embedded into the design of a machine learningalgorithm to protect the resulting model against privacy leakage, although this often comes with asignificant loss of accuracy. In this paper, we aim at improving this trade-off for rule lists modelsby establishing the smooth sensitivity of the Gini impurity and leveraging it to propose a DP greedyrule list algorithm. In particular, our theoretical analysis and experimental results demonstrate thatthe DP rule lists models integrating smooth sensitivity have higher accuracy that those using otherDP frameworks based on global sensitivity.","creator":"Timoth\\'ee Ly (LAAS-ROC), Julien Ferry (EPM), Marie-Jos\\'e Huguet (LAAS-ROC), S\\'ebastien Gambs (UQAM), Ulrich Aivodji (ETS)"},{"id":"2403.13849","slug":"graphs-unveiled-graph-neural-networks-and-graph-generation","title":"Graphs Unveiled: Graph Neural Networks and Graph Generation","link":"https://arxiv.org/abs/2403.13849","abstract":"arXiv:2403.13849v1 Announce Type: cross  Abstract: One of the hot topics in machine learning is the field of GNN. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. This paper represents a survey, providing a comprehensive overview of Graph Neural Networks (GNNs). We discuss the applications of graph neural networks across various domains. Finally, we present an advanced field in GNNs: graph generation.","creator":"L\\'aszl\\'o Kov\\'acs, Ali Jlidi"},{"id":"2403.13850","slug":"spatio-temporal-fluid-dynamics-modeling-via-physical-awareness-and-parameter-diffusion-guidance","title":"Spatio-Temporal Fluid Dynamics Modeling via Physical-Awareness and Parameter Diffusion Guidance","link":"https://arxiv.org/abs/2403.13850","abstract":"arXiv:2403.13850v1 Announce Type: cross  Abstract: This paper proposes a two-stage framework named ST-PAD for spatio-temporal fluid dynamics modeling in the field of earth sciences, aiming to achieve high-precision simulation and prediction of fluid dynamics through spatio-temporal physics awareness and parameter diffusion guidance. In the upstream stage, we design a vector quantization reconstruction module with temporal evolution characteristics, ensuring balanced and resilient parameter distribution by introducing general physical constraints. In the downstream stage, a diffusion probability network involving parameters is utilized to generate high-quality future states of fluids, while enhancing the model's generalization ability by perceiving parameters in various physical setups. Extensive experiments on multiple benchmark datasets have verified the effectiveness and robustness of the ST-PAD framework, which showcase that ST-PAD outperforms current mainstream models in fluid dynamics modeling and prediction, especially in effectively capturing local representations and maintaining significant advantages in OOD generations.","creator":"Hao Wu, Fan Xu, Yifan Duan, Ziwei Niu, Weiyan Wang, Gaofeng Lu, Kun Wang, Yuxuan Liang, Yang Wang"},{"id":"2403.13863","slug":"diffimpute-tabular-data-imputation-with-denoising-diffusion-probabilistic-model","title":"DiffImpute: Tabular Data Imputation With Denoising Diffusion Probabilistic Model","link":"https://arxiv.org/abs/2403.13863","abstract":"arXiv:2403.13863v1 Announce Type: cross  Abstract: Tabular data plays a crucial role in various domains but often suffers from missing values, thereby curtailing its potential utility. Traditional imputation techniques frequently yield suboptimal results and impose substantial computational burdens, leading to inaccuracies in subsequent modeling tasks. To address these challenges, we propose DiffImpute, a novel Denoising Diffusion Probabilistic Model (DDPM). Specifically, DiffImpute is trained on complete tabular datasets, ensuring that it can produce credible imputations for missing entries without undermining the authenticity of the existing data. Innovatively, it can be applied to various settings of Missing Completely At Random (MCAR) and Missing At Random (MAR). To effectively handle the tabular features in DDPM, we tailor four tabular denoising networks, spanning MLP, ResNet, Transformer, and U-Net. We also propose Harmonization to enhance coherence between observed and imputed data by infusing the data back and denoising them multiple times during the sampling stage. To enable efficient inference while maintaining imputation performance, we propose a refined non-Markovian sampling process that works along with Harmonization. Empirical evaluations on seven diverse datasets underscore the prowess of DiffImpute. Specifically, when paired with the Transformer as the denoising network, it consistently outperforms its competitors, boasting an average ranking of 1.7 and the most minimal standard deviation. In contrast, the next best method lags with a ranking of 2.8 and a standard deviation of 0.9. The code is available at https://github.com/Dendiiiii/DiffImpute.","creator":"Yizhu Wen, Kai Yi, Jing Ke, Yiqing Shen"},{"id":"2403.13866","slug":"the-bid-picture-auction-inspired-multi-player-generative-adversarial-networks-training","title":"The Bid Picture: Auction-Inspired Multi-player Generative Adversarial Networks Training","link":"https://arxiv.org/abs/2403.13866","abstract":"arXiv:2403.13866v1 Announce Type: cross  Abstract: This article proposes auction-inspired multi-player generative adversarial networks training, which mitigates the mode collapse problem of GANs. Mode collapse occurs when an over-fitted generator generates a limited range of samples, often concentrating on a small subset of the data distribution. Despite the restricted diversity of generated samples, the discriminator can still be deceived into distinguishing these samples as real samples from the actual distribution. In the absence of external standards, a model cannot recognize its failure during the training phase. We extend the two-player game of generative adversarial networks to the multi-player game. During the training, the values of each model are determined by the bids submitted by other players in an auction-like process.","creator":"Joo Yong Shim, Jean Seong Bjorn Choe, Jong-Kook Kim"},{"id":"2403.13869","slug":"accurately-predicting-probabilities-of-safety-critical-rare-events-for-intelligent-systems","title":"Accurately Predicting Probabilities of Safety-Critical Rare Events for Intelligent Systems","link":"https://arxiv.org/abs/2403.13869","abstract":"arXiv:2403.13869v1 Announce Type: cross  Abstract: Intelligent systems are increasingly integral to our daily lives, yet rare safety-critical events present significant latent threats to their practical deployment. Addressing this challenge hinges on accurately predicting the probability of safety-critical events occurring within a given time step from the current state, a metric we define as 'criticality'. The complexity of predicting criticality arises from the extreme data imbalance caused by rare events in high dimensional variables associated with the rare events, a challenge we refer to as the curse of rarity. Existing methods tend to be either overly conservative or prone to overlooking safety-critical events, thus struggling to achieve both high precision and recall rates, which severely limits their applicability. This study endeavors to develop a criticality prediction model that excels in both precision and recall rates for evaluating the criticality of safety-critical autonomous systems. We propose a multi-stage learning framework designed to progressively densify the dataset, mitigating the curse of rarity across stages. To validate our approach, we evaluate it in two cases: lunar lander and bipedal walker scenarios. The results demonstrate that our method surpasses traditional approaches, providing a more accurate and dependable assessment of criticality in intelligent systems.","creator":"Ruoxuan Bai, Jingxuan Yang, Weiduo Gong, Yi Zhang, Qiujing Lu, Shuo Feng"},{"id":"2403.13890","slug":"towards-learning-contrast-kinetics-with-multi-condition-latent-diffusion-models","title":"Towards Learning Contrast Kinetics with Multi-Condition Latent Diffusion Models","link":"https://arxiv.org/abs/2403.13890","abstract":"arXiv:2403.13890v1 Announce Type: cross  Abstract: Contrast agents in dynamic contrast enhanced magnetic resonance imaging allow to localize tumors and observe their contrast kinetics, which is essential for cancer characterization and respective treatment decision-making. However, contrast agent administration is not only associated with adverse health risks, but also restricted for patients during pregnancy, and for those with kidney malfunction, or other adverse reactions. With contrast uptake as key biomarker for lesion malignancy, cancer recurrence risk, and treatment response, it becomes pivotal to reduce the dependency on intravenous contrast agent administration. To this end, we propose a multi-conditional latent diffusion model capable of acquisition time-conditioned image synthesis of DCE-MRI temporal sequences. To evaluate medical image synthesis, we additionally propose and validate the Fr\\'echet radiomics distance as an image quality measure based on biomarker variability between synthetic and real imaging data. Our results demonstrate our method's ability to generate realistic multi-sequence fat-saturated breast DCE-MRI and uncover the emerging potential of deep learning based contrast kinetics simulation. We publicly share our accessible codebase at https://github.com/RichardObi/ccnet.","creator":"Richard Osuala, Daniel Lang, Preeti Verma, Smriti Joshi, Apostolia Tsirikoglou, Grzegorz Skorupko, Kaisar Kushibar, Lidia Garrucho, Walter H. L. Pinaya, Oliver Diaz, Julia Schnabel, Karim Lekadir"},{"id":"2403.13925","slug":"reducing-large-language-model-bias-with-emphasis-on-restricted-industries-automated-dataset-augmentation-and-prejudice-quantification","title":"Reducing Large Language Model Bias with Emphasis on 'Restricted Industries': Automated Dataset Augmentation and Prejudice Quantification","link":"https://arxiv.org/abs/2403.13925","abstract":"arXiv:2403.13925v1 Announce Type: cross  Abstract: Despite the growing capabilities of large language models, there exists concerns about the biases they develop. In this paper, we propose a novel, automated mechanism for debiasing through specified dataset augmentation in the lens of bias producers and in the context of 'restricted industries' with limited data. We additionally create two new additional metrics, the mb-index and db-index, to quantify bias, considering the idea that bias occurs due to both intrinsic model architecture and dataset.","creator":"Devam Mondal, Carlo Lipizzi"},{"id":"2403.13940","slug":"multi-criteria-approach-for-selecting-an-explanation-from-the-set-of-counterfactuals-produced-by-an-ensemble-of-explainers","title":"Multi-criteria approach for selecting an explanation from the set of counterfactuals produced by an ensemble of explainers","link":"https://arxiv.org/abs/2403.13940","abstract":"arXiv:2403.13940v1 Announce Type: cross  Abstract: Counterfactuals are widely used to explain ML model predictions by providing alternative scenarios for obtaining the more desired predictions. They can be generated by a variety of methods that optimize different, sometimes conflicting, quality measures and produce quite different solutions. However, choosing the most appropriate explanation method and one of the generated counterfactuals is not an easy task. Instead of forcing the user to test many different explanation methods and analysing conflicting solutions, in this paper, we propose to use a multi-stage ensemble approach that will select single counterfactual based on the multiple-criteria analysis. It offers a compromise solution that scores well on several popular quality measures. This approach exploits the dominance relation and the ideal point decision aid method, which selects one counterfactual from the Pareto front. The conducted experiments demonstrated that the proposed approach generates fully actionable counterfactuals with attractive compromise values of the considered quality measures.","creator":"Ignacy St\\k{e}pka, Mateusz Lango, Jerzy Stefanowski"},{"id":"2403.13947","slug":"blendscape-enabling-unified-and-personalized-video-conferencing-environments-through-generative-ai","title":"BlendScape: Enabling Unified and Personalized Video-Conferencing Environments through Generative AI","link":"https://arxiv.org/abs/2403.13947","abstract":"arXiv:2403.13947v1 Announce Type: cross  Abstract: Today's video-conferencing tools support a rich range of professional and social activities, but their generic, grid-based environments cannot be easily adapted to meet the varying needs of distributed collaborators. To enable end-user customization, we developed BlendScape, a system for meeting participants to compose video-conferencing environments tailored to their collaboration context by leveraging AI image generation techniques. BlendScape supports flexible representations of task spaces by blending users' physical or virtual backgrounds into unified environments and implements multimodal interaction techniques to steer the generation. Through an evaluation with 15 end-users, we investigated their customization preferences for work and social scenarios. Participants could rapidly express their design intentions with BlendScape and envisioned using the system to structure collaboration in future meetings, but experienced challenges with preventing distracting elements. We implement scenarios to demonstrate BlendScape's expressiveness in supporting distributed collaboration techniques from prior work and propose composition techniques to improve the quality of environments.","creator":"Shwetha Rajaram, Nels Numan, Balasaravanan Thoravi Kumaravel, Nicolai Marquardt, Andrew D. Wilson"},{"id":"2403.13950","slug":"evo-2023-late-breaking-abstracts-volume","title":"Evo* 2023 -- Late-Breaking Abstracts Volume","link":"https://arxiv.org/abs/2403.13950","abstract":"arXiv:2403.13950v1 Announce Type: cross  Abstract: Volume with the Late-Breaking Abstracts submitted to the Evo* 2023 Conference, held in Brno (Czech Republic), from 12 to 14 of April. These papers present ongoing research and preliminary results investigating on the application of different approaches of Bioinspired Methods (mainly Evolutionary Computation) to different problems, most of them real world ones.","creator":"A. M. Mora, A. I. Esparcia-Alc\\'azar"},{"id":"2403.13951","slug":"acdg-vton-accurate-and-contained-diffusion-generation-for-virtual-try-on","title":"ACDG-VTON: Accurate and Contained Diffusion Generation for Virtual Try-On","link":"https://arxiv.org/abs/2403.13951","abstract":"arXiv:2403.13951v1 Announce Type: cross  Abstract: Virtual Try-on (VTON) involves generating images of a person wearing selected garments. Diffusion-based methods, in particular, can create high-quality images, but they struggle to maintain the identities of the input garments. We identified this problem stems from the specifics in the training formulation for diffusion. To address this, we propose a unique training scheme that limits the scope in which diffusion is trained. We use a control image that perfectly aligns with the target image during training. In turn, this accurately preserves garment details during inference. We demonstrate our method not only effectively conserves garment details but also allows for layering, styling, and shoe try-on. Our method runs multi-garment try-on in a single inference cycle and can support high-quality zoomed-in generations without training in higher resolutions. Finally, we show our method surpasses prior methods in accuracy and quality.","creator":"Jeffrey Zhang, Kedan Li, Shao-Yu Chang, David Forsyth"},{"id":"2403.13960","slug":"open-access-nao-oan-a-ros2-based-software-framework-for-hri-applications-with-the-nao-robot","title":"Open Access NAO (OAN): a ROS2-based software framework for HRI applications with the NAO robot","link":"https://arxiv.org/abs/2403.13960","abstract":"arXiv:2403.13960v1 Announce Type: cross  Abstract: This paper presents a new software framework for HRI experimentation with the sixth version of the common NAO robot produced by the United Robotics Group. Embracing the common demand of researchers for better performance and new features for NAO, the authors took advantage of the ability to run ROS2 onboard on the NAO to develop a framework independent of the APIs provided by the manufacturer. Such a system provides NAO with not only the basic skills of a humanoid robot such as walking and reproducing movements of interest but also features often used in HRI such as: speech recognition/synthesis, face and object detention, and the use of Generative Pre-trained Transformer (GPT) models for conversation. The developed code is therefore configured as a ready-to-use but also highly expandable and improvable tool thanks to the possibilities provided by the ROS community.","creator":"Antonio Bono, Kenji Brameld, Luigi D'Alfonso, Giuseppe Fedele"},{"id":"2403.13969","slug":"this-is-not-a-data-problem-algorithms-and-power-in-public-higher-education-in-canada","title":"\"This is not a data problem\": Algorithms and Power in Public Higher Education in Canada","link":"https://arxiv.org/abs/2403.13969","abstract":"arXiv:2403.13969v1 Announce Type: cross  Abstract: Algorithmic decision-making is increasingly being adopted across public higher education. The expansion of data-driven practices by post-secondary institutions has occurred in parallel with the adoption of New Public Management approaches by neoliberal administrations. In this study, we conduct a qualitative analysis of an in-depth ethnographic case study of data and algorithms in use at a public college in Ontario, Canada. We identify the data, algorithms, and outcomes in use at the college. We assess how the college's processes and relationships support those outcomes and the different stakeholders' perceptions of the college's data-driven systems. In addition, we find that the growing reliance on algorithmic decisions leads to increased student surveillance, exacerbation of existing inequities, and the automation of the faculty-student relationship. Finally, we identify a cycle of increased institutional power perpetuated by algorithmic decision-making, and driven by a push towards financial sustainability.","creator":"Kelly McConvey, Shion Guha"},{"id":"2403.14006","slug":"on-prompt-sensitivity-of-chatgpt-in-affective-computing","title":"On Prompt Sensitivity of ChatGPT in Affective Computing","link":"https://arxiv.org/abs/2403.14006","abstract":"arXiv:2403.14006v1 Announce Type: cross  Abstract: Recent studies have demonstrated the emerging capabilities of foundation models like ChatGPT in several fields, including affective computing. However, accessing these emerging capabilities is facilitated through prompt engineering. Despite the existence of some prompting techniques, the field is still rapidly evolving and many prompting ideas still require investigation. In this work, we introduce a method to evaluate and investigate the sensitivity of the performance of foundation models based on different prompts or generation parameters. We perform our evaluation on ChatGPT within the scope of affective computing on three major problems, namely sentiment analysis, toxicity detection, and sarcasm detection. First, we carry out a sensitivity analysis on pivotal parameters in auto-regressive text generation, specifically the temperature parameter $T$ and the top-$p$ parameter in Nucleus sampling, dictating how conservative or creative the model should be during generation. Furthermore, we explore the efficacy of several prompting ideas, where we explore how giving different incentives or structures affect the performance. Our evaluation takes into consideration performance measures on the affective computing tasks, and the effectiveness of the model to follow the stated instructions, hence generating easy-to-parse responses to be smoothly used in downstream applications.","creator":"Mostafa M. Amin, Bj\\\"orn W. Schuller"},{"id":"2403.14019","slug":"searching-search-spaces-meta-evolving-a-geometric-encoding-for-neural-networks","title":"Searching Search Spaces: Meta-evolving a Geometric Encoding for Neural Networks","link":"https://arxiv.org/abs/2403.14019","abstract":"arXiv:2403.14019v1 Announce Type: cross  Abstract: In evolutionary policy search, neural networks are usually represented using a direct mapping: each gene encodes one network weight. Indirect encoding methods, where each gene can encode for multiple weights, shorten the genome to reduce the dimensions of the search space and better exploit permutations and symmetries. The Geometric Encoding for Neural network Evolution (GENE) introduced an indirect encoding where the weight of a connection is computed as the (pseudo-)distance between the two linked neurons, leading to a genome size growing linearly with the number of genes instead of quadratically in direct encoding. However GENE still relies on hand-crafted distance functions with no prior optimization. Here we show that better performing distance functions can be found for GENE using Cartesian Genetic Programming (CGP) in a meta-evolution approach, hence optimizing the encoding to create a search space that is easier to exploit. We show that GENE with a learned function can outperform both direct encoding and the hand-crafted distances, generalizing on unseen problems, and we study how the encoding impacts neural network properties.","creator":"Tarek Kunze, Paul Templier, Dennis G Wilson"},{"id":"2403.14037","slug":"ax-to-grind-urdu-benchmark-dataset-for-urdu-fake-news-detection","title":"Ax-to-Grind Urdu: Benchmark Dataset for Urdu Fake News Detection","link":"https://arxiv.org/abs/2403.14037","abstract":"arXiv:2403.14037v1 Announce Type: cross  Abstract: Misinformation can seriously impact society, affecting anything from public opinion to institutional confidence and the political horizon of a state. Fake News (FN) proliferation on online websites and Online Social Networks (OSNs) has increased profusely. Various fact-checking websites include news in English and barely provide information about FN in regional languages. Thus the Urdu FN purveyors cannot be discerned using factchecking portals. SOTA approaches for Fake News Detection (FND) count upon appropriately labelled and large datasets. FND in regional and resource-constrained languages lags due to the lack of limited-sized datasets and legitimate lexical resources. The previous datasets for Urdu FND are limited-sized, domain-restricted, publicly unavailable and not manually verified where the news is translated from English into Urdu. In this paper, we curate and contribute the first largest publicly available dataset for Urdu FND, Ax-to-Grind Urdu, to bridge the identified gaps and limitations of existing Urdu datasets in the literature. It constitutes 10,083 fake and real news on fifteen domains collected from leading and authentic Urdu newspapers and news channel websites in Pakistan and India. FN for the Ax-to-Grind dataset is collected from websites and crowdsourcing. The dataset contains news items in Urdu from the year 2017 to the year 2023. Expert journalists annotated the dataset. We benchmark the dataset with an ensemble model of mBERT,XLNet, and XLM RoBERTa. The selected models are originally trained on multilingual large corpora. The results of the proposed model are based on performance metrics, F1-score, accuracy, precision, recall and MCC value.","creator":"Sheetal Harris, Jinshuo Liu, Hassan Jalil Hadi, Yue Cao"},{"id":"2403.14049","slug":"a-roadmap-towards-automated-and-regulated-robotic-systems","title":"A Roadmap Towards Automated and Regulated Robotic Systems","link":"https://arxiv.org/abs/2403.14049","abstract":"arXiv:2403.14049v1 Announce Type: cross  Abstract: The rapid development of generative technology opens up possibility for higher level of automation, and artificial intelligence (AI) embodiment in robotic systems is imminent. However, due to the blackbox nature of the generative technology, the generation of the knowledge and workflow scheme is uncontrolled, especially in a dynamic environment and a complex scene. This poses challenges to regulations in safety-demanding applications such as medical scenes. We argue that the unregulated generative processes from AI is fitted for low level end tasks, but intervention in the form of manual or automated regulation should happen post-workflow-generation and pre-robotic-execution. To address this, we propose a roadmap that can lead to fully automated and regulated robotic systems. In this paradigm, the high level policies are generated as structured graph data, enabling regulatory oversight and reusability, while the code base for lower level tasks is generated by generative models. Our approach aims the transitioning from expert knowledge to regulated action, akin to the iterative processes of study, practice, scrutiny, and execution in human tasks. We identify the generative and deterministic processes in a design cycle, where generative processes serve as a text-based world simulator and the deterministic processes generate the executable system. We propose State Machine Seralization Language (SMSL) to be the conversion point between text simulator and executable workflow control. From there, we analyze the modules involved based on the current literature, and discuss human in the loop. As a roadmap, this work identifies the current possible implementation and future work. This work does not provide an implemented system but envisions to inspire the researchers working on the direction in the roadmap. We implement the SMSL and D-SFO paradigm that serve as the starting point of the roadmap.","creator":"Yihao Liu, Mehran Armand"},{"id":"2403.14092","slug":"carbon-footprint-reduction-for-sustainable-data-centers-in-real-time","title":"Carbon Footprint Reduction for Sustainable Data Centers in Real-Time","link":"https://arxiv.org/abs/2403.14092","abstract":"arXiv:2403.14092v1 Announce Type: cross  Abstract: As machine learning workloads significantly increase energy consumption, sustainable data centers with low carbon emissions are becoming a top priority for governments and corporations worldwide. This requires a paradigm shift in optimizing power consumption in cooling and IT loads, shifting flexible loads based on the availability of renewable energy in the power grid, and leveraging battery storage from the uninterrupted power supply in data centers, using collaborative agents. The complex association between these optimization strategies and their dependencies on variable external factors like weather and the power grid carbon intensity makes this a hard problem. Currently, a real-time controller to optimize all these goals simultaneously in a dynamic real-world setting is lacking. We propose a Data Center Carbon Footprint Reduction (DC-CFR) multi-agent Reinforcement Learning (MARL) framework that optimizes data centers for the multiple objectives of carbon footprint reduction, energy consumption, and energy cost. The results show that the DC-CFR MARL agents effectively resolved the complex interdependencies in optimizing cooling, load shifting, and energy storage in real-time for various locations under real-world dynamic weather and grid carbon intensity conditions. DC-CFR significantly outperformed the industry standard ASHRAE controller with a considerable reduction in carbon emissions (14.5%), energy usage (14.4%), and energy cost (13.7%) when evaluated over one year across multiple geographical regions.","creator":"Soumyendu Sarkar, Avisek Naug, Ricardo Luna, Antonio Guillen, Vineet Gundecha, Sahand Ghorbanpour, Sajad Mousavi, Dejan Markovikj, Ashwin Ramesh Babu"},{"id":"2403.14110","slug":"heuristic-algorithm-based-action-masking-reinforcement-learning-haam-rl-with-ensemble-inference-method","title":"Heuristic Algorithm-based Action Masking Reinforcement Learning (HAAM-RL) with Ensemble Inference Method","link":"https://arxiv.org/abs/2403.14110","abstract":"arXiv:2403.14110v1 Announce Type: cross  Abstract: This paper presents a novel reinforcement learning (RL) approach called HAAM-RL (Heuristic Algorithm-based Action Masking Reinforcement Learning) for optimizing the color batching re-sequencing problem in automobile painting processes. The existing heuristic algorithms have limitations in adequately reflecting real-world constraints and accurately predicting logistics performance. Our methodology incorporates several key techniques including a tailored Markov Decision Process (MDP) formulation, reward setting including Potential-Based Reward Shaping, action masking using heuristic algorithms (HAAM-RL), and an ensemble inference method that combines multiple RL models. The RL agent is trained and evaluated using FlexSim, a commercial 3D simulation software, integrated with our RL MLOps platform BakingSoDA. Experimental results across 30 scenarios demonstrate that HAAM-RL with an ensemble inference method achieves a 16.25% performance improvement over the conventional heuristic algorithm, with stable and consistent results. The proposed approach exhibits superior performance and generalization capability, indicating its effectiveness in optimizing complex manufacturing processes. The study also discusses future research directions, including alternative state representations, incorporating model-based RL methods, and integrating additional real-world constraints.","creator":"Kyuwon Choi, Cheolkyun Rho, Taeyoun Kim, Daewoo Choi"},{"id":"2403.14119","slug":"c-tpt-calibrated-test-time-prompt-tuning-for-vision-language-models-via-text-feature-dispersion","title":"C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion","link":"https://arxiv.org/abs/2403.14119","abstract":"arXiv:2403.14119v1 Announce Type: cross  Abstract: In deep learning, test-time adaptation has gained attention as a method for model fine-tuning without the need for labeled data. A prime exemplification is the recently proposed test-time prompt tuning for large-scale vision-language models such as CLIP. Unfortunately, these prompts have been mainly developed to improve accuracy, overlooking the importance of calibration-a crucial aspect for quantifying prediction uncertainty. However, traditional calibration methods rely on substantial amounts of labeled data, making them impractical for test-time scenarios. To this end, this paper explores calibration during test-time prompt tuning by leveraging the inherent properties of CLIP. Through a series of observations, we find that the prompt choice significantly affects the calibration in CLIP, where the prompts leading to higher text feature dispersion result in better-calibrated predictions. Introducing the Average Text Feature Dispersion (ATFD), we establish its relationship with calibration error and present a novel method, Calibrated Test-time Prompt Tuning (C-TPT), for optimizing prompts during test-time with enhanced calibration. Through extensive experiments on different CLIP architectures and datasets, we show that C-TPT can effectively improve the calibration of test-time prompt tuning without needing labeled data.","creator":"Hee Suk Yoon, Eunseop Yoon, Joshua Tian Jin Tee, Mark Hasegawa-Johnson, Yingzhen Li, Chang D. Yoo"},{"id":"2403.14120","slug":"advancing-iiot-with-over-the-air-federated-learning-the-role-of-iterative-magnitude-pruning","title":"Advancing IIoT with Over-the-Air Federated Learning: The Role of Iterative Magnitude Pruning","link":"https://arxiv.org/abs/2403.14120","abstract":"arXiv:2403.14120v1 Announce Type: cross  Abstract: The industrial Internet of Things (IIoT) under Industry 4.0 heralds an era of interconnected smart devices where data-driven insights and machine learning (ML) fuse to revolutionize manufacturing. A noteworthy development in IIoT is the integration of federated learning (FL), which addresses data privacy and security among devices. FL enables edge sensors, also known as peripheral intelligence units (PIUs) to learn and adapt using their data locally, without explicit sharing of confidential data, to facilitate a collaborative yet confidential learning process. However, the lower memory footprint and computational power of PIUs inherently require deep neural network (DNN) models that have a very compact size. Model compression techniques such as pruning can be used to reduce the size of DNN models by removing unnecessary connections that have little impact on the model's performance, thus making the models more suitable for the limited resources of PIUs. Targeting the notion of compact yet robust DNN models, we propose the integration of iterative magnitude pruning (IMP) of the DNN model being trained in an over-the-air FL (OTA-FL) environment for IIoT. We provide a tutorial overview and also present a case study of the effectiveness of IMP in OTA-FL for an IIoT environment. Finally, we present future directions for enhancing and optimizing these deep compression techniques further, aiming to push the boundaries of IIoT capabilities in acquiring compact yet robust and high-performing DNN models.","creator":"Fazal Muhammad Ali Khan, Hatem Abou-Zeid, Aryan Kaushik, Syed Ali Hassan"},{"id":"2403.14146","slug":"evolving-benchmark-functions-to-compare-evolutionary-algorithms-via-genetic-programming","title":"Evolving Benchmark Functions to Compare Evolutionary Algorithms via Genetic Programming","link":"https://arxiv.org/abs/2403.14146","abstract":"arXiv:2403.14146v1 Announce Type: cross  Abstract: In this study, we use Genetic Programming (GP) to compose new optimization benchmark functions. Optimization benchmarks have the important role of showing the differences between evolutionary algorithms, making it possible for further analysis and comparisons. We show that the benchmarks generated by GP are able to differentiate algorithms better than human-made benchmark functions. The fitness measure of the GP is the Wasserstein distance of the solutions found by a pair of optimizers. Additionally, we use MAP-Elites to both enhance the search power of the GP and also illustrate how the difference between optimizers changes by various landscape features. Our approach provides a novel way to automate the design of benchmark functions and to compare evolutionary algorithms.","creator":"Yifan He, Claus Aranha"},{"id":"2403.14151","slug":"deep-learning-for-trajectory-data-management-and-mining-a-survey-and-beyond","title":"Deep Learning for Trajectory Data Management and Mining: A Survey and Beyond","link":"https://arxiv.org/abs/2403.14151","abstract":"arXiv:2403.14151v1 Announce Type: cross  Abstract: Trajectory computing is a pivotal domain encompassing trajectory data management and mining, garnering widespread attention due to its crucial role in various practical applications such as location services, urban traffic, and public safety. Traditional methods, focusing on simplistic spatio-temporal features, face challenges of complex calculations, limited scalability, and inadequate adaptability to real-world complexities. In this paper, we present a comprehensive review of the development and recent advances in deep learning for trajectory computing (DL4Traj). We first define trajectory data and provide a brief overview of widely-used deep learning models. Systematically, we explore deep learning applications in trajectory management (pre-processing, storage, analysis, and visualization) and mining (trajectory-related forecasting, trajectory-related recommendation, trajectory classification, travel time estimation, anomaly detection, and mobility generation). Notably, we encapsulate recent advancements in Large Language Models (LLMs) that hold the potential to augment trajectory computing. Additionally, we summarize application scenarios, public datasets, and toolkits. Finally, we outline current challenges in DL4Traj research and propose future directions. Relevant papers and open-source resources have been collated and are continuously updated at: \\href{https://github.com/yoshall/Awesome-Trajectory-Computing}{DL4Traj Repo}.","creator":"Wei Chen, Yuxuan Liang, Yuanshao Zhu, Yanchuan Chang, Kang Luo, Haomin Wen, Lei Li, Yanwei Yu, Qingsong Wen, Chao Chen, Kai Zheng, Yunjun Gao, Xiaofang Zhou, Yu Zheng"},{"id":"2403.14156","slug":"policy-mirror-descent-with-lookahead","title":"Policy Mirror Descent with Lookahead","link":"https://arxiv.org/abs/2403.14156","abstract":"arXiv:2403.14156v1 Announce Type: cross  Abstract: Policy Mirror Descent (PMD) stands as a versatile algorithmic framework encompassing several seminal policy gradient algorithms such as natural policy gradient, with connections with state-of-the-art reinforcement learning (RL) algorithms such as TRPO and PPO. PMD can be seen as a soft Policy Iteration algorithm implementing regularized 1-step greedy policy improvement. However, 1-step greedy policies might not be the best choice and recent remarkable empirical successes in RL such as AlphaGo and AlphaZero have demonstrated that greedy approaches with respect to multiple steps outperform their 1-step counterpart. In this work, we propose a new class of PMD algorithms called $h$-PMD which incorporates multi-step greedy policy improvement with lookahead depth $h$ to the PMD update rule. To solve discounted infinite horizon Markov Decision Processes with discount factor $\\gamma$, we show that $h$-PMD which generalizes the standard PMD enjoys a faster dimension-free $\\gamma^h$-linear convergence rate, contingent on the computation of multi-step greedy policies. We propose an inexact version of $h$-PMD where lookahead action values are estimated. Under a generative model, we establish a sample complexity for $h$-PMD which improves over prior work. Finally, we extend our result to linear function approximation to scale to large state spaces. Under suitable assumptions, our sample complexity only involves dependence on the dimension of the feature map space instead of the state space size.","creator":"Kimon Protopapas, Anas Barakat"},{"id":"2403.14163","slug":"leveraging-large-language-model-based-room-object-relationships-knowledge-for-enhancing-multimodal-input-object-goal-navigation","title":"Leveraging Large Language Model-based Room-Object Relationships Knowledge for Enhancing Multimodal-Input Object Goal Navigation","link":"https://arxiv.org/abs/2403.14163","abstract":"arXiv:2403.14163v1 Announce Type: cross  Abstract: Object-goal navigation is a crucial engineering task for the community of embodied navigation; it involves navigating to an instance of a specified object category within unseen environments. Although extensive investigations have been conducted on both end-to-end and modular-based, data-driven approaches, fully enabling an agent to comprehend the environment through perceptual knowledge and perform object-goal navigation as efficiently as humans remains a significant challenge. Recently, large language models have shown potential in this task, thanks to their powerful capabilities for knowledge extraction and integration. In this study, we propose a data-driven, modular-based approach, trained on a dataset that incorporates common-sense knowledge of object-to-room relationships extracted from a large language model. We utilize the multi-channel Swin-Unet architecture to conduct multi-task learning incorporating with multimodal inputs. The results in the Habitat simulator demonstrate that our framework outperforms the baseline by an average of 10.6% in the efficiency metric, Success weighted by Path Length (SPL). The real-world demonstration shows that the proposed approach can efficiently conduct this task by traversing several rooms. For more details and real-world demonstrations, please check our project webpage (https://sunleyuan.github.io/ObjectNav).","creator":"Leyuan Sun, Asako Kanezaki, Guillaume Caron, Yusuke Yoshiyasu"},{"id":"2403.14183","slug":"otseg-multi-prompt-sinkhorn-attention-for-zero-shot-semantic-segmentation","title":"OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic Segmentation","link":"https://arxiv.org/abs/2403.14183","abstract":"arXiv:2403.14183v1 Announce Type: cross  Abstract: The recent success of CLIP has demonstrated promising results in zero-shot semantic segmentation by transferring muiltimodal knowledge to pixel-level classification. However, leveraging pre-trained CLIP knowledge to closely align text embeddings with pixel embeddings still has limitations in existing approaches. To address this issue, we propose OTSeg, a novel multimodal attention mechanism aimed at enhancing the potential of multiple text prompts for matching associated pixel embeddings. We first propose Multi-Prompts Sinkhorn (MPS) based on the Optimal Transport (OT) algorithm, which leads multiple text prompts to selectively focus on various semantic features within image pixels. Moreover, inspired by the success of Sinkformers in unimodal settings, we introduce the extension of MPS, called Multi-Prompts Sinkhorn Attention (MPSA), which effectively replaces cross-attention mechanisms within Transformer framework in multimodal settings. Through extensive experiments, we demonstrate that OTSeg achieves state-of-the-art (SOTA) performance with significant gains on Zero-Shot Semantic Segmentation (ZS3) tasks across three benchmark datasets.","creator":"Kwanyoung Kim, Yujin Oh, Jong Chul Ye"},{"id":"2403.14186","slug":"stylecinegan-landscape-cinemagraph-generation-using-a-pre-trained-stylegan","title":"StyleCineGAN: Landscape Cinemagraph Generation using a Pre-trained StyleGAN","link":"https://arxiv.org/abs/2403.14186","abstract":"arXiv:2403.14186v1 Announce Type: cross  Abstract: We propose a method that can generate cinemagraphs automatically from a still landscape image using a pre-trained StyleGAN. Inspired by the success of recent unconditional video generation, we leverage a powerful pre-trained image generator to synthesize high-quality cinemagraphs. Unlike previous approaches that mainly utilize the latent space of a pre-trained StyleGAN, our approach utilizes its deep feature space for both GAN inversion and cinemagraph generation. Specifically, we propose multi-scale deep feature warping (MSDFW), which warps the intermediate features of a pre-trained StyleGAN at different resolutions. By using MSDFW, the generated cinemagraphs are of high resolution and exhibit plausible looping animation. We demonstrate the superiority of our method through user studies and quantitative comparisons with state-of-the-art cinemagraph generation methods and a video generation method that uses a pre-trained StyleGAN.","creator":"Jongwoo Choi, Kwanggyoon Seo, Amirsaman Ashtari, Junyong Noh"},{"id":"2403.14188","slug":"quantum-activated-neural-reservoirs-on-chip-open-up-large-hardware-security-models-for-resilient-authentication","title":"Quantum-activated neural reservoirs on-chip open up large hardware security models for resilient authentication","link":"https://arxiv.org/abs/2403.14188","abstract":"arXiv:2403.14188v1 Announce Type: cross  Abstract: Quantum artificial intelligence is a frontier of artificial intelligence research, pioneering quantum AI-powered circuits to address problems beyond the reach of deep learning with classical architectures. This work implements a large-scale quantum-activated recurrent neural network possessing more than 3 trillion hardware nodes/cm$^2$, originating from repeatable atomic-scale nucleation dynamics in an amorphous material integrated on-chip, controlled with 0.07 nW electric power per readout channel. Compared to the best-performing reservoirs currently reported, this implementation increases the scale of the network by two orders of magnitude and reduces the power consumption by six, reaching power efficiencies in the range of the human brain, dissipating 0.2 nW/neuron. When interrogated by a classical input, the chip implements a large-scale hardware security model, enabling dictionary-free authentication secure against statistical inference attacks, including AI's present and future development, even for an adversary with a copy of all the classical components available. Experimental tests report 99.6% reliability, 100% user authentication accuracy, and an ideal 50% key uniqueness. Due to its quantum nature, the chip supports a bit density per feature size area three times higher than the best technology available, with the capacity to store more than $2^{1104}$ keys in a footprint of 1 cm$^2$. Such a quantum-powered platform could help counteract the emerging form of warfare led by the cybercrime industry in breaching authentication to target small to large-scale facilities, from private users to intelligent energy grids.","creator":"Zhao He, Maxim S. Elizarov, Ning Li, Fei Xiang, Andrea Fratalocchi"},{"id":"2403.14200","slug":"debiasing-surgeon-fantastic-weights-and-how-to-find-them","title":"Debiasing surgeon: fantastic weights and how to find them","link":"https://arxiv.org/abs/2403.14200","abstract":"arXiv:2403.14200v1 Announce Type: cross  Abstract: Nowadays an ever-growing concerning phenomenon, the emergence of algorithmic biases that can lead to unfair models, emerges. Several debiasing approaches have been proposed in the realm of deep learning, employing more or less sophisticated approaches to discourage these models from massively employing these biases. However, a question emerges: is this extra complexity really necessary? Is a vanilla-trained model already embodying some ``unbiased sub-networks'' that can be used in isolation and propose a solution without relying on the algorithmic biases? In this work, we show that such a sub-network typically exists, and can be extracted from a vanilla-trained model without requiring additional training. We further validate that such specific architecture is incapable of learning a specific bias, suggesting that there are possible architectural countermeasures to the problem of biases in deep neural networks.","creator":"R\\'emi Nahon, Ivan Luiz De Moura Matos, Van-Tam Nguyen, Enzo Tartaglione"},{"id":"2403.14203","slug":"unsupervised-audio-visual-segmentation-with-modality-alignment","title":"Unsupervised Audio-Visual Segmentation with Modality Alignment","link":"https://arxiv.org/abs/2403.14203","abstract":"arXiv:2403.14203v1 Announce Type: cross  Abstract: Audio-Visual Segmentation (AVS) aims to identify, at the pixel level, the object in a visual scene that produces a given sound. Current AVS methods rely on costly fine-grained annotations of mask-audio pairs, making them impractical for scalability. To address this, we introduce unsupervised AVS, eliminating the need for such expensive annotation. To tackle this more challenging problem, we propose an unsupervised learning method, named Modality Correspondence Alignment (MoCA), which seamlessly integrates off-the-shelf foundation models like DINO, SAM, and ImageBind. This approach leverages their knowledge complementarity and optimizes their joint usage for multi-modality association. Initially, we estimate positive and negative image pairs in the feature space. For pixel-level association, we introduce an audio-visual adapter and a novel pixel matching aggregation strategy within the image-level contrastive learning framework. This allows for a flexible connection between object appearance and audio signal at the pixel level, with tolerance to imaging variations such as translation and rotation. Extensive experiments on the AVSBench (single and multi-object splits) and AVSS datasets demonstrate that our MoCA outperforms strongly designed baseline methods and approaches supervised counterparts, particularly in complex scenarios with multiple auditory objects. Notably when comparing mIoU, MoCA achieves a substantial improvement over baselines in both the AVSBench (S4: +17.24%; MS3: +67.64%) and AVSS (+19.23%) audio-visual segmentation challenges.","creator":"Swapnil Bhosale, Haosen Yang, Diptesh Kanojia, Jiangkang Deng, Xiatian Zhu"},{"id":"2403.14227","slug":"peergpt-probing-the-roles-of-llm-based-peer-agents-as-team-moderators-and-participants-in-children-s-collaborative-learning","title":"PeerGPT: Probing the Roles of LLM-based Peer Agents as Team Moderators and Participants in Children's Collaborative Learning","link":"https://arxiv.org/abs/2403.14227","abstract":"arXiv:2403.14227v1 Announce Type: cross  Abstract: In children's collaborative learning, effective peer conversations can significantly enhance the quality of children's collaborative interactions. The integration of Large Language Model (LLM) agents into this setting explores their novel role as peers, assessing impacts as team moderators and participants. We invited two groups of participants to engage in a collaborative learning workshop, where they discussed and proposed conceptual solutions to a design problem. The peer conversation transcripts were analyzed using thematic analysis. We discovered that peer agents, while managing discussions effectively as team moderators, sometimes have their instructions disregarded. As participants, they foster children's creative thinking but may not consistently provide timely feedback. These findings highlight potential design improvements and considerations for peer agents in both roles.","creator":"Jiawen Liu, Yuanyuan Yao, Pengcheng An, Qi Wang"},{"id":"2403.14233","slug":"softpatch-unsupervised-anomaly-detection-with-noisy-data","title":"SoftPatch: Unsupervised Anomaly Detection with Noisy Data","link":"https://arxiv.org/abs/2403.14233","abstract":"arXiv:2403.14233v1 Announce Type: cross  Abstract: Although mainstream unsupervised anomaly detection (AD) algorithms perform well in academic datasets, their performance is limited in practical application due to the ideal experimental setting of clean training data. Training with noisy data is an inevitable problem in real-world anomaly detection but is seldom discussed. This paper considers label-level noise in image sensory anomaly detection for the first time. To solve this problem, we proposed a memory-based unsupervised AD method, SoftPatch, which efficiently denoises the data at the patch level. Noise discriminators are utilized to generate outlier scores for patch-level noise elimination before coreset construction. The scores are then stored in the memory bank to soften the anomaly detection boundary. Compared with existing methods, SoftPatch maintains a strong modeling ability of normal data and alleviates the overconfidence problem in coreset. Comprehensive experiments in various noise scenes demonstrate that SoftPatch outperforms the state-of-the-art AD methods on the MVTecAD and BTAD benchmarks and is comparable to those methods under the setting without noise.","creator":"Xi Jiang, Ying Chen, Qiang Nie, Yong Liu, Jianlin Liu, Bin-Bin Gao, Jun Liu, Chengjie Wang, Feng Zheng"},{"id":"2403.14236","slug":"a-unified-framework-for-model-editing","title":"A Unified Framework for Model Editing","link":"https://arxiv.org/abs/2403.14236","abstract":"arXiv:2403.14236v1 Announce Type: cross  Abstract: Model editing is a growing area focused on updating the knowledge embedded within models. Among the various methodologies, ROME and MEMIT stand out as leading \"locate-and-edit\" model editing techniques. While MEMIT enables batched editing of memories, ROME is limited to changing one fact at a time. This paper introduces a unifying framework that brings ROME and MEMIT under a single conceptual umbrella, optimizing for the same goal, which we call the \"preservation-memorization\" objective. This objective aims to preserve the representations of certain selected vectors while memorizing the representations of new factual information. Specifically, ROME optimizes this objective using an equality constraint, whereas MEMIT employs a more flexible least-square constraint. In addition to making batched edits, MEMIT also edits the model at multiple layers. We disentangle the distribution of edits to multiple layers from the optimization objective of MEMIT and show that these edit-distribution algorithms should be considered separate entities worthy of their own line of research.   Finally, we present EMMET - an Equality-constrained Mass Model Editing algorithm for Transformers, a new batched memory-editing algorithm. With EMMET, we present a closed form solution for the equality-constrained version of the preservation-memorization objective. We show that EMMET is able to perform batched-edits on par with MEMIT up to a batch-size of 256 and discuss the challenges in stabilizing EMMET. By articulating the \"locate-and-edit\" model editing algorithms under a simple conceptual framework of \"preservation-memorization\", we aim to bridge the gap between intuition and mathematics and hope to simplify the journey for future researchers in model editing.","creator":"Akshat Gupta, Dev Sajnani, Gopala Anumanchipalli"},{"id":"2403.14238","slug":"reinforcement-learning-from-reflective-feedback-rlrf-aligning-and-improving-llms-via-fine-grained-self-reflection","title":"Reinforcement Learning from Reflective Feedback (RLRF): Aligning and Improving LLMs via Fine-Grained Self-Reflection","link":"https://arxiv.org/abs/2403.14238","abstract":"arXiv:2403.14238v1 Announce Type: cross  Abstract: Despite the promise of RLHF in aligning LLMs with human preferences, it often leads to superficial alignment, prioritizing stylistic changes over improving downstream performance of LLMs. Underspecified preferences could obscure directions to align the models. Lacking exploration restricts identification of desirable outputs to improve the models. To overcome these challenges, we propose a novel framework: Reinforcement Learning from Reflective Feedback (RLRF), which leverages fine-grained feedback based on detailed criteria to improve the core capabilities of LLMs. RLRF employs a self-reflection mechanism to systematically explore and refine LLM responses, then fine-tuning the models via a RL algorithm along with promising responses. Our experiments across Just-Eval, Factuality, and Mathematical Reasoning demonstrate the efficacy and transformative potential of RLRF beyond superficial surface-level adjustment.","creator":"Kyungjae Lee, Dasol Hwang, Sunghyun Park, Youngsoo Jang, Moontae Lee"},{"id":"2403.14243","slug":"dermacen-analytica-a-novel-methodology-integrating-multi-modal-large-language-models-with-machine-learning-in-tele-dermatology","title":"Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large Language Models with Machine Learning in tele-dermatology","link":"https://arxiv.org/abs/2403.14243","abstract":"arXiv:2403.14243v1 Announce Type: cross  Abstract: The rise of Artificial Intelligence creates great promise in the field of medical discovery, diagnostics and patient management. However, the vast complexity of all medical domains require a more complex approach that combines machine learning algorithms, classifiers, segmentation algorithms and, lately, large language models. In this paper, we describe, implement and assess an Artificial Intelligence-empowered system and methodology aimed at assisting the diagnosis process of skin lesions and other skin conditions within the field of dermatology that aims to holistically address the diagnostic process in this domain. The workflow integrates large language, transformer-based vision models and sophisticated machine learning tools. This holistic approach achieves a nuanced interpretation of dermatological conditions that simulates and facilitates a dermatologist's workflow. We assess our proposed methodology through a thorough cross-model validation technique embedded in an evaluation pipeline that utilizes publicly available medical case studies of skin conditions and relevant images. To quantitatively score the system performance, advanced machine learning and natural language processing tools are employed which focus on similarity comparison and natural language inference. Additionally, we incorporate a human expert evaluation process based on a structured checklist to further validate our results. We implemented the proposed methodology in a system which achieved approximate (weighted) scores of 0.87 for both contextual understanding and diagnostic accuracy, demonstrating the efficacy of our approach in enhancing dermatological analysis. The proposed methodology is expected to prove useful in the development of next-generation tele-dermatology applications, enhancing remote consultation capabilities and access to care, especially in underserved areas.","creator":"Dimitrios P. Panagoulias, Evridiki Tsoureli-Nikita, Maria Virvou, George A. Tsihrintzis"},{"id":"2403.14244","slug":"isotropic-gaussian-splatting-for-real-time-radiance-field-rendering","title":"Isotropic Gaussian Splatting for Real-Time Radiance Field Rendering","link":"https://arxiv.org/abs/2403.14244","abstract":"arXiv:2403.14244v1 Announce Type: cross  Abstract: The 3D Gaussian splatting method has drawn a lot of attention, thanks to its high performance in training and high quality of the rendered image. However, it uses anisotropic Gaussian kernels to represent the scene. Although such anisotropic kernels have advantages in representing the geometry, they lead to difficulties in terms of computation, such as splitting or merging two kernels. In this paper, we propose to use isotropic Gaussian kernels to avoid such difficulties in the computation, leading to a higher performance method. The experiments confirm that the proposed method is about {\\bf 100X} faster without losing the geometry representation accuracy. The proposed method can be applied in a large range applications where the radiance field is needed, such as 3D reconstruction, view synthesis, and dynamic object modeling.","creator":"Yuanhao Gong, Lantao Yu, Guanghui Yue"},{"id":"2403.14246","slug":"catse-a-context-aware-framework-for-causal-target-sound-extraction","title":"CATSE: A Context-Aware Framework for Causal Target Sound Extraction","link":"https://arxiv.org/abs/2403.14246","abstract":"arXiv:2403.14246v1 Announce Type: cross  Abstract: Target Sound Extraction (TSE) focuses on the problem of separating sources of interest, indicated by a user's cue, from the input mixture. Most existing solutions operate in an offline fashion and are not suited to the low-latency causal processing constraints imposed by applications in live-streamed content such as augmented hearing. We introduce a family of context-aware low-latency causal TSE models suitable for real-time processing. First, we explore the utility of context by providing the TSE model with oracle information about what sound classes make up the input mixture, where the objective of the model is to extract one or more sources of interest indicated by the user. Since the practical applications of oracle models are limited due to their assumptions, we introduce a composite multi-task training objective involving separation and classification losses. Our evaluation involving single- and multi-source extraction shows the benefit of using context information in the model either by means of providing full context or via the proposed multi-task training loss without the need for full context information. Specifically, we show that our proposed model outperforms size- and latency-matched Waveformer, a state-of-the-art model for real-time TSE.","creator":"Shrishail Baligar, Mikolaj Kegler, Bryce Irvin, Marko Stamenovic, Shawn Newsam"},{"id":"2403.14252","slug":"layoutllm-large-language-model-instruction-tuning-for-visually-rich-document-understanding","title":"LayoutLLM: Large Language Model Instruction Tuning for Visually Rich Document Understanding","link":"https://arxiv.org/abs/2403.14252","abstract":"arXiv:2403.14252v1 Announce Type: cross  Abstract: This paper proposes LayoutLLM, a more flexible document analysis method for understanding imaged documents. Visually Rich Document Understanding tasks, such as document image classification and information extraction, have gained significant attention due to their importance. Existing methods have been developed to enhance document comprehension by incorporating pre-training awareness of images, text, and layout structure. However, these methods require fine-tuning for each task and dataset, and the models are expensive to train and operate. To overcome this limitation, we propose a new LayoutLLM that integrates these with large-scale language models (LLMs). By leveraging the strengths of existing research in document image understanding and LLMs' superior language understanding capabilities, the proposed model, fine-tuned with multimodal instruction datasets, performs an understanding of document images in a single model. Our experiments demonstrate improvement over the baseline model in various document analysis tasks.","creator":"Masato Fujitake"},{"id":"2403.14264","slug":"a-framework-for-portrait-stylization-with-skin-tone-awareness-and-nudity-identification","title":"A Framework for Portrait Stylization with Skin-Tone Awareness and Nudity Identification","link":"https://arxiv.org/abs/2403.14264","abstract":"arXiv:2403.14264v1 Announce Type: cross  Abstract: Portrait stylization is a challenging task involving the transformation of an input portrait image into a specific style while preserving its inherent characteristics. The recent introduction of Stable Diffusion (SD) has significantly improved the quality of outcomes in this field. However, a practical stylization framework that can effectively filter harmful input content and preserve the distinct characteristics of an input, such as skin-tone, while maintaining the quality of stylization remains lacking. These challenges have hindered the wide deployment of such a framework. To address these issues, this study proposes a portrait stylization framework that incorporates a nudity content identification module (NCIM) and a skin-tone-aware portrait stylization module (STAPSM). In experiments, NCIM showed good performance in enhancing explicit content filtering, and STAPSM accurately represented a diverse range of skin tones. Our proposed framework has been successfully deployed in practice, and it has effectively satisfied critical requirements of real-world applications.","creator":"Seungkwon Kim, Sangyeon Kim, Seung-Hun Nam"},{"id":"2403.14273","slug":"reactor-optimization-benchmark-by-reinforcement-learning","title":"Reactor Optimization Benchmark by Reinforcement Learning","link":"https://arxiv.org/abs/2403.14273","abstract":"arXiv:2403.14273v1 Announce Type: cross  Abstract: Neutronic calculations for reactors are a daunting task when using Monte Carlo (MC) methods. As high-performance computing has advanced, the simulation of a reactor is nowadays more readily done, but design and optimization with multiple parameters is still a computational challenge. MC transport simulations, coupled with machine learning techniques, offer promising avenues for enhancing the efficiency and effectiveness of nuclear reactor optimization. This paper introduces a novel benchmark problem within the OpenNeoMC framework designed specifically for reinforcement learning. The benchmark involves optimizing a unit cell of a research reactor with two varying parameters (fuel density and water spacing) to maximize neutron flux while maintaining reactor criticality. The test case features distinct local optima, representing different physical regimes, thus posing a challenge for learning algorithms. Through extensive simulations utilizing evolutionary and neuroevolutionary algorithms, we demonstrate the effectiveness of reinforcement learning in navigating complex optimization landscapes with strict constraints. Furthermore, we propose acceleration techniques within the OpenNeoMC framework, including model updating and cross-section usage by RAM utilization, to expedite simulation times. Our findings emphasize the importance of machine learning integration in reactor optimization and contribute to advancing methodologies for addressing intricate optimization challenges in nuclear engineering. The sources of this work are available at our GitHub repository: https://github.com/Scientific-Computing-Lab-NRCN/RLOpenNeoMC","creator":"Deborah Schwarcz, Nadav Schneider, Gal Oren, Uri Steinitz"},{"id":"2403.14274","slug":"multi-role-consensus-through-llms-discussions-for-vulnerability-detection","title":"Multi-role Consensus through LLMs Discussions for Vulnerability Detection","link":"https://arxiv.org/abs/2403.14274","abstract":"arXiv:2403.14274v1 Announce Type: cross  Abstract: Recent advancements in large language models (LLMs) have highlighted the potential for vulnerability detection, a crucial component of software quality assurance. Despite this progress, most studies have been limited to the perspective of a single role, usually testers, lacking diverse viewpoints from different roles in a typical software development life-cycle, including both developers and testers. To this end, this paper introduces an approach to employ LLMs to act as different roles to simulate real-life code review process, engaging in discussions towards a consensus on the existence and classification of vulnerabilities in the code. Preliminary evaluation of the proposed approach indicates a 4.73% increase in the precision rate, 58.9% increase in the recall rate, and a 28.1% increase in the F1 score.","creator":"Zhenyu Mao, Jialong Li, Munan Li, Kenji Tei"},{"id":"2403.14282","slug":"how-to-be-fair-a-study-of-label-and-selection-bias","title":"How to be fair? A study of label and selection bias","link":"https://arxiv.org/abs/2403.14282","abstract":"arXiv:2403.14282v1 Announce Type: cross  Abstract: It is widely accepted that biased data leads to biased and thus potentially unfair models. Therefore, several measures for bias in data and model predictions have been proposed, as well as bias mitigation techniques whose aim is to learn models that are fair by design. Despite the myriad of mitigation techniques developed in the past decade, however, it is still poorly understood under what circumstances which methods work. Recently, Wick et al. showed, with experiments on synthetic data, that there exist situations in which bias mitigation techniques lead to more accurate models when measured on unbiased data. Nevertheless, in the absence of a thorough mathematical analysis, it remains unclear which techniques are effective under what circumstances. We propose to address this problem by establishing relationships between the type of bias and the effectiveness of a mitigation technique, where we categorize the mitigation techniques by the bias measure they optimize. In this paper we illustrate this principle for label and selection bias on the one hand, and demographic parity and ``We're All Equal'' on the other hand. Our theoretical analysis allows to explain the results of Wick et al. and we also show that there are situations where minimizing fairness measures does not result in the fairest possible distribution.","creator":"Marco Favier, Toon Calders, Sam Pinxteren, Jonathan Meyer"},{"id":"2403.14287","slug":"enhancing-historical-image-retrieval-with-compositional-cues","title":"Enhancing Historical Image Retrieval with Compositional Cues","link":"https://arxiv.org/abs/2403.14287","abstract":"arXiv:2403.14287v1 Announce Type: cross  Abstract: In analyzing vast amounts of digitally stored historical image data, existing content-based retrieval methods often overlook significant non-semantic information, limiting their effectiveness for flexible exploration across varied themes. To broaden the applicability of image retrieval methods for diverse purposes and uncover more general patterns, we innovatively introduce a crucial factor from computational aesthetics, namely image composition, into this topic. By explicitly integrating composition-related information extracted by CNN into the designed retrieval model, our method considers both the image's composition rules and semantic information. Qualitative and quantitative experiments demonstrate that the image retrieval network guided by composition information outperforms those relying solely on content information, facilitating the identification of images in databases closer to the target image in human perception. Please visit https://github.com/linty5/CCBIR to try our codes.","creator":"Tingyu Lin, Robert Sablatnig"},{"id":"2403.14297","slug":"impact-assessment-of-missing-data-in-model-predictions-for-earth-observation-applications","title":"Impact Assessment of Missing Data in Model Predictions for Earth Observation Applications","link":"https://arxiv.org/abs/2403.14297","abstract":"arXiv:2403.14297v1 Announce Type: cross  Abstract: Earth observation (EO) applications involving complex and heterogeneous data sources are commonly approached with machine learning models. However, there is a common assumption that data sources will be persistently available. Different situations could affect the availability of EO sources, like noise, clouds, or satellite mission failures. In this work, we assess the impact of missing temporal and static EO sources in trained models across four datasets with classification and regression tasks. We compare the predictive quality of different methods and find that some are naturally more robust to missing data. The Ensemble strategy, in particular, achieves a prediction robustness up to 100%. We evidence that missing scenarios are significantly more challenging in regression than classification tasks. Finally, we find that the optical view is the most critical view when it is missing individually.","creator":"Francisco Mena, Diego Arenas, Marcela Charfuelan, Marlon Nuske, Andreas Dengel"},{"id":"2403.14298","slug":"from-perils-to-possibilities-understanding-how-human-and-ai-biases-affect-online-fora","title":"From Perils to Possibilities: Understanding how Human (and AI) Biases affect Online Fora","link":"https://arxiv.org/abs/2403.14298","abstract":"arXiv:2403.14298v1 Announce Type: cross  Abstract: Social media platforms are online fora where users engage in discussions, share content, and build connections. This review explores the dynamics of social interactions, user-generated contents, and biases within the context of social media analysis (analyzing works that use the tools offered by complex network analysis and natural language processing) through the lens of three key points of view: online debates, online support, and human-AI interactions. On the one hand, we delineate the phenomenon of online debates, where polarization, misinformation, and echo chamber formation often proliferate, driven by algorithmic biases and extreme mechanisms of homophily. On the other hand, we explore the emergence of online support groups through users' self-disclosure and social support mechanisms. Online debates and support mechanisms present a duality of both perils and possibilities within social media; perils of segregated communities and polarized debates, and possibilities of empathy narratives and self-help groups. This dichotomy also extends to a third perspective: users' reliance on AI-generated content, such as the ones produced by Large Language Models, which can manifest both human biases hidden in training sets and non-human biases that emerge from their artificial neural architectures. Analyzing interdisciplinary approaches, we aim to deepen the understanding of the complex interplay between social interactions, user-generated content, and biases within the realm of social media ecosystems.","creator":"Virginia Morini, Valentina Pansanella, Katherine Abramski, Erica Cau, Andrea Failla, Salvatore Citraro, Giulio Rossetti"},{"id":"2403.14300","slug":"dexdribbler-learning-dexterous-soccer-manipulation-via-dynamic-supervision","title":"DexDribbler: Learning Dexterous Soccer Manipulation via Dynamic Supervision","link":"https://arxiv.org/abs/2403.14300","abstract":"arXiv:2403.14300v1 Announce Type: cross  Abstract: Learning dexterous locomotion policy for legged robots is becoming increasingly popular due to its ability to handle diverse terrains and resemble intelligent behaviors. However, joint manipulation of moving objects and locomotion with legs, such as playing soccer, receive scant attention in the learning community, although it is natural for humans and smart animals. A key challenge to solve this multitask problem is to infer the objectives of locomotion from the states and targets of the manipulated objects. The implicit relation between the object states and robot locomotion can be hard to capture directly from the training experience. We propose adding a feedback control block to compute the necessary body-level movement accurately and using the outputs as dynamic joint-level locomotion supervision explicitly. We further utilize an improved ball dynamic model, an extended context-aided estimator, and a comprehensive ball observer to facilitate transferring policy learned in simulation to the real world. We observe that our learning scheme can not only make the policy network converge faster but also enable soccer robots to perform sophisticated maneuvers like sharp cuts and turns on flat surfaces, a capability that was lacking in previous methods. Video and code are available at https://github.com/SysCV/soccer-player","creator":"Yutong Hu, Kehan Wen, Fisher Yu"},{"id":"2403.14328","slug":"distilling-reinforcement-learning-policies-for-interpretable-robot-locomotion-gradient-boosting-machines-and-symbolic-regression","title":"Distilling Reinforcement Learning Policies for Interpretable Robot Locomotion: Gradient Boosting Machines and Symbolic Regression","link":"https://arxiv.org/abs/2403.14328","abstract":"arXiv:2403.14328v1 Announce Type: cross  Abstract: Recent advancements in reinforcement learning (RL) have led to remarkable achievements in robot locomotion capabilities. However, the complexity and ``black-box'' nature of neural network-based RL policies hinder their interpretability and broader acceptance, particularly in applications demanding high levels of safety and reliability. This paper introduces a novel approach to distill neural RL policies into more interpretable forms using Gradient Boosting Machines (GBMs), Explainable Boosting Machines (EBMs) and Symbolic Regression. By leveraging the inherent interpretability of generalized additive models, decision trees, and analytical expressions, we transform opaque neural network policies into more transparent ``glass-box'' models. We train expert neural network policies using RL and subsequently distill them into (i) GBMs, (ii) EBMs, and (iii) symbolic policies. To address the inherent distribution shift challenge of behavioral cloning, we propose to use the Dataset Aggregation (DAgger) algorithm with a curriculum of episode-dependent alternation of actions between expert and distilled policies, to enable efficient distillation of feedback control policies. We evaluate our approach on various robot locomotion gaits -- walking, trotting, bounding, and pacing -- and study the importance of different observations in joint actions for distilled policies using various methods. We train neural expert policies for 205 hours of simulated experience and distill interpretable policies with only 10 minutes of simulated interaction for each gait using the proposed method.","creator":"Fernando Acero, Zhibin Li"},{"id":"2403.14339","slug":"nabla-tau-gradient-based-and-task-agnostic-machine-unlearning","title":"$\\nabla \\tau$: Gradient-based and Task-Agnostic machine Unlearning","link":"https://arxiv.org/abs/2403.14339","abstract":"arXiv:2403.14339v1 Announce Type: cross  Abstract: Machine Unlearning, the process of selectively eliminating the influence of certain data examples used during a model's training, has gained significant attention as a means for practitioners to comply with recent data protection regulations. However, existing unlearning methods face critical drawbacks, including their prohibitively high cost, often associated with a large number of hyperparameters, and the limitation of forgetting only relatively small data portions. This often makes retraining the model from scratch a quicker and more effective solution. In this study, we introduce Gradient-based and Task-Agnostic machine Unlearning ($\\nabla \\tau$), an optimization framework designed to remove the influence of a subset of training data efficiently. It applies adaptive gradient ascent to the data to be forgotten while using standard gradient descent for the remaining data. $\\nabla \\tau$ offers multiple benefits over existing approaches. It enables the unlearning of large sections of the training dataset (up to 30%). It is versatile, supporting various unlearning tasks (such as subset forgetting or class removal) and applicable across different domains (images, text, etc.). Importantly, $\\nabla \\tau$ requires no hyperparameter adjustments, making it a more appealing option than retraining the model from scratch. We evaluate our framework's effectiveness using a set of well-established Membership Inference Attack metrics, demonstrating up to 10% enhancements in performance compared to state-of-the-art methods without compromising the original model's accuracy.","creator":"Daniel Trippa, Cesare Campagnano, Maria Sofia Bucarelli, Gabriele Tolomei, Fabrizio Silvestri"},{"id":"2403.14340","slug":"exploring-task-unification-in-graph-representation-learning-via-generative-approach","title":"Exploring Task Unification in Graph Representation Learning via Generative Approach","link":"https://arxiv.org/abs/2403.14340","abstract":"arXiv:2403.14340v1 Announce Type: cross  Abstract: Graphs are ubiquitous in real-world scenarios and encompass a diverse range of tasks, from node-, edge-, and graph-level tasks to transfer learning. However, designing specific tasks for each type of graph data is often costly and lacks generalizability. Recent endeavors under the \"Pre-training + Fine-tuning\" or \"Pre-training + Prompt\" paradigms aim to design a unified framework capable of generalizing across multiple graph tasks. Among these, graph autoencoders (GAEs), generative self-supervised models, have demonstrated their potential in effectively addressing various graph tasks. Nevertheless, these methods typically employ multi-stage training and require adaptive designs, which on one hand make it difficult to be seamlessly applied to diverse graph tasks and on the other hand overlook the negative impact caused by discrepancies in task objectives between the different stages. To address these challenges, we propose GA^2E, a unified adversarially masked autoencoder capable of addressing the above challenges seamlessly. Specifically, GA^2E proposes to use the subgraph as the meta-structure, which remains consistent across all graph tasks (ranging from node-, edge-, and graph-level to transfer learning) and all stages (both during training and inference). Further, GA^2E operates in a \\textbf{\"Generate then Discriminate\"} manner. It leverages the masked GAE to reconstruct the input subgraph whilst treating it as a generator to compel the reconstructed graphs resemble the input subgraph. Furthermore, GA^2E introduces an auxiliary discriminator to discern the authenticity between the reconstructed (generated) subgraph and the input subgraph, thus ensuring the robustness of the graph representation through adversarial training mechanisms. We validate GA^2E's capabilities through extensive experiments on 21 datasets across four types of graph tasks.","creator":"Yulan Hu, Sheng Ouyang, Zhirui Yang, Ge Chen, Junchen Wan, Xiao Wang, Yong Liu"},{"id":"2403.14358","slug":"exploring-the-potential-of-large-language-models-in-graph-generation","title":"Exploring the Potential of Large Language Models in Graph Generation","link":"https://arxiv.org/abs/2403.14358","abstract":"arXiv:2403.14358v1 Announce Type: cross  Abstract: Large language models (LLMs) have achieved great success in many fields, and recent works have studied exploring LLMs for graph discriminative tasks such as node classification. However, the abilities of LLMs for graph generation remain unexplored in the literature. Graph generation requires the LLM to generate graphs with given properties, which has valuable real-world applications such as drug discovery, while tends to be more challenging. In this paper, we propose LLM4GraphGen to explore the ability of LLMs for graph generation with systematical task designs and extensive experiments. Specifically, we propose several tasks tailored with comprehensive experiments to address key questions regarding LLMs' understanding of different graph structure rules, their ability to capture structural type distributions, and their utilization of domain knowledge for property-based graph generation. Our evaluations demonstrate that LLMs, particularly GPT-4, exhibit preliminary abilities in graph generation tasks, including rule-based and distribution-based generation. We also observe that popular prompting methods, such as few-shot and chain-of-thought prompting, do not consistently enhance performance. Besides, LLMs show potential in generating molecules with specific properties. These findings may serve as foundations for designing good LLMs based models for graph generation and provide valuable insights and further research.","creator":"Yang Yao, Xin Wang, Zeyang Zhang, Yijian Qin, Ziwei Zhang, Xu Chu, Yuekui Yang, Wenwu Zhu, Hong Mei"},{"id":"2403.14371","slug":"loop-improvement-an-efficient-approach-for-extracting-shared-features-from-heterogeneous-data-without-central-server","title":"Loop Improvement: An Efficient Approach for Extracting Shared Features from Heterogeneous Data without Central Server","link":"https://arxiv.org/abs/2403.14371","abstract":"arXiv:2403.14371v1 Announce Type: cross  Abstract: In federated learning, data heterogeneity significantly impacts performance. A typical solution involves segregating these parameters into shared and personalized components, a concept also relevant in multi-task learning. Addressing this, we propose \"Loop Improvement\" (LI), a novel method enhancing this separation and feature extraction without necessitating a central server or data interchange among participants. Our experiments reveal LI's superiority in several aspects: In personalized federated learning environments, LI consistently outperforms the advanced FedALA algorithm in accuracy across diverse scenarios. Additionally, LI's feature extractor closely matches the performance achieved when aggregating data from all clients. In global model contexts, employing LI with stacked personalized layers and an additional network also yields comparable results to combined client data scenarios. Furthermore, LI's adaptability extends to multi-task learning, streamlining the extraction of common features across tasks and obviating the need for simultaneous training. This approach not only enhances individual task performance but also achieves accuracy levels on par with classic multi-task learning methods where all tasks are trained simultaneously. LI integrates a loop topology with layer-wise and end-to-end training, compatible with various neural network models. This paper also delves into the theoretical underpinnings of LI's effectiveness, offering insights into its potential applications. The code is on https://github.com/axedge1983/LI","creator":"Fei Li, Chu Kiong Loo, Wei Shiung Liew, Xiaofeng Liu"},{"id":"2403.14381","slug":"editing-knowledge-representation-of-language-lodel-via-rephrased-prefix-prompts","title":"Editing Knowledge Representation of Language Lodel via Rephrased Prefix Prompts","link":"https://arxiv.org/abs/2403.14381","abstract":"arXiv:2403.14381v1 Announce Type: cross  Abstract: Neural language models (LMs) have been extensively trained on vast corpora to store factual knowledge about various aspects of the world described in texts. Current technologies typically employ knowledge editing methods or specific prompts to modify LM outputs. However, existing knowledge editing methods are costly and inefficient, struggling to produce appropriate text. Additionally, prompt engineering is opaque and requires significant effort to find suitable prompts. To address these issues, we introduce a new method called PSPEM (Prefix Soft Prompt Editing Method), that can be used for a lifetime with just one training. It resolves the inefficiencies and generalizability issues in knowledge editing methods and overcomes the opacity of prompt engineering by automatically seeking optimal soft prompts. Specifically, PSPEM utilizes a prompt encoder and an encoding converter to refine key information in prompts and uses prompt alignment techniques to guide model generation, ensuring text consistency and adherence to the intended structure and content, thereby maintaining an optimal balance between efficiency and accuracy. We have validated the effectiveness of PSPEM through knowledge editing and attribute inserting. On the COUNTERFACT dataset, PSPEM achieved nearly 100\\% editing accuracy and demonstrated the highest level of fluency. We further analyzed the similarities between PSPEM and original prompts and their impact on the model's internals. The results indicate that PSPEM can serve as an alternative to original prompts, supporting the model in effective editing.","creator":"Yuchen Cai, Ding Cao, Rongxi Guo, Yaqin Wen, Guiquan Liu, Enhong Chen"},{"id":"2403.14399","slug":"building-accurate-translation-tailored-llms-with-language-aware-instruction-tuning","title":"Building Accurate Translation-Tailored LLMs with Language Aware Instruction Tuning","link":"https://arxiv.org/abs/2403.14399","abstract":"arXiv:2403.14399v1 Announce Type: cross  Abstract: Translation-tailored Large language models (LLMs) exhibit remarkable translation capabilities, even competing with supervised-trained commercial translation systems. However, off-target translation remains an unsolved problem, especially for low-resource languages, hindering us from developing accurate LLMs-based translation models. To mitigate the off-target translation problem and enhance the performance of LLMs on translation, recent works have either designed advanced prompting strategies to highlight the functionality of translation instructions or exploited the in-context learning ability of LLMs by feeding few-shot demonstrations. However, these methods essentially do not improve LLM's ability to follow translation instructions, especially the language direction information. In this work, we design a two-stage fine-tuning algorithm to improve the instruction-following ability (especially the translation direction) of LLMs. Specifically, we first tune LLMs with the maximum likelihood estimation loss on the translation dataset to elicit the basic translation capabilities. In the second stage, we construct instruction-conflicting samples by randomly replacing the translation directions with a wrong one within the instruction, and then introduce an extra unlikelihood loss to learn those samples. Experiments on IWSLT and WMT benchmarks upon the LLaMA model spanning 16 zero-shot directions show that, compared to the competitive baseline -- translation-finetuned LLama, our method could effectively reduce the off-target translation ratio (averagely -53.3\\%), thus improving translation quality with average +5.7 SacreBLEU and +16.4 BLEURT. Analysis shows that our method could preserve the model's general task performance on AlpacaEval. Code and models will be released at \\url{https://github.com/alphadl/LanguageAware_Tuning}.","creator":"Changtong Zan, Liang Ding, Li Shen, Yibing Zhen, Weifeng Liu, Dacheng Tao"},{"id":"2403.14403","slug":"adaptive-rag-learning-to-adapt-retrieval-augmented-large-language-models-through-question-complexity","title":"Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity","link":"https://arxiv.org/abs/2403.14403","abstract":"arXiv:2403.14403v1 Announce Type: cross  Abstract: Retrieval-Augmented Large Language Models (LLMs), which incorporate the non-parametric knowledge from external knowledge bases into LLMs, have emerged as a promising approach to enhancing response accuracy in several tasks, such as Question-Answering (QA). However, even though there are various approaches dealing with queries of different complexities, they either handle simple queries with unnecessary computational overhead or fail to adequately address complex multi-step queries; yet, not all user requests fall into only one of the simple or complex categories. In this work, we propose a novel adaptive QA framework, that can dynamically select the most suitable strategy for (retrieval-augmented) LLMs from the simplest to the most sophisticated ones based on the query complexity. Also, this selection process is operationalized with a classifier, which is a smaller LM trained to predict the complexity level of incoming queries with automatically collected labels, obtained from actual predicted outcomes of models and inherent inductive biases in datasets. This approach offers a balanced strategy, seamlessly adapting between the iterative and single-step retrieval-augmented LLMs, as well as the no-retrieval methods, in response to a range of query complexities. We validate our model on a set of open-domain QA datasets, covering multiple query complexities, and show that ours enhances the overall efficiency and accuracy of QA systems, compared to relevant baselines including the adaptive retrieval approaches. Code is available at: https://github.com/starsuzi/Adaptive-RAG.","creator":"Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju Hwang, Jong C. Park"},{"id":"2403.14409","slug":"locating-and-mitigating-gender-bias-in-large-language-models","title":"Locating and Mitigating Gender Bias in Large Language Models","link":"https://arxiv.org/abs/2403.14409","abstract":"arXiv:2403.14409v1 Announce Type: cross  Abstract: Large language models(LLM) are pre-trained on extensive corpora to learn facts and human cognition which contain human preferences. However, this process can inadvertently lead to these models acquiring biases and stereotypes prevalent in society. Prior research has typically tackled the issue of bias through a one-dimensional perspective, concentrating either on locating or mitigating it. This limited perspective has created obstacles in facilitating research on bias to synergistically complement and progressively build upon one another. In this study, we integrate the processes of locating and mitigating bias within a unified framework. Initially, we use causal mediation analysis to trace the causal effects of different components' activation within a large language model. Building on this, we propose the LSDM (Least Square Debias Method), a knowledge-editing based method for mitigating gender bias in occupational pronouns, and compare it against two baselines on three gender bias datasets and seven knowledge competency test datasets. The experimental results indicate that the primary contributors to gender bias are the bottom MLP modules acting on the last token of occupational pronouns and the top attention module acting on the final word in the sentence. Furthermore, LSDM mitigates gender bias in the model more effectively than the other baselines, while fully preserving the model's capabilities in all other aspects.","creator":"Yuchen Cai, Ding Cao, Rongxi Guo, Yaqin Wen, Guiquan Liu, Enhong Chen"},{"id":"2403.14410","slug":"glc-source-free-universal-domain-adaptation-through-global-local-clustering-and-contrastive-affinity-learning","title":"GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning","link":"https://arxiv.org/abs/2403.14410","abstract":"arXiv:2403.14410v1 Announce Type: cross  Abstract: Deep neural networks often exhibit sub-optimal performance under covariate and category shifts. Source-Free Domain Adaptation (SFDA) presents a promising solution to this dilemma, yet most SFDA approaches are restricted to closed-set scenarios. In this paper, we explore Source-Free Universal Domain Adaptation (SF-UniDA) aiming to accurately classify \"known\" data belonging to common categories and segregate them from target-private \"unknown\" data. We propose a novel Global and Local Clustering (GLC) technique, which comprises an adaptive one-vs-all global clustering algorithm to discern between target classes, complemented by a local k-NN clustering strategy to mitigate negative transfer. Despite the effectiveness, the inherent closed-set source architecture leads to uniform treatment of \"unknown\" data, impeding the identification of distinct \"unknown\" categories. To address this, we evolve GLC to GLC++, integrating a contrastive affinity learning strategy. We examine the superiority of GLC and GLC++ across multiple benchmarks and category shift scenarios. Remarkably, in the most challenging open-partial-set scenarios, GLC and GLC++ surpass GATE by 16.7% and 18.6% in H-score on VisDA, respectively. GLC++ enhances the novel category clustering accuracy of GLC by 4.3% in open-set scenarios on Office-Home. Furthermore, the introduced contrastive learning strategy not only enhances GLC but also significantly facilitates existing methodologies.","creator":"Sanqing Qu, Tianpei Zou, Florian R\\\"ohrbein, Cewu Lu, Guang Chen, Dacheng Tao, Changjun Jiang"},{"id":"2403.14429","slug":"style-extracting-diffusion-models-for-semi-supervised-histopathology-segmentation","title":"Style-Extracting Diffusion Models for Semi-Supervised Histopathology Segmentation","link":"https://arxiv.org/abs/2403.14429","abstract":"arXiv:2403.14429v1 Announce Type: cross  Abstract: Deep learning-based image generation has seen significant advancements with diffusion models, notably improving the quality of generated images. Despite these developments, generating images with unseen characteristics beneficial for downstream tasks has received limited attention. To bridge this gap, we propose Style-Extracting Diffusion Models, featuring two conditioning mechanisms. Specifically, we utilize 1) a style conditioning mechanism which allows to inject style information of previously unseen images during image generation and 2) a content conditioning which can be targeted to a downstream task, e.g., layout for segmentation. We introduce a trainable style encoder to extract style information from images, and an aggregation block that merges style information from multiple style inputs. This architecture enables the generation of images with unseen styles in a zero-shot manner, by leveraging styles from unseen images, resulting in more diverse generations. In this work, we use the image layout as target condition and first show the capability of our method on a natural image dataset as a proof-of-concept. We further demonstrate its versatility in histopathology, where we combine prior knowledge about tissue composition and unannotated data to create diverse synthetic images with known layouts. This allows us to generate additional synthetic data to train a segmentation network in a semi-supervised fashion. We verify the added value of the generated images by showing improved segmentation results and lower performance variability between patients when synthetic images are included during segmentation training. Our code will be made publicly available at [LINK].","creator":"Mathias \\\"Ottl, Frauke Wilm, Jana Steenpass, Jingna Qiu, Matthias R\\\"ubner, Arndt Hartmann, Matthias Beckmann, Peter Fasching, Andreas Maier, Ramona Erber, Bernhard Kainz, Katharina Breininger"},{"id":"2403.14432","slug":"on-the-continuity-and-smoothness-of-the-value-function-in-reinforcement-learning-and-optimal-control","title":"On the continuity and smoothness of the value function in reinforcement learning and optimal control","link":"https://arxiv.org/abs/2403.14432","abstract":"arXiv:2403.14432v1 Announce Type: cross  Abstract: The value function plays a crucial role as a measure for the cumulative future reward an agent receives in both reinforcement learning and optimal control. It is therefore of interest to study how similar the values of neighboring states are, i.e., to investigate the continuity of the value function. We do so by providing and verifying upper bounds on the value function's modulus of continuity. Additionally, we show that the value function is always H\\\"older continuous under relatively weak assumptions on the underlying system and that non-differentiable value functions can be made differentiable by slightly \"disturbing\" the system.","creator":"Hans Harder, Sebastian Peitz"},{"id":"2403.14435","slug":"biased-binary-attribute-classifiers-ignore-the-majority-classes","title":"Biased Binary Attribute Classifiers Ignore the Majority Classes","link":"https://arxiv.org/abs/2403.14435","abstract":"arXiv:2403.14435v1 Announce Type: cross  Abstract: To visualize the regions of interest that classifiers base their decisions on, different Class Activation Mapping (CAM) methods have been developed. However, all of these techniques target categorical classifiers only, though most real-world tasks are binary classification. In this paper, we extend gradient-based CAM techniques to work with binary classifiers and visualize the active regions for binary facial attribute classifiers. When training an unbalanced binary classifier on an imbalanced dataset, it is well-known that the majority class, i.e. the class with many training samples, is mostly predicted much better than minority class with few training instances. In our experiments on the CelebA dataset, we verify these results, when training an unbalanced classifier to extract 40 facial attributes simultaneously. One would expect that the biased classifier has learned to extract features mainly for the majority classes and that the proportional energy of the activations mainly reside in certain specific regions of the image where the attribute is located. However, we find very little regular activation for samples of majority classes, while the active regions for minority classes seem mostly reasonable and overlap with our expectations. These results suggest that biased classifiers mainly rely on bias activation for majority classes. When training a balanced classifier on the imbalanced data by employing attribute-specific class weights, majority and minority classes are classified similarly well and show expected activations for almost all attributes","creator":"Xinyi Zhang, Johanna Sophie Bieri, Manuel G\\\"unther"},{"id":"2403.14459","slug":"multi-level-explanations-for-generative-language-models","title":"Multi-Level Explanations for Generative Language Models","link":"https://arxiv.org/abs/2403.14459","abstract":"arXiv:2403.14459v1 Announce Type: cross  Abstract: Perturbation-based explanation methods such as LIME and SHAP are commonly applied to text classification. This work focuses on their extension to generative language models. To address the challenges of text as output and long text inputs, we propose a general framework called MExGen that can be instantiated with different attribution algorithms. To handle text output, we introduce the notion of scalarizers for mapping text to real numbers and investigate multiple possibilities. To handle long inputs, we take a multi-level approach, proceeding from coarser levels of granularity to finer ones, and focus on algorithms with linear scaling in model queries. We conduct a systematic evaluation, both automated and human, of perturbation-based attribution methods for summarization and context-grounded question answering. The results show that our framework can provide more locally faithful explanations of generated outputs.","creator":"Lucas Monteiro Paes, Dennis Wei, Hyo Jin Do, Hendrik Strobelt, Ronny Luss, Amit Dhurandhar, Manish Nagireddy, Karthikeyan Natesan Ramamurthy, Prasanna Sattigeri, Werner Geyer, Soumya Ghosh"},{"id":"2403.14460","slug":"towards-single-system-illusion-in-software-defined-vehicles-automated-ai-powered-workflow","title":"Towards Single-System Illusion in Software-Defined Vehicles -- Automated, AI-Powered Workflow","link":"https://arxiv.org/abs/2403.14460","abstract":"arXiv:2403.14460v1 Announce Type: cross  Abstract: We propose a novel model- and feature-based approach to development of vehicle software systems, where the end architecture is not explicitly defined. Instead, it emerges from an iterative process of search and optimization given certain constraints, requirements and hardware architecture, while retaining the property of single-system illusion, where applications run in a logically uniform environment. One of the key points of the presented approach is the inclusion of modern generative AI, specifically Large Language Models (LLMs), in the loop. With the recent advances in the field, we expect that the LLMs will be able to assist in processing of requirements, generation of formal system models, as well as generation of software deployment specification and test code. The resulting pipeline is automated to a large extent, with feedback being generated at each step.","creator":"Krzysztof Lebioda, Viktor Vorobev, Nenad Petrovic, Fengjunjie Pan, Vahid Zolfaghari, Alois Knoll"},{"id":"2403.14468","slug":"anyv2v-a-plug-and-play-framework-for-any-video-to-video-editing-tasks","title":"AnyV2V: A Plug-and-Play Framework For Any Video-to-Video Editing Tasks","link":"https://arxiv.org/abs/2403.14468","abstract":"arXiv:2403.14468v1 Announce Type: cross  Abstract: Video-to-video editing involves editing a source video along with additional control (such as text prompts, subjects, or styles) to generate a new video that aligns with the source video and the provided control. Traditional methods have been constrained to certain editing types, limiting their ability to meet the wide range of user demands. In this paper, we introduce AnyV2V, a novel training-free framework designed to simplify video editing into two primary steps: (1) employing an off-the-shelf image editing model (e.g. InstructPix2Pix, InstantID, etc) to modify the first frame, (2) utilizing an existing image-to-video generation model (e.g. I2VGen-XL) for DDIM inversion and feature injection. In the first stage, AnyV2V can plug in any existing image editing tools to support an extensive array of video editing tasks. Beyond the traditional prompt-based editing methods, AnyV2V also can support novel video editing tasks, including reference-based style transfer, subject-driven editing, and identity manipulation, which were unattainable by previous methods. In the second stage, AnyV2V can plug in any existing image-to-video models to perform DDIM inversion and intermediate feature injection to maintain the appearance and motion consistency with the source video. On the prompt-based editing, we show that AnyV2V can outperform the previous best approach by 35\\% on prompt alignment, and 25\\% on human preference. On the three novel tasks, we show that AnyV2V also achieves a high success rate. We believe AnyV2V will continue to thrive due to its ability to seamlessly integrate the fast-evolving image editing methods. Such compatibility can help AnyV2V to increase its versatility to cater to diverse user demands.","creator":"Max Ku, Cong Wei, Weiming Ren, Huan Yang, Wenhu Chen"},{"id":"2403.14469","slug":"chatgpt-alternative-solutions-large-language-models-survey","title":"ChatGPT Alternative Solutions: Large Language Models Survey","link":"https://arxiv.org/abs/2403.14469","abstract":"arXiv:2403.14469v1 Announce Type: cross  Abstract: In recent times, the grandeur of Large Language Models (LLMs) has not only shone in the realm of natural language processing but has also cast its brilliance across a vast array of applications. This remarkable display of LLM capabilities has ignited a surge in research contributions within this domain, spanning a diverse spectrum of topics. These contributions encompass advancements in neural network architecture, context length enhancements, model alignment, training datasets, benchmarking, efficiency improvements, and more. Recent years have witnessed a dynamic synergy between academia and industry, propelling the field of LLM research to new heights. A notable milestone in this journey is the introduction of ChatGPT, a powerful AI chatbot grounded in LLMs, which has garnered widespread societal attention. The evolving technology of LLMs has begun to reshape the landscape of the entire AI community, promising a revolutionary shift in the way we create and employ AI algorithms. Given this swift-paced technical evolution, our survey embarks on a journey to encapsulate the recent strides made in the world of LLMs. Through an exploration of the background, key discoveries, and prevailing methodologies, we offer an up-to-the-minute review of the literature. By examining multiple LLM models, our paper not only presents a comprehensive overview but also charts a course that identifies existing challenges and points toward potential future research trajectories. This survey furnishes a well-rounded perspective on the current state of generative AI, shedding light on opportunities for further exploration, enhancement, and innovation.","creator":"Hanieh Alipour, Nick Pendar, Kohinoor Roy"},{"id":"2403.14472","slug":"detoxifying-large-language-models-via-knowledge-editing","title":"Detoxifying Large Language Models via Knowledge Editing","link":"https://arxiv.org/abs/2403.14472","abstract":"arXiv:2403.14472v1 Announce Type: cross  Abstract: This paper investigates using knowledge editing techniques to detoxify Large Language Models (LLMs). We construct a benchmark, SafeEdit, which covers nine unsafe categories with various powerful attack prompts and equips comprehensive metrics for systematic evaluation. We conduct experiments to compare knowledge editing approaches with previous baselines, indicating that knowledge editing has the potential to efficiently detoxify LLMs with limited impact on general performance. Then, we propose a simple yet effective baseline, dubbed Detoxifying with Intraoperative Neural Monitoring (DINM), to diminish the toxicity of LLMs within a few tuning steps via only one instance. We further provide an in-depth analysis of the internal mechanism for various detoxify approaches, demonstrating that previous methods like SFT and DPO may merely suppress the activations of toxic parameters, while DINM mitigates the toxicity of the toxic parameters to a certain extent, making permanent adjustments. We hope that these insights could shed light on future work of developing detoxifying approaches and the underlying knowledge mechanisms of LLMs. Code and benchmark are available at https://github.com/zjunlp/EasyEdit.","creator":"Mengru Wang, Ningyu Zhang, Ziwen Xu, Zekun Xi, Shumin Deng, Yunzhi Yao, Qishen Zhang, Linyi Yang, Jindong Wang, Huajun Chen"},{"id":"2403.14483","slug":"utilizing-the-lightgbm-algorithm-for-operator-user-credit-assessment-research","title":"Utilizing the LightGBM Algorithm for Operator User Credit Assessment Research","link":"https://arxiv.org/abs/2403.14483","abstract":"arXiv:2403.14483v1 Announce Type: cross  Abstract: Mobile Internet user credit assessment is an important way for communication operators to establish decisions and formulate measures, and it is also a guarantee for operators to obtain expected benefits. However, credit evaluation methods have long been monopolized by financial industries such as banks and credit. As supporters and providers of platform network technology and network resources, communication operators are also builders and maintainers of communication networks. Internet data improves the user's credit evaluation strategy. This paper uses the massive data provided by communication operators to carry out research on the operator's user credit evaluation model based on the fusion LightGBM algorithm. First, for the massive data related to user evaluation provided by operators, key features are extracted by data preprocessing and feature engineering methods, and a multi-dimensional feature set with statistical significance is constructed; then, linear regression, decision tree, LightGBM, and other machine learning algorithms build multiple basic models to find the best basic model; finally, integrates Averaging, Voting, Blending, Stacking and other integrated algorithms to refine multiple fusion models, and finally establish the most suitable fusion model for operator user evaluation.","creator":"Shaojie Li, Xinqi Dong, Danqing Ma, Bo Dang, Hengyi Zang, Yulu Gong"},{"id":"2403.14484","slug":"hypergale-asd-classification-via-hypergraph-gated-attention-with-learnable-hyperedges","title":"HyperGALE: ASD Classification via Hypergraph Gated Attention with Learnable Hyperedges","link":"https://arxiv.org/abs/2403.14484","abstract":"arXiv:2403.14484v1 Announce Type: cross  Abstract: Autism Spectrum Disorder (ASD) is a neurodevelopmental condition characterized by varied social cognitive challenges and repetitive behavioral patterns. Identifying reliable brain imaging-based biomarkers for ASD has been a persistent challenge due to the spectrum's diverse symptomatology. Existing baselines in the field have made significant strides in this direction, yet there remains room for improvement in both performance and interpretability. We propose \\emph{HyperGALE}, which builds upon the hypergraph by incorporating learned hyperedges and gated attention mechanisms. This approach has led to substantial improvements in the model's ability to interpret complex brain graph data, offering deeper insights into ASD biomarker characterization. Evaluated on the extensive ABIDE II dataset, \\emph{HyperGALE} not only improves interpretability but also demonstrates statistically significant enhancements in key performance metrics compared to both previous baselines and the foundational hypergraph model. The advancement \\emph{HyperGALE} brings to ASD research highlights the potential of sophisticated graph-based techniques in neurodevelopmental studies. The source code and implementation instructions are available at GitHub:https://github.com/mehular0ra/HyperGALE.","creator":"Mehul Arora, Chirag Shantilal Jain, Lalith Bharadwaj Baru, Kamalaker Dadi, Bapi Raju Surampudi"},{"id":"2403.14488","slug":"physics-based-causal-reasoning-for-safe-robust-next-best-action-selection-in-robot-manipulation-tasks","title":"Physics-Based Causal Reasoning for Safe & Robust Next-Best Action Selection in Robot Manipulation Tasks","link":"https://arxiv.org/abs/2403.14488","abstract":"arXiv:2403.14488v1 Announce Type: cross  Abstract: Safe and efficient object manipulation is a key enabler of many real-world robot applications. However, this is challenging because robot operation must be robust to a range of sensor and actuator uncertainties. In this paper, we present a physics-informed causal-inference-based framework for a robot to probabilistically reason about candidate actions in a block stacking task in a partially observable setting. We integrate a physics-based simulation of the rigid-body system dynamics with a causal Bayesian network (CBN) formulation to define a causal generative probabilistic model of the robot decision-making process. Using simulation-based Monte Carlo experiments, we demonstrate our framework's ability to successfully: (1) predict block tower stability with high accuracy (Pred Acc: 88.6%); and, (2) select an approximate next-best action for the block stacking task, for execution by an integrated robot system, achieving 94.2% task success rate. We also demonstrate our framework's suitability for real-world robot systems by demonstrating successful task executions with a domestic support robot, with perception and manipulation sub-system integration. Hence, we show that by embedding physics-based causal reasoning into robots' decision-making processes, we can make robot task execution safer, more reliable, and more robust to various types of uncertainty.","creator":"Ricardo Cannizzaro, Michael Groom, Jonathan Routley, Robert Osazuwa Ness, Lars Kunze"},{"id":"2403.14494","slug":"learning-to-project-for-cross-task-knowledge-distillation","title":"Learning to Project for Cross-Task Knowledge Distillation","link":"https://arxiv.org/abs/2403.14494","abstract":"arXiv:2403.14494v1 Announce Type: cross  Abstract: Traditional knowledge distillation (KD) relies on a proficient teacher trained on the target task, which is not always available. In this setting, cross-task distillation can be used, enabling the use of any teacher model trained on a different task. However, many KD methods prove ineffective when applied to this cross-task setting. To address this limitation, we propose a simple modification: the use of an inverted projection. We show that this drop-in replacement for a standard projector is effective by learning to disregard any task-specific features which might degrade the student's performance. We find that this simple modification is sufficient for extending many KD methods to the cross-task setting, where the teacher and student tasks can be very different. In doing so, we obtain up to a 1.9% improvement in the cross-task setting compared to the traditional projection, at no additional cost. Our method can obtain significant performance improvements (up to 7%) when using even a randomly-initialised teacher on various tasks such as depth estimation, image translation, and semantic segmentation, despite the lack of any learned knowledge to transfer. To provide conceptual and analytical insights into this result, we show that using an inverted projection allows the distillation loss to be decomposed into a knowledge transfer and a spectral regularisation component. Through this analysis we are additionally able to propose a novel regularisation loss that allows teacher-free distillation, enabling performance improvements of up to 8.57% on ImageNet with no additional training costs.","creator":"Dylan Auty, Roy Miles, Benedikt Kolbeinsson, Krystian Mikolajczyk"},{"id":"2403.14496","slug":"how-human-centered-explainable-ai-interface-are-designed-and-evaluated-a-systematic-survey","title":"How Human-Centered Explainable AI Interface Are Designed and Evaluated: A Systematic Survey","link":"https://arxiv.org/abs/2403.14496","abstract":"arXiv:2403.14496v1 Announce Type: cross  Abstract: Despite its technological breakthroughs, eXplainable Artificial Intelligence (XAI) research has limited success in producing the {\\em effective explanations} needed by users. In order to improve XAI systems' usability, practical interpretability, and efficacy for real users, the emerging area of {\\em Explainable Interfaces} (EIs) focuses on the user interface and user experience design aspects of XAI. This paper presents a systematic survey of 53 publications to identify current trends in human-XAI interaction and promising directions for EI design and development. This is among the first systematic survey of EI research.","creator":"Thu Nguyen, Alessandro Canossa, Jichen Zhu"},{"id":"2403.14504","slug":"soft-learning-probabilistic-circuits","title":"Soft Learning Probabilistic Circuits","link":"https://arxiv.org/abs/2403.14504","abstract":"arXiv:2403.14504v1 Announce Type: cross  Abstract: Probabilistic Circuits (PCs) are prominent tractable probabilistic models, allowing for a range of exact inferences. This paper focuses on the main algorithm for training PCs, LearnSPN, a gold standard due to its efficiency, performance, and ease of use, in particular for tabular data. We show that LearnSPN is a greedy likelihood maximizer under mild assumptions. While inferences in PCs may use the entire circuit structure for processing queries, LearnSPN applies a hard method for learning them, propagating at each sum node a data point through one and only one of the children/edges as in a hard clustering process. We propose a new learning procedure named SoftLearn, that induces a PC using a soft clustering process. We investigate the effect of this learning-inference compatibility in PCs. Our experiments show that SoftLearn outperforms LearnSPN in many situations, yielding better likelihoods and arguably better samples. We also analyze comparable tractable models to highlight the differences between soft/hard learning and model querying.","creator":"Soroush Ghandi, Benjamin Quost, Cassio de Campos"},{"id":"2403.14508","slug":"constrained-reinforcement-learning-with-smoothed-log-barrier-function","title":"Constrained Reinforcement Learning with Smoothed Log Barrier Function","link":"https://arxiv.org/abs/2403.14508","abstract":"arXiv:2403.14508v1 Announce Type: cross  Abstract: Reinforcement Learning (RL) has been widely applied to many control tasks and substantially improved the performances compared to conventional control methods in many domains where the reward function is well defined. However, for many real-world problems, it is often more convenient to formulate optimization problems in terms of rewards and constraints simultaneously. Optimizing such constrained problems via reward shaping can be difficult as it requires tedious manual tuning of reward functions with several interacting terms. Recent formulations which include constraints mostly require a pre-training phase, which often needs human expertise to collect data or assumes having a sub-optimal policy readily available. We propose a new constrained RL method called CSAC-LB (Constrained Soft Actor-Critic with Log Barrier Function), which achieves competitive performance without any pre-training by applying a linear smoothed log barrier function to an additional safety critic. It implements an adaptive penalty for policy learning and alleviates the numerical issues that are known to complicate the application of the log barrier function method. As a result, we show that with CSAC-LB, we achieve state-of-the-art performance on several constrained control tasks with different levels of difficulty and evaluate our methods in a locomotion task on a real quadruped robot platform.","creator":"Baohe Zhang, Yuan Zhang, Lilli Frison, Thomas Brox, Joschka B\\\"odecker"},{"id":"2403.14526","slug":"click-to-grasp-zero-shot-precise-manipulation-via-visual-diffusion-descriptors","title":"Click to Grasp: Zero-Shot Precise Manipulation via Visual Diffusion Descriptors","link":"https://arxiv.org/abs/2403.14526","abstract":"arXiv:2403.14526v1 Announce Type: cross  Abstract: Precise manipulation that is generalizable across scenes and objects remains a persistent challenge in robotics. Current approaches for this task heavily depend on having a significant number of training instances to handle objects with pronounced visual and/or geometric part ambiguities. Our work explores the grounding of fine-grained part descriptors for precise manipulation in a zero-shot setting by utilizing web-trained text-to-image diffusion-based generative models. We tackle the problem by framing it as a dense semantic part correspondence task. Our model returns a gripper pose for manipulating a specific part, using as reference a user-defined click from a source image of a visually different instance of the same object. We require no manual grasping demonstrations as we leverage the intrinsic object geometry and features. Practical experiments in a real-world tabletop scenario validate the efficacy of our approach, demonstrating its potential for advancing semantic-aware robotics manipulation. Web page: https://tsagkas.github.io/click2grasp","creator":"Nikolaos Tsagkas, Jack Rome, Subramanian Ramamoorthy, Oisin Mac Aodha, Chris Xiaoxuan Lu"},{"id":"2403.14539","slug":"object-centric-domain-randomization-for-3d-shape-reconstruction-in-the-wild","title":"Object-Centric Domain Randomization for 3D Shape Reconstruction in the Wild","link":"https://arxiv.org/abs/2403.14539","abstract":"arXiv:2403.14539v1 Announce Type: cross  Abstract: One of the biggest challenges in single-view 3D shape reconstruction in the wild is the scarcity of -paired data from real-world environments. Inspired by remarkable achievements via domain randomization, we propose ObjectDR which synthesizes such paired data via a random simulation of visual variations in object appearances and backgrounds. Our data synthesis framework exploits a conditional generative model (e.g., ControlNet) to generate images conforming to spatial conditions such as 2.5D sketches, which are obtainable through a rendering process of 3D shapes from object collections (e.g., Objaverse-XL). To simulate diverse variations while preserving object silhouettes embedded in spatial conditions, we also introduce a disentangled framework which leverages an initial object guidance. After synthesizing a wide range of data, we pre-train a model on them so that it learns to capture a domain-invariant geometry prior which is consistent across various domains. We validate its effectiveness by substantially improving 3D shape reconstruction models on a real-world benchmark. In a scale-up evaluation, our pre-training achieves 23.6% superior results compared with the pre-training on high-quality computer graphics renderings.","creator":"Junhyeong Cho, Kim Youwang, Hunmin Yang, Tae-Hyun Oh"},{"id":"2403.14550","slug":"dynamic-explanation-emphasis-in-human-xai-interaction-with-communication-robot","title":"Dynamic Explanation Emphasis in Human-XAI Interaction with Communication Robot","link":"https://arxiv.org/abs/2403.14550","abstract":"arXiv:2403.14550v1 Announce Type: cross  Abstract: Communication robots have the potential to contribute to effective human-XAI interaction as an interface that goes beyond textual or graphical explanations. One of their strengths is that they can use physical and vocal expressions to add detailed nuances to explanations. However, it is not clear how a robot can apply such expressions, or in particular, how we can develop a strategy to adaptively use such expressions depending on the task and user in dynamic interactions. To address this question, this paper proposes DynEmph, a method for a communication robot to decide where to emphasize XAI-generated explanations with physical expressions. It predicts the effect of emphasizing certain points on a user and aims to minimize the expected difference between predicted user decisions and AI-suggested ones. DynEmph features a strategy for deciding where to emphasize in a data-driven manner, relieving engineers from the need to manually design a strategy. We further conducted experiments to investigate how emphasis selection strategies affect the performance of user decisions. The results suggest that, while a naive strategy (emphasizing explanations for an AI's most probable class) does not necessarily work better, DynEmph effectively guides users to better decisions under the condition that the performance of the AI suggestion is high.","creator":"Yosuke Fukuchi, Seiji Yamada"},{"id":"2403.14551","slug":"lexicon-level-contrastive-visual-grounding-improves-language-modeling","title":"Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling","link":"https://arxiv.org/abs/2403.14551","abstract":"arXiv:2403.14551v1 Announce Type: cross  Abstract: Today's most accurate language models are trained on orders of magnitude more language data than human language learners receive - but with no supervision from other sensory modalities that play a crucial role in human learning. Can we make LMs' representations and predictions more accurate (and more human-like) with more ecologically plausible supervision? This paper describes LexiContrastive Grounding (LCG), a grounded language learning procedure that leverages visual supervision to improve textual representations. LexiContrastive Grounding combines a next token prediction strategy with a contrastive visual grounding objective, focusing on early-layer representations that encode lexical information. Across multiple word-learning and sentence-understanding benchmarks, LexiContrastive Grounding not only outperforms standard language-only models in learning efficiency, but also improves upon vision-and-language learning procedures including CLIP, GIT, Flamingo, and Vokenization. Moreover, LexiContrastive Grounding improves perplexity by around 5% on multiple language modeling tasks. This work underscores the potential of incorporating visual grounding into language models, aligning more closely with the multimodal nature of human language acquisition.","creator":"Chengxu Zhuang, Evelina Fedorenko, Jacob Andreas"},{"id":"2403.14562","slug":"the-era-of-semantic-decoding","title":"The Era of Semantic Decoding","link":"https://arxiv.org/abs/2403.14562","abstract":"arXiv:2403.14562v1 Announce Type: cross  Abstract: Recent work demonstrated great promise in the idea of orchestrating collaborations between LLMs, human input, and various tools to address the inherent limitations of LLMs. We propose a novel perspective called semantic decoding, which frames these collaborative processes as optimization procedures in semantic space. Specifically, we conceptualize LLMs as semantic processors that manipulate meaningful pieces of information that we call semantic tokens (known thoughts). LLMs are among a large pool of other semantic processors, including humans and tools, such as search engines or code executors. Collectively, semantic processors engage in dynamic exchanges of semantic tokens to progressively construct high-utility outputs. We refer to these orchestrated interactions among semantic processors, optimizing and searching in semantic space, as semantic decoding algorithms. This concept draws a direct parallel to the well-studied problem of syntactic decoding, which involves crafting algorithms to best exploit auto-regressive language models for extracting high-utility sequences of syntactic tokens. By focusing on the semantic level and disregarding syntactic details, we gain a fresh perspective on the engineering of AI systems, enabling us to imagine systems with much greater complexity and capabilities. In this position paper, we formalize the transition from syntactic to semantic tokens as well as the analogy between syntactic and semantic decoding. Subsequently, we explore the possibilities of optimizing within the space of semantic tokens via semantic decoding algorithms. We conclude with a list of research opportunities and questions arising from this fresh perspective. The semantic decoding perspective offers a powerful abstraction for search and optimization directly in the space of meaningful concepts, with semantic tokens as the fundamental units of a new type of computation.","creator":"Maxime Peyrard, Martin Josifoski, Robert West"},{"id":"2403.14582","slug":"large-language-models-for-multi-choice-question-classification-of-medical-subjects","title":"Large Language Models for Multi-Choice Question Classification of Medical Subjects","link":"https://arxiv.org/abs/2403.14582","abstract":"arXiv:2403.14582v1 Announce Type: cross  Abstract: The aim of this paper is to evaluate whether large language models trained on multi-choice question data can be used to discriminate between medical subjects. This is an important and challenging task for automatic question answering. To achieve this goal, we train deep neural networks for multi-class classification of questions into the inferred medical subjects. Using our Multi-Question (MQ) Sequence-BERT method, we outperform the state-of-the-art results on the MedMCQA dataset with an accuracy of 0.68 and 0.60 on their development and test sets, respectively. In this sense, we show the capability of AI and LLMs in particular for multi-classification tasks in the Healthcare domain.","creator":"V\\'ictor Ponce-L\\'opez"},{"id":"2403.14592","slug":"envisioning-the-next-generation-ai-coding-assistants-insights-proposals","title":"Envisioning the Next-Generation AI Coding Assistants: Insights & Proposals","link":"https://arxiv.org/abs/2403.14592","abstract":"arXiv:2403.14592v1 Announce Type: cross  Abstract: As a research-product hybrid group in AI for Software Engineering (AI4SE), we present four key takeaways from our experience developing in-IDE AI coding assistants. AI coding assistants should set clear expectations for usage, integrate with advanced IDE capabilities and existing extensions, use extendable backend designs, and collect app data responsibly for downstream analyses. We propose open questions and challenges that academia and industry should address to realize the vision of next-generation AI coding assistants.","creator":"Khanh Nghiem, Anh Minh Nguyen, Nghi D. Q. Bui"},{"id":"2403.14617","slug":"videoshop-localized-semantic-video-editing-with-noise-extrapolated-diffusion-inversion","title":"Videoshop: Localized Semantic Video Editing with Noise-Extrapolated Diffusion Inversion","link":"https://arxiv.org/abs/2403.14617","abstract":"arXiv:2403.14617v1 Announce Type: cross  Abstract: We introduce Videoshop, a training-free video editing algorithm for localized semantic edits. Videoshop allows users to use any editing software, including Photoshop and generative inpainting, to modify the first frame; it automatically propagates those changes, with semantic, spatial, and temporally consistent motion, to the remaining frames. Unlike existing methods that enable edits only through imprecise textual instructions, Videoshop allows users to add or remove objects, semantically change objects, insert stock photos into videos, etc. with fine-grained control over locations and appearance. We achieve this through image-based video editing by inverting latents with noise extrapolation, from which we generate videos conditioned on the edited image. Videoshop produces higher quality edits against 6 baselines on 2 editing benchmarks using 10 evaluation metrics.","creator":"Xiang Fan, Anand Bhattad, Ranjay Krishna"},{"id":"2403.14624","slug":"mathverse-does-your-multi-modal-llm-truly-see-the-diagrams-in-visual-math-problems","title":"MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?","link":"https://arxiv.org/abs/2403.14624","abstract":"arXiv:2403.14624v1 Announce Type: cross  Abstract: The remarkable progress of Multi-modal Large Language Models (MLLMs) has garnered unparalleled attention, due to their superior performance in visual contexts. However, their capabilities in visual math problem-solving remain insufficiently evaluated and understood. We investigate current benchmarks to incorporate excessive visual content within textual questions, which potentially assist MLLMs in deducing answers without truly interpreting the input diagrams. To this end, we introduce MathVerse, an all-around visual math benchmark designed for an equitable and in-depth evaluation of MLLMs. We meticulously collect 2,612 high-quality, multi-subject math problems with diagrams from publicly available sources. Each problem is then transformed by human annotators into six distinct versions, each offering varying degrees of information content in multi-modality, contributing to 15K test samples in total. This approach allows MathVerse to comprehensively assess whether and how much MLLMs can truly understand the visual diagrams for mathematical reasoning. In addition, we propose a Chain-of-Thought (CoT) evaluation strategy for a fine-grained assessment of the output answers. Rather than naively judging True or False, we employ GPT-4(V) to adaptively extract crucial reasoning steps, and then score each step with detailed error analysis, which can reveal the intermediate CoT reasoning quality by MLLMs. We hope the MathVerse benchmark may provide unique insights to guide the future development of MLLMs. Project page: https://mathverse-cuhk.github.io","creator":"Renrui Zhang, Dongzhi Jiang, Yichi Zhang, Haokun Lin, Ziyu Guo, Pengshuo Qiu, Aojun Zhou, Pan Lu, Kai-Wei Chang, Peng Gao, Hongsheng Li"},{"id":"2303.15662","slug":"chatgpt4pcg-competition-character-like-level-generation-for-science-birds","title":"ChatGPT4PCG Competition: Character-like Level Generation for Science Birds","link":"https://arxiv.org/abs/2303.15662","abstract":"arXiv:2303.15662v3 Announce Type: replace  Abstract: This paper presents the first ChatGPT4PCG Competition at the 2023 IEEE Conference on Games. The objective of this competition is for participants to create effective prompts for ChatGPT--enabling it to generate Science Birds levels with high stability and character-like qualities--fully using their creativity as well as prompt engineering skills. ChatGPT is a conversational agent developed by OpenAI. Science Birds is selected as the competition platform because designing an Angry Birds-like level is not a trivial task due to the in-game gravity; the quality of the levels is determined by their stability. To lower the entry barrier to the competition, we limit the task to the generation of capitalized English alphabetical characters. We also allow only a single prompt to be used for generating all the characters. Here, the quality of the generated levels is determined by their stability and similarity to the given characters. A sample prompt is provided to participants for their reference. An experiment is conducted to determine the effectiveness of several modified versions of this sample prompt on level stability and similarity by testing them on several characters. To the best of our knowledge, we believe that ChatGPT4PCG is the first competition of its kind and hope to inspire enthusiasm for prompt engineering in procedural content generation.","creator":"Pittawat Taveekitworachai, Febri Abdullah, Mury F. Dewantoro, Ruck Thawonmas, Julian Togelius, Jochen Renz"},{"id":"2308.05374","slug":"trustworthy-llms-a-survey-and-guideline-for-evaluating-large-language-models-alignment","title":"Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment","link":"https://arxiv.org/abs/2308.05374","abstract":"arXiv:2308.05374v2 Announce Type: replace  Abstract: Ensuring alignment, which refers to making models behave in accordance with human intentions [1,2], has become a critical task before deploying large language models (LLMs) in real-world applications. For instance, OpenAI devoted six months to iteratively aligning GPT-4 before its release [3]. However, a major challenge faced by practitioners is the lack of clear guidance on evaluating whether LLM outputs align with social norms, values, and regulations. This obstacle hinders systematic iteration and deployment of LLMs. To address this issue, this paper presents a comprehensive survey of key dimensions that are crucial to consider when assessing LLM trustworthiness. The survey covers seven major categories of LLM trustworthiness: reliability, safety, fairness, resistance to misuse, explainability and reasoning, adherence to social norms, and robustness. Each major category is further divided into several sub-categories, resulting in a total of 29 sub-categories. Additionally, a subset of 8 sub-categories is selected for further investigation, where corresponding measurement studies are designed and conducted on several widely-used LLMs. The measurement results indicate that, in general, more aligned models tend to perform better in terms of overall trustworthiness. However, the effectiveness of alignment varies across the different trustworthiness categories considered. This highlights the importance of conducting more fine-grained analyses, testing, and making continuous improvements on LLM alignment. By shedding light on these key dimensions of LLM trustworthiness, this paper aims to provide valuable insights and guidance to practitioners in the field. Understanding and addressing these concerns will be crucial in achieving reliable and ethically sound deployment of LLMs in various applications.","creator":"Yang Liu, Yuanshun Yao, Jean-Francois Ton, Xiaoying Zhang, Ruocheng Guo, Hao Cheng, Yegor Klochkov, Muhammad Faaiz Taufiq, Hang Li"},{"id":"2402.07234","slug":"cpsdbench-a-large-language-model-evaluation-benchmark-and-baseline-for-chinese-public-security-domain","title":"CPSDBench: A Large Language Model Evaluation Benchmark and Baseline for Chinese Public Security Domain","link":"https://arxiv.org/abs/2402.07234","abstract":"arXiv:2402.07234v3 Announce Type: replace  Abstract: Large Language Models (LLMs) have demonstrated significant potential and effectiveness across multiple application domains. To assess the performance of mainstream LLMs in public security tasks, this study aims to construct a specialized evaluation benchmark tailored to the Chinese public security domain--CPSDbench. CPSDbench integrates datasets related to public security collected from real-world scenarios, supporting a comprehensive assessment of LLMs across four key dimensions: text classification, information extraction, question answering, and text generation. Furthermore, this study introduces a set of innovative evaluation metrics designed to more precisely quantify the efficacy of LLMs in executing tasks related to public security. Through the in-depth analysis and evaluation conducted in this research, we not only enhance our understanding of the performance strengths and limitations of existing models in addressing public security issues but also provide references for the future development of more accurate and customized LLM models targeted at applications in this field.","creator":"Xin Tong, Bo Jin, Zhi Lin, Binjun Wang, Ting Yu, Qiang Cheng"},{"id":"2402.09099","slug":"exploring-neuron-interactions-and-emergence-in-llms-from-the-multifractal-analysis-perspective","title":"Exploring Neuron Interactions and Emergence in LLMs: From the Multifractal Analysis Perspective","link":"https://arxiv.org/abs/2402.09099","abstract":"arXiv:2402.09099v4 Announce Type: replace  Abstract: Prior studies on the emergence in large models have primarily focused on how the functional capabilities of large language models (LLMs) scale with model size. Our research, however, transcends this traditional paradigm, aiming to deepen our understanding of the emergence within LLMs by placing a special emphasis not just on the model size but more significantly on the complex behavior of neuron interactions during the training process. By introducing the concepts of \"self-organization\" and \"multifractal analysis,\" we explore how neuron interactions dynamically evolve during training, leading to \"emergence,\" mirroring the phenomenon in natural systems where simple micro-level interactions give rise to complex macro-level behaviors. To quantitatively analyze the continuously evolving interactions among neurons in large models during training, we propose the Neuron-based Multifractal Analysis (NeuroMFA). Utilizing NeuroMFA, we conduct a comprehensive examination of the emergent behavior in LLMs through the lens of both model size and training process, paving new avenues for research into the emergence in large models.","creator":"Xiongye Xiao, Chenyu Zhou, Heng Ping, Defu Cao, Yaxing Li, Yizhuo Zhou, Shixuan Li, Paul Bogdan"},{"id":"2209.00568","slug":"multi-scale-contrastive-knowledge-co-distillation-for-event-temporal-relation-extraction","title":"Multi-Scale Contrastive Knowledge Co-Distillation for Event Temporal Relation Extraction","link":"https://arxiv.org/abs/2209.00568","abstract":"arXiv:2209.00568v2 Announce Type: replace-cross  Abstract: Event Temporal Relation Extraction (ETRE) is a crucial yet challenging problem. Event pairs are situated within a discourse at different distances, which we refer to as proximity bands. The temporal ordering communicated about event pairs situated at more remote (i.e., ``long'') or less remote (i.e., ``short'') proximity bands is encoded differently. SOTA ETRE models have tended to perform well on events situated at either short or long proximity bands, but not both. Yet, real-world, natural texts contain all types of temporal event-pairs. In this paper, we present MulCo: Multi-Scale Contrastive Knowledge Co-Distillation, a fusion approach that shares knowledge across multiple event pair proximity bands in order to improve performance on all types of temporal datasets. Our experimental results show that MulCo successfully integrates linguistic cues pertaining to temporal reasoning across both short and long proximity bands and achieves new state-of-the-art results on several ETRE benchmark datasets.","creator":"Hao-Ren Yao, Luke Breitfeller, Aakanksha Naik, Chunxiao Zhou, Carolyn Rose"},{"id":"2211.13854","slug":"comclip-training-free-compositional-image-and-text-matching","title":"ComCLIP: Training-Free Compositional Image and Text Matching","link":"https://arxiv.org/abs/2211.13854","abstract":"arXiv:2211.13854v4 Announce Type: replace-cross  Abstract: Contrastive Language-Image Pretraining (CLIP) has demonstrated great zero-shot performance for matching images and text. However, it is still challenging to adapt vision-lanaguage pretrained models like CLIP to compositional image and text matching -- a more challenging image and text matching task requiring the model understanding of compositional word concepts and visual components. Towards better compositional generalization in zero-shot image and text matching, in this paper, we study the problem from a causal perspective: the erroneous semantics of individual entities are essentially confounders that cause the matching failure. Therefore, we propose a novel \\textbf{\\textit{training-free}} compositional CLIP model (ComCLIP). ComCLIP disentangles input images into subjects, objects, and action sub-images and composes CLIP's vision encoder and text encoder to perform evolving matching over compositional text embedding and sub-image embeddings. In this way, ComCLIP can mitigate spurious correlations introduced by the pretrained CLIP models and dynamically evaluate the importance of each component. Experiments on four compositional image-text matching datasets: SVO, ComVG, Winoground, and VL-checklist, and two general image-text retrieval datasets: Flick30K, and MSCOCO demonstrate the effectiveness of our plug-and-play method, which boosts the \\textbf{\\textit{zero-shot}} inference ability of CLIP, SLIP, and BLIP2 even without further training or fine-tuning. Our codes can be found at https://github.com/eric-ai-lab/ComCLIP.","creator":"Kenan Jiang, Xuehai He, Ruize Xu, Xin Eric Wang"},{"id":"2302.01385","slug":"hyper-parameter-tuning-for-fair-classification-without-sensitive-attribute-access","title":"Hyper-parameter Tuning for Fair Classification without Sensitive Attribute Access","link":"https://arxiv.org/abs/2302.01385","abstract":"arXiv:2302.01385v2 Announce Type: replace-cross  Abstract: Fair machine learning methods seek to train models that balance model performance across demographic subgroups defined over sensitive attributes like race and gender. Although sensitive attributes are typically assumed to be known during training, they may not be available in practice due to privacy and other logistical concerns. Recent work has sought to train fair models without sensitive attributes on training data. However, these methods need extensive hyper-parameter tuning to achieve good results, and hence assume that sensitive attributes are known on validation data. However, this assumption too might not be practical. Here, we propose Antigone, a framework to train fair classifiers without access to sensitive attributes on either training or validation data. Instead, we generate pseudo sensitive attributes on the validation data by training a biased classifier and using the classifier's incorrectly (correctly) labeled examples as proxies for minority (majority) groups. Since fairness metrics like demographic parity, equal opportunity and subgroup accuracy can be estimated to within a proportionality constant even with noisy sensitive attribute information, we show theoretically and empirically that these proxy labels can be used to maximize fairness under average accuracy constraints. Key to our results is a principled approach to select the hyper-parameters of the biased classifier in a completely unsupervised fashion (meaning without access to ground truth sensitive attributes) that minimizes the gap between fairness estimated using noisy versus ground-truth sensitive labels.","creator":"Akshaj Kumar Veldanda, Ivan Brugere, Sanghamitra Dutta, Alan Mishler, Siddharth Garg"},{"id":"2302.03788","slug":"toward-a-theory-of-causation-for-interpreting-neural-code-models","title":"Toward a Theory of Causation for Interpreting Neural Code Models","link":"https://arxiv.org/abs/2302.03788","abstract":"arXiv:2302.03788v3 Announce Type: replace-cross  Abstract: Neural Language Models of Code, or Neural Code Models (NCMs), are rapidly progressing from research prototypes to commercial developer tools. As such, understanding the capabilities and limitations of such models is becoming critical. However, the abilities of these models are typically measured using automated metrics that often only reveal a portion of their real-world performance. While, in general, the performance of NCMs appears promising, currently much is unknown about how such models arrive at decisions. To this end, this paper introduces $do_{code}$, a post hoc interpretability method specific to NCMs that is capable of explaining model predictions. $do_{code}$ is based upon causal inference to enable programming language-oriented explanations. While the theoretical underpinnings of $do_{code}$ are extensible to exploring different model properties, we provide a concrete instantiation that aims to mitigate the impact of spurious correlations by grounding explanations of model behavior in properties of programming languages. To demonstrate the practical benefit of $do_{code}$, we illustrate the insights that our framework can provide by performing a case study on two popular deep learning architectures and ten NCMs. The results of this case study illustrate that our studied NCMs are sensitive to changes in code syntax. All our NCMs, except for the BERT-like model, statistically learn to predict tokens related to blocks of code (\\eg brackets, parenthesis, semicolon) with less confounding bias as compared to other programming language constructs. These insights demonstrate the potential of $do_{code}$ as a useful method to detect and facilitate the elimination of confounding bias in NCMs.","creator":"David N. Palacio, Alejandro Velasco, Nathan Cooper, Alvaro Rodriguez, Kevin Moran, Denys Poshyvanyk"},{"id":"2306.00618","slug":"effective-structured-prompting-by-meta-learning-and-representative-verbalizer","title":"Effective Structured Prompting by Meta-Learning and Representative Verbalizer","link":"https://arxiv.org/abs/2306.00618","abstract":"arXiv:2306.00618v2 Announce Type: replace-cross  Abstract: Prompt tuning for pre-trained masked language models (MLM) has shown promising performance in natural language processing tasks with few labeled examples. It tunes a prompt for the downstream task, and a verbalizer is used to bridge the predicted token and label prediction. Due to the limited training data, prompt initialization is crucial for prompt tuning. Recently, MetaPrompting (Hou et al., 2022) uses meta-learning to learn a shared initialization for all task-specific prompts. However, a single initialization is insufficient to obtain good prompts for all tasks and samples when the tasks are complex. Moreover, MetaPrompting requires tuning the whole MLM, causing a heavy burden on computation and memory as the MLM is usually large. To address these issues, we use a prompt pool to extract more task knowledge and construct instance-dependent prompts via attention. We further propose a novel soft verbalizer (RepVerb) which constructs label embedding from feature embeddings directly. Combining meta-learning the prompt pool and RepVerb, we propose MetaPrompter for effective structured prompting. MetaPrompter is parameter-efficient as only the pool is required to be tuned. Experimental results demonstrate that MetaPrompter performs better than the recent state-of-the-arts and RepVerb outperforms existing soft verbalizers.","creator":"Weisen Jiang, Yu Zhang, James T. Kwok"},{"id":"2306.02090","slug":"deep-classifier-mimicry-without-data-access","title":"Deep Classifier Mimicry without Data Access","link":"https://arxiv.org/abs/2306.02090","abstract":"arXiv:2306.02090v3 Announce Type: replace-cross  Abstract: Access to pre-trained models has recently emerged as a standard across numerous machine learning domains. Unfortunately, access to the original data the models were trained on may not equally be granted. This makes it tremendously challenging to fine-tune, compress models, adapt continually, or to do any other type of data-driven update. We posit that original data access may however not be required. Specifically, we propose Contrastive Abductive Knowledge Extraction (CAKE), a model-agnostic knowledge distillation procedure that mimics deep classifiers without access to the original data. To this end, CAKE generates pairs of noisy synthetic samples and diffuses them contrastively toward a model's decision boundary. We empirically corroborate CAKE's effectiveness using several benchmark datasets and various architectural choices, paving the way for broad application.","creator":"Steven Braun, Martin Mundt, Kristian Kersting"},{"id":"2306.09549","slug":"qh9-a-quantum-hamiltonian-prediction-benchmark-for-qm9-molecules","title":"QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules","link":"https://arxiv.org/abs/2306.09549","abstract":"arXiv:2306.09549v4 Announce Type: replace-cross  Abstract: Supervised machine learning approaches have been increasingly used in accelerating electronic structure prediction as surrogates of first-principle computational methods, such as density functional theory (DFT). While numerous quantum chemistry datasets focus on chemical properties and atomic forces, the ability to achieve accurate and efficient prediction of the Hamiltonian matrix is highly desired, as it is the most important and fundamental physical quantity that determines the quantum states of physical systems and chemical properties. In this work, we generate a new Quantum Hamiltonian dataset, named as QH9, to provide precise Hamiltonian matrices for 999 or 2998 molecular dynamics trajectories and 130,831 stable molecular geometries, based on the QM9 dataset. By designing benchmark tasks with various molecules, we show that current machine learning models have the capacity to predict Hamiltonian matrices for arbitrary molecules. Both the QH9 dataset and the baseline models are provided to the community through an open-source benchmark, which can be highly valuable for developing machine learning methods and accelerating molecular and materials design for scientific and technological applications. Our benchmark is publicly available at https://github.com/divelab/AIRS/tree/main/OpenDFT/QHBench.","creator":"Haiyang Yu, Meng Liu, Youzhi Luo, Alex Strasser, Xiaofeng Qian, Xiaoning Qian, Shuiwang Ji"},{"id":"2308.05342","slug":"metacognitive-prompting-improves-understanding-in-large-language-models","title":"Metacognitive Prompting Improves Understanding in Large Language Models","link":"https://arxiv.org/abs/2308.05342","abstract":"arXiv:2308.05342v4 Announce Type: replace-cross  Abstract: In Large Language Models (LLMs), there have been consistent advancements in task-specific performance, largely influenced by effective prompt design. Recent advancements in prompting have enhanced reasoning in logic-intensive tasks for LLMs, yet the nuanced understanding abilities of these models, crucial for processing and interpreting complex information, remain underexplored. In this study, we introduce Metacognitive Prompting (MP), a strategy inspired by human introspective reasoning processes. Using MP, LLMs undergo a systematic series of structured, self-aware evaluations, drawing on both their vast inherent knowledge and new insights. We conduct extensive experiments on four prevalent LLMs: Llama2, PaLM2, GPT-3.5, and GPT-4, across ten natural language understanding (NLU) datasets from GLUE, SuperGLUE, BLUE, and LexGLUE benchmarks. Additionally, we compare our method with chain-of-thought prompting and its advanced versions. The results show that GPT-4 consistently excels across all tasks, while other models have shown significant progress in some tasks when used in conjunction with MP. Furthermore, MP consistently outperforms existing prompting methods in both general and domain-specific NLU tasks. This study underscores the potential to amplify the understanding abilities of LLMs and highlights the benefits of mirroring human introspective reasoning in NLU tasks.","creator":"Yuqing Wang, Yun Zhao"},{"id":"2308.14296","slug":"recmind-large-language-model-powered-agent-for-recommendation","title":"RecMind: Large Language Model Powered Agent For Recommendation","link":"https://arxiv.org/abs/2308.14296","abstract":"arXiv:2308.14296v3 Announce Type: replace-cross  Abstract: While the recommendation system (RS) has advanced significantly through deep learning, current RS approaches usually train and fine-tune models on task-specific datasets, limiting their generalizability to new recommendation tasks and their ability to leverage external knowledge due to model scale and data size constraints. Thus, we designed an LLM-powered autonomous recommender agent, RecMind, which is capable of leveraging external knowledge, utilizing tools with careful planning to provide zero-shot personalized recommendations. We propose a Self-Inspiring algorithm to improve the planning ability. At each intermediate step, the LLM self-inspires to consider all previously explored states to plan for the next step. This mechanism greatly improves the model's ability to comprehend and utilize historical information in planning for recommendation. We evaluate RecMind's performance in various recommendation scenarios. Our experiment shows that RecMind outperforms existing zero/few-shot LLM-based recommendation baseline methods in various tasks and achieves comparable performance to a fully trained recommendation model P5.","creator":"Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, Yingzhen Yang"},{"id":"2309.00903","slug":"an-explainable-three-dimension-framework-to-uncover-learning-patterns-a-unified-look-in-variable-sulci-recognition","title":"An explainable three dimension framework to uncover learning patterns: A unified look in variable sulci recognition","link":"https://arxiv.org/abs/2309.00903","abstract":"arXiv:2309.00903v2 Announce Type: replace-cross  Abstract: Explainable AI is crucial in medical imaging. In the challenging field of neuroscience, visual topics present a high level of complexity, particularly within three-dimensional space. The application of neuroscience, which involves identifying brain sulcal features from MRI, faces significant hurdles due to varying annotation protocols among experts and the intricate three-dimension functionality of the brain. Consequently, traditional explainability approaches fall short in effectively validating and evaluating these networks. To address this, we first present a mathematical formulation delineating various categories of explanation needs across diverse computer vision tasks, categorized into self-explanatory, semi-explanatory, non-explanatory, and new-pattern learning applications based on the reliability of the validation protocol. With respect to this mathematical formulation, we propose a 3D explainability framework aimed at validating the outputs of deep learning networks in detecting the paracingulate sulcus an essential brain anatomical feature. The framework integrates local 3D explanations, global explanations through dimensionality reduction, concatenated global explanations, and statistical shape features, unveiling new insights into pattern learning. We trained and tested two advanced 3D deep learning networks on the challenging TOP-OSLO dataset, significantly improving sulcus detection accuracy, particularly on the left hemisphere. During evaluation with diverse annotation protocols for this dataset, we highlighted the crucial role of an unbiased annotation process in achieving precise predictions and effective pattern learning within our proposed 3D framework. The proposed framework not only annotates the variable sulcus but also uncovers hidden AI knowledge, promising to advance our understanding of brain anatomy and function.","creator":"Michail Mamalakis, Heloise de Vareilles, Atheer AI-Manea, Samantha C. Mitchell, Ingrid Arartz, Lynn Egeland Morch-Johnsen, Jane Garrison, Jon Simons, Pietro Lio, John Suckling, Graham Murray"},{"id":"2309.02094","slug":"tensorbank-tensor-lakehouse-for-foundation-model-training","title":"TensorBank: Tensor Lakehouse for Foundation Model Training","link":"https://arxiv.org/abs/2309.02094","abstract":"arXiv:2309.02094v3 Announce Type: replace-cross  Abstract: Storing and streaming high dimensional data for foundation model training became a critical requirement with the rise of foundation models beyond natural language. In this paper we introduce TensorBank, a petabyte scale tensor lakehouse capable of streaming tensors from Cloud Object Store (COS) to GPU memory at wire speed based on complex relational queries. We use Hierarchical Statistical Indices (HSI) for query acceleration. Our architecture allows to directly address tensors on block level using HTTP range reads. Once in GPU memory, data can be transformed using PyTorch transforms. We provide a generic PyTorch dataset type with a corresponding dataset factory translating relational queries and requested transformations as an instance. By making use of the HSI, irrelevant blocks can be skipped without reading them as those indices contain statistics on their content at different hierarchical resolution levels. This is an opinionated architecture powered by open standards and making heavy use of open-source technology. Although, hardened for production use using geospatial-temporal data, this architecture generalizes to other use case like computer vision, computational neuroscience, biological sequence analysis and more.","creator":"Romeo Kienzler, Leonardo Pondian Tizzei, Benedikt Blumenstiel, Zoltan Arnold Nagy, S. Karthik Mukkavilli, Johannes Schmude, Marcus Freitag, Michael Behrendt, Daniel Salles Civitarese, Naomi Simumba, Daiki Kimura, Hendrik Hamann"},{"id":"2309.02632","slug":"deep-reinforcement-learning-with-hierarchical-reward-modeling","title":"Deep Reinforcement Learning with Hierarchical Reward Modeling","link":"https://arxiv.org/abs/2309.02632","abstract":"arXiv:2309.02632v2 Announce Type: replace-cross  Abstract: Reward design is a fundamental, yet challenging aspect of reinforcement learning (RL). Researchers typically utilize feedback signals from the environment to handcraft a reward function, but this process is not always effective due to the varying scale and intricate dependencies of the feedback signals. This paper shows by exploiting certain structures, one can ease the reward design process. Specifically, we propose a hierarchical reward modeling framework -- HERON for scenarios: (I) The feedback signals naturally present hierarchy; (II) The reward is sparse, but with less important surrogate feedback to help policy learning. Both scenarios allow us to design a hierarchical decision tree induced by the importance ranking of the feedback signals to compare RL trajectories. With such preference data, we can then train a reward model for policy learning. We apply HERON to several RL applications, and we find that our framework can not only train high performing agents on a variety of difficult tasks, but also provide additional benefits such as improved sample efficiency and robustness. Our code is available at \\url{https://github.com/abukharin3/HERON}.","creator":"Alexander Bukharin, Yixiao Li, Pengcheng He, Weizhu Chen, Tuo Zhao"},{"id":"2309.06255","slug":"enhancing-multimodal-cooperation-via-fine-grained-modality-valuation","title":"Enhancing Multimodal Cooperation via Fine-grained Modality Valuation","link":"https://arxiv.org/abs/2309.06255","abstract":"arXiv:2309.06255v3 Announce Type: replace-cross  Abstract: One primary topic of multimodal learning is to jointly incorporate heterogeneous information from different modalities. However, most models often suffer from unsatisfactory multimodal cooperation, which cannot jointly utilize all modalities well. Some methods are proposed to identify and enhance the worse learnt modality, but they are often hard to provide the fine-grained observation of multimodal cooperation at sample-level with theoretical support. Hence, it is essential to reasonably observe and improve the fine-grained cooperation between modalities, especially when facing realistic scenarios where the modality discrepancy could vary across different samples. To this end, we introduce a sample-level modality valuation metric to evaluate the contribution of each modality for each sample. Via modality valuation, we observe that modality discrepancy indeed could be different at sample-level, beyond the global contribution discrepancy at dataset-level. We further analyze this issue and improve cooperation between modalities at sample-level by enhancing the discriminative ability of low-contributing modalities in a targeted manner. Overall, our methods reasonably observe the fine-grained uni-modal contribution and achieve considerable improvement. The source code and dataset are available at \\url{https://github.com/GeWu-Lab/Valuate-and-Enhance-Multimodal-Cooperation}.","creator":"Yake Wei, Ruoxuan Feng, Zihe Wang, Di Hu"},{"id":"2309.11259","slug":"sequence-to-sequence-spanish-pre-trained-language-models","title":"Sequence-to-Sequence Spanish Pre-trained Language Models","link":"https://arxiv.org/abs/2309.11259","abstract":"arXiv:2309.11259v2 Announce Type: replace-cross  Abstract: In recent years, significant advancements in pre-trained language models have driven the creation of numerous non-English language variants, with a particular emphasis on encoder-only and decoder-only architectures. While Spanish language models based on BERT and GPT have demonstrated proficiency in natural language understanding and generation, there remains a noticeable scarcity of encoder-decoder models explicitly designed for sequence-to-sequence tasks, which aim to map input sequences to generate output sequences conditionally. This paper breaks new ground by introducing the implementation and evaluation of renowned encoder-decoder architectures exclusively pre-trained on Spanish corpora. Specifically, we present Spanish versions of BART, T5, and BERT2BERT-style models and subject them to a comprehensive assessment across various sequence-to-sequence tasks, including summarization, question answering, split-and-rephrase, dialogue, and translation. Our findings underscore the competitive performance of all models, with the BART- and T5-based models emerging as top performers across all tasks. We have made all models publicly available to the research community to foster future explorations and advancements in Spanish NLP: https://github.com/vgaraujov/Seq2Seq-Spanish-PLMs.","creator":"Vladimir Araujo, Maria Mihaela Trusca, Rodrigo Tufi\\~no, Marie-Francine Moens"},{"id":"2309.14974","slug":"detecting-sexual-content-at-the-sentence-level-in-first-millennium-latin-texts","title":"Detecting Sexual Content at the Sentence Level in First Millennium Latin Texts","link":"https://arxiv.org/abs/2309.14974","abstract":"arXiv:2309.14974v2 Announce Type: replace-cross  Abstract: In this study, we propose to evaluate the use of deep learning methods for semantic classification at the sentence level to accelerate the process of corpus building in the field of humanities and linguistics, a traditional and time-consuming task. We introduce a novel corpus comprising around 2500 sentences spanning from 300 BCE to 900 CE including sexual semantics (medical, erotica, etc.). We evaluate various sentence classification approaches and different input embedding layers, and show that all consistently outperform simple token-based searches. We explore the integration of idiolectal and sociolectal metadata embeddings (centuries, author, type of writing), but find that it leads to overfitting. Our results demonstrate the effectiveness of this approach, achieving high precision and true positive rates (TPR) of respectively 70.60% and 86.33% using HAN. We evaluate the impact of the dataset size on the model performances (420 instead of 2013), and show that, while our models perform worse, they still offer a high enough precision and TPR, even without MLM, respectively 69% and 51%. Given the result, we provide an analysis of the attention mechanism as a supporting added value for humanists in order to produce more data.","creator":"Thibault Cl\\'erice (ALMAnaCH, CJM)"},{"id":"2310.02712","slug":"ed-nerf-efficient-text-guided-editing-of-3d-scene-with-latent-space-nerf","title":"ED-NeRF: Efficient Text-Guided Editing of 3D Scene with Latent Space NeRF","link":"https://arxiv.org/abs/2310.02712","abstract":"arXiv:2310.02712v2 Announce Type: replace-cross  Abstract: Recently, there has been a significant advancement in text-to-image diffusion models, leading to groundbreaking performance in 2D image generation. These advancements have been extended to 3D models, enabling the generation of novel 3D objects from textual descriptions. This has evolved into NeRF editing methods, which allow the manipulation of existing 3D objects through textual conditioning. However, existing NeRF editing techniques have faced limitations in their performance due to slow training speeds and the use of loss functions that do not adequately consider editing. To address this, here we present a novel 3D NeRF editing approach dubbed ED-NeRF by successfully embedding real-world scenes into the latent space of the latent diffusion model (LDM) through a unique refinement layer. This approach enables us to obtain a NeRF backbone that is not only faster but also more amenable to editing compared to traditional image space NeRF editing. Furthermore, we propose an improved loss function tailored for editing by migrating the delta denoising score (DDS) distillation loss, originally used in 2D image editing to the three-dimensional domain. This novel loss function surpasses the well-known score distillation sampling (SDS) loss in terms of suitability for editing purposes. Our experimental results demonstrate that ED-NeRF achieves faster editing speed while producing improved output quality compared to state-of-the-art 3D editing models.","creator":"Jangho Park, Gihyun Kwon, Jong Chul Ye"},{"id":"2310.04451","slug":"autodan-generating-stealthy-jailbreak-prompts-on-aligned-large-language-models","title":"AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models","link":"https://arxiv.org/abs/2310.04451","abstract":"arXiv:2310.04451v2 Announce Type: replace-cross  Abstract: The aligned Large Language Models (LLMs) are powerful language understanding and decision-making tools that are created through extensive alignment with human feedback. However, these large models remain susceptible to jailbreak attacks, where adversaries manipulate prompts to elicit malicious outputs that should not be given by aligned LLMs. Investigating jailbreak prompts can lead us to delve into the limitations of LLMs and further guide us to secure them. Unfortunately, existing jailbreak techniques suffer from either (1) scalability issues, where attacks heavily rely on manual crafting of prompts, or (2) stealthiness problems, as attacks depend on token-based algorithms to generate prompts that are often semantically meaningless, making them susceptible to detection through basic perplexity testing. In light of these challenges, we intend to answer this question: Can we develop an approach that can automatically generate stealthy jailbreak prompts? In this paper, we introduce AutoDAN, a novel jailbreak attack against aligned LLMs. AutoDAN can automatically generate stealthy jailbreak prompts by the carefully designed hierarchical genetic algorithm. Extensive evaluations demonstrate that AutoDAN not only automates the process while preserving semantic meaningfulness, but also demonstrates superior attack strength in cross-model transferability, and cross-sample universality compared with the baseline. Moreover, we also compare AutoDAN with perplexity-based defense methods and show that AutoDAN can bypass them effectively.","creator":"Xiaogeng Liu, Nan Xu, Muhao Chen, Chaowei Xiao"},{"id":"2310.14525","slug":"graph-ranking-contrastive-learning-a-extremely-simple-yet-efficient-method","title":"Graph Ranking Contrastive Learning: A Extremely Simple yet Efficient Method","link":"https://arxiv.org/abs/2310.14525","abstract":"arXiv:2310.14525v2 Announce Type: replace-cross  Abstract: Graph contrastive learning (GCL) has emerged as a representative graph self-supervised method, achieving significant success. The currently prevalent optimization objective for GCL is InfoNCE. Typically, it employs augmentation techniques to obtain two views, where a node in one view acts as the anchor, the corresponding node in the other view serves as the positive sample, and all other nodes are regarded as negative samples. The goal is to minimize the distance between the anchor node and positive samples and maximize the distance to negative samples. However, due to the lack of label information during training, InfoNCE inevitably treats samples from the same class as negative samples, leading to the issue of false negative samples. This can impair the learned node representations and subsequently hinder performance in downstream tasks. While numerous methods have been proposed to mitigate the impact of false negatives, they still face various challenges. For instance, while increasing the number of negative samples can dilute the impact of false negatives, it concurrently increases computational burden. Thus, we propose GraphRank, a simple yet efficient graph contrastive learning method that addresses the problem of false negative samples by redefining the concept of negative samples to a certain extent, thereby avoiding the issue of false negative samples. The effectiveness of GraphRank is empirically validated through experiments on the node, edge, and graph level tasks.","creator":"Yulan Hu, Sheng Ouyang, Jingyu Liu, Ge Chen, Zhirui Yang, Junchen Wan, Fuzheng Zhang, Zhongyuan Wang, Yong Liu"},{"id":"2310.16828","slug":"td-mpc2-scalable-robust-world-models-for-continuous-control","title":"TD-MPC2: Scalable, Robust World Models for Continuous Control","link":"https://arxiv.org/abs/2310.16828","abstract":"arXiv:2310.16828v2 Announce Type: replace-cross  Abstract: TD-MPC is a model-based reinforcement learning (RL) algorithm that performs local trajectory optimization in the latent space of a learned implicit (decoder-free) world model. In this work, we present TD-MPC2: a series of improvements upon the TD-MPC algorithm. We demonstrate that TD-MPC2 improves significantly over baselines across 104 online RL tasks spanning 4 diverse task domains, achieving consistently strong results with a single set of hyperparameters. We further show that agent capabilities increase with model and data size, and successfully train a single 317M parameter agent to perform 80 tasks across multiple task domains, embodiments, and action spaces. We conclude with an account of lessons, opportunities, and risks associated with large TD-MPC2 agents. Explore videos, models, data, code, and more at https://tdmpc2.com","creator":"Nicklas Hansen, Hao Su, Xiaolong Wang"},{"id":"2310.17918","slug":"knowing-what-llms-do-not-know-a-simple-yet-effective-self-detection-method","title":"Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method","link":"https://arxiv.org/abs/2310.17918","abstract":"arXiv:2310.17918v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have shown great potential in Natural Language Processing (NLP) tasks. However, recent literature reveals that LLMs generate nonfactual responses intermittently, which impedes the LLMs' reliability for further utilization. In this paper, we propose a novel self-detection method to detect which questions that a LLM does not know that are prone to generate nonfactual results. Specifically, we first diversify the textual expressions for a given question and collect the corresponding answers. Then we examine the divergencies between the generated answers to identify the questions that the model may generate falsehoods. All of the above steps can be accomplished by prompting the LLMs themselves without referring to any other external resources. We conduct comprehensive experiments and demonstrate the effectiveness of our method on recently released LLMs, e.g., Vicuna, ChatGPT, and GPT-4.","creator":"Yukun Zhao, Lingyong Yan, Weiwei Sun, Guoliang Xing, Chong Meng, Shuaiqiang Wang, Zhicong Cheng, Zhaochun Ren, Dawei Yin"},{"id":"2311.01623","slug":"vqpy-an-object-oriented-approach-to-modern-video-analytics","title":"VQPy: An Object-Oriented Approach to Modern Video Analytics","link":"https://arxiv.org/abs/2311.01623","abstract":"arXiv:2311.01623v2 Announce Type: replace-cross  Abstract: Video analytics is widely used in contemporary systems and services. At the forefront of video analytics are video queries that users develop to find objects of particular interest. Building upon the insight that video objects (e.g., human, animals, cars, etc.), the center of video analytics, are similar in spirit to objects modeled by traditional object-oriented languages, we propose to develop an object-oriented approach to video analytics. This approach, named VQPy, consists of a frontend$\\unicode{x2015}$a Python variant with constructs that make it easy for users to express video objects and their interactions$\\unicode{x2015}$as well as an extensible backend that can automatically construct and optimize pipelines based on video objects. We have implemented and open-sourced VQPy, which has been productized in Cisco as part of its DeepVision framework.","creator":"Shan Yu, Zhenting Zhu, Yu Chen, Hanchen Xu, Pengzhan Zhao, Yang Wang, Arthi Padmanabhan, Hugo Latapie, Harry Xu"},{"id":"2311.01753","slug":"riskq-risk-sensitive-multi-agent-reinforcement-learning-value-factorization","title":"RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value Factorization","link":"https://arxiv.org/abs/2311.01753","abstract":"arXiv:2311.01753v2 Announce Type: replace-cross  Abstract: Multi-agent systems are characterized by environmental uncertainty, varying policies of agents, and partial observability, which result in significant risks. In the context of Multi-Agent Reinforcement Learning (MARL), learning coordinated and decentralized policies that are sensitive to risk is challenging. To formulate the coordination requirements in risk-sensitive MARL, we introduce the Risk-sensitive Individual-Global-Max (RIGM) principle as a generalization of the Individual-Global-Max (IGM) and Distributional IGM (DIGM) principles. This principle requires that the collection of risk-sensitive action selections of each agent should be equivalent to the risk-sensitive action selection of the central policy. Current MARL value factorization methods do not satisfy the RIGM principle for common risk metrics such as the Value at Risk (VaR) metric or distorted risk measurements. Therefore, we propose RiskQ to address this limitation, which models the joint return distribution by modeling quantiles of it as weighted quantile mixtures of per-agent return distribution utilities. RiskQ satisfies the RIGM principle for the VaR and distorted risk metrics. We show that RiskQ can obtain promising performance through extensive experiments. The source code of RiskQ is available in https://github.com/xmu-rl-3dv/RiskQ.","creator":"Siqi Shen, Chennan Ma, Chao Li, Weiquan Liu, Yongquan Fu, Songzhu Mei, Xinwang Liu, Cheng Wang"},{"id":"2311.10678","slug":"distilling-and-retrieving-generalizable-knowledge-for-robot-manipulation-via-language-corrections","title":"Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections","link":"https://arxiv.org/abs/2311.10678","abstract":"arXiv:2311.10678v2 Announce Type: replace-cross  Abstract: Today's robot policies exhibit subpar performance when faced with the challenge of generalizing to novel environments. Human corrective feedback is a crucial form of guidance to enable such generalization. However, adapting to and learning from online human corrections is a non-trivial endeavor: not only do robots need to remember human feedback over time to retrieve the right information in new settings and reduce the intervention rate, but also they would need to be able to respond to feedback that can be arbitrary corrections about high-level human preferences to low-level adjustments to skill parameters. In this work, we present Distillation and Retrieval of Online Corrections (DROC), a large language model (LLM)-based system that can respond to arbitrary forms of language feedback, distill generalizable knowledge from corrections, and retrieve relevant past experiences based on textual and visual similarity for improving performance in novel settings. DROC is able to respond to a sequence of online language corrections that address failures in both high-level task plans and low-level skill primitives. We demonstrate that DROC effectively distills the relevant information from the sequence of online corrections in a knowledge base and retrieves that knowledge in settings with new task or object instances. DROC outperforms other techniques that directly generate robot code via LLMs by using only half of the total number of corrections needed in the first round and requires little to no corrections after two iterations. We show further results, videos, prompts and code on https://sites.google.com/stanford.edu/droc .","creator":"Lihan Zha, Yuchen Cui, Li-Heng Lin, Minae Kwon, Montserrat Gonzalez Arenas, Andy Zeng, Fei Xia, Dorsa Sadigh"},{"id":"2311.14758","slug":"point2rbox-combine-knowledge-from-synthetic-visual-patterns-for-end-to-end-oriented-object-detection-with-single-point-supervision","title":"Point2RBox: Combine Knowledge from Synthetic Visual Patterns for End-to-end Oriented Object Detection with Single Point Supervision","link":"https://arxiv.org/abs/2311.14758","abstract":"arXiv:2311.14758v2 Announce Type: replace-cross  Abstract: With the rapidly increasing demand for oriented object detection (OOD), recent research involving weakly-supervised detectors for learning rotated box (RBox) from the horizontal box (HBox) has attracted more and more attention. In this paper, we explore a more challenging yet label-efficient setting, namely single point-supervised OOD, and present our approach called Point2RBox. Specifically, we propose to leverage two principles: 1) Synthetic pattern knowledge combination: By sampling around each labeled point on the image, we spread the object feature to synthetic visual patterns with known boxes to provide the knowledge for box regression. 2) Transform self-supervision: With a transformed input image (e.g. scaled/rotated), the output RBoxes are trained to follow the same transformation so that the network can perceive the relative size/rotation between objects. The detector is further enhanced by a few devised techniques to cope with peripheral issues, e.g. the anchor/layer assignment as the size of the object is not available in our point supervision setting. To our best knowledge, Point2RBox is the first end-to-end solution for point-supervised OOD. In particular, our method uses a lightweight paradigm, yet it achieves a competitive performance among point-supervised alternatives, 41.05%/27.62%/80.01% on DOTA/DIOR/HRSC datasets.","creator":"Yi Yu, Xue Yang, Qingyun Li, Feipeng Da, Jifeng Dai, Yu Qiao, Junchi Yan"},{"id":"2311.15619","slug":"align-before-adapt-leveraging-entity-to-region-alignments-for-generalizable-video-action-recognition","title":"Align before Adapt: Leveraging Entity-to-Region Alignments for Generalizable Video Action Recognition","link":"https://arxiv.org/abs/2311.15619","abstract":"arXiv:2311.15619v3 Announce Type: replace-cross  Abstract: Large-scale visual-language pre-trained models have achieved significant success in various video tasks. However, most existing methods follow an \"adapt then align\" paradigm, which adapts pre-trained image encoders to model video-level representations and utilizes one-hot or text embedding of the action labels for supervision. This paradigm overlooks the challenge of mapping from static images to complicated activity concepts. In this paper, we propose a novel \"Align before Adapt\" (ALT) paradigm. Prior to adapting to video representation learning, we exploit the entity-to-region alignments for each frame. The alignments are fulfilled by matching the region-aware image embeddings to an offline-constructed text corpus. With the aligned entities, we feed their text embeddings to a transformer-based video adapter as the queries, which can help extract the semantics of the most important entities from a video to a vector. This paradigm reuses the visual-language alignment of VLP during adaptation and tries to explain an action by the underlying entities. This helps understand actions by bridging the gap with complex activity semantics, particularly when facing unfamiliar or unseen categories. ALT demonstrates competitive performance while maintaining remarkably low computational costs. In fully supervised experiments, it achieves 88.1% top-1 accuracy on Kinetics-400 with only 4947 GFLOPs. Moreover, ALT outperforms the previous state-of-the-art methods in both zero-shot and few-shot experiments, emphasizing its superior generalizability across various learning scenarios.","creator":"Yifei Chen, Dapeng Chen, Ruijin Liu, Sai Zhou, Wenyuan Xue, Wei Peng"},{"id":"2311.15876","slug":"lmm-assisted-breast-cancer-treatment-target-segmentation-with-consistency-embedding","title":"LMM-Assisted Breast Cancer Treatment Target Segmentation with Consistency Embedding","link":"https://arxiv.org/abs/2311.15876","abstract":"arXiv:2311.15876v2 Announce Type: replace-cross  Abstract: Recent advancements in Artificial Intelligence (AI) have profoundly influenced medical fields, by providing tools to reduce clinical workloads. However, most AI models are constrained to execute unimodal tasks, in stark contrast to the comprehensive approaches utilized by medical professionals. To address this, here we present RO-LMM, a multi-purpose large multimodal model (LMM) tailored for the field of radiation oncology. This model covers series of tasks within clinical workflow, adept at clinical report summarization, radiation treatment plan suggestion, and plan-guided target volume segmentation. In particular, to perform consecutive clinical tasks, we further present a novel Consistency Embedding Fine-Tuning (CEFTune) technique, which boosts LMM's robustness to noisy inputs while preserving the capability of handling clean inputs, and transform this concept into LMM-driven segmentation framework as Consistency Embedding Segmentation~(CESEG). Experimental results on multi-centre cohorts demonstrate our RO-LMM's promising performance for multiple clinical tasks with generalization capabilities.","creator":"Kwanyoung Kim, Yujin Oh, Sangjoon Park, Hwa Kyung Byun, Jin Sung Kim, Yong Bae Kim, Jong Chul Ye"},{"id":"2312.02003","slug":"a-survey-on-large-language-model-llm-security-and-privacy-the-good-the-bad-and-the-ugly","title":"A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly","link":"https://arxiv.org/abs/2312.02003","abstract":"arXiv:2312.02003v3 Announce Type: replace-cross  Abstract: Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized natural language understanding and generation. They possess deep language comprehension, human-like text generation capabilities, contextual awareness, and robust problem-solving skills, making them invaluable in various domains (e.g., search engines, customer support, translation). In the meantime, LLMs have also gained traction in the security community, revealing security vulnerabilities and showcasing their potential in security-related tasks. This paper explores the intersection of LLMs with security and privacy. Specifically, we investigate how LLMs positively impact security and privacy, potential risks and threats associated with their use, and inherent vulnerabilities within LLMs. Through a comprehensive literature review, the paper categorizes the papers into \"The Good\" (beneficial LLM applications), \"The Bad\" (offensive applications), and \"The Ugly\" (vulnerabilities of LLMs and their defenses). We have some interesting findings. For example, LLMs have proven to enhance code security (code vulnerability detection) and data privacy (data confidentiality protection), outperforming traditional methods. However, they can also be harnessed for various attacks (particularly user-level attacks) due to their human-like reasoning abilities. We have identified areas that require further research efforts. For example, Research on model and parameter extraction attacks is limited and often theoretical, hindered by LLM parameter scale and confidentiality. Safe instruction tuning, a recent development, requires more exploration. We hope that our work can shed light on the LLMs' potential to both bolster and jeopardize cybersecurity.","creator":"Yifan Yao, Jinhao Duan, Kaidi Xu, Yuanfang Cai, Zhibo Sun, Yue Zhang"},{"id":"2312.02352","slug":"working-backwards-learning-to-place-by-picking","title":"Working Backwards: Learning to Place by Picking","link":"https://arxiv.org/abs/2312.02352","abstract":"arXiv:2312.02352v2 Announce Type: replace-cross  Abstract: We present placing via picking (PvP), a method to autonomously collect real-world demonstrations for a family of placing tasks in which objects must be manipulated to specific contact-constrained locations. With PvP, we approach the collection of robotic object placement demonstrations by reversing the grasping process and exploiting the inherent symmetry of the pick and place problems. Specifically, we obtain placing demonstrations from a set of grasp sequences of objects initially located at their target placement locations. Our system can collect hundreds of demonstrations in contact-constrained environments without human intervention by combining two modules: tactile regrasping and compliant control for grasps. We train a policy directly from visual observations through behavioral cloning, using the autonomously-collected demonstrations. By doing so, the policy can generalize to object placement scenarios outside of the training environment without privileged information (e.g., placing a plate picked up from a table). We validate our approach in home robotic scenarios that include dishwasher loading and table setting. Our approach yields robotic placing policies that outperform policies trained with kinesthetic teaching, both in terms of performance and data efficiency, while requiring no human supervision.","creator":"Oliver Limoyo, Abhisek Konar, Trevor Ablett, Jonathan Kelly, Francois R. Hogan, Gregory Dudek"},{"id":"2312.07214","slug":"exploring-large-language-models-to-facilitate-variable-autonomy-for-human-robot-teaming","title":"Exploring Large Language Models to Facilitate Variable Autonomy for Human-Robot Teaming","link":"https://arxiv.org/abs/2312.07214","abstract":"arXiv:2312.07214v3 Announce Type: replace-cross  Abstract: In a rapidly evolving digital landscape autonomous tools and robots are becoming commonplace. Recognizing the significance of this development, this paper explores the integration of Large Language Models (LLMs) like Generative pre-trained transformer (GPT) into human-robot teaming environments to facilitate variable autonomy through the means of verbal human-robot communication. In this paper, we introduce a novel framework for such a GPT-powered multi-robot testbed environment, based on a Unity Virtual Reality (VR) setting. This system allows users to interact with robot agents through natural language, each powered by individual GPT cores. By means of OpenAI's function calling, we bridge the gap between unstructured natural language input and structure robot actions. A user study with 12 participants explores the effectiveness of GPT-4 and, more importantly, user strategies when being given the opportunity to converse in natural language within a multi-robot environment. Our findings suggest that users may have preconceived expectations on how to converse with robots and seldom try to explore the actual language and cognitive capabilities of their robot collaborators. Still, those users who did explore where able to benefit from a much more natural flow of communication and human-like back-and-forth. We provide a set of lessons learned for future research and technical implementations of similar systems.","creator":"Younes Lakhnati, Max Pascher, Jens Gerken"},{"id":"2312.08977","slug":"weighted-ensemble-models-are-strong-continual-learners","title":"Weighted Ensemble Models Are Strong Continual Learners","link":"https://arxiv.org/abs/2312.08977","abstract":"arXiv:2312.08977v2 Announce Type: replace-cross  Abstract: In this work, we study the problem of continual learning (CL) where the goal is to learn a model on a sequence of tasks, such that the data from the previous tasks becomes unavailable while learning on the current task data. CL is essentially a balancing act between being able to learn on the new task (i.e., plasticity) and maintaining the performance on the previously learned concepts (i.e., stability). Intending to address the stability-plasticity trade-off, we propose to perform weight-ensembling of the model parameters of the previous and current tasks. This weighted-ensembled model, which we call Continual Model Averaging (or CoMA), attains high accuracy on the current task by leveraging plasticity, while not deviating too far from the previous weight configuration, ensuring stability. We also propose an improved variant of CoMA, named Continual Fisher-weighted Model Averaging (or CoFiMA), that selectively weighs each parameter in the weights ensemble by leveraging the Fisher information of the weights of the model. Both variants are conceptually simple, easy to implement, and effective in attaining state-of-the-art performance on several standard CL benchmarks. Code is available at: https://github.com/IemProg/CoFiMA.","creator":"Imad Eddine Marouf, Subhankar Roy, Enzo Tartaglione, St\\'ephane Lathuili\\`ere"},{"id":"2312.12274","slug":"intrinsic-image-diffusion-for-indoor-single-view-material-estimation","title":"Intrinsic Image Diffusion for Indoor Single-view Material Estimation","link":"https://arxiv.org/abs/2312.12274","abstract":"arXiv:2312.12274v2 Announce Type: replace-cross  Abstract: We present Intrinsic Image Diffusion, a generative model for appearance decomposition of indoor scenes. Given a single input view, we sample multiple possible material explanations represented as albedo, roughness, and metallic maps. Appearance decomposition poses a considerable challenge in computer vision due to the inherent ambiguity between lighting and material properties and the lack of real datasets. To address this issue, we advocate for a probabilistic formulation, where instead of attempting to directly predict the true material properties, we employ a conditional generative model to sample from the solution space. Furthermore, we show that utilizing the strong learned prior of recent diffusion models trained on large-scale real-world images can be adapted to material estimation and highly improves the generalization to real images. Our method produces significantly sharper, more consistent, and more detailed materials, outperforming state-of-the-art methods by $1.5dB$ on PSNR and by $45\\%$ better FID score on albedo prediction. We demonstrate the effectiveness of our approach through experiments on both synthetic and real-world datasets.","creator":"Peter Kocsis (Technical University of Munich), Vincent Sitzmann (MIT EECS), Matthias Nie{\\ss}ner (Technical University of Munich)"},{"id":"2312.13927","slug":"on-the-convergence-of-loss-and-uncertainty-based-active-learning-algorithms","title":"On the convergence of loss and uncertainty-based active learning algorithms","link":"https://arxiv.org/abs/2312.13927","abstract":"arXiv:2312.13927v2 Announce Type: replace-cross  Abstract: We consider the convergence rates of loss and uncertainty-based active learning algorithms under various assumptions. Firstly, we establish a set of conditions that ensure convergence rates when applied to linear classifiers and linearly separable datasets. This includes demonstrating convergence rate guarantees for loss-based sampling with various loss functions. Secondly, we introduce a framework that allows us to derive convergence rate bounds for loss-based sampling by leveraging known convergence rate bounds for stochastic gradient descent algorithms. Lastly, we propose a new algorithm that combines point sampling and stochastic Polyak's step size. We establish a condition on the sampling process, ensuring a convergence rate guarantee for this algorithm, particularly in the case of smooth convex loss functions. Our numerical results showcase the efficiency of the proposed algorithm.","creator":"Daniel Haimovich, Dima Karamshuk, Fridolin Linder, Niek Tax, Milan Vojnovic"},{"id":"2401.05584","slug":"fourcastnext-optimizing-fourcastnet-training-for-limited-compute","title":"FourCastNeXt: Optimizing FourCastNet Training for Limited Compute","link":"https://arxiv.org/abs/2401.05584","abstract":"arXiv:2401.05584v2 Announce Type: replace-cross  Abstract: FourCastNeXt is an optimization of FourCastNet - a global machine learning weather forecasting model - that performs with a comparable level of accuracy and can be trained using around 5% of the original FourCastNet computational requirements. This technical report presents strategies for model optimization that maintain similar performance as measured by the root-mean-square error (RMSE) of the modelled variables. By providing a model with very low comparative training costs, FourCastNeXt makes Neural Earth System Modelling much more accessible to researchers looking to conduct training experiments and ablation studies. FourCastNeXt training and inference code are available at https://github.com/nci/FourCastNeXt","creator":"Edison Guo, Maruf Ahmed, Yue Sun, Rui Yang, Harrison Cook, Tennessee Leeuwenburg, Ben Evans"},{"id":"2401.11061","slug":"photobot-reference-guided-interactive-photography-via-natural-language","title":"PhotoBot: Reference-Guided Interactive Photography via Natural Language","link":"https://arxiv.org/abs/2401.11061","abstract":"arXiv:2401.11061v2 Announce Type: replace-cross  Abstract: We introduce PhotoBot, a framework for fully automated photo acquisition based on an interplay between high-level human language guidance and a robot photographer. We propose to communicate photography suggestions to the user via reference images that are selected from a curated gallery. We leverage a visual language model (VLM) and an object detector to characterize the reference images via textual descriptions and then use a large language model (LLM) to retrieve relevant reference images based on a user's language query through text-based reasoning. To correspond the reference image and the observed scene, we exploit pre-trained features from a vision transformer capable of capturing semantic similarity across marked appearance variations. Using these features, we compute pose adjustments for an RGB-D camera by solving a perspective-n-point (PnP) problem. We demonstrate our approach using a manipulator equipped with a wrist camera. Our user studies show that photos taken by PhotoBot are often more aesthetically pleasing than those taken by users themselves, as measured by human feedback. We also show that PhotoBot can generalize to other reference sources such as paintings.","creator":"Oliver Limoyo, Jimmy Li, Dmitriy Rivkin, Jonathan Kelly, Gregory Dudek"},{"id":"2401.11609","slug":"graph-edits-for-counterfactual-explanations-a-comparative-study","title":"Graph Edits for Counterfactual Explanations: A comparative study","link":"https://arxiv.org/abs/2401.11609","abstract":"arXiv:2401.11609v2 Announce Type: replace-cross  Abstract: Counterfactuals have been established as a popular explainability technique which leverages a set of minimal edits to alter the prediction of a classifier. When considering conceptual counterfactuals on images, the edits requested should correspond to salient concepts present in the input data. At the same time, conceptual distances are defined by knowledge graphs, ensuring the optimality of conceptual edits. In this work, we extend previous endeavors on graph edits as counterfactual explanations by conducting a comparative study which encompasses both supervised and unsupervised Graph Neural Network (GNN) approaches. To this end, we pose the following significant research question: should we represent input data as graphs, which is the optimal GNN approach in terms of performance and time efficiency to generate minimal and meaningful counterfactual explanations for black-box image classifiers?","creator":"Angeliki Dimitriou, Nikolaos Chaidos, Maria Lymperaiou, Giorgos Stamou"},{"id":"2401.12258","slug":"emergent-dominance-hierarchies-in-reinforcement-learning-agents","title":"Emergent Dominance Hierarchies in Reinforcement Learning Agents","link":"https://arxiv.org/abs/2401.12258","abstract":"arXiv:2401.12258v5 Announce Type: replace-cross  Abstract: Modern Reinforcement Learning (RL) algorithms are able to outperform humans in a wide variety of tasks. Multi-agent reinforcement learning (MARL) settings present additional challenges, and successful cooperation in mixed-motive groups of agents depends on a delicate balancing act between individual and group objectives. Social conventions and norms, often inspired by human institutions, are used as tools for striking this balance.   In this paper, we examine a fundamental, well-studied social convention that underlies cooperation in both animal and human societies: dominance hierarchies.   We adapt the ethological theory of dominance hierarchies to artificial agents, borrowing the established terminology and definitions with as few amendments as possible. We demonstrate that populations of RL agents, operating without explicit programming or intrinsic rewards, can invent, learn, enforce, and transmit a dominance hierarchy to new populations. The dominance hierarchies that emerge have a similar structure to those studied in chickens, mice, fish, and other species.","creator":"Ram Rachum, Yonatan Nakar, Bill Tomlinson, Nitay Alon, Reuth Mirsky"},{"id":"2402.00823","slug":"slim-skill-learning-with-multiple-critics","title":"SLIM: Skill Learning with Multiple Critics","link":"https://arxiv.org/abs/2402.00823","abstract":"arXiv:2402.00823v2 Announce Type: replace-cross  Abstract: Self-supervised skill learning aims to acquire useful behaviors that leverage the underlying dynamics of the environment. Latent variable models, based on mutual information maximization, have been successful in this task but still struggle in the context of robotic manipulation. As it requires impacting a possibly large set of degrees of freedom composing the environment, mutual information maximization fails alone in producing useful and safe manipulation behaviors. Furthermore, tackling this by augmenting skill discovery rewards with additional rewards through a naive combination might fail to produce desired behaviors. To address this limitation, we introduce SLIM, a multi-critic learning approach for skill discovery with a particular focus on robotic manipulation. Our main insight is that utilizing multiple critics in an actor-critic framework to gracefully combine multiple reward functions leads to a significant improvement in latent-variable skill discovery for robotic manipulation while overcoming possible interference occurring among rewards which hinders convergence to useful skills. Furthermore, in the context of tabletop manipulation, we demonstrate the applicability of our novel skill discovery approach to acquire safe and efficient motor primitives in a hierarchical reinforcement learning fashion and leverage them through planning, significantly surpassing baseline approaches for skill discovery.","creator":"David Emukpere, Bingbing Wu, Julien Perez, Jean-Michel Renders"},{"id":"2402.03049","slug":"easyinstruct-an-easy-to-use-instruction-processing-framework-for-large-language-models","title":"EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models","link":"https://arxiv.org/abs/2402.03049","abstract":"arXiv:2402.03049v3 Announce Type: replace-cross  Abstract: In recent years, instruction tuning has gained increasing attention and emerged as a crucial technique to enhance the capabilities of Large Language Models (LLMs). To construct high-quality instruction datasets, many instruction processing approaches have been proposed, aiming to achieve a delicate balance between data quantity and data quality. Nevertheless, due to inconsistencies that persist among various instruction processing methods, there is no standard open-source instruction processing implementation framework available for the community, which hinders practitioners from further developing and advancing. To facilitate instruction processing research and development, we present EasyInstruct, an easy-to-use instruction processing framework for LLMs, which modularizes instruction generation, selection, and prompting, while also considering their combination and interaction. EasyInstruct is publicly released and actively maintained at https://github.com/zjunlp/EasyInstruct, along with an online demo app and a demo video for quick-start, calling for broader research centered on instruction data and synthetic data.","creator":"Yixin Ou, Ningyu Zhang, Honghao Gui, Ziwen Xu, Shuofei Qiao, Yida Xue, Runnan Fang, Kangwei Liu, Lei Li, Zhen Bi, Guozhou Zheng, Huajun Chen"},{"id":"2402.03848","slug":"anls-a-universal-document-processing-metric-for-generative-large-language-models","title":"ANLS* -- A Universal Document Processing Metric for Generative Large Language Models","link":"https://arxiv.org/abs/2402.03848","abstract":"arXiv:2402.03848v3 Announce Type: replace-cross  Abstract: Traditionally, discriminative models have been the predominant choice for tasks like document classification and information extraction. These models make predictions that fall into a limited number of predefined classes, facilitating a binary true or false evaluation and enabling the direct calculation of metrics such as the F1 score. However, recent advancements in generative large language models (GLLMs) have prompted a shift in the field due to their enhanced zero-shot capabilities, which eliminate the need for a downstream dataset and computationally expensive fine-tuning. However, evaluating GLLMs presents a challenge as the binary true or false evaluation used for discriminative models is not applicable to the predictions made by GLLMs.   This paper introduces a new metric for generative models called ANLS* for evaluating a wide variety of tasks, including information extraction and classification tasks. The ANLS* metric extends existing ANLS metrics as a drop-in-replacement and is still compatible with previously reported ANLS scores. An evaluation of 7 different datasets, 6 different GLLMs and 3 different prompting methods using the ANLS* metric is also provided, demonstrating the importance of the proposed metric.   We also benchmark a novel approach to generate prompts for documents, called SFT, against other prompting techniques such as LATIN. In 27 out of 35 cases, SFT outperforms other techniques and improves the state-of-the-art, sometimes by as much as $18$ percentage points.   Sources are available at https://github.com/deepopinion/anls_star_metric","creator":"David Peer, Philemon Sch\\\"opf, Volckmar Nebendahl, Alexander Rietzler, Sebastian Stabinger"},{"id":"2402.08812","slug":"intelligent-canvas-enabling-design-like-exploratory-visual-data-analysis-with-generative-ai-through-rapid-prototyping-iteration-and-curation","title":"Intelligent Canvas: Enabling Design-Like Exploratory Visual Data Analysis with Generative AI through Rapid Prototyping, Iteration and Curation","link":"https://arxiv.org/abs/2402.08812","abstract":"arXiv:2402.08812v3 Announce Type: replace-cross  Abstract: Complex data analysis inherently seeks unexpected insights through exploratory visual analysis methods, transcending logical, step-by-step processing. However, existing interfaces such as notebooks and dashboards have limitations in exploration and comparison for visual data analysis. Addressing these limitations, we introduce a \"design-like\" intelligent canvas environment integrating generative AI into data analysis, offering rapid prototyping, iteration, and comparative visualization management. Our dual contributions include the integration of generative AI components into a canvas interface, and empirical findings from a user study (N=10) evaluating the effectiveness of the canvas interface.","creator":"Zijian Ding, Joel Chan"},{"id":"2402.16068","slug":"ros-causal-a-ros-based-causal-analysis-framework-for-human-robot-interaction-applications","title":"ROS-Causal: A ROS-based Causal Analysis Framework for Human-Robot Interaction Applications","link":"https://arxiv.org/abs/2402.16068","abstract":"arXiv:2402.16068v3 Announce Type: replace-cross  Abstract: Deploying robots in human-shared spaces requires understanding interactions among nearby agents and objects. Modelling cause-and-effect relations through causal inference aids in predicting human behaviours and anticipating robot interventions. However, a critical challenge arises as existing causal discovery methods currently lack an implementation inside the ROS ecosystem, the standard de facto in robotics, hindering effective utilisation in robotics. To address this gap, this paper introduces ROS-Causal, a ROS-based framework for onboard data collection and causal discovery in human-robot spatial interactions. An ad-hoc simulator, integrated with ROS, illustrates the approach's effectiveness, showcasing the robot onboard generation of causal models during data collection. ROS-Causal is available on GitHub: https://github.com/lcastri/roscausal.git.","creator":"Luca Castri, Gloria Beraldo, Sariah Mghames, Marc Hanheide, Nicola Bellotto"},{"id":"2403.00862","slug":"newsbench-systematic-evaluation-of-llms-for-writing-proficiency-and-safety-adherence-in-chinese-journalistic-editorial-applications","title":"NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications","link":"https://arxiv.org/abs/2403.00862","abstract":"arXiv:2403.00862v2 Announce Type: replace-cross  Abstract: This study presents NewsBench, a novel benchmark framework developed to evaluate the capability of Large Language Models (LLMs) in Chinese Journalistic Writing Proficiency (JWP) and their Safety Adherence (SA), addressing the gap between journalistic ethics and the risks associated with AI utilization. Comprising 1,267 tasks across 5 editorial applications, 7 aspects (including safety and journalistic writing with 4 detailed facets), and spanning 24 news topics domains, NewsBench employs two GPT-4 based automatic evaluation protocols validated by human assessment. Our comprehensive analysis of 10 LLMs highlighted GPT-4 and ERNIE Bot as top performers, yet revealed a relative deficiency in journalistic ethic adherence during creative writing tasks. These findings underscore the need for enhanced ethical guidance in AI-generated journalistic content, marking a step forward in aligning AI capabilities with journalistic standards and safety considerations.","creator":"Miao Li, Ming-Bin Chen, Bo Tang, Shengbin Hou, Pengyu Wang, Haiying Deng, Zhiyu Li, Feiyu Xiong, Keming Mao, Peng Cheng, Yi Luo"},{"id":"2403.02302","slug":"beyond-specialization-assessing-the-capabilities-of-mllms-in-age-and-gender-estimation","title":"Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation","link":"https://arxiv.org/abs/2403.02302","abstract":"arXiv:2403.02302v2 Announce Type: replace-cross  Abstract: Multimodal Large Language Models (MLLMs) have recently gained immense popularity. Powerful commercial models like ChatGPT-4V and Gemini, as well as open-source ones such as LLaVA, are essentially general-purpose models and are applied to solve a wide variety of tasks, including those in computer vision. These neural networks possess such strong general knowledge and reasoning abilities that they have proven capable of working even on tasks for which they were not specifically trained. We compared the capabilities of the most powerful MLLMs to date: ShareGPT4V, ChatGPT, LLaVA-Next in a specialized task of age and gender estimation with our state-of-the-art specialized model, MiVOLO. We also updated MiVOLO and provide details and new metrics in this article. This comparison has yielded some interesting results and insights about the strengths and weaknesses of the participating models. Furthermore, we attempted various ways to fine-tune the ShareGPT4V model for this specific task, aiming to achieve state-of-the-art results in this particular challenge. Although such a model would not be practical in production, as it is incredibly expensive compared to a specialized model like MiVOLO, it could be very useful in some tasks, like data annotation.","creator":"Maksim Kuprashevich, Grigorii Alekseenko, Irina Tolstykh"},{"id":"2403.05020","slug":"is-this-the-real-life-is-this-just-fantasy-the-misleading-success-of-simulating-social-interactions-with-llms","title":"Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs","link":"https://arxiv.org/abs/2403.05020","abstract":"arXiv:2403.05020v2 Announce Type: replace-cross  Abstract: Recent advances in large language models (LLM) have enabled richer social simulations, allowing for the study of various social phenomena with LLM-based agents. However, most work has used an omniscient perspective on these simulations (e.g., single LLM to generate all interlocutors), which is fundamentally at odds with the non-omniscient, information asymmetric interactions that humans have. To examine these differences, we develop an evaluation framework to simulate social interactions with LLMs in various settings (omniscient, non-omniscient). Our experiments show that interlocutors simulated omnisciently are much more successful at accomplishing social goals compared to non-omniscient agents, despite the latter being the more realistic setting. Furthermore, we demonstrate that learning from omniscient simulations improves the apparent naturalness of interactions but scarcely enhances goal achievement in cooperative scenarios. Our findings indicate that addressing information asymmetry remains a fundamental challenge for LLM-based agents.","creator":"Xuhui Zhou, Zhe Su, Tiwalayo Eisape, Hyunwoo Kim, Maarten Sap"},{"id":"2403.06906","slug":"cost-sensitive-learning-to-defer-to-multiple-experts-with-workload-constraints","title":"Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints","link":"https://arxiv.org/abs/2403.06906","abstract":"arXiv:2403.06906v2 Announce Type: replace-cross  Abstract: Learning to defer (L2D) aims to improve human-AI collaboration systems by learning how to defer decisions to humans when they are more likely to be correct than an ML classifier. Existing research in L2D overlooks key aspects of real-world systems that impede its practical adoption, namely: i) neglecting cost-sensitive scenarios, where type 1 and type 2 errors have different costs; ii) requiring concurrent human predictions for every instance of the training dataset and iii) not dealing with human work capacity constraints. To address these issues, we propose the deferral under cost and capacity constraints framework (DeCCaF). DeCCaF is a novel L2D approach, employing supervised learning to model the probability of human error under less restrictive data requirements (only one expert prediction per instance) and using constraint programming to globally minimize the error cost subject to workload limitations. We test DeCCaF in a series of cost-sensitive fraud detection scenarios with different teams of 9 synthetic fraud analysts, with individual work capacity constraints. The results demonstrate that our approach performs significantly better than the baselines in a wide array of scenarios, achieving an average 8.4% reduction in the misclassification cost.","creator":"Jean V. Alves, Diogo Leit\\~ao, S\\'ergio Jesus, Marco O. P. Sampaio, Javier Li\\'ebana, Pedro Saleiro, M\\'ario A. T. Figueiredo, Pedro Bizarro"},{"id":"2403.10882","slug":"optimizing-language-augmentation-for-multilingual-large-language-models-a-case-study-on-korean","title":"Optimizing Language Augmentation for Multilingual Large Language Models: A Case Study on Korean","link":"https://arxiv.org/abs/2403.10882","abstract":"arXiv:2403.10882v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) use pretraining to predict the subsequent word; however, their expansion requires significant computing resources. Numerous big tech companies and research institutes have developed multilingual LLMs (MLLMs) to meet current demands, overlooking less-resourced languages (LRLs). This study proposed three strategies to enhance the performance of LRLs based on the publicly available MLLMs. First, the MLLM vocabularies of LRLs were expanded to enhance expressiveness. Second, bilingual data were used for pretraining to align the high- and less-resourced languages. Third, a high-quality small-scale instruction dataset was constructed and instruction-tuning was performed to augment the LRL. The experiments employed the Llama2 model and Korean was used as the LRL, which was quantitatively evaluated against other developed LLMs across eight tasks. Furthermore, a qualitative assessment was performed based on human evaluation and GPT4. Experimental results showed that our proposed Bllossom model exhibited superior performance in qualitative analyses compared to previously proposed Korean monolingual models.","creator":"ChangSu Choi, Yongbin Jeong, Seoyoon Park, InHo Won, HyeonSeok Lim, SangMin Kim, Yejee Kang, Chanhyuk Yoon, Jaewan Park, Yiseul Lee, HyeJin Lee, Younggyun Hahm, Hansaem Kim, KyungTae Lim"},{"id":"2403.11879","slug":"unimodal-multi-task-fusion-for-emotional-mimicry-prediciton","title":"Unimodal Multi-Task Fusion for Emotional Mimicry Prediciton","link":"https://arxiv.org/abs/2403.11879","abstract":"arXiv:2403.11879v2 Announce Type: replace-cross  Abstract: In this study, we propose a methodology for the Emotional Mimicry Intensity (EMI) Estimation task within the context of the 6th Workshop and Competition on Affective Behavior Analysis in-the-wild. Our approach leverages the Wav2Vec 2.0 framework, pre-trained on a comprehensive podcast dataset, to extract a broad range of audio features encompassing both linguistic and paralinguistic elements. We enhance feature representation through a fusion technique that integrates individual features with a global mean vector, introducing global contextual insights into our analysis. Additionally, we incorporate a pre-trained valence-arousal-dominance (VAD) module from the Wav2Vec 2.0 model. Our fusion employs a Long Short-Term Memory (LSTM) architecture for efficient temporal analysis of audio data. Utilizing only the provided audio data, our approach demonstrates significant improvements over the established baseline.","creator":"Tobias Hallmen, Fabian Deuser, Norbert Oswald, Elisabeth Andr\\'e"},{"id":"2403.12777","slug":"discover-and-mitigate-multiple-biased-subgroups-in-image-classifiers","title":"Discover and Mitigate Multiple Biased Subgroups in Image Classifiers","link":"https://arxiv.org/abs/2403.12777","abstract":"arXiv:2403.12777v2 Announce Type: replace-cross  Abstract: Machine learning models can perform well on in-distribution data but often fail on biased subgroups that are underrepresented in the training data, hindering the robustness of models for reliable applications. Such subgroups are typically unknown due to the absence of subgroup labels. Discovering biased subgroups is the key to understanding models' failure modes and further improving models' robustness. Most previous works of subgroup discovery make an implicit assumption that models only underperform on a single biased subgroup, which does not hold on in-the-wild data where multiple biased subgroups exist.   In this work, we propose Decomposition, Interpretation, and Mitigation (DIM), a novel method to address a more challenging but also more practical problem of discovering multiple biased subgroups in image classifiers. Our approach decomposes the image features into multiple components that represent multiple subgroups. This decomposition is achieved via a bilinear dimension reduction method, Partial Least Square (PLS), guided by useful supervision from the image classifier. We further interpret the semantic meaning of each subgroup component by generating natural language descriptions using vision-language foundation models. Finally, DIM mitigates multiple biased subgroups simultaneously via two strategies, including the data- and model-centric strategies. Extensive experiments on CIFAR-100 and Breeds datasets demonstrate the effectiveness of DIM in discovering and mitigating multiple biased subgroups. Furthermore, DIM uncovers the failure modes of the classifier on Hard ImageNet, showcasing its broader applicability to understanding model bias in image classifiers. The code is available at https://github.com/ZhangAIPI/DIM.","creator":"Zeliang Zhang, Mingqian Feng, Zhiheng Li, Chenliang Xu"},{"id":"2403.12821","slug":"flowerformer-empowering-neural-architecture-encoding-using-a-flow-aware-graph-transformer","title":"FlowerFormer: Empowering Neural Architecture Encoding using a Flow-aware Graph Transformer","link":"https://arxiv.org/abs/2403.12821","abstract":"arXiv:2403.12821v2 Announce Type: replace-cross  Abstract: The success of a specific neural network architecture is closely tied to the dataset and task it tackles; there is no one-size-fits-all solution. Thus, considerable efforts have been made to quickly and accurately estimate the performances of neural architectures, without full training or evaluation, for given tasks and datasets. Neural architecture encoding has played a crucial role in the estimation, and graphbased methods, which treat an architecture as a graph, have shown prominent performance. For enhanced representation learning of neural architectures, we introduce FlowerFormer, a powerful graph transformer that incorporates the information flows within a neural architecture. FlowerFormer consists of two key components: (a) bidirectional asynchronous message passing, inspired by the flows; (b) global attention built on flow-based masking. Our extensive experiments demonstrate the superiority of FlowerFormer over existing neural encoding methods, and its effectiveness extends beyond computer vision models to include graph neural networks and auto speech recognition models. Our code is available at http://github.com/y0ngjaenius/CVPR2024_FLOWERFormer.","creator":"Dongyeong Hwang, Hyunju Kim, Sunwoo Kim, Kijung Shin"},{"id":"2403.13257","slug":"arcee-s-mergekit-a-toolkit-for-merging-large-language-models","title":"Arcee's MergeKit: A Toolkit for Merging Large Language Models","link":"https://arxiv.org/abs/2403.13257","abstract":"arXiv:2403.13257v2 Announce Type: replace-cross  Abstract: The rapid expansion of the open-source language model landscape presents an opportunity to merge the competencies of these model checkpoints by combining their parameters. Advances in transfer learning, the process of fine-tuning pretrained models for specific tasks, has resulted in the development of vast amounts of task-specific models, typically specialized in individual tasks and unable to utilize each other's strengths. Model merging facilitates the creation of multitask models without the need for additional training, offering a promising avenue for enhancing model performance and versatility. By preserving the intrinsic capabilities of the original models, model merging addresses complex challenges in AI - including the difficulties of catastrophic forgetting and multitask learning. To support this expanding area of research, we introduce MergeKit, a comprehensive, open-source library designed to facilitate the application of model merging strategies. MergeKit offers an extensible framework to efficiently merge models on any hardware, providing utility to researchers and practitioners. To date, thousands of models have been merged by the open-source community, leading to the creation of some of the worlds most powerful open-source model checkpoints, as assessed by the Open LLM Leaderboard. The library is accessible at https://github.com/arcee-ai/MergeKit.","creator":"Charles Goddard, Shamane Siriwardhana, Malikeh Ehghaghi, Luke Meyers, Vlad Karpukhin, Brian Benedict, Mark McQuade, Jacob Solawetz"},{"id":"2403.13372","slug":"llamafactory-unified-efficient-fine-tuning-of-100-language-models","title":"LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models","link":"https://arxiv.org/abs/2403.13372","abstract":"arXiv:2403.13372v2 Announce Type: replace-cross  Abstract: Efficient fine-tuning is vital for adapting large language models (LLMs) to downstream tasks. However, it requires non-trivial efforts to implement these methods on different models. We present LlamaFactory, a unified framework that integrates a suite of cutting-edge efficient training methods. It allows users to flexibly customize the fine-tuning of 100+ LLMs without the need for coding through the built-in web UI LlamaBoard. We empirically validate the efficiency and effectiveness of our framework on language modeling and text generation tasks. It has been released at https://github.com/hiyouga/LLaMA-Factory and already received over 13,000 stars and 1,600 forks.","creator":"Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo, Yongqiang Ma"}]},{"name":"Plant Biology","feed":[{"id":"2024.03.19.585643v1","slug":"epigenetic-and-transcriptional-consequences-of-chemically-induced-transposon-mobilization-in-the-endosperm","title":"Epigenetic and transcriptional consequences of chemically induced transposon mobilization in the endosperm","link":"http://biorxiv.org/cgi/content/short/2024.03.19.585643v1?rss=1","abstract":"Genomic imprinting, an epigenetic phenomenon leading to parent-of-origin-specific gene expression, has independently evolved in the endosperm of flowering plants and the placenta of mammals -- tissues crucial for nurturing embryos. While transposable elements (TEs) frequently colocalize with imprinted genes and are implicated in imprinting establishment, direct investigations of the impact of de novo TE transposition on genomic imprinting remain scarce. In this study, we explored the effects of chemically induced transposition of the Copia element ONSEN on genomic imprinting in Arabidopsis thaliana Through the combination of chemical TE mobilization and doubled haploid induction, we generated a line with 40 new ONSEN copies. Our findings reveal a preferential targeting of maternally expressed genes (MEGs) for transposition, aligning with the colocalization of H2A.Z and H3K27me3 in MEGs-- both previously identified as promoters of ONSEN insertions. Additionally, we demonstrate that chemically-induced DNA hypomethylation induces global transcriptional deregulation in the endosperm, leading to the breakdown of MEG imprinting. This study provides insights into the consequences of chemically induced TE remobilization in the endosperm, underscoring the need for cautious interpretation of the connection between TEs and genomic imprinting.","creator":"del Toro-de Leon, G., van Boven, J., Santos-Gonzalez, J., Jiao, W.-B., Schneeberger, K., Köhler, C."},{"id":"2024.03.19.585220v1","slug":"exploring-the-role-of-cultivar-year-and-plot-age-in-the-incidence-of-grapevine-trunk-diseases-insights-from-20-years-of-regional-surveys-in-france","title":"Exploring the role of cultivar, year and plot age in the incidence of grapevine trunk diseases: insights from 20 years of regional surveys in France","link":"http://biorxiv.org/cgi/content/short/2024.03.19.585220v1?rss=1","abstract":"Grapevine trunk diseases cause yield losses and vine mortality in vineyards worldwide. However, there have been few quantitative studies evaluating grapevine dieback on a large spatial and temporal scale. Here, we consolidated and standardised databases from the 13 main wine regions of France, compiling records of foliar symptoms associated with esca and Eutypa dieback from 2082 plots and 36 cultivars over a 20-year period. This large dataset was used (1) for quantitative analysis of the prevalence (number of plots with at least one symptomatic plant) and incidence (percentage of symptomatic plants) of esca and Eutypa dieback; (2) to decipher the effects of cultivar, year and plot age on both the prevalence and incidence of esca leaf symptoms by temporal Bayesian modelling. Esca was present on a mean of 74 +/- 2% plots annually, with an incidence of 3.1 +/- 0.1%. Eutypa dieback occurred in 41 +/- 3% of the plots, with an incidence of 1.4 +/- 0.1%. Our modelling approach revealed that the cultivar had a significant impact on the prevalence of esca, but not on its incidence when prevalence is greater than zero. Esca prevalence remained stable, whereas esca incidence was higher than the mean value in six of the years after 2012. We also found a significant non-linear effect of plot age, 10- to 30-year-old plots significantly more susceptible, depending on the cultivar. This study clearly illustrates the importance of considering extensive and continuous monitoring to improve our understanding of the impact and evolution of crop diseases.","creator":"Etienne, L., Fabre, F., Martinetti, D., Frank, E., Michel, L., Bonnardot, V., Guerin Dubrana, L., Delmas, C. E. L."},{"id":"2024.03.18.585502v1","slug":"identifying-leaf-anatomy-and-metabolic-regulators-that-underpin-c4-photosynthesis-in-alloteropsis-semialata","title":"Identifying leaf anatomy and metabolic regulators that underpin C4 photosynthesis in \tAlloteropsis semialata","link":"http://biorxiv.org/cgi/content/short/2024.03.18.585502v1?rss=1","abstract":"C4 photosynthesis is a complex trait requiring multiple developmental and metabolic alterations. Despite this complexity, it has independently evolved over 60 times. However, our understanding of the transition to C4 is complicated by the fact that variation in photosynthetic type is usually segregated between species. Here, we perform a genome wide association study (GWAS) using the grass Alloteropsis semialata, the only known species to have C3, intermediate, and C4 accessions. We aimed to identify genomic regions associated with the strength of the C4 cycle (measured using {delta}13C), and the development of C4 leaf anatomy. Genomic regions correlated with {delta}13C include regulators of C4 decarboxylation enzymes (RIPK), non-photochemical quenching (SOQ1), and the development of Kranz anatomy (SCARECROW-LIKE). Regions associated with the development of C4 leaf anatomy in the intermediate accessions contain additional leaf anatomy regulators, including those responsible for vein patterning (GSL8) and meristem determinacy (GRF1). The detection of highly correlated genomic regions with a modest sample size indicates that the emergence of C4 photosynthesis in A. semialata required a few loci of large effect. The candidate genes could prove to be relevant for engineering C4 leaf anatomy in C3 species.","creator":"Alenazi, A. S., Pereira, L., Christin, P.-A., Osborne, C. P., Dunning, L. T."},{"id":"2024.03.18.585622v1","slug":"molecular-phylogeny-and-cryptic-morphology-a-combined-approach-to-taxonomic-novelties-in-polycarpaea-caryophyllaceae-from-vietnam","title":"Molecular Phylogeny and Cryptic Morphology: A Combined Approach to Taxonomic Novelties in Polycarpaea (Caryophyllaceae) from Vietnam","link":"http://biorxiv.org/cgi/content/short/2024.03.18.585622v1?rss=1","abstract":"Three new species of Polycarpaea from Vietnam, P. vanana, P. chungana, P. duongana are described and illustrated based on evidence of molecular sequence data from two markers (ITS1-5.8S-ITS2 and rps16) and combined morphological characteristics. Polycarpaea vanana is closely related to Polycarpaea gaudichaudi, P. arenaria, P. duongana but differs by its stem glabrous, leaf ovate to elliptic, glabrous, ovary oblong ovoid, base obtuse, apex attenuate, capsule oblong void, 3.8 mm long. P. duongana differs from the three species mentioned above by its stem being densely villous, leaf spathulate, ciliate, ovary ovoid, base acute, apex obtuse, capsule ovoid, 1.2 mm long. Polycarpaea chungana is most similar to P. lignosa but differs in having leaf oblong or linear, sparse ciliate, sepal and petal apex deeply concaved or slightly bifid, ovary ovoid, ovoid, 0.8-1.0 mm long. Furthermore, the achievements of analysis using molecular data on the systematic positions of 7 other species are results that have not been in previous molecular analyses.","creator":"Tran, T. V., Hoang, T. T., Le, L. B., Le, N. T. K., Nguyen, M. T. A., Truong, A. T. L., Tran, N. T., Tran, V. T., Le, S. V., Duong, K. T., Hoang, K. V. B., Le, T. N., Nguyen, B. V."},{"id":"2024.03.18.585636v1","slug":"manipulating-plant-development-by-editing-histone-methylation-with-the-dcas9-tool-the-cuc3-boundary-gene-as-a-case-study","title":"Manipulating plant development by editing histone methylation with the dCas9 tool: the CUC3 boundary gene as a case study","link":"http://biorxiv.org/cgi/content/short/2024.03.18.585636v1?rss=1","abstract":"Chromatin modifications are deemed to associate with gene expression patterns, yet their causal function on transcription and cell fate remains unestablished. Here, we demonstrate the direct impact of an epigenome editing tool designed to remove a key chromatin modification at a precise locus in living plants, with outcomes from the molecular to the developmental scale. The manipulated mark, H3K27me3, deposited at Lysine 27 of Histone 3 by the methyltransferase Polycomb PRC2 complex, is associated with the repression of developmental genes. As a new approach to investigate this histone mark genuine function, we used a dCas9-derived tool to bring a specific demethylase function at the CUP SHAPED COTYLEDON 3 (CUC3) organ frontier gene, aiming to remove the trimethyl mark at H3K27. We show that the removal of H3K27me3 at the locus causally induces activation of CUC3 expression within its regular territory, as well as ectopically. Our precise perturbation strategy reveals that alterations in a chromatin mark lead to changes in transcription and developmental gene expression patterning, with sharp consequences on plant morphogenesis and growth. Our work thus constitutes a proof of concept for the effective use of epigenome editing tools in unveiling the causal role of mark dynamics, supported by both molecular and developmental evidences.","creator":"Fal, K., Le Masson, M., Berr, A., CARLES, C. C."},{"id":"2024.03.18.585645v1","slug":"seaweed-amino-acid-and-l-amino-acid-improve-coriander-growth","title":"Seaweed Amino Acid and L-Amino Acid Improve Coriander Growth","link":"http://biorxiv.org/cgi/content/short/2024.03.18.585645v1?rss=1","abstract":"This study investigates the impact of Seaweed amino acid (SG) and L-amino acid (LG) treatments on the growth and root development of coriander plants compared to a control group (CG). The results from Figure 1 illustrate a significant increase in biomass and foliage density for the SG and LG groups, suggesting an enhanced nutritional uptake resulting from these amino acid treatments. Both SG and LG treatments produced more vigorous growth and higher plant height compared to the CG, which received only water. Additionally, a closer inspection of coriander root systems in Figure 2 reveals an improvement in root biomass and architecture, indicating that both SG and LG applications contribute positively to root development, potentially enhancing plant resilience and yield. While both treatments showed comparable effects on root morphology, further research is required to determine if one has superior longterm benefits over the other. The findings point towards the efficacy of using amino acid treatments as bio-stimulants in agricultural practices to improve crop yield, especially in challenging growth conditions such as those found in Guangzhou, China","creator":"Chen, X., Shang, Z., Chen, H., Wan, S."},{"id":"2024.03.18.585510v1","slug":"strong-heterologous-electron-sink-outcompetes-alternative-electron-transport-pathways-in-photosynthesis","title":"Strong heterologous electron sink outcompetes alternative electron transport pathways in photosynthesis","link":"http://biorxiv.org/cgi/content/short/2024.03.18.585510v1?rss=1","abstract":"Improvement of photosynthesis requires a thorough understanding of electron partitioning under both natural and strong electron sink conditions. We applied a wide array of state-of-the-art biophysical and biochemical techniques to thoroughly investigate the fate of photosynthetic electrons in the engineered cyanobacterium Synechocystis sp. PCC 6803, a blueprint for photosynthetic biotechnology, expressing the heterologous gene for ene-reductase, YqjM. This recombinant enzyme catalyses the reduction of an exogenously added substrate into the desired product by utilising photosynthetically produced NAD(P)H, enabling whole-cell biotransformation. Through coupling the biotransformation reaction with biophysical measurements, we demonstrated that the strong artificial electron sink, outcompetes the natural electron valves, the flavodiiron protein-driven Mehler-like reaction, and cyclic electron transport. These results show that ferredoxin-NAD(P)H-oxidoreductase (FNR) is the preferred route for delivering photosynthetic electrons from reduced ferredoxin and the cellular NADPH/NADP+ ratio as a key factor in orchestrating photosynthetic electron flux. These insights are crucial for understanding molecular mechanisms of photosynthetic electron transport and harnessing photosynthesis for sustainable bioproduction by engineering the cellular source/sink balance. Furthermore, we conclude that identifying the bioenergetic bottleneck of a heterologous electron sink is a crucial prerequisite for targeted engineering of photosynthetic biotransformation platforms.","creator":"Hubacek, M., Wey, L. T., Kourist, R., Malihan-Yap, L., Nikkanen, L., Allahverdiyeva, Y."},{"id":"2024.03.18.585484v1","slug":"investigating-the-interactions-of-the-cucumber-mosaic-virus-2b-protein-with-the-viral-1a-replicase-component-and-the-cellular-rna-silencing-factor-argonaute-1","title":"Investigating the interactions of the cucumber mosaic virus 2b protein with the viral 1a replicase component and the cellular RNA silencing factor Argonaute 1","link":"http://biorxiv.org/cgi/content/short/2024.03.18.585484v1?rss=1","abstract":"The cucumber mosaic virus (CMV) 2b protein is a suppressor of plant defenses and a pathogenicity determinant. Amongst the host targets of the 2b protein is the RNA silencing factor Argonaute 1 (AGO1), which it binds to and inhibits. In Arabidopsis thaliana, if 2b-induced inhibition of AGO1 is too efficient it induces reinforcement of antiviral silencing by AGO2, and triggers increased resistance against aphids, the insect vectors of CMV. These effects would be deleterious to CMV replication and transmission, respectively, but are moderated by the CMV 1a protein by sequestering sufficient 2b protein molecules into P-bodies to prevent excessive inhibition of AGO1. Mutant 2b protein variants were generated and red and green fluorescent protein fusions used to investigate subcellular colocalization with AGO1 and the 1a protein, and the effects of mutations on complex formation with the 1a protein and AGO1 were investigated using bimolecular fluorescence complementation and co-immunoprecipitation assays. Although we found that residues 56-60 influenced the interactions of the 2b protein with the 1a protein and AGO1, it appears unlikely that any single residue or sequence domain is solely responsible. In silico predictions of intrinsic disorder within the 2b protein secondary structure were supported by circular dichroism (CD) but not by nuclear magnetic resonance (NMR) spectroscopy. Intrinsic disorder provides a plausible model to explain the ability of the 2b protein to interact with AGO1, the 1a protein and other factors. However, the reasons for the conflicting conclusions provided by CD and NMR must first be resolved.","creator":"Crawshaw, S., Murphy, A. M., Rowling, P. J. E., Nietlispach, D., Itzhaki, L. S., Carr, J. P."},{"id":"2024.03.18.585633v1","slug":"grapevine-shiraz-disease-associated-viruses-lead-to-significant-yield-losses-by-altering-transcription-of-genes-related-to-defence-responses-and-photosynthesis","title":"Grapevine Shiraz Disease-associated viruses lead to significant yield losses by altering transcription of genes related to defence responses and photosynthesis","link":"http://biorxiv.org/cgi/content/short/2024.03.18.585633v1?rss=1","abstract":"Grapevine Shiraz disease (SD), which is associated with Grapevine Virus A (GVA), is one of the highly destructive diseases affecting Australian and South African vineyards. However, virtually nothing is known about the transcriptional modifications in grapevine phloem tissues induced by SD as well as its impact on vine physiology, yield and fruit composition. In this study, we assessed the physiological parameters of SD-infected Vitis vinifera L. cv. Shiraz vines grown in a commercial vineyard in South Australia over two growing seasons. Viruses present in symptomatic SD-affected and asymptomatic vines were investigated using serological (ELISA) and molecular tests (PCR and Illumina next generation sequencing). SD did not alter plant water status over the growing season, however significantly decreased canopy size, leaf gas exchange, chlorophyll fluorescence, and yield. Differential gene expression analysis revealed significantly higher expression of genes associated with systemic acquired resistance (SAR) and downregulation of defence- and photosynthesis-related genes in phloem tissues of SD vines. This is the first comprehensive report of the physiological and transcriptomic responses of grapevine to SD.","creator":"Nagahatenna, D., Onetto, C. A., Wang, Y. M., Borneman, A. R., Pagay, V. V."},{"id":"2024.03.18.585579v1","slug":"nonexpressor-of-pathogenesis-related-genes-control-huanglongbing-tolerance-by-regulating-immune-balance-in-citrus-plants","title":"NONEXPRESSOR OF PATHOGENESIS-RELATED GENES control Huanglongbing tolerance by regulating immune balance in citrus plants","link":"http://biorxiv.org/cgi/content/short/2024.03.18.585579v1?rss=1","abstract":"Huanglongbing (HLB) is a devastating citrus disease caused by the phloem-resident bacterial pathogen Candidatus liberibacter asiaticus (CLas). CLas infection of susceptible varieties triggers unbalanced immune responses, leading to overaccumulation of callose and reactive oxygen species (ROS), which in turn causes phloem plugging and HLB symptom development. Interestingly, some citrus relatives exhibit little or no symptoms in the presence of CLas, a phenomenon termed HLB tolerance. Moreover, overexpression of the Arabidopsis thaliana NPR1 (AtNPR1) gene in susceptible varieties has been shown to confer robust HLB tolerance. However, the mechanisms underlying HLB tolerance remain enigmatic. Here, we show that overexpression of AtNPR1 suppresses CLas- and Pseudomonas syringae pv. maculicola ES4326 (Psm)-induced overaccumulation of callose and ROS in citrus and Arabidopsis, respectively. Importantly, we found that knocking out of the Arabidopsis negative immune regulators, AtNPR3 and AtNPR4, and silencing of their Citrus sinensis ortholog CsNPR3, similarly suppress Psm- and CLas-induced callose and ROS overaccumulation, respectively, and that silencing of CsNPR3 also enhances HLB tolerance. These results reveal a conserved role of the NPR1/NPR3/NPR4-mediated signaling pathway in regulating plant immune balances and provide mechanistic support for overexpression of AtNPR1 or silencing of AtNPR3/AtNPR4 orthologs in citrus as a long-term solution to the HLB disease.","creator":"Sarkar, P., El-Mohtar, C., Turner, D., Welker, S., Robertson, C. J., Orbovic, V., Mou, Z., Levy, A."},{"id":"2024.03.14.585081v1","slug":"chloroplastic-ascorbate-acts-as-a-regulatory-hub-in-plant-metabolism-regardless-of-oxidative-stress","title":"Chloroplastic ascorbate acts as a regulatory hub in plant metabolism regardless of oxidative stress","link":"http://biorxiv.org/cgi/content/short/2024.03.14.585081v1?rss=1","abstract":"Ascorbate is a major plant metabolite that plays crucial roles in various processes, from reactive oxygen scavenging to epigenetic regulation. However, to what extent and how ascorbate modulates metabolism is largely unknown. To address this, we investigated the consequences of chloroplastic and total cellular ascorbate-deficiencies by studying chloroplastic ascorbate-transporter pht4;4 mutant lines, and the ascorbate-deficient vtc2-4 mutant of Arabidopsis thaliana. Under regular growth conditions, both ascorbate-deficiencies caused minor alterations in photosynthesis, with no apparent signs of oxidative damage. In contrast, metabolomics analysis revealed a global and largely overlapping metabolome rewiring in both ascorbate-deficiencies, suggesting that chloroplastic ascorbate modulates plant metabolism. We observed significant alterations in amino acid metabolism, particularly in arginine metabolism, activation of nucleotide salvage pathways, and changes in secondary metabolism. In addition, proteome-wide analysis of thermostability revealed that ascorbate may interact with enzymes involved in arginine metabolism, the Calvin-Benson cycle, and several photosynthetic electron transport components. Overall, our results suggest that, independently of oxidative stress, chloroplastic ascorbate interconnects and coordinates diverse metabolic pathways in vascular plants and thus acts as a regulatory hub.","creator":"Toth, D., Tengolics, R., Aarabi, F., Karlsson, A., Vidal-Meireles, A., Kovacs, L., Kuntam, S., Kormoczi, T., Fernie, A. R., Hudson, E., Papp, B., Toth, S. Z."},{"id":"2024.03.18.585456v1","slug":"discovery-of-active-mouse-plant-and-fungal-cytochrome-p450s-in-endogenous-proteomes-and-upon-expression-in-planta","title":"Discovery of active mouse, plant and fungal cytochrome P450s in endogenous proteomes and upon expression in planta.","link":"http://biorxiv.org/cgi/content/short/2024.03.18.585456v1?rss=1","abstract":"Eukaryotes produce a large number of cytochrome P450s that mediate the synthesis and degradation of diverse endogenous and exogenous metabolites. Yet, most of these P450s are uncharacterized and global tools to study these challenging, membrane-resident enzymes remain to be exploited. Here, we applied activity profiling of plant, mouse and fungal P450s with chemical probes that become reactive when oxidized by P450 enzymes. Identification by mass spectrometry revealed labeling of a wide range of active P450s, including six plant P450s, 40 mouse P450s and 13 P450s of the fungal wheat pathogen Zymoseptoria tritici. We next used transient expression of GFP-tagged P450s by agroinfiltration to show ER-targeting and NADPH-dependent, activity-based labeling of plant, mouse and fungal P450s. Both global profiling and transient expression can be used to detect a broad range of active P450s to study e.g. their regulation and discover selective inhibitors.","creator":"Font Farre, M., Brown, D., Toth, R., Mahadevan, C., Brazier-Hicks, M., Morimoto, K., Kaschani, F., Sinclair, J., Dale, R., Hall, S., Morris, M., Kaiser, M., Wright, A. T., Burton, J., van der Hoorn, R. A. L."},{"id":"2024.03.17.585425v1","slug":"high-resolution-mapping-of-novel-non-transgressive-hybrid-susceptibility-in-barley-exploited-by-p-teres-f-maculata-maps-to-a-single-pentatricopeptide-repeat-containing-protein","title":"High resolution mapping of novel non-transgressive hybrid susceptibility in barley exploited by P. teres f. maculata maps to a single pentatricopeptide repeat-containing protein","link":"http://biorxiv.org/cgi/content/short/2024.03.17.585425v1?rss=1","abstract":"Hybrid genotypes can provide significant yield gains over conventional inbred varieties due to heterosis or hybrid vigor. However, hybrids can also display unintended negative attributes or phenotypes such as extreme pathogen susceptibility. The necrotrophic pathogen Pyrenophora teres f. maculata (Ptm) causes spot form net blotch, which has caused significant losses to barley worldwide. Here, we report on a non-transgressive hybrid susceptibility locus in barley initially recognized because the three parental lines CI5791, Tifang and Golden Promise are resistant to Ptm isolate 13IM.3, however F2 progeny from CI5791 x Tifang and CI5791 x Golden Promise crosses exhibited extreme susceptibility. The susceptible phenotype segregated in a ratio of 1 resistant:1 susceptible representing a genetic segregation ratio of 1 parental (res):2 heterozygous (sus):1 parental (res) suggesting a single hybrid susceptibility locus. Genetic mapping using a total of 715 CI5791 x Tifang F2 individuals (1430 recombinant gametes) and 149 targeted SNPs delimited the hybrid susceptibility locus designated Susceptibility to Pyrenophora teres 2 (Spt2) to an [~]198 kb region on chromosome 5H of the Morex V3 reference assembly. This single locus was independently mapped with 83 CI5791 x Golden Promise F2 individuals (166 recombinant gametes) and 180 genome wide SNPs that colocalized to the same Spt2 locus. The CI5791 genome was sequenced using PacBio Continuous Long Read technology and comparative analysis between CI5791 and the publicly available Golden Promise genome assembly determined that the delimited region contained a single high confidence Spt2 candidate gene predicted to encode a pentatricopeptide repeat-containing protein.","creator":"Clare, S. J., Alhashel, A. F., Li, M., Effertz, K. M., Poudel, R. S., Zhang, J., Brueggeman, R. S."},{"id":"2024.03.17.585399v1","slug":"effects-of-arbuscular-mycorrhizal-fungi-on-nitrogen-uptake-in-cotton-gossypium-hirsutum-l-under-low-nitrogen-conditions","title":"Effects of arbuscular mycorrhizal fungi on nitrogen uptake in cotton (Gossypium hirsutum L.) under low-nitrogen conditions","link":"http://biorxiv.org/cgi/content/short/2024.03.17.585399v1?rss=1","abstract":"SummaryO_LICotton is an important global cash crop whose yield and quality are highly influenced by soil nitrogen. Therefore, examining the interactions between roots and arbuscular mycorrhizal fungi (AMF) under reduced nitrogen conditions is of great significance. C_LIO_LIWe investigated the effects of nitrogen application (0, 250, and 375 kg{middle dot} hm-2) on the AMF infection rate of cotton, the nitrogen content of each organ, root morphological characteristics and biomass, soil extracellular enzyme activity, and soil carbon and nitrogen content using a compartmentalized culture system. C_LIO_LIThe contribution of AMF to plant nitrogen was 10.40, 22.72, and 16.67% under high, low, and no nitrogen treatments, respectively. Under low-nitrogen conditions, the symbiosis between AMF and roots increased root surface area, tip number, branch number, mean diameter, and biomass; and increased soil extracellular enzyme activity (protease, NAG, PER, and PPO), the microbial biomass carbon-to-nitrogen ratio, active carbon content, and the soil nitrogen mineralization rate. Soil NO3--N, NH4+-N, and organic nitrogen content decreased, whereas the absorption of NO3--N by AMF hyphae was higher than that of NH4+-N. C_LIO_LIUnder low-nitrogen conditions, AMF promoted the decomposition of soil organic matter and the transformation of soil nitrogen through the action of hyphal microorganisms. C_LI","creator":"Wang, H., wang, y., cheng, X., He, Y., shen, z., zhang, W., pu, x."},{"id":"2024.03.16.585355v1","slug":"the-distribution-of-particulate-organic-matter-in-the-heterogeneous-soil-matrix-balancing-between-aerobic-respiration-and-denitrification","title":"The distribution of particulate organic matter in the heterogeneous soil matrix - balancing between aerobic respiration and denitrification","link":"http://biorxiv.org/cgi/content/short/2024.03.16.585355v1?rss=1","abstract":"Denitrification, a key process in soil nitrogen cycling, occurs predominantly within microbial hotspots, where denitrifiers use nitrate as an alternative electron acceptor. For accurate prediction of dinitrogen (N2) and nitrous oxide (N2O) emissions from denitrification, a precise quantification of these microscale hotspots is required.  Employing a unique combination of X-ray CT imaging, microscale O2 measurements, and 15N labeling, we were able to quantify hotspots of aerobic respiration and denitrification. We analyzed the dynamics of greenhouse gas (GHG) fluxes, soil oxygen supply, and the distribution of particulate organic matter (POM) in intact soil samples from a grassland and a cropland under different moisture conditions. Our findings reveal that both free and occluded particulate organic matter (POM), identified through X-ray CT imaging, contribute to GHG emissions. The occluded POM, i.e. POM at distant locations to air-filled pores, emerged as a primary driver of denitrification within structured soils of both land uses. Thus, the higher denitrification rates in the grassland could be attributed to the higher content of occluded POM. Conversely, despite possessing compacted areas that could favor denitrification, the cropland had only small amounts of occluded POM to stimulate denitrification. This underlines the complex interaction between soil structural heterogeneity, organic carbon supply, and microbial hotspot formation and thus contributes to a better understanding of soil-related GHG emissions.  In summary, our study provides a holistic understanding of soil-borne greenhouse gas emissions and emphasizes the need to refine predictive models for soil denitrification and N2O emissions by incorporating the microscale distribution of POM.","creator":"Lucas, M., Rohe, L., Apelt, B., Stange, C. F., Vogel, H.-J., Well, R., Schlüter, S."},{"id":"2024.03.16.585323v1","slug":"deep-learning-based-genomic-breeding-of-pest-resistant-grapevine","title":"Deep learning based genomic breeding of pest-resistant grapevine","link":"http://biorxiv.org/cgi/content/short/2024.03.16.585323v1?rss=1","abstract":"Crop pests have profoundly deleterious effects on crop yield and food security. However, conventional pest control depends heavily on the utilization of insecticides, which develops strong pesticide resistance and concerns of food safety. Crop and their wild relatives display diverse levels of pest resistance, indicating the feasibility for breeding of pest-resistant crop varieties. In this study, we integrate deep learning (DL)/machine learning (ML) algorithms, plant phenomics and whole genome sequencing (WGS) data to conduct genomic selection (GS) of pest-resistance in grapevine. We employ deep convolutional neural networks (DCNN) to accurately calculate the severity of damage by pests on grape leaves, which achieves a classification accuracy of 95.3% (Visual Geometry Group 16, VGG16, for binary trait) and a correlation coefficient of 0.94 in regression analysis (DCNN with Pest Damage Score, DCNN-PDS, for continuous trait). We apply DL models to predict and integrate phenotype (both binary and continuous) along with WGS data from 231 grape accessions, conducting Genome-Wide Association Studies (GWAS). This analysis detects a total of 69 QTLs, encompassing 139 candidate genes involved in pathways associated with pest resistance, including jasmonic acid (JA), salicylic acid (SA), ethylene, and other related pathways. Furthermore, through the combination with transcriptome data, we identify specific pest-resistant genes, such as ACA12 and CRK3, which play distinct roles in resisting herbivore attacks. Machine learning-based GS demonstrates a high accuracy (95.7%) and a strong correlation (0.90) in predicting the leaf area damaged by pests as binary and continuous traits in grapevine, respectively. In general, our study highlights the power of DL/ML in plant phenomics and GS, facilitating genomic breeding of pest-resistant grapevine.","creator":"Gan, Y., Liu, Z., Zhang, F., Xu, Q., Wang, X., Xue, H., Su, X., Ma, W., Long, Q., Ma, A., Huang, G., Liu, W., Xu, X., Sun, L., Zhang, Y., Liu, Y., Fang, X., Li, C., Yang, X., Wei, P., Fan, X., Zhang, C., Zhang, P., Liu, C., Zhang, Z., Huang, S., Wang, Y., Liu, Z., Zhou, Y."},{"id":"2024.03.15.585278v1","slug":"hairpin-rna-spray-confers-resistance-to-mungbean-yellow-mosaic-india-virus-in-mungbean","title":"Hairpin-RNA Spray Confers Resistance to Mungbean Yellow Mosaic India Virus in Mungbean","link":"http://biorxiv.org/cgi/content/short/2024.03.15.585278v1?rss=1","abstract":"The prevalence of Begomovirus diseases poses a significant threat to legume crops, necessitating the exploration of innovative control measures. This investigation explores the utilization of dsRNA molecules to initiate RNA interference (RNAi) targeting begomovirus, particularly focusing on Mungbean yellow mosaic India virus (MYMIV) and its potential threat to mungbean crops. Given the lack of genetic resistance in commercially available mungbean varieties, the study endeavors to employ RNAi as a strategic method for the effective control of MYMIV. The approach involves the preparation of vectors for the transient expression of three dsRNA targeting multiple overlapping ORFs of MYMIV DNA A through agroinoculation, and the selection of a highly efficient construct for dsRNA expression in bacteria, enabling topical application to mungbean plants in growth chamber experiments. Agroinoculation assays demonstrate effective resistance against MYMIV, as confirmed by reduced symptom severity, limited virus accumulation, and the presence of viral mRNAs. The stability of the prepared dsRNA against nucleases is confirmed, showcasing its ability to enter plant cells, move to non treated trifoliate leaves, and form siRNA when sprayed onto mungbean leaves, as validated by qRT-PCR and northern blotting. Varied combinations of the timing of dsRNA spray and virus infection reveal differential resistance against the virus. Notably, spraying two days before or on the same day as virus exposure emerges as the most suitable time to achieve optimal resistance against virus infection. In light of these findings, the topical application of dsRNAs stands out as a promising and effective strategy for MYMIV control in mungbean crops.","creator":"Dhobale, K. V., Sahoo, L."},{"id":"2024.03.15.585305v1","slug":"transcriptomic-analyses-in-the-gametophyte-ofdryopteris-affinis-apomixis-and-more","title":"Transcriptomic analyses in the gametophyte ofDryopteris affinis: apomixis and more","link":"http://biorxiv.org/cgi/content/short/2024.03.15.585305v1?rss=1","abstract":"The gametophyte of the fern Dryopteris affinis ssp. affinis represents a good model to explore the molecular basis of vegetative and reproductive development, as well as stress responses. Specifically, this fern reproduces asexually by apogamy, a peculiar case of apomixis whereby a sporophyte forms directly from a gametophytic cell without fertilization. Using an RNA-sequencing approach, we have previously annotated more than six thousand transcripts. Here, we selected one hundred of the inferred proteins that seemed particularly interesting for a detailed study of their potential functions, protein-protein interactions, and molecular phylogenies. As expected, a plethora of proteins associated with gametogenesis and embryogenesis in angiosperms, such as FERONIA (FER) and CHROMATING REMODELING 11 (CHR11) were identified, and more than a dozen candidates potentially involved in apomixis, such as ARGONAUTE4 (AGO4), AGO9, and AGO10, BABY BOOM (BBM), FASCIATED STEM4 (FAS4), FERTILIZATION-INDEPENDENT ENDOSPERM (FIE), and MATERNAL EFFECT EMBRYO ARREST29 (MEE29). In addition, proteins involved in the response to biotic and abiotic stresses were widely represented, as shown by the enrichment of heat-shock proteins. Using the String platform, studying interactomes revealed that most of the protein-protein interactions were predicted based on experimental, database, and text mining datasets, with MULTICOPY SUPPRESSOR OF IRA4 (MSI4) showing the highest number of 16 interactions. Lastly, some proteins were studied from a phylogenetic point of view, comparing the alignments with respect to more distantly or closely related plant groups, identifying AGO1 as the evolutionarily most similar to that other ferns and the most distant to the predicted common ancestor. This work sets the stage for future functional characterizations in relation to gametophyte development including apomictic reproduction.","creator":"Ojosnegros, S., Alvarez, J. M., Gagliardini, V., Quintanilla, L. G., Grossniklaus, U., Fernandez, H."},{"id":"2024.03.14.585007v1","slug":"an-optimized-somatic-embryo-transformation-system-assisted-homozygous-edited-rubber-tree-generation-method-mediated-by-crispr-cas9","title":"An optimized somatic embryo transformation system assisted homozygous edited rubber tree generation method mediated by CRISPR/Cas9","link":"http://biorxiv.org/cgi/content/short/2024.03.14.585007v1?rss=1","abstract":"Previously, we have realized the CRISPR/Cas9-RNP and plasmid mediated protoplast transient transformation genome editing in the rubber tree (Hevea brasiliensis), but no gene editing plants were acquired due to the bottleneck of genetic transformation. In present study, antibiotic sensitivity tests against kanamycin, hygromycin and basta were analyzed for embryo screening, the results demonstrated that 10 mg/L hygromycin is the best for transformation. Then Agrobacterium mediated transformation of H. brasiliensis embryos was carried out using a pCAMBIA1300-based CRISPR/Cas9 vector targeting Phytoene desaturase gene (HbPDS). High-throughput sequencing of T0 generation positive embryos which were used as regeneration materials in typical transformation procedure showed that more than 90% T0 edited embryos are chimeric with a 3.2% transformation efficiency. A T0 embryo with 9.8% edited cells was sliced into small pieces for one more cycle embryogenesis to produce T1 generation embryos in order to improve the ratio of homozygous embryos. Subsequently, next-generation sequencing (NGS) demonstrated that 29 out of 33 T1 embryos were edited, nearly 50% of which were found homozygous. At last, besides four chimeric plantlets with partial albino leaves, four plantlets with complete albino phenotype were regenerated from the 29 T1 generation edited embryos, among which one is a homozygous mono-allelic mutant and the other three are homozygous bi-allelic mutants. NGS demonstrated that the threshold for the proportion of edited cells with expected albino phenotype is between 70-85%. Additionally, Tail-PCR indicate that the T-DNA was inserted into different genome positions in the four homozygous edited plantlets, combined with the different genotypes are considered, the four homozygous plantlets can be confirmed as independently derived from single transformed cells. Overall, this is the first edited rubber trees with expected phenotype reported publicly, which shows the potential in genetic improvement of H. brasiliensis by CRISPR/Cas9 gene editing, and subculture of T0 positive transformed somatic embryos into T1 generation is proved to be an effective and necessary procedure to produce homozygous transgenic plantlets. This study presents a significant advancement in transgenic and gene editing for rubber tree.","creator":"Yang, X., Lin, Q., Udayabhanu, J., Hua, Y., Dai, X., Xin, S., Huang, H., Huang, T."},{"id":"2024.03.14.584999v1","slug":"decoding-strawberry-volatile-cultivar-diversity-through-comparative-transcriptome-analysis","title":"Decoding strawberry volatile cultivar diversity through comparative transcriptome analysis","link":"http://biorxiv.org/cgi/content/short/2024.03.14.584999v1?rss=1","abstract":"This study presents a comparative transcriptomic analysis of three commercial strawberry cultivars:  Rociera,  Calderon, and  Victory, aimed at uncovering the molecular basis of their distinct flavor and aroma profiles. Through RNA sequencing, we analyzed the transcriptomic landscape of these varieties, uncovering a notable array of differentially expressed genes (DEGs) between them. Specifically,  Rociera showed a higher count of DEGs compared to  Victory, suggesting significant differences in gene expression related to flavor and aroma between those cultivars. Our further investigations revealed pivotal metabolic pathways-- such as those involving furanones, amino acids, fatty acids, and terpenoids--participating in generating volatile organic compounds in strawberries. These pathways exhibited variety-specific expression patterns, underlining the genetic determinants of each varietys unique sensory characteristics. Gene Ontology (GO) enrichment analysis underscored important pathways like phototropism, sugar-mediated signaling, and terpenoid biosynthesis, highlighting the genetic intricacy that influences strawberry flavor and aroma. Additionally, our study identified 31,677 single nucleotide polymorphisms (SNPs) with a significant impact on genes associated with volatile compound biosynthesis. Notably, SNPs linked to key enzymes such as lipoxygenase 6, omega-6 fatty acid desaturase (FaFAD1), and phenylalanine ammonia-lyase 1 (PAL) were discovered, shedding light on the genetic variations that underlie flavor differences. Therefore, this research advances our comprehension of the genetic elements that impact strawberry fruit flavor and aroma, offering invaluable insights for molecular breeding endeavors focused on enhancing strawberry flavor.","creator":"Passa, K., Tsormpatsidis, E., Ganopoulos, I., Bazakos, C., Papasotiropoulos, V."},{"id":"2024.03.14.585090v1","slug":"postembryonic-developmental-roles-of-the-arabidopsis-keule-gene","title":"Postembryonic developmental roles of the Arabidopsis KEULE gene","link":"http://biorxiv.org/cgi/content/short/2024.03.14.585090v1?rss=1","abstract":"Cytokinesis in plant cells begins with the fusion of vesicles that transport cell wall materials at the center of the cell division plane, where the cell plate forms and expands radially until it fuses with the parental cell wall at the preprophase band. Vesicle fusion is facilitated by trans-SNARE complexes, with assistance from Sec1/Munc18 (SM) proteins. The SNARE protein KNOLLE and the SM protein KEULE are required for membrane fusion at the cell plate. Due to the crucial function of KEULE, all Arabidopsis (Arabidopsis thaliana) keule mutants identified to date are seedling lethal. Here, we identified the Arabidopsis serrata4-1 (sea4-1) and sea4-2 mutants, which carry recessive, hypomorphic alleles of KEULE. Homozygous sea4-1 and sea4-2 plants are viable and fertile but exhibit smaller rosettes and fewer leaves at bolting than the wild type. Their leaves are serrated, small, and undulated, with a complex venation pattern, develop necrotic patches, and undergo premature senescence. We established a likely relationship between these phenotypes and their defects in cytokinesis through reduced cell wall integrity and increased unfolded protein response. These findings shed light on the roles of KEULE in postembryonic development, particularly in the patterning of rosette leaves and leaf margins.","creator":"Ruiz-Bayon, A., Cara-Rodriguez, C., Sarmiento-Manus, R., Munoz-Viana, R., Lozano, F. M., Ponce, M. R., Micol, J. L."},{"id":"2024.03.15.585124v1","slug":"a-bacterial-type-iii-effector-hijacks-plant-ubiquitin-proteases-to-evade-degradation","title":"A bacterial type III effector hijacks plant ubiquitin proteases to evade degradation","link":"http://biorxiv.org/cgi/content/short/2024.03.15.585124v1?rss=1","abstract":"Gram-negative bacterial pathogens inject effector proteins inside plant cells using a type III secretion system. These effectors manipulate plant cellular functions and suppress the plant immune system in order to promote bacterial proliferation. Despite the fact that bacterial effectors are exogenous threatening proteins potentially exposed to the protein degradation systems inside plant cells, effectors are relative stable and able to perform their virulence functions. In this work, we found that RipE1, an effector protein secreted by the bacterial wilt pathogen, Ralstonia solanacearum, undergoes phosphorylation of specific residues inside plant cells, and this promotes its stability. Moreover, RipE1 associates with plant ubiquitin proteases, which contribute to RipE1 deubiquitination and stabilization. The absence of those specific phosphorylation sites or specific host ubiquitin proteases leads to a substantial decrease in RipE1 protein accumulation, indicating that RipE1 hijacks plant post-translational modification regulators in order to promote its own stability. These results suggest that effector stability or degradation in plant cells constitute another molecular event subject to co-evolution between plants and pathogens.","creator":"Yu, W., Li, M., Wang, W., Zhuang, H., Luo, J., Sang, Y., Segonzac, C., Macho, A. P."},{"id":"2024.03.14.585028v1","slug":"graphical-pangenomics-enabled-characterisation-of-structural-variant-impact-on-gene-expression-in-brassica-napus","title":"Graphical pangenomics-enabled characterisation of structural variant impact on gene expression in Brassica napus","link":"http://biorxiv.org/cgi/content/short/2024.03.14.585028v1?rss=1","abstract":"Structural variants (SVs, eg. insertions and deletions) are genomic variations > 50 bp that are known to be associated with a range of crop traits, from yield to flowering behaviour and stress responses. Recently, pangenome graphs have emerged as a powerful framework for analysing genomic data by encoding population- or species-level diversity in one data structure. Pangenome graphs have the potential to serve as unbiased references for downstream applications, including SV genotyping and pan-transcriptomic analyses.  In this work, we hypothesized that extensive variation affects transcript quantification and expression quantitative trait locus (eQTL) analysis when relying on a single reference, and that using pangenome graphs can mitigate reference sequence bias.  We combined long and short read whole genome sequencing data with expression profiling of Brassica napus (oilseed rape) to assess the impact of SVs on gene expression regulation and explored the utility of pangenome graphs for eQTL analysis. We demonstrate that pangenome graphs provides a superior framework for eQTL analysis by eliminating single reference bias in gene expression quantification. Combined with the graph-based genotyping of SVs, we identified 240 eQTL-SVs found in close proximity of target loci. These SVs affect expression of genes related to important traits, are often not in linkage with SNPs and represent diversity unaccounted for in classical SNP-based analyses.  This study highlights the multiple advantages of graph-based approaches in population-scale studies and provides novel insight into gene expression regulation in an important crop.","creator":"Golicz, A. A., Yildiz, G., Weber, S., Kox, T., Abbadi, A., Snowdon, R. J., Zanini, S. F."},{"id":"2024.03.14.584694v1","slug":"the-transcription-factor-atml1-maintains-giant-cell-identity-by-inducing-synthesis-of-its-own-very-long-chain-fatty-acid-containing-ligands","title":"The transcription factor ATML1 maintains giant cell identity by inducing synthesis of its own (very) long-chain fatty acid-containing ligands","link":"http://biorxiv.org/cgi/content/short/2024.03.14.584694v1?rss=1","abstract":"During development, cells not only adopt specialized identities but also maintain those identities. Endoreduplication is thought to maintain cell identity. High concentrations of ARABIDOPSIS THALIANA MERISTEM LAYER1 (ATML1) specify giant cell identity and induce endoreduplication in sepals. How different concentrations of ATML1 can specify different identities remains unclear. Here, we show that high concentrations of ATML1 induce the biosynthesis of both long-chain and very long-chain fatty acids (LCFAs/VLCFAs), and these fatty acids are required for the maintenance of giant cell identity. Inhibition of VLCFA biosynthesis causes endoreduplicated giant cells to resume division and lose their identity, indicating that endoreduplication is not sufficient to maintain cell identity. Structural predictions suggest that LCFA-containing lipids bind to the START domain 2 of ATML1, causing ATML1 dimerization and its auto-activation. Our data and modeling imply that ATML1 induces biosynthesis of its own lipid ligands in a positive feedback loop, shedding light on the intricate network dynamics that specify and maintain giant cell identity.  Teaser: Endoreduplicated cells in Arabidopsis thaliana sepals divide and de-differentiate in the absence of VLCFA biosynthesis.","creator":"Vadde, B. V. L., Russell, N. J., Bagde, S. R., Askey, B., Saint-Antoine, M. M., Brownfield, B. A., Mughal, S., Apprill, L. E., Khosla, A., Clark, F. K., Schwarz, E. M., Alseekh, S., Fernie, A. R., Singh, A., Schrick, K., Fromme, J. C., Skirycz, A., Formosa-Jordan, P., Roeder, A. H. K."},{"id":"2024.03.15.585069v1","slug":"overlapping-roles-of-arabidopsis-incurvata11-and-cupuliformis2-as-polycomb-repressive-complex-2-accessory-proteins","title":"Overlapping roles of Arabidopsis INCURVATA11 and CUPULIFORMIS2 as Polycomb Repressive Complex 2 accessory proteins","link":"http://biorxiv.org/cgi/content/short/2024.03.15.585069v1?rss=1","abstract":"Polycomb Repressive Complex 2 (PRC2) catalyzes the trimethylation of lysine 27 of histone H3 (H3K27me3) and plays a key role in epigenetic repression of gene expression in plants and animals. PRC2 core components have all been identified in Arabidopsis thaliana, with an expanding list of accessory proteins, some of which facilitate the recruitment of PRC2 to specific targets. INCURVATA11 (ICU11) is a 2-oxoglutarate and Fe2+-dependent dioxygenase that was previously shown to be a likely PRC2 accessory protein. In Tandem Affinity Purification (TAP)-based screens for interacting partners of ICU11 and its redundant paralog CUPULIFORMIS2 (CP2), we discovered that ICU11 interacts with four PRC2 core components, including EMBRYONIC FLOWER 2 (EMF2), and with the accessory proteins EMF1, TELOMERE REPEAT BINDING 1 (TRB1), TRB2, and TRB3. CP2 did not interact with PRC2 core components, nor with TRB1, TRB2, or TRB3, but did interact with TRB4 and TRB5. Both ICU11 and CP2 interacted with the nuclear proteins NAC DOMAIN CONTAINING PROTEIN 50 (NAC050), NAC052 and COP9 SIGNALOSOME SUBUNIT 1 (CSN1). Bimolecular Fluorescence Complementation (BiFC) assays revealed that ICU11 and CP2 both interact with the PRC2 core components CURLY LEAF and SWINGER, and the accessory proteins LIKE HETEROCHROMATIN PROTEIN 1, TRB1, and TRB3. ICU11 and CP2 did not interact with each other. Beyond their phenotypes, transcriptomic profiles revealed strong similarities between emf2-3 and the double mutant icu11-5 cp2-1, as well as with mutants in PRC2 core components. A significant proportion of the genes mis-regulated in icu11-5 cp2-1 are known to harbor H3K27me3 repressive marks in the wild type. Our results provide further evidence that ICU11 acts as a PRC2 accessory protein, and strongly suggest that CP2 plays a similar role.","creator":"Nadi, R., Juan-Vicente, L., Lup, S. D., Fernandez, Y., Rubio, V., Micol, J. L."},{"id":"2024.03.13.584811v1","slug":"simultaneous-and-dynamic-super-resolution-imaging-of-two-proteins-in-arabidopsis-thaliana-using-dual-color-sptpalm","title":"Simultaneous and Dynamic Super-Resolution Imaging of Two Proteins in Arabidopsis thaliana using dual-color sptPALM","link":"http://biorxiv.org/cgi/content/short/2024.03.13.584811v1?rss=1","abstract":"Super-resolution microscopy techniques have revolutionized cell biology by providing insights into the dynamics of single molecules and nanoscale organization within living cells. However, the application of dynamic live-cell methods in plants has been limited by the lack of suitable fluorophores for simultaneous visualization of multiple proteins. To address this challenge, we implemented a two-color sptPALM approach using codon-optimized photoactivatable fluorescent proteins PA-GFP and PATagRFP. Recently, we showed their individual usability in single-color experiments in Nicotiana benthamiana and Arabidopsis thaliana cells. Here, we now demonstrate the suitability of these fluorophores and their combined use for dual-color sptPALM for the simultaneous observation of two different protein fusions in the same plant cell.","creator":"Rohr, L., Ehinger, A., Burmeister, N. G., Meixner, A. J., Kemmerling, B., Harter, K., zur Oven-Krockhaus, S."},{"id":"2024.03.13.584916v1","slug":"a-rapid-and-efficient-in-vivo-inoculation-method-for-introducing-tree-stem-canker-pathogens-onto-leaves-suitable-for-large-scale-assessment-of-resistance-in-poplar-breeding-progeny","title":"A rapid and efficient in vivo inoculation method for introducing tree stem canker pathogens onto leaves, suitable for large-scale assessment of resistance in poplar breeding progeny","link":"http://biorxiv.org/cgi/content/short/2024.03.13.584916v1?rss=1","abstract":"Hybrid breeding is the most direct and efficient method of controlling and managing tree diseases. However, \"in vitro stem inoculation\" can not be used for rapid, efficient, and low-cost screening of resistant clones in the early stage of stem canker infection. Therefore, we inoculated stem canker pathogens on poplar leaves to evaluate the resistance of hybrid clones in the poplar-Valsa sordida pathosystem. \"In vivo leaf inoculation\" showed that: 1) V. sordida induces extended necrotic lesions and conidia on leaves. 2) The upper leaves exhibited higher resistance than the middle leaves. 3) The shading conditions induced more severe symptoms on leaves than the lighting conditions. 4) The susceptibility of poplar leaves to juvenile mycelium was higher than old myceliums. 5) The resistance of 48 poplar clones against V. sordida was distributed normally. 6) The efficacy of \"in vivo leaf inoculation\" was consistent with \"in vitro stem inoculation\". In summary, \"in vivo leaf inoculation\" has the advantages of a wide application range, simple operation, short experimental process, and host safety. This method is of great significance for poplar breeding, the study of pathology and molecular biology, pathogenic differentiation, and sporulation of fungal canker pathogens.","creator":"li, z., Zhang, B., Fu, Y., Suo, Y., Zhang, Y., Feng, J., Pan, L., Shen, W., Liu, H., Su, X., Zhao, J."},{"id":"2024.03.12.584584v1","slug":"natural-soil-suppressiveness-against-soilborne-phytopathogens-extends-to-the-control-of-insect-pest","title":"Natural soil suppressiveness against soilborne phytopathogens extends to the control of insect pest","link":"http://biorxiv.org/cgi/content/short/2024.03.12.584584v1?rss=1","abstract":"Since the 1980s, soils in a 22-km2 area near Lake Neuchatel in Switzerland have been recognized for their innate ability to suppress the black root rot plant disease. Their efficacy against insect pests has not been studied. We demonstrate that natural soil suppressiveness also protects plants from the leaf-feeding pest insect Oulema melanopus. Plants grown in the most suppressive soil have a reduced stress response to Oulema feeding, reflected by dampened levels of herbivore defense-related phytohormones and benzoxazinoids, and enhanced salicylate levels in plants without the insect indicate defense-priming. The rhizosphere microbiome network of the suppressive soils was highly tolerant to the destabilizing impact of insect exposure. The presence of plant-beneficial bacteria in the suppressive soils along with priming conferred plant resistance to the insect pest, manifesting also in the onset of insect microbiome dysbiosis. This intricate soil-plant-insect feedback extends natural soil suppressiveness from soilborne diseases to insect pests.","creator":"Harmsen, N., Vesga, P., Glauser, G., Klötzli, F., Heiman, C. M., Altenried, A., Vacheron, J., Muller, D., Moënne-Loccoz, Y., Steinger, T., Keel, C., Garrido-Sanz, D."},{"id":"2024.03.13.584802v1","slug":"unveiling-shared-genetic-regulators-for-plant-architectural-and-biomass-yield-traits-in-sorghum","title":"Unveiling shared genetic regulators for plant architectural and biomass yield traits in sorghum","link":"http://biorxiv.org/cgi/content/short/2024.03.13.584802v1?rss=1","abstract":"Sorghum is emerging as an ideal genetic model for designing high-biomass bioenergy crops. Biomass yield, a complex trait influenced by various plant architectural features, is typically regulated by numerous genes. This study aims to dissect the genetic mechanisms underlying fourteen plant architectural and ten biomass yield traits in a sorghum association panel (SAP) across two growing seasons. We identified 321 associated loci via genome-wide association studies involving 234,264 single nucleotide polymorphisms (SNPs). These loci encompass both genes with a priori links to biomass traits, such as  maturity,  dwarfing (Dw),  leafbladeless1,  cryptochrome, and several loci not previously linked to roles in determining these traits. We identified 22 pleiotropic loci associated with variation in multiple phenotypes. Three of these loci, located on chromosomes 3 (S03_15463061), 6 (S06_42790178; Dw2), and 9 (S09_57005346; Dw1), exert significant and consistent effects on multiple traits. Additionally, we identified three genomic hotspots on chromosomes 6, 7, and 9, containing multiple SNPs associated with variation in plant architecture and biomass yield traits. Positive correlations were observed among linked SNPs close to or within the same genomic regions. Thirteen haplotypes were identified from these positively correlated SNPs on chr 6, with haplotypes 8 and 11 emerging as optimal combinations, exhibiting pronounced effects on the traits. Lastly, network analysis revealed that loci associated with flowering, plant heights, leaf characteristics, plant number, and tiller number per plant were highly interconnected with other genetic loci linked to plant architecture and biomass yield traits. The pyramiding of favorable alleles related to these traits holds promise for enhancing the future development of bioenergy sorghum crops.","creator":"Singh, A., Newton, L. A., Schnable, J. C., Thompson, A. M."},{"id":"2024.03.13.584774v1","slug":"viewing-stomata-in-action-autonomous-in-planta-imaging-of-individual-stomatal-movement-links-morphology-and-kinetics","title":"Viewing stomata in action: Autonomous in planta imaging of individual stomatal movement links morphology and kinetics","link":"http://biorxiv.org/cgi/content/short/2024.03.13.584774v1?rss=1","abstract":"Stomata regulate plant gas exchange with the environment, balancing between water loss and CO2 uptake. Gas exchange dynamics are influenced by traits such as stomatal morphology, size and density, which are commonly investigated using imprints and manual microscopy, methods that are destructive and time consuming. Moreover, these microscopic properties are statically sampled and related to the dynamic ensemble behavior: gas exchange of an entire plant or part of a leaf. Knowledge on how morphology, size and density of stomata influence the movement of individual stomata is limited. We developed a compact microscope system that can measure the kinetics of tens of stomata in vivo simultaneously, with sub-minute time resolution. The system can be deployed in the plants growth environment, at minimal impact on leaf microclimate. The characteristics of our microscope and data analyses are described, and we demonstrate its capabilities on Chrysanthemum morifolium with novel insight into individual stomatas contribution to water-use efficiency.","creator":"van den Berg, T. E., Sanders, R. G. P., Kaiser, E., Schmitz, J."}]},{"name":"Economics","feed":[{"id":"2403.13983","slug":"robust-communication-between-parties-with-nearly-independent-preferences","title":"Robust Communication Between Parties with Nearly Independent Preferences","link":"https://arxiv.org/abs/2403.13983","abstract":"Abstract: We study finite-state communication games in which the sender's preference is perturbed by random private idiosyncrasies. Persuasion is generically impossible within the class of statistically independent sender/receiver preferences -- contrary to prior research establishing persuasive equilibria when the sender's preference is precisely transparent.   Nevertheless, robust persuasion may occur when the sender's preference is only slightly state-dependent/idiosyncratic. This requires approximating an `acyclic' equilibrium of the transparent preference game, generically implying that this equilibrium is also `connected' -- a generalization of partial-pooling equilibria. It is then necessary and sufficient that the sender's preference satisfy a monotonicity condition relative to the approximated equilibrium.   If the sender's preference further satisfies a `semi-local' version of increasing differences, then this analysis extends to sender preferences that rank pure actions (but not mixed actions) according to a state-independent order.   We apply these techniques to study (1) how ethical considerations, such as empathy for the receiver, may improve or impede comm","creator":"Alistair Barton"},{"id":"2403.14036","slug":"fused-lasso-as-non-crossing-quantile-regression","title":"Fused LASSO as Non-Crossing Quantile Regression","link":"https://arxiv.org/abs/2403.14036","abstract":"Abstract: Quantile crossing has been an ever-present thorn in the side of quantile regression. This has spurred research into obtaining densities and coefficients that obey the quantile monotonicity property. While important contributions, these papers do not provide insight into how exactly these constraints influence the estimated coefficients. This paper extends non-crossing constraints and shows that by varying a single hyperparameter ($\\alpha$) one can obtain commonly used quantile estimators. Namely, we obtain the quantile regression estimator of Koenker and Bassett (1978) when $\\alpha=0$, the non crossing quantile regression estimator of Bondell et al. (2010) when $\\alpha=1$, and the composite quantile regression estimator of Koenker (1984) and Zou and Yuan (2008) when $\\alpha\\rightarrow\\infty$. As such, we show that non-crossing constraints are simply a special type of fused-shrinkage.","creator":"Tibor Szendrei, Arnab Bhattacharjee, Mark E. Schaffer"},{"id":"2403.14216","slug":"a-gaussian-smooth-transition-vector-autoregressive-model-an-application-to-the-macroeconomic-effects-of-severe-weather-shocks","title":"A Gaussian smooth transition vector autoregressive model: An application to the macroeconomic effects of severe weather shocks","link":"https://arxiv.org/abs/2403.14216","abstract":"Abstract: We introduce a new smooth transition vector autoregressive model with a Gaussian conditional distribution and transition weights that, for a $p$th order model, depend on the full distribution of the preceding $p$ observations. Specifically, the transition weight of each regime increases in its relative weighted likelihood. This data-driven approach facilitates capturing complex switching dynamics, enhancing the identification of gradual regime shifts. In an empirical application to the macroeconomic effects of a severe weather shock, we find that in monthly U.S. data from 1961:1 to 2022:3, the impacts of the shock are stronger in the regime prevailing in the early part of the sample and in certain crisis periods than in the regime dominating the latter part of the sample. This suggests overall adaptation of the U.S. economy to increased severe weather over time.","creator":"Markku Lanne, Savi Virolainen"},{"id":"2403.14385","slug":"estimating-causal-effects-with-double-machine-learning-a-method-evaluation","title":"Estimating Causal Effects with Double Machine Learning -- A Method Evaluation","link":"https://arxiv.org/abs/2403.14385","abstract":"arXiv:2403.14385v1 Announce Type: cross  Abstract: The estimation of causal effects with observational data continues to be a very active research area. In recent years, researchers have developed new frameworks which use machine learning to relax classical assumptions necessary for the estimation of causal effects. In this paper, we review one of the most prominent methods - \"double/debiased machine learning\" (DML) - and empirically evaluate it by comparing its performance on simulated data relative to more traditional statistical methods, before applying it to real-world data. Our findings indicate that the application of a suitably flexible machine learning algorithm within DML improves the adjustment for various nonlinear confounding relationships. This advantage enables a departure from traditional functional form assumptions typically necessary in causal effect estimation. However, we demonstrate that the method continues to critically depend on standard assumptions about causal structure and identification. When estimating the effects of air pollution on housing prices in our application, we find that DML estimates are consistently larger than estimates of less flexible methods. From our overall results, we provide actionable recommendations for specific choices researchers must make when applying DML in practice.","creator":"Jonathan Fuhr (School of Business and Economics, University of T\\\"ubingen), Philipp Berens (Hertie Institute for AI in Brain Health, University of T\\\"ubingen), Dominik Papies (School of Business and Economics, University of T\\\"ubingen)"},{"id":"1905.07812","slug":"iterative-estimation-of-nonparametric-regressions-with-continuous-endogenous-variables-and-discrete-instruments","title":"Iterative Estimation of Nonparametric Regressions with Continuous Endogenous Variables and Discrete Instruments","link":"https://arxiv.org/abs/1905.07812","abstract":"arXiv:1905.07812v2 Announce Type: replace  Abstract: We consider a nonparametric regression model with continuous endogenous independent variables when only discrete instruments are available that are independent of the error term. While this framework is very relevant for applied research, its implementation is cumbersome, as the regression function becomes the solution to a nonlinear integral equation. We propose a simple iterative procedure to estimate such models and showcase some of its asymptotic properties. In a simulation experiment, we discuss the details of its implementation in the case when the instrumental variable is binary. We conclude with an empirical application in which we examine the effect of pollution on house prices in a short panel of U.S. counties.","creator":"Samuele Centorrino, Fr\\'ed\\'erique F\\`eve, Jean-Pierre Florens"},{"id":"2201.06694","slug":"homophily-in-preferences-or-meetings-identifying-and-estimating-an-iterative-network-formation-model","title":"Homophily in preferences or meetings? Identifying and estimating an iterative network formation model","link":"https://arxiv.org/abs/2201.06694","abstract":"arXiv:2201.06694v4 Announce Type: replace  Abstract: Is homophily in social and economic networks driven by a taste for homogeneity (preferences) or by a higher probability of meeting individuals with similar attributes (opportunity)? This paper studies identification and estimation of an iterative network game that distinguishes between these two mechanisms. Our approach enables us to assess the counterfactual effects of changing the meeting protocol between agents. As an application, we study the role of preferences and meetings in shaping classroom friendship networks in Brazil. In a network structure in which homophily due to preferences is stronger than homophily due to meeting opportunities, tracking students may improve welfare. Still, the relative benefit of this policy diminishes over the school year.","creator":"Luis Alvarez, Cristine Pinto, Vladimir Ponczek"},{"id":"2204.11318","slug":"identification-and-statistical-decision-theory","title":"Identification and Statistical Decision Theory","link":"https://arxiv.org/abs/2204.11318","abstract":"arXiv:2204.11318v2 Announce Type: replace  Abstract: Econometricians have usefully separated study of estimation into identification and statistical components. Identification analysis, which assumes knowledge of the probability distribution generating observable data, places an upper bound on what may be learned about population parameters of interest with finite sample data. Yet Wald's statistical decision theory studies decision making with sample data without reference to identification, indeed without reference to estimation. This paper asks if identification analysis is useful to statistical decision theory. The answer is positive, as it can yield an informative and tractable upper bound on the achievable finite sample performance of decision criteria. The reasoning is simple when the decision relevant parameter is point identified. It is more delicate when the true state is partially identified and a decision must be made under ambiguity. Then the performance of some criteria, such as minimax regret, is enhanced by randomizing choice of an action. This may be accomplished by making choice a function of sample data. I find it useful to recast choice of a statistical decision function as selection of choice probabilities for the elements of the choice set. Using sample data to randomize choice conceptually differs from and is complementary to its traditional use to estimate population parameters.","creator":"Charles F. Manski"},{"id":"2205.13773","slug":"wildfire-modeling-designing-a-market-to-restore-assets","title":"Wildfire Modeling: Designing a Market to Restore Assets","link":"https://arxiv.org/abs/2205.13773","abstract":"arXiv:2205.13773v4 Announce Type: replace  Abstract: In the past decade, summer wildfires have become the norm in California, and the United States of America. These wildfires are caused due to variety of reasons. The state collects wildfire funds to help the impacted customers. However, the funds are eligible only under certain conditions and are collected uniformly throughout California. Therefore, the overall idea of this project is to look for quantitative results on how electrical corporations cause wildfires and how they can help to collect the wildfire funds or charge fairly to the customers to maximize the social impact. The research project aims to propose the implication of wildfire risk associated with vegetation, and due to power lines and incorporate that in dollars. Therefore, the project helps to solve the problem of collecting wildfire funds associated with each location and incorporate energy prices to charge their customers according to their wildfire risk related to the location to maximize the social surplus for the society. The thesis findings will help to calculate the risk premium involving wildfire risk associated with the location and incorporate the risk into pricing. The research of this submitted proposal provides the potential contribution towards detecting the utilities associated wildfire risk in the power lines, which can prevent wildfires by controlling the line flows of the system. Ultimately, the goal of this proposal is a social benefit to save money for the electrical corporations and their customers in California, who pay flat charges for Wildfire Fund each month $0.00580/kWh (in dollars). Therefore, this proposal will propose new method to collect wildfire fund with maximum customer surplus for future generations.","creator":"Ramandeep Kaur Bagri, Yihsu Chen"},{"id":"2308.08430","slug":"a-majority-rule-philosophy-for-instant-runoff-voting","title":"A Majority Rule Philosophy for Instant Runoff Voting","link":"https://arxiv.org/abs/2308.08430","abstract":"arXiv:2308.08430v2 Announce Type: replace  Abstract: We present the core support criterion, a voting criterion satisfied by Instant Runoff Voting (IRV) that is analogous to the Condorcet criterion but reflective of a different majority rule philosophy. Condorcet methods can be thought of as conducting elections between each pair of candidates, counting all ballots to determine the winner of each pair-election. IRV can also be thought of as conducting elections between all pairs of candidates but for each pair-election only counting ballots from voters who do not prefer another major candidate (as determined self-consistently from the IRV social ranking) to the two candidates in contention. The appropriateness of including all ballots or a subset of ballots for a pair-election, depends on whether the society deems the entire or a selected ballot set in compliance with freedom of association (which implies freedom of non-association) for a given pair election. Arguments based on freedom of association rely on more information about an electorate than can be learned from ranked ballots alone. We present a freedom-of-association based argument to explain why IRV may be preferable to Condorcet in some circumstances, including the 2022 Alaska special congressional election, based on the political context of that election.","creator":"Ross Hyman, Deb Otis, Seamus Allen, Greg Dennis"},{"id":"2312.02465","slug":"ex-ante-design-of-persuasion-games","title":"Ex-Ante Design of Persuasion Games","link":"https://arxiv.org/abs/2312.02465","abstract":"arXiv:2312.02465v3 Announce Type: replace  Abstract: How does receiver commitment affect incentives for information revelation in Bayesian persuasion? We study many-sender persuasion games where a single receiver commits to a posterior-dependent action profile, or allocation, before senders design the informational environment. We develop a novel revelation-like principle for ex-ante mechanism design settings where sender reports are Blackwell experiments and use it to characterize the set of implementable allocations in our model. We show global incentive constraints are pinned down by \"worst-case\" punishments at finitely many posterior beliefs, whose values are independent of the allocation. Moreover, the receiver will generically benefit from the ability to randomize over deterministic outcomes when solving for the constrained optimal allocation, in contrast to standard mechanism design models. Finally, we apply our results to analyze efficiency in multi-good allocation problems, full surplus extraction in auctions with allocation externalities, and optimal audit design, highlighting the role that monotone mechanisms play in these settings.","creator":"Eric Gao, Daniel Luo"},{"id":"2310.01666","slug":"the-dictator-dilemma-the-distortion-of-information-flow-in-autocratic-regimes-and-its-consequences","title":"The Dictator Dilemma: The Distortion of Information Flow in Autocratic Regimes and Its Consequences","link":"https://arxiv.org/abs/2310.01666","abstract":"arXiv:2310.01666v3 Announce Type: replace-cross  Abstract: Humans have been arguing about the benefits of dictatorial versus democratic regimes for millennia. Despite drastic differences between the dictatorships in the world, one of the key common features is the \\emph{Dictator's Dilemma} as defined by Wintrobe [1]: a dictator will never know the true state of affairs in his country and is perpetually presented distorted information, thus having difficulties in making the right governing decisions. The dictator's dilemma is essential to most autocratic regimes and is one of the key features in the literature on the subject. Yet, no quantitative theory of how the distortion of information develops from the initial state has been developed up to date. I present a model of the appearance and evolution of such information distortion, with subsequent degradation of control by the dictator. The model is based on the following fundamental and general premises: a) the dictator governs aiming to follow the desired trajectory of development based only on the information from the advisors; b) the deception from the advisors cannot decrease in time; and c) the deception change depends on the difficulties the country encounters. The model shows effective control in the short term (a few months to a year), followed by instability leading to the country's gradual deterioration of the state over many years. I derive some universal parameters applicable to all dictators and show that advisors' deception increases parallel with the decline of the control. In contrast, the dictator thinks the government is doing a reasonable, but not perfect, job. Finally, I present a match of our model to the historical data of grain production in the Soviet Union in 1928-1940.","creator":"Vakhtang Putkaradze"},{"id":"2310.03501","slug":"designing-digital-voting-systems-for-citizens-achieving-fairness-and-legitimacy-in-participatory-budgeting","title":"Designing Digital Voting Systems for Citizens: Achieving Fairness and Legitimacy in Participatory Budgeting","link":"https://arxiv.org/abs/2310.03501","abstract":"arXiv:2310.03501v2 Announce Type: replace-cross  Abstract: Participatory Budgeting (PB) has evolved into a key democratic instrument for resource allocation in cities. Enabled by digital platforms, cities now have the opportunity to let citizens directly propose and vote on urban projects, using different voting input and aggregation rules. However, the choices cities make in terms of the rules of their PB have often not been informed by academic studies on voter behaviour and preferences. Therefore, this work presents the results of behavioural experiments where participants were asked to vote in a fictional PB setting. We identified approaches to designing PB voting that minimise cognitive load and enhance the perceived fairness and legitimacy of the digital process from the citizens' perspective. In our study, participants preferred voting input formats that are more expressive (like rankings and distributing points) over simpler formats (like approval voting). Participants also indicated a desire for the budget to be fairly distributed across city districts and project categories. Participants found the Method of Equal Shares voting rule to be fairer than the conventional Greedy voting rule. These findings offer actionable insights for digital governance, contributing to the development of fairer and more transparent digital systems and collective decision-making processes for citizens.","creator":"Joshua C. Yang, Carina I. Hausladen, Dominik Peters, Evangelos Pournaras, Regula H\\\"anggli Fricker, Dirk Helbing"}]}]