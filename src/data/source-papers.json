[{"name":"Artificial Intelligence","feed":[{"id":"2403.03288","slug":"should-we-fear-large-language-models-a-structural-analysis-of-the-human-reasoning-system-for-elucidating-llm-capabilities-and-risks-through-the-lens-of-heidegger-s-philosophy","title":"Should We Fear Large Language Models? A Structural Analysis of the Human Reasoning System for Elucidating LLM Capabilities and Risks Through the Lens of Heidegger's Philosophy","link":"https://arxiv.org/abs/2403.03288","abstract":"Abstract: In the rapidly evolving field of Large Language Models (LLMs), there is a critical need to thoroughly analyze their capabilities and risks. Central to our investigation are two novel elements. Firstly, it is the innovative parallels between the statistical patterns of word relationships within LLMs and Martin Heidegger's concepts of \"ready-to-hand\" and \"present-at-hand,\" which encapsulate the utilitarian and scientific altitudes humans employ in interacting with the world. This comparison lays the groundwork for positioning LLMs as the digital counterpart to the Faculty of Verbal Knowledge, shedding light on their capacity to emulate certain facets of human reasoning. Secondly, a structural analysis of human reasoning, viewed through Heidegger's notion of truth as \"unconcealment\" is conducted This foundational principle enables us to map out the inputs and outputs of the reasoning system and divide reasoning into four distinct categories. Respective cognitive faculties are delineated, allowing us to place LLMs within the broader schema of human reasoning, thus clarifying their strengths and inherent limitations. Our findings reveal that while LLMs possess the capability for Direct Explicative Reasoning and Pseudo Rational Reasoning, they fall short in authentic rational reasoning and have no creative reasoning capabilities, due to the current lack of many analogous AI models such as the Faculty of Judgement. The potential and risks of LLMs when they are augmented with other AI technologies are also evaluated. The results indicate that although LLMs have achieved proficiency in some reasoning abilities, the aspiration to match or exceed human intellectual capabilities is yet unattained. This research not only enriches our comprehension of LLMs but also propels forward the discourse on AI's potential and its bounds, paving the way for future explorations into AI's evolving landscape.","creator":"Jianqiiu Zhang"},{"id":"2403.03293","slug":"ai-insights-a-case-study-on-utilizing-chatgpt-intelligence-for-research-paper-analysis","title":"AI Insights: A Case Study on Utilizing ChatGPT Intelligence for Research Paper Analysis","link":"https://arxiv.org/abs/2403.03293","abstract":"Abstract: This paper discusses the effectiveness of leveraging Chatbot: Generative Pre-trained Transformer (ChatGPT) versions 3.5 and 4 for analyzing research papers for effective writing of scientific literature surveys. The study selected the \\textit{Application of Artificial Intelligence in Breast Cancer Treatment} as the research topic. Research papers related to this topic were collected from three major publication databases Google Scholar, Pubmed, and Scopus. ChatGPT models were used to identify the category, scope, and relevant information from the research papers for automatic identification of relevant papers related to Breast Cancer Treatment (BCT), organization of papers according to scope, and identification of key information for survey paper writing. Evaluations performed using ground truth data annotated using subject experts reveal, that GPT-4 achieves 77.3\\% accuracy in identifying the research paper categories and 50\\% of the papers were correctly identified by GPT-4 for their scopes. Further, the results demonstrate that GPT-4 can generate reasons for its decisions with an average of 27\\% new words, and 67\\% of the reasons given by the model were completely agreeable to the subject experts.","creator":"Anjalee De Silva, Janaka L. Wijekoon, Rashini Liyanarachchi, Rrubaa Panchendrarajan, Weranga Rajapaksha"},{"id":"2403.03357","slug":"the-case-for-globalizing-fairness-a-mixed-methods-study-on-colonialism-ai-and-health-in-africa","title":"The Case for Globalizing Fairness: A Mixed Methods Study on Colonialism, AI, and Health in Africa","link":"https://arxiv.org/abs/2403.03357","abstract":"Abstract: With growing application of machine learning (ML) technologies in healthcare, there have been calls for developing techniques to understand and mitigate biases these systems may exhibit. Fair-ness considerations in the development of ML-based solutions for health have particular implications for Africa, which already faces inequitable power imbalances between the Global North and South.This paper seeks to explore fairness for global health, with Africa as a case study. We conduct a scoping review to propose axes of disparities for fairness consideration in the African context and delineate where they may come into play in different ML-enabled medical modalities. We then conduct qualitative research studies with 672 general population study participants and 28 experts inML, health, and policy focused on Africa to obtain corroborative evidence on the proposed axes of disparities. Our analysis focuses on colonialism as the attribute of interest and examines the interplay between artificial intelligence (AI), health, and colonialism. Among the pre-identified attributes, we found that colonial history, country of origin, and national income level were specific axes of disparities that participants believed would cause an AI system to be biased.However, there was also divergence of opinion between experts and general population participants. Whereas experts generally expressed a shared view about the relevance of colonial history for the development and implementation of AI technologies in Africa, the majority of the general population participants surveyed did not think there was a direct link between AI and colonialism. Based on these findings, we provide practical recommendations for developing fairness-aware ML solutions for health in Africa.","creator":"Mercy Asiedu, Awa Dieng, Alexander Haykel, Negar Rostamzadeh, Stephen Pfohl, Chirag Nagpal, Maria Nagawa, Abigail Oppong, Sanmi Koyejo, Katherine Heller"},{"id":"2403.03359","slug":"race-sm-reinforcement-learning-based-autonomous-control-for-social-on-ramp-merging","title":"RACE-SM: Reinforcement Learning Based Autonomous Control for Social On-Ramp Merging","link":"https://arxiv.org/abs/2403.03359","abstract":"Abstract: Autonomous parallel-style on-ramp merging in human controlled traffic continues to be an existing issue for autonomous vehicle control. Existing non-learning based solutions for vehicle control rely on rules and optimization primarily. These methods have been seen to present significant challenges. Recent advancements in Deep Reinforcement Learning have shown promise and have received significant academic interest however the available learning based approaches show inadequate attention to other highway vehicles and often rely on inaccurate road traffic assumptions. In addition, the parallel-style case is rarely considered. A novel learning based model for acceleration and lane change decision making that explicitly considers the utility to both the ego vehicle and its surrounding vehicles which may be cooperative or uncooperative to produce behaviour that is socially acceptable is proposed. The novel reward function makes use of Social Value Orientation to weight the vehicle's level of social cooperation and is divided into ego vehicle and surrounding vehicle utility which are weighted according to the model's designated Social Value Orientation. A two-lane highway with an on-ramp divided into a taper-style and parallel-style section is considered. Simulation results indicated the importance of considering surrounding vehicles in reward function design and show that the proposed model matches or surpasses those in literature in terms of collisions while also introducing socially courteous behaviour avoiding near misses and anti-social behaviour through direct consideration of the effect of merging on surrounding vehicles.","creator":"Jordan Poots"},{"id":"2403.03382","slug":"adaptive-discovering-and-merging-for-incremental-novel-class-discovery","title":"Adaptive Discovering and Merging for Incremental Novel Class Discovery","link":"https://arxiv.org/abs/2403.03382","abstract":"Abstract: One important desideratum of lifelong learning aims to discover novel classes from unlabelled data in a continuous manner. The central challenge is twofold: discovering and learning novel classes while mitigating the issue of catastrophic forgetting of established knowledge. To this end, we introduce a new paradigm called Adaptive Discovering and Merging (ADM) to discover novel categories adaptively in the incremental stage and integrate novel knowledge into the model without affecting the original knowledge. To discover novel classes adaptively, we decouple representation learning and novel class discovery, and use Triple Comparison (TC) and Probability Regularization (PR) to constrain the probability discrepancy and diversity for adaptive category assignment. To merge the learned novel knowledge adaptively, we propose a hybrid structure with base and novel branches named Adaptive Model Merging (AMM), which reduces the interference of the novel branch on the old classes to preserve the previous knowledge, and merges the novel branch to the base model without performance loss and parameter growth. Extensive experiments on several datasets show that ADM significantly outperforms existing class-incremental Novel Class Discovery (class-iNCD) approaches. Moreover, our AMM also benefits the class-incremental Learning (class-IL) task by alleviating the catastrophic forgetting problem.","creator":"Guangyao Chen, Peixi Peng, Yangru Huang, Mengyue Geng, Yonghong Tian"},{"id":"2403.03401","slug":"bait-benchmarking-embedding-architectures-for-interactive-theorem-proving","title":"BAIT: Benchmarking (Embedding) Architectures for Interactive Theorem-Proving","link":"https://arxiv.org/abs/2403.03401","abstract":"Abstract: Artificial Intelligence for Theorem Proving has given rise to a plethora of benchmarks and methodologies, particularly in Interactive Theorem Proving (ITP). Research in the area is fragmented, with a diverse set of approaches being spread across several ITP systems. This presents a significant challenge to the comparison of methods, which are often complex and difficult to replicate. Addressing this, we present BAIT, a framework for fair and streamlined comparison of learning approaches in ITP. We demonstrate BAIT's capabilities with an in-depth comparison, across several ITP benchmarks, of state-of-the-art architectures applied to the problem of formula embedding. We find that Structure Aware Transformers perform particularly well, improving on techniques associated with the original problem sets. BAIT also allows us to assess the end-to-end proving performance of systems built on interactive environments. This unified perspective reveals a novel end-to-end system that improves on prior work. We also provide a qualitative analysis, illustrating that improved performance is associated with more semantically-aware embeddings. By streamlining the implementation and comparison of Machine Learning algorithms in the ITP context, we anticipate BAIT will be a springboard for future research.","creator":"Sean Lamont, Michael Norrish, Amir Dezfouli, Christian Walder, Paul Montague"},{"id":"2403.03406","slug":"an-enkf-lstm-assimilation-algorithm-for-crop-growth-model","title":"An EnKF-LSTM Assimilation Algorithm for Crop Growth Model","link":"https://arxiv.org/abs/2403.03406","abstract":"Abstract: Accurate and timely prediction of crop growth is of great significance to ensure crop yields and researchers have developed several crop models for the prediction of crop growth. However, there are large difference between the simulation results obtained by the crop models and the actual results, thus in this paper, we proposed to combine the simulation results with the collected crop data for data assimilation so that the accuracy of prediction will be improved. In this paper, an EnKF-LSTM data assimilation method for various crops is proposed by combining ensemble Kalman filter and LSTM neural network, which effectively avoids the overfitting problem of existing data assimilation methods and eliminates the uncertainty of the measured data. The verification of the proposed EnKF-LSTM method and the comparison of the proposed method with other data assimilation methods were performed using datasets collected by sensor equipment deployed on a farm.","creator":"Siqi Zhou, Ling Wang, Jie Liu, Jinshan Tang"},{"id":"2403.03517","slug":"ib-net-initial-branch-network-for-variable-decision-in-boolean-satisfiability","title":"IB-Net: Initial Branch Network for Variable Decision in Boolean Satisfiability","link":"https://arxiv.org/abs/2403.03517","abstract":"Abstract: Boolean Satisfiability problems are vital components in Electronic Design Automation, particularly within the Logic Equivalence Checking process. Currently, SAT solvers are employed for these problems and neural network is tried as assistance to solvers. However, as SAT problems in the LEC context are distinctive due to their predominantly unsatisfiability nature and a substantial proportion of UNSAT-core variables, existing neural network assistance has proven unsuccessful in this specialized domain. To tackle this challenge, we propose IB-Net, an innovative framework utilizing graph neural networks and novel graph encoding techniques to model unsatisfiable problems and interact with state-of-the-art solvers. Extensive evaluations across solvers and datasets demonstrate IB-Net's acceleration, achieving an average runtime speedup of 5.0% on industrial data and 8.3% on SAT competition data empirically. This breakthrough advances efficient solving in LEC workflows.","creator":"Tsz Ho Chan, Wenyi Xiao, Junhua Huang, Huiling Zhen, Guangji Tian, Mingxuan Yuan"},{"id":"2403.03544","slug":"prompt-mining-for-language-based-human-mobility-forecasting","title":"Prompt Mining for Language-based Human Mobility Forecasting","link":"https://arxiv.org/abs/2403.03544","abstract":"Abstract: With the advancement of large language models, language-based forecasting has recently emerged as an innovative approach for predicting human mobility patterns. The core idea is to use prompts to transform the raw mobility data given as numerical values into natural language sentences so that the language models can be leveraged to generate the description for future observations. However, previous studies have only employed fixed and manually designed templates to transform numerical values into sentences. Since the forecasting performance of language models heavily relies on prompts, using fixed templates for prompting may limit the forecasting capability of language models. In this paper, we propose a novel framework for prompt mining in language-based mobility forecasting, aiming to explore diverse prompt design strategies. Specifically, the framework includes a prompt generation stage based on the information entropy of prompts and a prompt refinement stage to integrate mechanisms such as the chain of thought. Experimental results on real-world large-scale data demonstrate the superiority of generated prompts from our prompt mining pipeline. Additionally, the comparison of different prompt variants shows that the proposed prompt refinement process is effective. Our study presents a promising direction for further advancing language-based mobility forecasting.","creator":"Hao Xue, Tianye Tang, Ali Payani, Flora D. Salim"},{"id":"2403.03550","slug":"emotional-manipulation-through-prompt-engineering-amplifies-disinformation-generation-in-ai-large-language-models","title":"Emotional Manipulation Through Prompt Engineering Amplifies Disinformation Generation in AI Large Language Models","link":"https://arxiv.org/abs/2403.03550","abstract":"Abstract: This study investigates the generation of synthetic disinformation by OpenAI's Large Language Models (LLMs) through prompt engineering and explores their responsiveness to emotional prompting. Leveraging various LLM iterations using davinci-002, davinci-003, gpt-3.5-turbo and gpt-4, we designed experiments to assess their success in producing disinformation. Our findings, based on a corpus of 19,800 synthetic disinformation social media posts, reveal that all LLMs by OpenAI can successfully produce disinformation, and that they effectively respond to emotional prompting, indicating their nuanced understanding of emotional cues in text generation. When prompted politely, all examined LLMs consistently generate disinformation at a high frequency. Conversely, when prompted impolitely, the frequency of disinformation production diminishes, as the models often refuse to generate disinformation and instead caution users that the tool is not intended for such purposes. This research contributes to the ongoing discourse surrounding responsible development and application of AI technologies, particularly in mitigating the spread of disinformation and promoting transparency in AI-generated content.","creator":"Rasita Vinay, Giovanni Spitale, Nikola Biller-Andorno, Federico Germani"},{"id":"2403.03594","slug":"assessing-the-aesthetic-evaluation-capabilities-of-gpt-4-with-vision-insights-from-group-and-individual-assessments","title":"Assessing the Aesthetic Evaluation Capabilities of GPT-4 with Vision: Insights from Group and Individual Assessments","link":"https://arxiv.org/abs/2403.03594","abstract":"Abstract: Recently, it has been recognized that large language models demonstrate high performance on various intellectual tasks. However, few studies have investigated alignment with humans in behaviors that involve sensibility, such as aesthetic evaluation. This study investigates the performance of GPT-4 with Vision, a state-of-the-art language model that can handle image input, on the task of aesthetic evaluation of images. We employ two tasks, prediction of the average evaluation values of a group and an individual's evaluation values. We investigate the performance of GPT-4 with Vision by exploring prompts and analyzing prediction behaviors. Experimental results reveal GPT-4 with Vision's superior performance in predicting aesthetic evaluations and the nature of different responses to beauty and ugliness. Finally, we discuss developing an AI system for aesthetic evaluation based on scientific knowledge of the human perception of beauty, employing agent technologies that integrate traditional deep learning models with large language models.","creator":"Yoshia Abe, Tatsuya Daikoku, Yasuo Kuniyoshi"},{"id":"2403.03600","slug":"a-privacy-preserving-framework-with-multi-modal-data-for-cross-domain-recommendation","title":"A Privacy-Preserving Framework with Multi-Modal Data for Cross-Domain Recommendation","link":"https://arxiv.org/abs/2403.03600","abstract":"Abstract: Cross-domain recommendation (CDR) aims to enhance recommendation accuracy in a target domain with sparse data by leveraging rich information in a source domain, thereby addressing the data-sparsity problem. Some existing CDR methods highlight the advantages of extracting domain-common and domain-specific features to learn comprehensive user and item representations. However, these methods can't effectively disentangle these components as they often rely on simple user-item historical interaction information (such as ratings, clicks, and browsing), neglecting the rich multi-modal features. Additionally, they don't protect user-sensitive data from potential leakage during knowledge transfer between domains. To address these challenges, we propose a Privacy-Preserving Framework with Multi-Modal Data for Cross-Domain Recommendation, called P2M2-CDR. Specifically, we first design a multi-modal disentangled encoder that utilizes multi-modal information to disentangle more informative domain-common and domain-specific embeddings. Furthermore, we introduce a privacy-preserving decoder to mitigate user privacy leakage during knowledge transfer. Local differential privacy (LDP) is utilized to obfuscate the disentangled embeddings before inter-domain exchange, thereby enhancing privacy protection. To ensure both consistency and differentiation among these obfuscated disentangled embeddings, we incorporate contrastive learning-based domain-inter and domain-intra losses. Extensive Experiments conducted on four real-world datasets demonstrate that P2M2-CDR outperforms other state-of-the-art single-domain and cross-domain baselines.","creator":"Li Wang, Lei Sang, Quangui Zhang, Qiang Wu, Min Xu"},{"id":"2403.03607","slug":"the-geometric-structure-of-topic-models","title":"The Geometric Structure of Topic Models","link":"https://arxiv.org/abs/2403.03607","abstract":"Abstract: Topic models are a popular tool for clustering and analyzing textual data. They allow texts to be classified on the basis of their affiliation to the previously calculated topics. Despite their widespread use in research and application, an in-depth analysis of topic models is still an open research topic. State-of-the-art methods for interpreting topic models are based on simple visualizations, such as similarity matrices, top-term lists or embeddings, which are limited to a maximum of three dimensions. In this paper, we propose an incidence-geometric method for deriving an ordinal structure from flat topic models, such as non-negative matrix factorization. These enable the analysis of the topic model in a higher (order) dimension and the possibility of extracting conceptual relationships between several topics at once. Due to the use of conceptual scaling, our approach does not introduce any artificial topical relationships, such as artifacts of feature compression. Based on our findings, we present a new visualization paradigm for concept hierarchies based on ordinal motifs. These allow for a top-down view on topic spaces. We introduce and demonstrate the applicability of our approach based on a topic model derived from a corpus of scientific papers taken from 32 top machine learning venues.","creator":"Johannes Hirth, Tom Hanika"},{"id":"2403.03636","slug":"sheetagent-a-generalist-agent-for-spreadsheet-reasoning-and-manipulation-via-large-language-models","title":"SheetAgent: A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models","link":"https://arxiv.org/abs/2403.03636","abstract":"Abstract: Spreadsheet manipulation is widely existing in most daily works and significantly improves working efficiency. Large language model (LLM) has been recently attempted for automatic spreadsheet manipulation but has not yet been investigated in complicated and realistic tasks where reasoning challenges exist (e.g., long horizon manipulation with multi-step reasoning and ambiguous requirements). To bridge the gap with the real-world requirements, we introduce $\\textbf{SheetRM}$, a benchmark featuring long-horizon and multi-category tasks with reasoning-dependent manipulation caused by real-life challenges. To mitigate the above challenges, we further propose $\\textbf{SheetAgent}$, a novel autonomous agent that utilizes the power of LLMs. SheetAgent consists of three collaborative modules: $\\textit{Planner}$, $\\textit{Informer}$, and $\\textit{Retriever}$, achieving both advanced reasoning and accurate manipulation over spreadsheets without human interaction through iterative task reasoning and reflection. Extensive experiments demonstrate that SheetAgent delivers 20-30% pass rate improvements on multiple benchmarks over baselines, achieving enhanced precision in spreadsheet manipulation and demonstrating superior table reasoning abilities. More details and visualizations are available at https://sheetagent.github.io.","creator":"Yibin Chen, Yifu Yuan, Zeyu Zhang, Yan Zheng, Jinyi Liu, Fei Ni, Jianye Hao"},{"id":"2403.03645","slug":"k-link-knowledge-link-graph-from-llms-for-enhanced-representation-learning-in-multivariate-time-series-data","title":"K-Link: Knowledge-Link Graph from LLMs for Enhanced Representation Learning in Multivariate Time-Series Data","link":"https://arxiv.org/abs/2403.03645","abstract":"Abstract: Sourced from various sensors and organized chronologically, Multivariate Time-Series (MTS) data involves crucial spatial-temporal dependencies, e.g., correlations among sensors. To capture these dependencies, Graph Neural Networks (GNNs) have emerged as powerful tools, yet their effectiveness is restricted by the quality of graph construction from MTS data. Typically, existing approaches construct graphs solely from MTS signals, which may introduce bias due to a small training dataset and may not accurately represent underlying dependencies. To address this challenge, we propose a novel framework named K-Link, leveraging Large Language Models (LLMs) to encode extensive general knowledge and thereby providing effective solutions to reduce the bias. Leveraging the knowledge embedded in LLMs, such as physical principles, we extract a \\textit{Knowledge-Link graph}, capturing vast semantic knowledge of sensors and the linkage of the sensor-level knowledge. To harness the potential of the knowledge-link graph in enhancing the graph derived from MTS data, we propose a graph alignment module, facilitating the transfer of semantic knowledge within the knowledge-link graph into the MTS-derived graph. By doing so, we can improve the graph quality, ensuring effective representation learning with GNNs for MTS data. Extensive experiments demonstrate the efficacy of our approach for superior performance across various MTS-related downstream tasks.","creator":"Yucheng Wang, Ruibing Jin, Min Wu, Xiaoli Li, Lihua Xie, Zhenghua Chen"},{"id":"2403.03744","slug":"towards-safe-and-aligned-large-language-models-for-medicine","title":"Towards Safe and Aligned Large Language Models for Medicine","link":"https://arxiv.org/abs/2403.03744","abstract":"Abstract: The capabilities of large language models (LLMs) have been progressing at a breathtaking speed, leaving even their own developers grappling with the depth of their potential and risks. While initial steps have been taken to evaluate the safety and alignment of general-knowledge LLMs, exposing some weaknesses, to our knowledge, the safety and alignment of medical LLMs has not been evaluated despite their risks for personal health and safety, public health and safety, and human rights. To this end, we carry out the first safety evaluation for medical LLMs. Specifically, we set forth a definition of medical safety and alignment for medical artificial intelligence systems, develop a dataset of harmful medical questions to evaluate the medical safety and alignment of an LLM, evaluate both general and medical safety and alignment of medical LLMs, demonstrate fine-tuning as an effective mitigation strategy, and discuss broader, large-scale approaches used by the machine learning community to develop safe and aligned LLMs. We hope that this work casts light on the safety and alignment of medical LLMs and motivates future work to study it and develop additional mitigation strategies, minimizing the risks of harm of LLMs in medicine.","creator":"Tessa Han, Aounon Kumar, Chirag Agarwal, Himabindu Lakkaraju"},{"id":"2403.03768","slug":"deepcre-revolutionizing-drug-r-d-with-cutting-edge-computational-models","title":"DeepCRE: Revolutionizing Drug R&D with Cutting-Edge Computational Models","link":"https://arxiv.org/abs/2403.03768","abstract":"Abstract: The field of pharmaceutical development and therapeutic application both face substantial challenges. Therapeutic domain calls for more treatment alternatives while numerous promising pre-clinical drugs fail in clinical trails. One of the reasons is the inadequacy of Cross-drug Response Evaluation (CRE) during the late stage of drug development. Although in-silico CRE models offer a solution to this problem, existing methodologies are either limited to early development stages or lack the capacity for a comprehensive CRE analysis. Herein, we introduce a novel computational model named DeepCRE and present the potential of DeepCRE in advancing therapeutic discovery and development. DeepCRE outperforms the existing best models by achieving an average performance improvement of 17.7\\% in patient-level CRE, and a 5-fold increase in indication-level CRE. Furthermore, DeepCRE has identified six drug candidates that show significantly greater effectiveness than a comparator set of two approved drug in 5/8 colorectal cancer (CRC) organoids. This highlights DeepCRE's ability to identify a collection of drug candidates with superior therapeutic effects, underscoring its potential to revolutionize the field of therapeutic development.","creator":"Yushuai Wu"},{"id":"2403.03828","slug":"from-clicks-to-security-investigating-continuous-authentication-via-mouse-dynamics","title":"From Clicks to Security: Investigating Continuous Authentication via Mouse Dynamics","link":"https://arxiv.org/abs/2403.03828","abstract":"Abstract: In the realm of computer security, the importance of efficient and reliable user authentication methods has become increasingly critical. This paper examines the potential of mouse movement dynamics as a consistent metric for continuous authentication. By analyzing user mouse movement patterns in two contrasting gaming scenarios, \"Team Fortress\" and Poly Bridge we investigate the distinctive behavioral patterns inherent in high-intensity and low-intensity UI interactions. The study extends beyond conventional methodologies by employing a range of machine learning models. These models are carefully selected to assess their effectiveness in capturing and interpreting the subtleties of user behavior as reflected in their mouse movements. This multifaceted approach allows for a more nuanced and comprehensive understanding of user interaction patterns. Our findings reveal that mouse movement dynamics can serve as a reliable indicator for continuous user authentication. The diverse machine learning models employed in this study demonstrate competent performance in user verification, marking an improvement over previous methods used in this field. This research contributes to the ongoing efforts to enhance computer security and highlights the potential of leveraging user behavior, specifically mouse dynamics, in developing robust authentication systems.","creator":"Rushit Dave, Marcho Handoko, Ali Rashid, Cole Schoenbauer"},{"id":"2403.03832","slug":"your-device-may-know-you-better-than-you-know-yourself-continuous-authentication-on-novel-dataset-using-machine-learning","title":"Your device may know you better than you know yourself -- continuous authentication on novel dataset using machine learning","link":"https://arxiv.org/abs/2403.03832","abstract":"Abstract: This research aims to further understanding in the field of continuous authentication using behavioral biometrics. We are contributing a novel dataset that encompasses the gesture data of 15 users playing Minecraft with a Samsung Tablet, each for a duration of 15 minutes. Utilizing this dataset, we employed machine learning (ML) binary classifiers, being Random Forest (RF), K-Nearest Neighbors (KNN), and Support Vector Classifier (SVC), to determine the authenticity of specific user actions. Our most robust model was SVC, which achieved an average accuracy of approximately 90%, demonstrating that touch dynamics can effectively distinguish users. However, further studies are needed to make it viable option for authentication systems","creator":"Pedro Gomes do Nascimento, Pidge Witiak, Tucker MacCallum, Zachary Winterfeldt, Rushit Dave"},{"id":"2403.03894","slug":"ircoder-intermediate-representations-make-language-models-robust-multilingual-code-generators","title":"IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators","link":"https://arxiv.org/abs/2403.03894","abstract":"Abstract: Code understanding and generation have fast become some of the most popular applications of language models (LMs). Nonetheless, research on multilingual aspects of Code-LMs (i.e., LMs for code generation) such as cross-lingual transfer between different programming languages, language-specific data augmentation, and post-hoc LM adaptation, alongside exploitation of data sources other than the original textual content, has been much sparser than for their natural language counterparts. In particular, most mainstream Code-LMs have been pre-trained on source code files alone. In this work, we investigate the prospect of leveraging readily available compiler intermediate representations - shared across programming languages - to improve the multilingual capabilities of Code-LMs and facilitate cross-lingual transfer.   To this end, we first compile SLTrans, a parallel dataset consisting of nearly 4M self-contained source code files coupled with respective intermediate representations. Next, starting from various base Code-LMs (ranging in size from 1.1B to 7.3B parameters), we carry out continued causal language modelling training on SLTrans, forcing the Code-LMs to (1) learn the IR language and (2) align the IR constructs with respective constructs of various programming languages. Our resulting models, dubbed IRCoder, display sizeable and consistent gains across a wide variety of code generation tasks and metrics, including prompt robustness, multilingual code completion, code understanding, and instruction following.","creator":"Indraneil Paul, Jun Luo, Goran Glava\\v{s}, Iryna Gurevych"},{"id":"2403.03920","slug":"enhancing-instructional-quality-leveraging-computer-assisted-textual-analysis-to-generate-in-depth-insights-from-educational-artifacts","title":"Enhancing Instructional Quality: Leveraging Computer-Assisted Textual Analysis to Generate In-Depth Insights from Educational Artifacts","link":"https://arxiv.org/abs/2403.03920","abstract":"Abstract: This paper explores the transformative potential of computer-assisted textual analysis in enhancing instructional quality through in-depth insights from educational artifacts. We integrate Richard Elmore's Instructional Core Framework to examine how artificial intelligence (AI) and machine learning (ML) methods, particularly natural language processing (NLP), can analyze educational content, teacher discourse, and student responses to foster instructional improvement. Through a comprehensive review and case studies within the Instructional Core Framework, we identify key areas where AI/ML integration offers significant advantages, including teacher coaching, student support, and content development. We unveil patterns that indicate AI/ML not only streamlines administrative tasks but also introduces novel pathways for personalized learning, providing actionable feedback for educators and contributing to a richer understanding of instructional dynamics. This paper emphasizes the importance of aligning AI/ML technologies with pedagogical goals to realize their full potential in educational settings, advocating for a balanced approach that considers ethical considerations, data quality, and the integration of human expertise.","creator":"Zewei Tian, Min Sun, Alex Liu, Shawon Sarkar, Jing Liu"},{"id":"2402.16627","slug":"cross-modal-contextualized-diffusion-models-for-text-guided-visual-generation-and-editing","title":"Cross-Modal Contextualized Diffusion Models for Text-Guided Visual Generation and Editing","link":"https://arxiv.org/abs/2402.16627","abstract":"arXiv:2402.16627v2 Announce Type: cross  Abstract: Conditional diffusion models have exhibited superior performance in high-fidelity text-guided visual generation and editing. Nevertheless, prevailing text-guided visual diffusion models primarily focus on incorporating text-visual relationships exclusively into the reverse process, often disregarding their relevance in the forward process. This inconsistency between forward and reverse processes may limit the precise conveyance of textual semantics in visual synthesis results. To address this issue, we propose a novel and general contextualized diffusion model (ContextDiff) by incorporating the cross-modal context encompassing interactions and alignments between text condition and visual sample into forward and reverse processes. We propagate this context to all timesteps in the two processes to adapt their trajectories, thereby facilitating cross-modal conditional modeling. We generalize our contextualized diffusion to both DDPMs and DDIMs with theoretical derivations, and demonstrate the effectiveness of our model in evaluations with two challenging tasks: text-to-image generation, and text-to-video editing. In each task, our ContextDiff achieves new state-of-the-art performance, significantly enhancing the semantic alignment between text condition and generated samples, as evidenced by quantitative and qualitative evaluations. Our code is available at https://github.com/YangLing0818/ContextDiff","creator":"Ling Yang, Zhilong Zhang, Zhaochen Yu, Jingwei Liu, Minkai Xu, Stefano Ermon, Bin Cui"},{"id":"2402.17563","slug":"structure-guided-adversarial-training-of-diffusion-models","title":"Structure-Guided Adversarial Training of Diffusion Models","link":"https://arxiv.org/abs/2402.17563","abstract":"arXiv:2402.17563v2 Announce Type: cross  Abstract: Diffusion models have demonstrated exceptional efficacy in various generative applications. While existing models focus on minimizing a weighted sum of denoising score matching losses for data distribution modeling, their training primarily emphasizes instance-level optimization, overlooking valuable structural information within each mini-batch, indicative of pair-wise relationships among samples. To address this limitation, we introduce Structure-guided Adversarial training of Diffusion Models (SADM). In this pioneering approach, we compel the model to learn manifold structures between samples in each training batch. To ensure the model captures authentic manifold structures in the data distribution, we advocate adversarial training of the diffusion generator against a novel structure discriminator in a minimax game, distinguishing real manifold structures from the generated ones. SADM substantially improves existing diffusion transformers (DiT) and outperforms existing methods in image generation and cross-domain fine-tuning tasks across 12 datasets, establishing a new state-of-the-art FID of 1.58 and 2.11 on ImageNet for class-conditional image generation at resolutions of 256x256 and 512x512, respectively.","creator":"Ling Yang, Haotian Qian, Zhilong Zhang, Jingwei Liu, Bin Cui"},{"id":"2403.03222","slug":"knowledge-guided-eeg-representation-learning","title":"Knowledge-guided EEG Representation Learning","link":"https://arxiv.org/abs/2403.03222","abstract":"arXiv:2403.03222v1 Announce Type: cross  Abstract: Self-supervised learning has produced impressive results in multimedia domains of audio, vision and speech. This paradigm is equally, if not more, relevant for the domain of biosignals, owing to the scarcity of labelled data in such scenarios. The ability to leverage large-scale unlabelled data to learn robust representations could help improve the performance of numerous inference tasks on biosignals. Given the inherent domain differences between multimedia modalities and biosignals, the established objectives for self-supervised learning may not translate well to this domain. Hence, there is an unmet need to adapt these methods to biosignal analysis. In this work we propose a self-supervised model for EEG, which provides robust performance and remarkable parameter efficiency by using state space-based deep learning architecture. We also propose a novel knowledge-guided pre-training objective that accounts for the idiosyncrasies of the EEG signal. The results indicate improved embedding representation learning and downstream performance compared to prior works on exemplary tasks. Also, the proposed objective significantly reduces the amount of pre-training data required to obtain performance equivalent to prior works.","creator":"Aditya Kommineni, Kleanthis Avramidis, Richard Leahy, Shrikanth Narayanan"},{"id":"2403.03224","slug":"reinforcement-learning-jazz-improvisation-when-music-meets-game-theory","title":"Reinforcement Learning Jazz Improvisation: When Music Meets Game Theory","link":"https://arxiv.org/abs/2403.03224","abstract":"arXiv:2403.03224v1 Announce Type: cross  Abstract: Live performances of music are always charming, with the unpredictability of improvisation due to the dynamic between musicians and interactions with the audience. Jazz improvisation is a particularly noteworthy example for further investigation from a theoretical perspective. Here, we introduce a novel mathematical game theory model for jazz improvisation, providing a framework for studying music theory and improvisational methodologies. We use computational modeling, mainly reinforcement learning, to explore diverse stochastic improvisational strategies and their paired performance on improvisation. We find that the most effective strategy pair is a strategy that reacts to the most recent payoff (Stepwise Changes) with a reinforcement learning strategy limited to notes in the given chord (Chord-Following Reinforcement Learning). Conversely, a strategy that reacts to the partner's last note and attempts to harmonize with it (Harmony Prediction) strategy pair yields the lowest non-control payoff and highest standard deviation, indicating that picking notes based on immediate reactions to the partner player can yield inconsistent outcomes. On average, the Chord-Following Reinforcement Learning strategy demonstrates the highest mean payoff, while Harmony Prediction exhibits the lowest. Our work lays the foundation for promising applications beyond jazz: including the use of artificial intelligence (AI) models to extract data from audio clips to refine musical reward systems, and training machine learning (ML) models on existing jazz solos to further refine strategies within the game.","creator":"Vedant Tapiavala, Joshua Piesner, Sourjyamoy Barman, Feng Fu"},{"id":"2403.03230","slug":"large-language-models-surpass-human-experts-in-predicting-neuroscience-results","title":"Large language models surpass human experts in predicting neuroscience results","link":"https://arxiv.org/abs/2403.03230","abstract":"arXiv:2403.03230v1 Announce Type: cross  Abstract: Scientific discoveries often hinge on synthesizing decades of research, a task that potentially outstrips human information processing capacities. Large language models (LLMs) offer a solution. LLMs trained on the vast scientific literature could potentially integrate noisy yet interrelated findings to forecast novel results better than human experts. To evaluate this possibility, we created BrainBench, a forward-looking benchmark for predicting neuroscience results. We find that LLMs surpass experts in predicting experimental outcomes. BrainGPT, an LLM we tuned on the neuroscience literature, performed better yet. Like human experts, when LLMs were confident in their predictions, they were more likely to be correct, which presages a future where humans and LLMs team together to make discoveries. Our approach is not neuroscience-specific and is transferable to other knowledge-intensive endeavors.","creator":"Xiaoliang Luo, Akilles Rechardt, Guangzhi Sun, Kevin K. Nejad, Felipe Y\\'a\\~nez, Bati Yilmaz, Kangjoo Lee, Alexandra O. Cohen, Valentina Borghesani, Anton Pashkov, Daniele Marinazzo, Jonathan Nicholas, Alessandro Salatiello, Ilia Sucholutsky, Pasquale Minervini, Sepehr Razavi, Roberta Rocca, Elkhan Yusifov, Tereza Okalova, Nianlong Gu, Martin Ferianc, Mikail Khona, Kaustubh R. Patil, Pui-Shee Lee, Rui Mata, Nicholas E. Myers, Jennifer K Bizley, Sebastian Musslick, Isil Poyraz Bilgin, Guiomar Niso, Justin M. Ales, Michael Gaebler, N Apurva Ratan Murty, Chloe M. Hall, Jessica Dafflon, Sherry Dongqi Bao, Bradley C. Love"},{"id":"2403.03239","slug":"note-harnessing-tellurium-nanoparticles-in-the-digital-realm-plasmon-resonance-in-the-context-of-brewster-s-angle-and-the-drude-model-for-fake-news-adsorption-in-incomplete-information-games","title":"Note: Harnessing Tellurium Nanoparticles in the Digital Realm Plasmon Resonance, in the Context of Brewster's Angle and the Drude Model for Fake News Adsorption in Incomplete Information Games","link":"https://arxiv.org/abs/2403.03239","abstract":"arXiv:2403.03239v1 Announce Type: cross  Abstract: This note explores the innovative application of soliton theory and plasmonic phenomena in modeling user behavior and engagement within digital health platforms. By introducing the concept of soliton solutions, we present a novel approach to understanding stable patterns of health improvement behaviors over time. Additionally, we delve into the role of tellurium nanoparticles and their plasmonic properties in adsorbing fake news, thereby influencing user interactions and engagement levels. Through a theoretical framework that combines nonlinear dynamics with the unique characteristics of tellurium nanoparticles, we aim to provide new insights into the dynamics of user engagement in digital health environments. Our analysis highlights the potential of soliton theory in capturing the complex, nonlinear dynamics of user behavior, while the application of plasmonic phenomena offers a promising avenue for enhancing the sensitivity and effectiveness of digital health platforms. This research ventures into an uncharted territory where optical phenomena such as Brewster's Angle and Snell's Law, along with the concept of spin solitons, are metaphorically applied to address the challenge of fake news dissemination. By exploring the analogy between light refraction, reflection, and the propagation of information in digital platforms, we unveil a novel perspective on how the 'angle' at which information is presented can significantly affect its acceptance and spread. Additionally, we propose the use of tellurium nanoparticles to manage 'information waves' through mechanisms akin to plasmonic resonance and soliton dynamics. This theoretical exploration aims to bridge the gap between physical sciences and digital communication, offering insights into the development of strategies for mitigating misinformation.","creator":"Yasuko Kawahata"},{"id":"2403.03274","slug":"from-noise-to-signal-unveiling-treatment-effects-from-digital-health-data-through-pharmacology-informed-neural-sde","title":"From Noise to Signal: Unveiling Treatment Effects from Digital Health Data through Pharmacology-Informed Neural-SDE","link":"https://arxiv.org/abs/2403.03274","abstract":"arXiv:2403.03274v1 Announce Type: cross  Abstract: Digital health technologies (DHT), such as wearable devices, provide personalized, continuous, and real-time monitoring of patient. These technologies are contributing to the development of novel therapies and personalized medicine. Gaining insight from these technologies requires appropriate modeling techniques to capture clinically-relevant changes in disease state. The data generated from these devices is characterized by being stochastic in nature, may have missing elements, and exhibits considerable inter-individual variability - thereby making it difficult to analyze using traditional longitudinal modeling techniques. We present a novel pharmacology-informed neural stochastic differential equation (SDE) model capable of addressing these challenges. Using synthetic data, we demonstrate that our approach is effective in identifying treatment effects and learning causal relationships from stochastic data, thereby enabling counterfactual simulation.","creator":"Samira Pakravan, Nikolaos Evangelou, Maxime Usdin, Logan Brooks, James Lu"},{"id":"2403.03276","slug":"arnn-attentive-recurrent-neural-network-for-multi-channel-eeg-signals-to-identify-epileptic-seizures","title":"ARNN: Attentive Recurrent Neural Network for Multi-channel EEG Signals to Identify Epileptic Seizures","link":"https://arxiv.org/abs/2403.03276","abstract":"arXiv:2403.03276v1 Announce Type: cross  Abstract: We proposed an Attentive Recurrent Neural Network (ARNN), which recurrently applies attention layers along a sequence and has linear complexity with respect to the sequence length. The proposed model operates on multi-channel EEG signals rather than single channel signals and leverages parallel computation. In this cell, the attention layer is a computational unit that efficiently applies self-attention and cross-attention mechanisms to compute a recurrent function over a wide number of state vectors and input signals. Our architecture is inspired in part by the attention layer and long short-term memory (LSTM) cells, and it uses long-short style gates, but it scales this typical cell up by several orders to parallelize for multi-channel EEG signals. It inherits the advantages of attention layers and LSTM gate while avoiding their respective drawbacks. We evaluated the model effectiveness through extensive experiments with heterogeneous datasets, including the CHB-MIT and UPenn and Mayos Clinic, CHB-MIT datasets. The empirical findings suggest that the ARNN model outperforms baseline methods such as LSTM, Vision Transformer (ViT), Compact Convolution Transformer (CCT), and R-Transformer (RT), showcasing superior performance and faster processing capabilities across a wide range of tasks. The code has been made publicly accessible at \\url{https://github.com/Salim-Lysiun/ARNN}.","creator":"Salim Rukhsar, Anil Kumar Tiwari"},{"id":"2403.03281","slug":"credibility-aware-multi-modal-fusion-using-probabilistic-circuits","title":"Credibility-Aware Multi-Modal Fusion Using Probabilistic Circuits","link":"https://arxiv.org/abs/2403.03281","abstract":"arXiv:2403.03281v1 Announce Type: cross  Abstract: We consider the problem of late multi-modal fusion for discriminative learning. Motivated by noisy, multi-source domains that require understanding the reliability of each data source, we explore the notion of credibility in the context of multi-modal fusion. We propose a combination function that uses probabilistic circuits (PCs) to combine predictive distributions over individual modalities. We also define a probabilistic measure to evaluate the credibility of each modality via inference queries over the PC. Our experimental evaluation demonstrates that our fusion method can reliably infer credibility while maintaining competitive performance with the state-of-the-art.","creator":"Sahil Sidheekh, Pranuthi Tenali, Saurabh Mathur, Erik Blasch, Kristian Kersting, Sriraam Natarajan"},{"id":"2403.03305","slug":"best-of-both-worlds-a-pliable-and-generalizable-neuro-symbolic-approach-for-relation-classification","title":"Best of Both Worlds: A Pliable and Generalizable Neuro-Symbolic Approach for Relation Classification","link":"https://arxiv.org/abs/2403.03305","abstract":"arXiv:2403.03305v1 Announce Type: cross  Abstract: This paper introduces a novel neuro-symbolic architecture for relation classification (RC) that combines rule-based methods with contemporary deep learning techniques. This approach capitalizes on the strengths of both paradigms: the adaptability of rule-based systems and the generalization power of neural networks. Our architecture consists of two components: a declarative rule-based model for transparent classification and a neural component to enhance rule generalizability through semantic text matching. Notably, our semantic matcher is trained in an unsupervised domain-agnostic way, solely with synthetic data. Further, these components are loosely coupled, allowing for rule modifications without retraining the semantic matcher. In our evaluation, we focused on two few-shot relation classification datasets: Few-Shot TACRED and a Few-Shot version of NYT29. We show that our proposed method outperforms previous state-of-the-art models in three out of four settings, despite not seeing any human-annotated training data. Further, we show that our approach remains modular and pliable, i.e., the corresponding rules can be locally modified to improve the overall model. Human interventions to the rules for the TACRED relation \\texttt{org:parents} boost the performance on that relation by as much as 26\\% relative improvement, without negatively impacting the other relations, and without retraining the semantic matching component.","creator":"Robert Vacareanu, Fahmida Alam, Md Asiful Islam, Haris Riaz, Mihai Surdeanu"},{"id":"2403.03322","slug":"deep-configuration-performance-learning-a-systematic-survey-and-taxonomy","title":"Deep Configuration Performance Learning: A Systematic Survey and Taxonomy","link":"https://arxiv.org/abs/2403.03322","abstract":"arXiv:2403.03322v1 Announce Type: cross  Abstract: Performance is arguably the most crucial attribute that reflects the behavior of a configurable software system. However, given the increasing scale and complexity of modern software, modeling and predicting how various configurations can impact performance becomes one of the major challenges in software maintenance. As such, performance is often modeled without having a thorough knowledge of the software system, but relying mainly on data, which fits precisely with the purpose of deep learning.   In this paper, we conduct a comprehensive review exclusively on the topic of deep learning for performance learning of configurable software, covering 948 searched papers spanning six indexing services, based on which 85 primary papers were extracted and analyzed. Our results summarize the key topics and statistics on how the configuration data is prepared; how the deep configuration performance learning model is built; how the model is evaluated and how they are exploited in different tasks related to software configuration. We also identify the good practice and the potentially problematic phenomena from the studies surveyed, together with insights on future opportunities for the field. To promote open science, all the raw results of this survey can be accessed at our repository: https://github.com/ideas-labo/DCPL-SLR.","creator":"Jingzhi Gong, Tao Chen"},{"id":"2403.03334","slug":"diverse-deciphering-internet-views-on-the-u-s-military-through-video-comment-stance-analysis-a-novel-benchmark-dataset-for-stance-classification","title":"DIVERSE: Deciphering Internet Views on the U.S. Military Through Video Comment Stance Analysis, A Novel Benchmark Dataset for Stance Classification","link":"https://arxiv.org/abs/2403.03334","abstract":"arXiv:2403.03334v1 Announce Type: cross  Abstract: Stance detection of social media text is a key component of downstream tasks involving the identification of groups of users with opposing opinions on contested topics such as vaccination and within arguments. In particular, stance provides an indication of an opinion towards an entity. This paper introduces DIVERSE, a dataset of over 173,000 YouTube video comments annotated for their stance towards videos of the U.S. military. The stance is annotated through a human-guided, machine-assisted labeling methodology that makes use of weak signals of tone within the sentence as supporting indicators, as opposed to using manual annotations by humans. These weak signals consist of the presence of hate speech and sarcasm, the presence of specific keywords, the sentiment of the text, and the stance inference from two Large Language Models. The weak signals are then consolidated using a data programming model before each comment is annotated with a final stance label. On average, the videos have 200 comments each, and the stance of the comments skews slightly towards the \"against\" characterization for both the U.S. Army and the videos posted on the channel.","creator":"Iain J. Cruickshank, Lynnette Hui Xian Ng"},{"id":"2403.03344","slug":"learn-to-code-sustainably-an-empirical-study-on-llm-based-green-code-generation","title":"Learn to Code Sustainably: An Empirical Study on LLM-based Green Code Generation","link":"https://arxiv.org/abs/2403.03344","abstract":"arXiv:2403.03344v1 Announce Type: cross  Abstract: The increasing use of information technology has led to a significant share of energy consumption and carbon emissions from data centers. These contributions are expected to rise with the growing demand for big data analytics, increasing digitization, and the development of large artificial intelligence (AI) models. The need to address the environmental impact of software development has led to increased interest in green (sustainable) coding and claims that the use of AI models can lead to energy efficiency gains. Here, we provide an empirical study on green code and an overview of green coding practices, as well as metrics used to quantify the sustainability awareness of AI models. In this framework, we evaluate the sustainability of auto-generated code. The auto-generate codes considered in this study are produced by generative commercial AI language models, GitHub Copilot, OpenAI ChatGPT-3, and Amazon CodeWhisperer. Within our methodology, in order to quantify the sustainability awareness of these AI models, we propose a definition of the code's \"green capacity\", based on certain sustainability metrics. We compare the performance and green capacity of human-generated code and code generated by the three AI language models in response to easy-to-hard problem statements. Our findings shed light on the current capacity of AI models to contribute to sustainable software development.","creator":"Tina Vartziotis, Ippolyti Dellatolas, George Dasoulas, Maximilian Schmidt, Florian Schneider, Tim Hoffmann, Sotirios Kotsopoulos, Michael Keckeisen"},{"id":"2403.03348","slug":"learning-to-maximize-mutual-information-for-chain-of-thought-distillation","title":"Learning to Maximize Mutual Information for Chain-of-Thought Distillation","link":"https://arxiv.org/abs/2403.03348","abstract":"arXiv:2403.03348v1 Announce Type: cross  Abstract: Knowledge distillation, the technique of transferring knowledge from large, complex models to smaller ones, marks a pivotal step towards efficient AI deployment. Distilling Step-by-Step (DSS), a novel method utilizing chain-of-thought (CoT) distillation, has demonstrated promise by imbuing smaller models with the superior reasoning capabilities of their larger counterparts. In DSS, the distilled model acquires the ability to generate rationales and predict labels concurrently through a multi-task learning framework. However, DSS overlooks the intrinsic relationship between the two training tasks, leading to ineffective integration of CoT knowledge with the task of label prediction. To this end, we investigate the mutual relationship of the two tasks from Information Bottleneck perspective and formulate it as maximizing the mutual information of the representation features of the two tasks. We propose a variational approach to solve this optimization problem using a learning-based method. Our experimental results across four datasets demonstrate that our method outperforms the state-of-the-art DSS. Our findings offer insightful guidance for future research on language model distillation as well as applications involving CoT. Code and models will be released soon.","creator":"Xin Chen, Hanxian Huang, Yanjun Gao, Yi Wang, Jishen Zhao, Ke Ding"},{"id":"2403.03385","slug":"multi-modal-deep-learning","title":"Multi-modal Deep Learning","link":"https://arxiv.org/abs/2403.03385","abstract":"arXiv:2403.03385v1 Announce Type: cross  Abstract: This article investigates deep learning methodologies for single-modality clinical data analysis, as a crucial precursor to multi-modal medical research. Building on Guo JingYuan's work, the study refines clinical data processing through Compact Convolutional Transformer (CCT), Patch Up, and the innovative CamCenterLoss technique, establishing a foundation for future multimodal investigations. The proposed methodology demonstrates improved prediction accuracy and at tentiveness to critically ill patients compared to Guo JingYuan's ResNet and StageNet approaches. Novelty that using image-pretrained vision transformer backbone to perform transfer learning time-series clinical data.The study highlights the potential of CCT, Patch Up, and novel CamCenterLoss in processing single modality clinical data within deep learning frameworks, paving the way for future multimodal medical research and promoting precision and personalized healthcare","creator":"Chen Yuhua"},{"id":"2403.03395","slug":"interactive-melody-generation-system-for-enhancing-the-creativity-of-musicians","title":"Interactive Melody Generation System for Enhancing the Creativity of Musicians","link":"https://arxiv.org/abs/2403.03395","abstract":"arXiv:2403.03395v1 Announce Type: cross  Abstract: This study proposes a system designed to enumerate the process of collaborative composition among humans, using automatic music composition technology. By integrating multiple Recurrent Neural Network (RNN) models, the system provides an experience akin to collaborating with several composers, thereby fostering diverse creativity. Through dynamic adaptation to the user's creative intentions, based on feedback, the system enhances its capability to generate melodies that align with user preferences and creative needs. The system's effectiveness was evaluated through experiments with composers of varying backgrounds, revealing its potential to facilitate musical creativity and suggesting avenues for further refinement. The study underscores the importance of interaction between the composer and AI, aiming to make music composition more accessible and personalized. This system represents a step towards integrating AI into the creative process, offering a new tool for composition support and collaborative artistic exploration.","creator":"So Hirawata, Noriko Otani"},{"id":"2403.03407","slug":"human-vs-machine-language-models-and-wargames","title":"Human vs. Machine: Language Models and Wargames","link":"https://arxiv.org/abs/2403.03407","abstract":"arXiv:2403.03407v1 Announce Type: cross  Abstract: Wargames have a long history in the development of military strategy and the response of nations to threats or attacks. The advent of artificial intelligence (AI) promises better decision-making and increased military effectiveness. However, there is still debate about how AI systems, especially large language models (LLMs), behave as compared to humans. To this end, we use a wargame experiment with 107 national security expert human players designed to look at crisis escalation in a fictional US-China scenario and compare human players to LLM-simulated responses. We find considerable agreement in the LLM and human responses but also significant quantitative and qualitative differences between simulated and human players in the wargame, motivating caution to policymakers before handing over autonomy or following AI-based strategy recommendations.","creator":"Max Lamparth, Anthony Corso, Jacob Ganz, Oriana Skylar Mastro, Jacquelyn Schneider, Harold Trinkunas"},{"id":"2403.03409","slug":"sparse-spiking-neural-network-exploiting-heterogeneity-in-timescales-for-pruning-recurrent-snn","title":"Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales for Pruning Recurrent SNN","link":"https://arxiv.org/abs/2403.03409","abstract":"arXiv:2403.03409v1 Announce Type: cross  Abstract: Recurrent Spiking Neural Networks (RSNNs) have emerged as a computationally efficient and brain-inspired learning model. The design of sparse RSNNs with fewer neurons and synapses helps reduce the computational complexity of RSNNs. Traditionally, sparse SNNs are obtained by first training a dense and complex SNN for a target task, and, then, pruning neurons with low activity (activity-based pruning) while maintaining task performance. In contrast, this paper presents a task-agnostic methodology for designing sparse RSNNs by pruning a large randomly initialized model. We introduce a novel Lyapunov Noise Pruning (LNP) algorithm that uses graph sparsification methods and utilizes Lyapunov exponents to design a stable sparse RSNN from a randomly initialized RSNN. We show that the LNP can leverage diversity in neuronal timescales to design a sparse Heterogeneous RSNN (HRSNN). Further, we show that the same sparse HRSNN model can be trained for different tasks, such as image classification and temporal prediction. We experimentally show that, in spite of being task-agnostic, LNP increases computational efficiency (fewer neurons and synapses) and prediction performance of RSNNs compared to traditional activity-based pruning of trained dense models.","creator":"Biswadeep Chakraborty, Beomseok Kang, Harshit Kumar, Saibal Mukhopadhyay"},{"id":"2403.03419","slug":"negating-negatives-alignment-without-human-positive-samples-via-distributional-dispreference-optimization","title":"Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization","link":"https://arxiv.org/abs/2403.03419","abstract":"arXiv:2403.03419v1 Announce Type: cross  Abstract: Large language models (LLMs) have revolutionized the role of AI, yet also pose potential risks of propagating unethical content. Alignment technologies have been introduced to steer LLMs towards human preference, gaining increasing attention. Despite notable breakthroughs in this direction, existing methods heavily rely on high-quality positive-negative training pairs, suffering from noisy labels and the marginal distinction between preferred and dispreferred response data. Given recent LLMs' proficiency in generating helpful responses, this work pivots towards a new research focus: achieving alignment using solely human-annotated negative samples, preserving helpfulness while reducing harmfulness. For this purpose, we propose Distributional Dispreference Optimization (D$^2$O), which maximizes the discrepancy between the generated responses and the dispreferred ones to effectively eschew harmful information. We theoretically demonstrate that D$^2$O is equivalent to learning a distributional instead of instance-level preference model reflecting human dispreference against the distribution of negative responses. Besides, D$^2$O integrates an implicit Jeffrey Divergence regularization to balance the exploitation and exploration of reference policies and converges to a non-negative one during training. Extensive experiments demonstrate that our method achieves comparable generation quality and surpasses the latest baselines in producing less harmful and more informative responses with better training stability and faster convergence.","creator":"Shitong Duan, Xiaoyuan Yi, Peng Zhang, Tun Lu, Xing Xie, Ning Gu"},{"id":"2403.03421","slug":"lead-learning-decomposition-for-source-free-universal-domain-adaptation","title":"LEAD: Learning Decomposition for Source-free Universal Domain Adaptation","link":"https://arxiv.org/abs/2403.03421","abstract":"arXiv:2403.03421v1 Announce Type: cross  Abstract: Universal Domain Adaptation (UniDA) targets knowledge transfer in the presence of both covariate and label shifts. Recently, Source-free Universal Domain Adaptation (SF-UniDA) has emerged to achieve UniDA without access to source data, which tends to be more practical due to data protection policies. The main challenge lies in determining whether covariate-shifted samples belong to target-private unknown categories. Existing methods tackle this either through hand-crafted thresholding or by developing time-consuming iterative clustering strategies. In this paper, we propose a new idea of LEArning Decomposition (LEAD), which decouples features into source-known and -unknown components to identify target-private data. Technically, LEAD initially leverages the orthogonal decomposition analysis for feature decomposition. Then, LEAD builds instance-level decision boundaries to adaptively identify target-private data. Extensive experiments across various UniDA scenarios have demonstrated the effectiveness and superiority of LEAD. Notably, in the OPDA scenario on VisDA dataset, LEAD outperforms GLC by 3.5% overall H-score and reduces 75% time to derive pseudo-labeling decision boundaries. Besides, LEAD is also appealing in that it is complementary to most existing methods. The code is available at https://github.com/ispc-lab/LEAD.","creator":"Sanqing Qu, Tianpei Zou, Lianghua He, Florian R\\\"ohrbein, Alois Knoll, Guang Chen, Changjun Jiang"},{"id":"2403.03432","slug":"mixture-of-loras-an-efficient-multitask-tuning-for-large-language-models","title":"Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language Models","link":"https://arxiv.org/abs/2403.03432","abstract":"arXiv:2403.03432v1 Announce Type: cross  Abstract: Instruction Tuning has the potential to stimulate or enhance specific capabilities of large language models (LLMs). However, achieving the right balance of data is crucial to prevent catastrophic forgetting and interference between tasks. To address these limitations and enhance training flexibility, we propose the Mixture-of-LoRAs (MoA) architecture which is a novel and parameter-efficient tuning method designed for multi-task learning with LLMs. In this paper, we start by individually training multiple domain-specific LoRA modules using corresponding supervised corpus data. These LoRA modules can be aligned with the expert design principles observed in Mixture-of-Experts (MoE). Subsequently, we combine the multiple LoRAs using an explicit routing strategy and introduce domain labels to facilitate multi-task learning, which help prevent interference between tasks and ultimately enhances the performance of each individual task. Furthermore, each LoRA model can be iteratively adapted to a new domain, allowing for quick domain-specific adaptation. Experiments on diverse tasks demonstrate superior and robust performance, which can further promote the wide application of domain-specific LLMs.","creator":"Wenfeng Feng, Chuzhan Hao, Yuewei Zhang, Yu Han, Hao Wang"},{"id":"2403.03444","slug":"uncertainty-quantification-for-deeponets-with-ensemble-kalman-inversion","title":"Uncertainty quantification for deeponets with ensemble kalman inversion","link":"https://arxiv.org/abs/2403.03444","abstract":"arXiv:2403.03444v1 Announce Type: cross  Abstract: In recent years, operator learning, particularly the DeepONet, has received much attention for efficiently learning complex mappings between input and output functions across diverse fields. However, in practical scenarios with limited and noisy data, accessing the uncertainty in DeepONet predictions becomes essential, especially in mission-critical or safety-critical applications. Existing methods, either computationally intensive or yielding unsatisfactory uncertainty quantification, leave room for developing efficient and informative uncertainty quantification (UQ) techniques tailored for DeepONets. In this work, we proposed a novel inference approach for efficient UQ for operator learning by harnessing the power of the Ensemble Kalman Inversion (EKI) approach. EKI, known for its derivative-free, noise-robust, and highly parallelizable feature, has demonstrated its advantages for UQ for physics-informed neural networks [28]. Our innovative application of EKI enables us to efficiently train ensembles of DeepONets while obtaining informative uncertainty estimates for the output of interest. We deploy a mini-batch variant of EKI to accommodate larger datasets, mitigating the computational demand due to large datasets during the training stage. Furthermore, we introduce a heuristic method to estimate the artificial dynamics covariance, thereby improving our uncertainty estimates. Finally, we demonstrate the effectiveness and versatility of our proposed methodology across various benchmark problems, showcasing its potential to address the pressing challenges of uncertainty quantification in DeepONets, especially for practical applications with limited and noisy data.","creator":"Andrew Pensoneault, Xueyu Zhu"},{"id":"2403.03456","slug":"dlp-gan-learning-to-draw-modern-chinese-landscape-photos-with-generative-adversarial-network","title":"DLP-GAN: Learning to Draw Modern Chinese Landscape Photos with Generative Adversarial Network","link":"https://arxiv.org/abs/2403.03456","abstract":"arXiv:2403.03456v1 Announce Type: cross  Abstract: Chinese landscape painting has a unique and artistic style, and its drawing technique is highly abstract in both the use of color and the realistic representation of objects. Previous methods focus on transferring from modern photos to ancient ink paintings. However, little attention has been paid to translating landscape paintings into modern photos. To solve such problems, in this paper, we (1) propose DLP-GAN (\\textbf{D}raw Modern Chinese \\textbf{L}andscape \\textbf{P}hotos with \\textbf{G}enerative \\textbf{A}dversarial \\textbf{N}etwork), an unsupervised cross-domain image translation framework with a novel asymmetric cycle mapping, and (2) introduce a generator based on a dense-fusion module to match different translation directions. Moreover, a dual-consistency loss is proposed to balance the realism and abstraction of model painting. In this way, our model can draw landscape photos and sketches in the modern sense. Finally, based on our collection of modern landscape and sketch datasets, we compare the images generated by our model with other benchmarks. Extensive experiments including user studies show that our model outperforms state-of-the-art methods.","creator":"Xiangquan Gui, Binxuan Zhang, Li Li, Yi Yang"},{"id":"2403.03506","slug":"towards-detecting-ai-generated-text-within-human-ai-collaborative-hybrid-texts","title":"Towards Detecting AI-Generated Text within Human-AI Collaborative Hybrid Texts","link":"https://arxiv.org/abs/2403.03506","abstract":"arXiv:2403.03506v1 Announce Type: cross  Abstract: This study explores the challenge of sentence-level AI-generated text detection within human-AI collaborative hybrid texts. Existing studies of AI-generated text detection for hybrid texts often rely on synthetic datasets. These typically involve hybrid texts with a limited number of boundaries. We contend that studies of detecting AI-generated content within hybrid texts should cover different types of hybrid texts generated in realistic settings to better inform real-world applications. Therefore, our study utilizes the CoAuthor dataset, which includes diverse, realistic hybrid texts generated through the collaboration between human writers and an intelligent writing system in multi-turn interactions. We adopt a two-step, segmentation-based pipeline: (i) detect segments within a given hybrid text where each segment contains sentences of consistent authorship, and (ii) classify the authorship of each identified segment. Our empirical findings highlight (1) detecting AI-generated sentences in hybrid texts is overall a challenging task because (1.1) human writers' selecting and even editing AI-generated sentences based on personal preferences adds difficulty in identifying the authorship of segments; (1.2) the frequent change of authorship between neighboring sentences within the hybrid text creates difficulties for segment detectors in identifying authorship-consistent segments; (1.3) the short length of text segments within hybrid texts provides limited stylistic cues for reliable authorship determination; (2) before embarking on the detection process, it is beneficial to assess the average length of segments within the hybrid text. This assessment aids in deciding whether (2.1) to employ a text segmentation-based strategy for hybrid texts with longer segments, or (2.2) to adopt a direct sentence-by-sentence classification strategy for those with shorter segments.","creator":"Zijie Zeng, Shiqi Liu, Lele Sha, Zhuang Li, Kaixun Yang, Sannyuya Liu, Dragan Ga\\v{s}evi\\'c, Guanliang Chen"},{"id":"2403.03536","slug":"towards-efficient-and-effective-unlearning-of-large-language-models-for-recommendation","title":"Towards Efficient and Effective Unlearning of Large Language Models for Recommendation","link":"https://arxiv.org/abs/2403.03536","abstract":"arXiv:2403.03536v1 Announce Type: cross  Abstract: The significant advancements in large language models (LLMs) give rise to a promising research direction, i.e., leveraging LLMs as recommenders (LLMRec). The efficacy of LLMRec arises from the open-world knowledge and reasoning capabilities inherent in LLMs. LLMRec acquires the recommendation capabilities through instruction tuning based on user interaction data. However, in order to protect user privacy and optimize utility, it is also crucial for LLMRec to intentionally forget specific user data, which is generally referred to as recommendation unlearning. In the era of LLMs, recommendation unlearning poses new challenges for LLMRec in terms of \\textit{inefficiency} and \\textit{ineffectiveness}. Existing unlearning methods require updating billions of parameters in LLMRec, which is costly and time-consuming. Besides, they always impact the model utility during the unlearning process. To this end, we propose \\textbf{E2URec}, the first \\underline{E}fficient and \\underline{E}ffective \\underline{U}nlearning method for LLM\\underline{Rec}. Our proposed E2URec enhances the unlearning efficiency by updating only a few additional LoRA parameters, and improves the unlearning effectiveness by employing a teacher-student framework, where we maintain multiple teacher networks to guide the unlearning process. Extensive experiments show that E2URec outperforms state-of-the-art baselines on two real-world datasets. Specifically, E2URec can efficiently forget specific data without affecting recommendation performance. The source code is at \\url{https://github.com/justarter/E2URec}.","creator":"Hangyu Wang, Jianghao Lin, Bo Chen, Yang Yang, Ruiming Tang, Weinan Zhang, Yong Yu"},{"id":"2403.03538","slug":"radia-radio-advertisement-detection-with-intelligent-analytics","title":"RADIA -- Radio Advertisement Detection with Intelligent Analytics","link":"https://arxiv.org/abs/2403.03538","abstract":"arXiv:2403.03538v1 Announce Type: cross  Abstract: Radio advertising remains an integral part of modern marketing strategies, with its appeal and potential for targeted reach undeniably effective. However, the dynamic nature of radio airtime and the rising trend of multiple radio spots necessitates an efficient system for monitoring advertisement broadcasts. This study investigates a novel automated radio advertisement detection technique incorporating advanced speech recognition and text classification algorithms. RadIA's approach surpasses traditional methods by eliminating the need for prior knowledge of the broadcast content. This contribution allows for detecting impromptu and newly introduced advertisements, providing a comprehensive solution for advertisement detection in radio broadcasting. Experimental results show that the resulting model, trained on carefully segmented and tagged text data, achieves an F1-macro score of 87.76 against a theoretical maximum of 89.33. This paper provides insights into the choice of hyperparameters and their impact on the model's performance. This study demonstrates its potential to ensure compliance with advertising broadcast contracts and offer competitive surveillance. This groundbreaking research could fundamentally change how radio advertising is monitored and open new doors for marketing optimization.","creator":"Jorge \\'Alvarez, Juan Carlos Armenteros, Camilo Torr\\'on, Miguel Ortega-Mart\\'in, Alfonso Ardoiz, \\'Oscar Garc\\'ia, Ignacio Arranz, \\'I\\~nigo Galdeano, Ignacio Garrido, Adri\\'an Alonso, Fernando Bay\\'on, Oleg Vorontsov"},{"id":"2403.03575","slug":"gahealth-an-english-irish-bilingual-corpus-of-health-data","title":"gaHealth: An English-Irish Bilingual Corpus of Health Data","link":"https://arxiv.org/abs/2403.03575","abstract":"arXiv:2403.03575v1 Announce Type: cross  Abstract: Machine Translation is a mature technology for many high-resource language pairs. However in the context of low-resource languages, there is a paucity of parallel data datasets available for developing translation models. Furthermore, the development of datasets for low-resource languages often focuses on simply creating the largest possible dataset for generic translation. The benefits and development of smaller in-domain datasets can easily be overlooked. To assess the merits of using in-domain data, a dataset for the specific domain of health was developed for the low-resource English to Irish language pair. Our study outlines the process used in developing the corpus and empirically demonstrates the benefits of using an in-domain dataset for the health domain. In the context of translating health-related data, models developed using the gaHealth corpus demonstrated a maximum BLEU score improvement of 22.2 points (40%) when compared with top performing models from the LoResMT2021 Shared Task. Furthermore, we define linguistic guidelines for developing gaHealth, the first bilingual corpus of health data for the Irish language, which we hope will be of use to other creators of low-resource data sets. gaHealth is now freely available online and is ready to be explored for further research.","creator":"S\\'eamus Lankford, Haithem Afli, \\'Orla N\\'i Loinsigh, Andy Way"},{"id":"2403.03578","slug":"causal-disentanglement-for-regulating-social-influence-bias-in-social-recommendation","title":"Causal Disentanglement for Regulating Social Influence Bias in Social Recommendation","link":"https://arxiv.org/abs/2403.03578","abstract":"arXiv:2403.03578v1 Announce Type: cross  Abstract: Social recommendation systems face the problem of social influence bias, which can lead to an overemphasis on recommending items that friends have interacted with. Addressing this problem is crucial, and existing methods often rely on techniques such as weight adjustment or leveraging unbiased data to eliminate this bias. However, we argue that not all biases are detrimental, i.e., some items recommended by friends may align with the user's interests. Blindly eliminating such biases could undermine these positive effects, potentially diminishing recommendation accuracy. In this paper, we propose a Causal Disentanglement-based framework for Regulating Social influence Bias in social recommendation, named CDRSB, to improve recommendation performance. From the perspective of causal inference, we find that the user social network could be regarded as a confounder between the user and item embeddings (treatment) and ratings (outcome). Due to the presence of this social network confounder, two paths exist from user and item embeddings to ratings: a non-causal social influence path and a causal interest path. Building upon this insight, we propose a disentangled encoder that focuses on disentangling user and item embeddings into interest and social influence embeddings. Mutual information-based objectives are designed to enhance the distinctiveness of these disentangled embeddings, eliminating redundant information. Additionally, a regulatory decoder that employs a weight calculation module to dynamically learn the weights of social influence embeddings for effectively regulating social influence bias has been designed. Experimental results on four large-scale real-world datasets Ciao, Epinions, Dianping, and Douban book demonstrate the effectiveness of CDRSB compared to state-of-the-art baselines.","creator":"Li Wang, Min Xu, Quangui Zhang, Yunxiao Shi, Qiang Wu"},{"id":"2403.03582","slug":"design-of-an-open-source-architecture-for-neural-machine-translation","title":"Design of an Open-Source Architecture for Neural Machine Translation","link":"https://arxiv.org/abs/2403.03582","abstract":"arXiv:2403.03582v1 Announce Type: cross  Abstract: adaptNMT is an open-source application that offers a streamlined approach to the development and deployment of Recurrent Neural Networks and Transformer models. This application is built upon the widely-adopted OpenNMT ecosystem, and is particularly useful for new entrants to the field, as it simplifies the setup of the development environment and creation of train, validation, and test splits. The application offers a graphing feature that illustrates the progress of model training, and employs SentencePiece for creating subword segmentation models. Furthermore, the application provides an intuitive user interface that facilitates hyperparameter customization. Notably, a single-click model development approach has been implemented, and models developed by adaptNMT can be evaluated using a range of metrics. To encourage eco-friendly research, adaptNMT incorporates a green report that flags the power consumption and kgCO${_2}$ emissions generated during model development. The application is freely available.","creator":"S\\'eamus Lankford, Haithem Afli, Andy Way"},{"id":"2403.03585","slug":"routeexplainer-an-explanation-framework-for-vehicle-routing-problem","title":"RouteExplainer: An Explanation Framework for Vehicle Routing Problem","link":"https://arxiv.org/abs/2403.03585","abstract":"arXiv:2403.03585v1 Announce Type: cross  Abstract: The Vehicle Routing Problem (VRP) is a widely studied combinatorial optimization problem and has been applied to various practical problems. While the explainability for VRP is significant for improving the reliability and interactivity in practical VRP applications, it remains unexplored. In this paper, we propose RouteExplainer, a post-hoc explanation framework that explains the influence of each edge in a generated route. Our framework realizes this by rethinking a route as the sequence of actions and extending counterfactual explanations based on the action influence model to VRP. To enhance the explanation, we additionally propose an edge classifier that infers the intentions of each edge, a loss function to train the edge classifier, and explanation-text generation by Large Language Models (LLMs). We quantitatively evaluate our edge classifier on four different VRPs. The results demonstrate its rapid computation while maintaining reasonable accuracy, thereby highlighting its potential for deployment in practical applications. Moreover, on the subject of a tourist route, we qualitatively evaluate explanations generated by our framework. This evaluation not only validates our framework but also shows the synergy between explanation frameworks and LLMs. See https://ntt-dkiku.github.io/xai-vrp for our code, datasets, models, and demo.","creator":"Daisuke Kikuta, Hiroki Ikeuchi, Kengo Tajiri, Yuusuke Nakano"},{"id":"2403.03592","slug":"wildest-dreams-reproducible-research-in-privacy-preserving-neural-network-training","title":"Wildest Dreams: Reproducible Research in Privacy-preserving Neural Network Training","link":"https://arxiv.org/abs/2403.03592","abstract":"arXiv:2403.03592v1 Announce Type: cross  Abstract: Machine Learning (ML), addresses a multitude of complex issues in multiple disciplines, including social sciences, finance, and medical research. ML models require substantial computing power and are only as powerful as the data utilized. Due to high computational cost of ML methods, data scientists frequently use Machine Learning-as-a-Service (MLaaS) to outsource computation to external servers. However, when working with private information, like financial data or health records, outsourcing the computation might result in privacy issues. Recent advances in Privacy-Preserving Techniques (PPTs) have enabled ML training and inference over protected data through the use of Privacy-Preserving Machine Learning (PPML). However, these techniques are still at a preliminary stage and their application in real-world situations is demanding. In order to comprehend discrepancy between theoretical research suggestions and actual applications, this work examines the past and present of PPML, focusing on Homomorphic Encryption (HE) and Secure Multi-party Computation (SMPC) applied to ML. This work primarily focuses on the ML model's training phase, where maintaining user data privacy is of utmost importance. We provide a solid theoretical background that eases the understanding of current approaches and their limitations. In addition, we present a SoK of the most recent PPML frameworks for model training and provide a comprehensive comparison in terms of the unique properties and performances on standard benchmarks. Also, we reproduce the results for some of the papers and examine at what level existing works in the field provide support for open science. We believe our work serves as a valuable contribution by raising awareness about the current gap between theoretical advancements and real-world applications in PPML, specifically regarding open-source availability, reproducibility, and usability.","creator":"Tanveer Khan, Mindaugas Budzys, Khoa Nguyen, Antonis Michalas"},{"id":"2403.03593","slug":"do-you-trust-your-model-emerging-malware-threats-in-the-deep-learning-ecosystem","title":"Do You Trust Your Model? Emerging Malware Threats in the Deep Learning Ecosystem","link":"https://arxiv.org/abs/2403.03593","abstract":"arXiv:2403.03593v1 Announce Type: cross  Abstract: Training high-quality deep learning models is a challenging task due to computational and technical requirements. A growing number of individuals, institutions, and companies increasingly rely on pre-trained, third-party models made available in public repositories. These models are often used directly or integrated in product pipelines with no particular precautions, since they are effectively just data in tensor form and considered safe. In this paper, we raise awareness of a new machine learning supply chain threat targeting neural networks. We introduce MaleficNet 2.0, a novel technique to embed self-extracting, self-executing malware in neural networks. MaleficNet 2.0 uses spread-spectrum channel coding combined with error correction techniques to inject malicious payloads in the parameters of deep neural networks. MaleficNet 2.0 injection technique is stealthy, does not degrade the performance of the model, and is robust against removal techniques. We design our approach to work both in traditional and distributed learning settings such as Federated Learning, and demonstrate that it is effective even when a reduced number of bits is used for the model parameters. Finally, we implement a proof-of-concept self-extracting neural network malware using MaleficNet 2.0, demonstrating the practicality of the attack against a widely adopted machine learning framework. Our aim with this work is to raise awareness against these new, dangerous attacks both in the research community and industry, and we hope to encourage further research in mitigation techniques against such threats.","creator":"Dorjan Hitaj, Giulio Pagnotta, Fabio De Gaspari, Sediola Ruko, Briland Hitaj, Luigi V. Mancini, Fernando Perez-Cruz"},{"id":"2403.03606","slug":"enhancing-price-prediction-in-cryptocurrency-using-transformer-neural-network-and-technical-indicators","title":"Enhancing Price Prediction in Cryptocurrency Using Transformer Neural Network and Technical Indicators","link":"https://arxiv.org/abs/2403.03606","abstract":"arXiv:2403.03606v1 Announce Type: cross  Abstract: This study presents an innovative approach for predicting cryptocurrency time series, specifically focusing on Bitcoin, Ethereum, and Litecoin. The methodology integrates the use of technical indicators, a Performer neural network, and BiLSTM (Bidirectional Long Short-Term Memory) to capture temporal dynamics and extract significant features from raw cryptocurrency data. The application of technical indicators, such facilitates the extraction of intricate patterns, momentum, volatility, and trends. The Performer neural network, employing Fast Attention Via positive Orthogonal Random features (FAVOR+), has demonstrated superior computational efficiency and scalability compared to the traditional Multi-head attention mechanism in Transformer models. Additionally, the integration of BiLSTM in the feedforward network enhances the model's capacity to capture temporal dynamics in the data, processing it in both forward and backward directions. This is particularly advantageous for time series data where past and future data points can influence the current state. The proposed method has been applied to the hourly and daily timeframes of the major cryptocurrencies and its performance has been benchmarked against other methods documented in the literature. The results underscore the potential of the proposed method to outperform existing models, marking a significant progression in the field of cryptocurrency price prediction.","creator":"Mohammad Ali Labbaf Khaniki, Mohammad Manthouri"},{"id":"2403.03608","slug":"gsnerf-generalizable-semantic-neural-radiance-fields-with-enhanced-3d-scene-understanding","title":"GSNeRF: Generalizable Semantic Neural Radiance Fields with Enhanced 3D Scene Understanding","link":"https://arxiv.org/abs/2403.03608","abstract":"arXiv:2403.03608v1 Announce Type: cross  Abstract: Utilizing multi-view inputs to synthesize novel-view images, Neural Radiance Fields (NeRF) have emerged as a popular research topic in 3D vision. In this work, we introduce a Generalizable Semantic Neural Radiance Field (GSNeRF), which uniquely takes image semantics into the synthesis process so that both novel view images and the associated semantic maps can be produced for unseen scenes. Our GSNeRF is composed of two stages: Semantic Geo-Reasoning and Depth-Guided Visual rendering. The former is able to observe multi-view image inputs to extract semantic and geometry features from a scene. Guided by the resulting image geometry information, the latter performs both image and semantic rendering with improved performances. Our experiments not only confirm that GSNeRF performs favorably against prior works on both novel-view image and semantic segmentation synthesis but the effectiveness of our sampling strategy for visual rendering is further verified.","creator":"Zi-Ting Chou, Sheng-Yu Huang, I-Jieh Liu, Yu-Chiang Frank Wang"},{"id":"2403.03627","slug":"multimodal-large-language-models-to-support-real-world-fact-checking","title":"Multimodal Large Language Models to Support Real-World Fact-Checking","link":"https://arxiv.org/abs/2403.03627","abstract":"arXiv:2403.03627v1 Announce Type: cross  Abstract: Multimodal large language models (MLLMs) carry the potential to support humans in processing vast amounts of information. While MLLMs are already being used as a fact-checking tool, their abilities and limitations in this regard are understudied. Here is aim to bridge this gap. In particular, we propose a framework for systematically assessing the capacity of current multimodal models to facilitate real-world fact-checking. Our methodology is evidence-free, leveraging only these models' intrinsic knowledge and reasoning capabilities. By designing prompts that extract models' predictions, explanations, and confidence levels, we delve into research questions concerning model accuracy, robustness, and reasons for failure. We empirically find that (1) GPT-4V exhibits superior performance in identifying malicious and misleading multimodal claims, with the ability to explain the unreasonable aspects and underlying motives, and (2) existing open-source models exhibit strong biases and are highly sensitive to the prompt. Our study offers insights into combating false multimodal information and building secure, trustworthy multimodal models. To the best of our knowledge, we are the first to evaluate MLLMs for real-world fact-checking.","creator":"Jiahui Geng, Yova Kementchedjhieva, Preslav Nakov, Iryna Gurevych"},{"id":"2403.03640","slug":"apollo-lightweight-multilingual-medical-llms-towards-democratizing-medical-ai-to-6b-people","title":"Apollo: Lightweight Multilingual Medical LLMs towards Democratizing Medical AI to 6B People","link":"https://arxiv.org/abs/2403.03640","abstract":"arXiv:2403.03640v1 Announce Type: cross  Abstract: Despite the vast repository of global medical knowledge predominantly being in English, local languages are crucial for delivering tailored healthcare services, particularly in areas with limited medical resources. To extend the reach of medical AI advancements to a broader population, we aim to develop medical LLMs across the six most widely spoken languages, encompassing a global population of 6.1 billion. This effort culminates in the creation of the ApolloCorpora multilingual medical dataset and the XMedBench benchmark. In the multilingual medical benchmark, the released Apollo models, at various relatively-small sizes (i.e., 0.5B, 1.8B, 2B, 6B, and 7B), achieve the best performance among models of equivalent size. Especially, Apollo-7B is the state-of-the-art multilingual medical LLMs up to 70B. Additionally, these lite models could be used to improve the multi-lingual medical capabilities of larger models without fine-tuning in a proxy-tuning fashion. We will open-source training corpora, code, model weights and evaluation benchmark.","creator":"Xidong Wang, Nuo Chen, Junyin Chen, Yan Hu, Yidong Wang, Xiangbo Wu, Anningzhe Gao, Xiang Wan, Haizhou Li, Benyou Wang"},{"id":"2403.03643","slug":"a-survey-on-applications-of-reinforcement-learning-in-spatial-resource-allocation","title":"A Survey on Applications of Reinforcement Learning in Spatial Resource Allocation","link":"https://arxiv.org/abs/2403.03643","abstract":"arXiv:2403.03643v1 Announce Type: cross  Abstract: The challenge of spatial resource allocation is pervasive across various domains such as transportation, industry, and daily life. As the scale of real-world issues continues to expand and demands for real-time solutions increase, traditional algorithms face significant computational pressures, struggling to achieve optimal efficiency and real-time capabilities. In recent years, with the escalating computational power of computers, the remarkable achievements of reinforcement learning in domains like Go and robotics have demonstrated its robust learning and sequential decision-making capabilities. Given these advancements, there has been a surge in novel methods employing reinforcement learning to tackle spatial resource allocation problems. These methods exhibit advantages such as rapid solution convergence and strong model generalization abilities, offering a new perspective on resolving spatial resource allocation problems. Therefore, this paper aims to summarize and review recent theoretical methods and applied research utilizing reinforcement learning to address spatial resource allocation problems. It provides a summary and comprehensive overview of its fundamental principles, related methodologies, and applied research. Additionally, it highlights several unresolved issues that urgently require attention in this direction for the future.","creator":"Di Zhang, Moyang Wang, Joseph Mango, Xiang Li"},{"id":"2403.03689","slug":"general2specialized-llms-translation-for-e-commerce","title":"General2Specialized LLMs Translation for E-commerce","link":"https://arxiv.org/abs/2403.03689","abstract":"arXiv:2403.03689v1 Announce Type: cross  Abstract: Existing Neural Machine Translation (NMT) models mainly handle translation in the general domain, while overlooking domains with special writing formulas, such as e-commerce and legal documents. Taking e-commerce as an example, the texts usually include amounts of domain-related words and have more grammar problems, which leads to inferior performances of current NMT methods. To address these problems, we collect two domain-related resources, including a set of term pairs (aligned Chinese-English bilingual terms) and a parallel corpus annotated for the e-commerce domain. Furthermore, we propose a two-step fine-tuning paradigm (named G2ST) with self-contrastive semantic enhancement to transfer one general NMT model to the specialized NMT model for e-commerce. The paradigm can be used for the NMT models based on Large language models (LLMs). Extensive evaluations on real e-commerce titles demonstrate the superior translation quality and robustness of our G2ST approach, as compared with state-of-the-art NMT models such as LLaMA, Qwen, GPT-3.5, and even GPT-4.","creator":"Kaidi Chen, Ben Chen, Dehong Gao, Huangyu Dai, Wen Jiang, Wei Ning, Shanqing Yu, Libin Yang, Xiaoyan Cai"},{"id":"2403.03690","slug":"rapidly-developing-high-quality-instruction-data-and-evaluation-benchmark-for-large-language-models-with-minimal-human-effort-a-case-study-on-japanese","title":"Rapidly Developing High-quality Instruction Data and Evaluation Benchmark for Large Language Models with Minimal Human Effort: A Case Study on Japanese","link":"https://arxiv.org/abs/2403.03690","abstract":"arXiv:2403.03690v1 Announce Type: cross  Abstract: The creation of instruction data and evaluation benchmarks for serving Large language models often involves enormous human annotation. This issue becomes particularly pronounced when rapidly developing such resources for a non-English language like Japanese. Instead of following the popular practice of directly translating existing English resources into Japanese (e.g., Japanese-Alpaca), we propose an efficient self-instruct method based on GPT-4. We first translate a small amount of English instructions into Japanese and post-edit them to obtain native-level quality. GPT-4 then utilizes them as demonstrations to automatically generate Japanese instruction data. We also construct an evaluation benchmark containing 80 questions across 8 categories, using GPT-4 to automatically assess the response quality of LLMs without human references. The empirical results suggest that the models fine-tuned on our GPT-4 self-instruct data significantly outperformed the Japanese-Alpaca across all three base pre-trained models. Our GPT-4 self-instruct data allowed the LLaMA 13B model to defeat GPT-3.5 (Davinci-003) with a 54.37\\% win-rate. The human evaluation exhibits the consistency between GPT-4's assessments and human preference. Our high-quality instruction data and evaluation benchmark have been released here.","creator":"Yikun Sun, Zhen Wan, Nobuhiro Ueda, Sakiko Yahata, Fei Cheng, Chenhui Chu, Sadao Kurohashi"},{"id":"2403.03691","slug":"molnextr-a-generalized-deep-learning-model-for-molecular-image-recognition","title":"MolNexTR: A Generalized Deep Learning Model for Molecular Image Recognition","link":"https://arxiv.org/abs/2403.03691","abstract":"arXiv:2403.03691v1 Announce Type: cross  Abstract: In the field of chemical structure recognition, the task of converting molecular images into graph structures and SMILES string stands as a significant challenge, primarily due to the varied drawing styles and conventions prevalent in chemical literature. To bridge this gap, we proposed MolNexTR, a novel image-to-graph deep learning model that collaborates to fuse the strengths of ConvNext, a powerful Convolutional Neural Network variant, and Vision-TRansformer. This integration facilitates a more nuanced extraction of both local and global features from molecular images. MolNexTR can predict atoms and bonds simultaneously and understand their layout rules. It also excels at flexibly integrating symbolic chemistry principles to discern chirality and decipher abbreviated structures. We further incorporate a series of advanced algorithms, including improved data augmentation module, image contamination module, and a post-processing module to get the final SMILES output. These modules synergistically enhance the model's robustness against the diverse styles of molecular imagery found in real literature. In our test sets, MolNexTR has demonstrated superior performance, achieving an accuracy rate of 81-97%, marking a significant advancement in the domain of molecular structure recognition. Scientific contribution: MolNexTR is a novel image-to-graph model that incorporates a unique dual-stream encoder to extract complex molecular image features, and combines chemical rules to predict atoms and bonds while understanding atom and bond layout rules. In addition, it employs a series of novel augmentation algorithms to significantly enhance the robustness and performance of the model.","creator":"Yufan Chen, Ching Ting Leung, Yong Huang, Jianwei Sun, Hao Chen, Hanyu Gao"},{"id":"2403.03698","slug":"towards-controllable-time-series-generation","title":"Towards Controllable Time Series Generation","link":"https://arxiv.org/abs/2403.03698","abstract":"arXiv:2403.03698v1 Announce Type: cross  Abstract: Time Series Generation (TSG) has emerged as a pivotal technique in synthesizing data that accurately mirrors real-world time series, becoming indispensable in numerous applications. Despite significant advancements in TSG, its efficacy frequently hinges on having large training datasets. This dependency presents a substantial challenge in data-scarce scenarios, especially when dealing with rare or unique conditions. To confront these challenges, we explore a new problem of Controllable Time Series Generation (CTSG), aiming to produce synthetic time series that can adapt to various external conditions, thereby tackling the data scarcity issue.   In this paper, we propose \\textbf{C}ontrollable \\textbf{T}ime \\textbf{S}eries (\\textsf{CTS}), an innovative VAE-agnostic framework tailored for CTSG. A key feature of \\textsf{CTS} is that it decouples the mapping process from standard VAE training, enabling precise learning of a complex interplay between latent features and external conditions. Moreover, we develop a comprehensive evaluation scheme for CTSG. Extensive experiments across three real-world time series datasets showcase \\textsf{CTS}'s exceptional capabilities in generating high-quality, controllable outputs. This underscores its adeptness in seamlessly integrating latent features with external conditions. Extending \\textsf{CTS} to the image domain highlights its remarkable potential for explainability and further reinforces its versatility across different modalities.","creator":"Yifan Bao, Yihao Ang, Qiang Huang, Anthony K. H. Tung, Zhiyong Huang"},{"id":"2403.03726","slug":"diffusion-on-language-model-embeddings-for-protein-sequence-generation","title":"Diffusion on language model embeddings for protein sequence generation","link":"https://arxiv.org/abs/2403.03726","abstract":"arXiv:2403.03726v1 Announce Type: cross  Abstract: Protein design requires a deep understanding of the inherent complexities of the protein universe. While many efforts lean towards conditional generation or focus on specific families of proteins, the foundational task of unconditional generation remains underexplored and undervalued. Here, we explore this pivotal domain, introducing DiMA, a model that leverages continuous diffusion on embeddings derived from the protein language model, ESM-2, to generate amino acid sequences. DiMA surpasses leading solutions, including autoregressive transformer-based and discrete diffusion models, and we quantitatively illustrate the impact of the design choices that lead to its superior performance. We extensively evaluate the quality, diversity, distribution similarity, and biological relevance of the generated sequences using multiple metrics across various modalities. Our approach consistently produces novel, diverse protein sequences that accurately reflect the inherent structural and functional diversity of the protein space. This work advances the field of protein design and sets the stage for conditional models by providing a robust framework for scalable and high-quality protein sequence generation.","creator":"Viacheslav Meshchaninov, Pavel Strashnov, Andrey Shevtsov, Fedor Nikolaev, Nikita Ivanisenko, Olga Kardymon, Dmitry Vetrov"},{"id":"2403.03728","slug":"bridging-diversity-and-uncertainty-in-active-learning-with-self-supervised-pre-training","title":"Bridging Diversity and Uncertainty in Active learning with Self-Supervised Pre-Training","link":"https://arxiv.org/abs/2403.03728","abstract":"arXiv:2403.03728v1 Announce Type: cross  Abstract: This study addresses the integration of diversity-based and uncertainty-based sampling strategies in active learning, particularly within the context of self-supervised pre-trained models. We introduce a straightforward heuristic called TCM that mitigates the cold start problem while maintaining strong performance across various data levels. By initially applying TypiClust for diversity sampling and subsequently transitioning to uncertainty sampling with Margin, our approach effectively combines the strengths of both strategies. Our experiments demonstrate that TCM consistently outperforms existing methods across various datasets in both low and high data regimes.","creator":"Paul Doucet, Benjamin Estermann, Till Aczel, Roger Wattenhofer"},{"id":"2403.03730","slug":"learning-3d-object-centric-representation-through-prediction","title":"Learning 3D object-centric representation through prediction","link":"https://arxiv.org/abs/2403.03730","abstract":"arXiv:2403.03730v1 Announce Type: cross  Abstract: As part of human core knowledge, the representation of objects is the building block of mental representation that supports high-level concepts and symbolic reasoning. While humans develop the ability of perceiving objects situated in 3D environments without supervision, models that learn the same set of abilities with similar constraints faced by human infants are lacking. Towards this end, we developed a novel network architecture that simultaneously learns to 1) segment objects from discrete images, 2) infer their 3D locations, and 3) perceive depth, all while using only information directly available to the brain as training data, namely: sequences of images and self-motion. The core idea is treating objects as latent causes of visual input which the brain uses to make efficient predictions of future scenes. This results in object representations being learned as an essential byproduct of learning to predict.","creator":"John Day, Tushar Arora, Jirui Liu, Li Erran Li, Ming Bo Cai"},{"id":"2403.03739","slug":"a-b-bnn-add-bit-operation-only-hardware-friendly-binary-neural-network","title":"A&B BNN: Add&Bit-Operation-Only Hardware-Friendly Binary Neural Network","link":"https://arxiv.org/abs/2403.03739","abstract":"arXiv:2403.03739v1 Announce Type: cross  Abstract: Binary neural networks utilize 1-bit quantized weights and activations to reduce both the model's storage demands and computational burden. However, advanced binary architectures still incorporate millions of inefficient and nonhardware-friendly full-precision multiplication operations. A&B BNN is proposed to directly remove part of the multiplication operations in a traditional BNN and replace the rest with an equal number of bit operations, introducing the mask layer and the quantized RPReLU structure based on the normalizer-free network architecture. The mask layer can be removed during inference by leveraging the intrinsic characteristics of BNN with straightforward mathematical transformations to avoid the associated multiplication operations. The quantized RPReLU structure enables more efficient bit operations by constraining its slope to be integer powers of 2. Experimental results achieved 92.30%, 69.35%, and 66.89% on the CIFAR-10, CIFAR-100, and ImageNet datasets, respectively, which are competitive with the state-of-the-art. Ablation studies have verified the efficacy of the quantized RPReLU structure, leading to a 1.14% enhancement on the ImageNet compared to using a fixed slope RLeakyReLU. The proposed add&bit-operation-only BNN offers an innovative approach for hardware-friendly network architecture.","creator":"Ruichen Ma, Guanchao Qiao, Yian Liu, Liwei Meng, Ning Ning, Yang Liu, Shaogang Hu"},{"id":"2403.03741","slug":"supclust-active-learning-at-the-boundaries","title":"SUPClust: Active Learning at the Boundaries","link":"https://arxiv.org/abs/2403.03741","abstract":"arXiv:2403.03741v1 Announce Type: cross  Abstract: Active learning is a machine learning paradigm designed to optimize model performance in a setting where labeled data is expensive to acquire. In this work, we propose a novel active learning method called SUPClust that seeks to identify points at the decision boundary between classes. By targeting these points, SUPClust aims to gather information that is most informative for refining the model's prediction of complex decision regions. We demonstrate experimentally that labeling these points leads to strong model performance. This improvement is observed even in scenarios characterized by strong class imbalance.","creator":"Yuta Ono, Till Aczel, Benjamin Estermann, Roger Wattenhofer"},{"id":"2403.03750","slug":"german-also-hallucinates-inconsistency-detection-in-news-summaries-with-the-absinth-dataset","title":"German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset","link":"https://arxiv.org/abs/2403.03750","abstract":"arXiv:2403.03750v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) has led to remarkable progress on a wide range of natural language processing tasks. Despite the advances, these large-sized models still suffer from hallucinating information in their output, which poses a major issue in automatic text summarization, as we must guarantee that the generated summary is consistent with the content of the source document. Previous research addresses the challenging task of detecting hallucinations in the output (i.e. inconsistency detection) in order to evaluate the faithfulness of the generated summaries. However, these works primarily focus on English and recent multilingual approaches lack German data. This work presents absinth, a manually annotated dataset for hallucination detection in German news summarization and explores the capabilities of novel open-source LLMs on this task in both fine-tuning and in-context learning settings. We open-source and release the absinth dataset to foster further research on hallucination detection in German.","creator":"Laura Mascarell, Ribin Chalumattu, Annette Rios"},{"id":"2403.03777","slug":"enot-expectile-regularization-for-fast-and-accurate-training-of-neural-optimal-transport","title":"ENOT: Expectile Regularization for Fast and Accurate Training of Neural Optimal Transport","link":"https://arxiv.org/abs/2403.03777","abstract":"arXiv:2403.03777v1 Announce Type: cross  Abstract: We present a new extension for Neural Optimal Transport (NOT) training procedure, capable of accurately and efficiently estimating optimal transportation plan via specific regularisation on conjugate potentials. The main bottleneck of existing NOT solvers is associated with the procedure of finding a near-exact approximation of the conjugate operator (i.e., the c-transform), which is done either by optimizing over maximin objectives or by the computationally-intensive fine-tuning of the initial approximated prediction. We resolve both issues by proposing a new, theoretically justified loss in the form of expectile regularization that enforces binding conditions on the learning dual potentials. Such a regularization provides the upper bound estimation over the distribution of possible conjugate potentials and makes the learning stable, eliminating the need for additional extensive finetuning. We formally justify the efficiency of our method, called Expectile-Regularised Neural Optimal Transport (ENOT). ENOT outperforms previous state-of-the-art approaches on the Wasserstein-2 benchmark tasks by a large margin (up to a 3-fold improvement in quality and up to a 10-fold improvement in runtime).","creator":"Nazar Buzun, Maksim Bobrin, Dmitry V. Dylov"},{"id":"2403.03781","slug":"neural-architecture-search-using-particle-swarm-and-ant-colony-optimization","title":"Neural Architecture Search using Particle Swarm and Ant Colony Optimization","link":"https://arxiv.org/abs/2403.03781","abstract":"arXiv:2403.03781v1 Announce Type: cross  Abstract: Neural network models have a number of hyperparameters that must be chosen along with their architecture. This can be a heavy burden on a novice user, choosing which architecture and what values to assign to parameters. In most cases, default hyperparameters and architectures are used. Significant improvements to model accuracy can be achieved through the evaluation of multiple architectures. A process known as Neural Architecture Search (NAS) may be applied to automatically evaluate a large number of such architectures. A system integrating open source tools for Neural Architecture Search (OpenNAS), in the classification of images, has been developed as part of this research. OpenNAS takes any dataset of grayscale, or RBG images, and generates Convolutional Neural Network (CNN) architectures based on a range of metaheuristics using either an AutoKeras, a transfer learning or a Swarm Intelligence (SI) approach. Particle Swarm Optimization (PSO) and Ant Colony Optimization (ACO) are used as the SI algorithms. Furthermore, models developed through such metaheuristics may be combined using stacking ensembles. In the context of this paper, we focus on training and optimizing CNNs using the Swarm Intelligence (SI) components of OpenNAS. Two major types of SI algorithms, namely PSO and ACO, are compared to see which is more effective in generating higher model accuracies. It is shown, with our experimental design, that the PSO algorithm performs better than ACO. The performance improvement of PSO is most notable with a more complex dataset. As a baseline, the performance of fine-tuned pre-trained models is also evaluated.","creator":"S\\'eamus Lankford, Diarmuid Grimes"},{"id":"2403.03791","slug":"kg-treat-pre-training-for-treatment-effect-estimation-by-synergizing-patient-data-with-knowledge-graphs","title":"KG-TREAT: Pre-training for Treatment Effect Estimation by Synergizing Patient Data with Knowledge Graphs","link":"https://arxiv.org/abs/2403.03791","abstract":"arXiv:2403.03791v1 Announce Type: cross  Abstract: Treatment effect estimation (TEE) is the task of determining the impact of various treatments on patient outcomes. Current TEE methods fall short due to reliance on limited labeled data and challenges posed by sparse and high-dimensional observational patient data. To address the challenges, we introduce a novel pre-training and fine-tuning framework, KG-TREAT, which synergizes large-scale observational patient data with biomedical knowledge graphs (KGs) to enhance TEE. Unlike previous approaches, KG-TREAT constructs dual-focus KGs and integrates a deep bi-level attention synergy method for in-depth information fusion, enabling distinct encoding of treatment-covariate and outcome-covariate relationships. KG-TREAT also incorporates two pre-training tasks to ensure a thorough grounding and contextualization of patient data and KGs. Evaluation on four downstream TEE tasks shows KG-TREAT's superiority over existing methods, with an average improvement of 7% in Area under the ROC Curve (AUC) and 9% in Influence Function-based Precision of Estimating Heterogeneous Effects (IF-PEHE). The effectiveness of our estimated treatment effects is further affirmed by alignment with established randomized clinical trial findings.","creator":"Ruoqi Liu, Lingfei Wu, Ping Zhang"},{"id":"2403.03808","slug":"confidence-aware-decision-making-and-control-for-tool-selection","title":"Confidence-Aware Decision-Making and Control for Tool Selection","link":"https://arxiv.org/abs/2403.03808","abstract":"arXiv:2403.03808v1 Announce Type: cross  Abstract: Self-reflecting about our performance (e.g., how confident we are) before doing a task is essential for decision making, such as selecting the most suitable tool or choosing the best route to drive. While this form of awareness -- thinking about our performance or metacognitive performance -- is well-known in humans, robots still lack this cognitive ability. This reflective monitoring can enhance their embodied decision power, robustness and safety. Here, we take a step in this direction by introducing a mathematical framework that allows robots to use their control self-confidence to make better-informed decisions. We derive a mathematical closed-form expression for control confidence for dynamic systems (i.e., the posterior inverse covariance of the control action). This control confidence seamlessly integrates within an objective function for decision making, that balances the: i) performance for task completion, ii) control effort, and iii) self-confidence. To evaluate our theoretical account, we framed the decision-making within the tool selection problem, where the agent has to select the best robot arm for a particular control task. The statistical analysis of the numerical simulations with randomized 2DOF arms shows that using control confidence during tool selection improves both real task performance, and the reliability of the tool for performance under unmodelled perturbations (e.g., external forces). Furthermore, our results indicate that control confidence is an early indicator of performance and thus, it can be used as a heuristic for making decisions when computation power is restricted or decision-making is intractable. Overall, we show the advantages of using confidence-aware decision-making and control scheme for dynamic systems.","creator":"Ajith Anil Meera, Pablo Lanillos"},{"id":"2403.03812","slug":"probsaint-probabilistic-tabular-regression-for-used-car-pricing","title":"ProbSAINT: Probabilistic Tabular Regression for Used Car Pricing","link":"https://arxiv.org/abs/2403.03812","abstract":"arXiv:2403.03812v1 Announce Type: cross  Abstract: Used car pricing is a critical aspect of the automotive industry, influenced by many economic factors and market dynamics. With the recent surge in online marketplaces and increased demand for used cars, accurate pricing would benefit both buyers and sellers by ensuring fair transactions. However, the transition towards automated pricing algorithms using machine learning necessitates the comprehension of model uncertainties, specifically the ability to flag predictions that the model is unsure about. Although recent literature proposes the use of boosting algorithms or nearest neighbor-based approaches for swift and precise price predictions, encapsulating model uncertainties with such algorithms presents a complex challenge. We introduce ProbSAINT, a model that offers a principled approach for uncertainty quantification of its price predictions, along with accurate point predictions that are comparable to state-of-the-art boosting techniques. Furthermore, acknowledging that the business prefers pricing used cars based on the number of days the vehicle was listed for sale, we show how ProbSAINT can be used as a dynamic forecasting model for predicting price probabilities for different expected offer duration. Our experiments further indicate that ProbSAINT is especially accurate on instances where it is highly certain. This proves the applicability of its probabilistic predictions in real-world scenarios where trustworthiness is crucial.","creator":"Kiran Madhusudhanan, Gunnar Behrens, Maximilian Stubbemann, Lars Schmidt-Thieme"},{"id":"2403.03814","slug":"evaluating-the-elementary-multilingual-capabilities-of-large-language-models-with-multiq","title":"Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ","link":"https://arxiv.org/abs/2403.03814","abstract":"arXiv:2403.03814v1 Announce Type: cross  Abstract: Large language models (LLMs) need to serve everyone, including a global majority of non-English speakers. However, most LLMs today, and open LLMs in particular, are often intended for use in just English (e.g. Llama2, Mistral) or a small handful of high-resource languages (e.g. Mixtral, Qwen). Recent research shows that, despite limits in their intended use, people prompt LLMs in many different languages. Therefore, in this paper, we investigate the basic multilingual capabilities of state-of-the-art open LLMs beyond their intended use. For this purpose, we introduce MultiQ, a new silver standard benchmark for basic open-ended question answering with 27.4k test questions across a typologically diverse set of 137 languages. With MultiQ, we evaluate language fidelity, i.e.\\ whether models respond in the prompted language, and question answering accuracy. All LLMs we test respond faithfully and/or accurately for at least some languages beyond their intended use. Most models are more accurate when they respond faithfully. However, differences across models are large, and there is a long tail of languages where models are neither accurate nor faithful. We explore differences in tokenization as a potential explanation for our findings, identifying possible correlations that warrant further investigation.","creator":"Carolin Holtermann, Paul R\\\"ottger, Timm Dill, Anne Lauscher"},{"id":"2403.03835","slug":"cobweb-an-incremental-and-hierarchical-model-of-human-like-category-learning","title":"Cobweb: An Incremental and Hierarchical Model of Human-Like Category Learning","link":"https://arxiv.org/abs/2403.03835","abstract":"arXiv:2403.03835v1 Announce Type: cross  Abstract: Cobweb, a human like category learning system, differs from other incremental categorization models in constructing hierarchically organized cognitive tree-like structures using the category utility measure. Prior studies have shown that Cobweb can capture psychological effects such as the basic level, typicality, and fan effects. However, a broader evaluation of Cobweb as a model of human categorization remains lacking. The current study addresses this gap. It establishes Cobweb's alignment with classical human category learning effects. It also explores Cobweb's flexibility to exhibit both exemplar and prototype like learning within a single model. These findings set the stage for future research on Cobweb as a comprehensive model of human category learning.","creator":"Xin Lian, Sashank Varma, Christopher J. MacLellan"},{"id":"2403.03852","slug":"accelerating-convergence-of-score-based-diffusion-models-provably","title":"Accelerating Convergence of Score-Based Diffusion Models, Provably","link":"https://arxiv.org/abs/2403.03852","abstract":"arXiv:2403.03852v1 Announce Type: cross  Abstract: Score-based diffusion models, while achieving remarkable empirical performance, often suffer from low sampling speed, due to extensive function evaluations needed during the sampling phase. Despite a flurry of recent activities towards speeding up diffusion generative modeling in practice, theoretical underpinnings for acceleration techniques remain severely limited. In this paper, we design novel training-free algorithms to accelerate popular deterministic (i.e., DDIM) and stochastic (i.e., DDPM) samplers. Our accelerated deterministic sampler converges at a rate $O(1/{T}^2)$ with $T$ the number of steps, improving upon the $O(1/T)$ rate for the DDIM sampler; and our accelerated stochastic sampler converges at a rate $O(1/T)$, outperforming the rate $O(1/\\sqrt{T})$ for the DDPM sampler. The design of our algorithms leverages insights from higher-order approximation, and shares similar intuitions as popular high-order ODE solvers like the DPM-Solver-2. Our theory accommodates $\\ell_2$-accurate score estimates, and does not require log-concavity or smoothness on the target distribution.","creator":"Gen Li, Yu Huang, Timofey Efimov, Yuting Wei, Yuejie Chi, Yuxin Chen"},{"id":"2403.03864","slug":"are-language-models-puzzle-prodigies-algorithmic-puzzles-unveil-serious-challenges-in-multimodal-reasoning","title":"Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious Challenges in Multimodal Reasoning","link":"https://arxiv.org/abs/2403.03864","abstract":"arXiv:2403.03864v1 Announce Type: cross  Abstract: This paper introduces the novel task of multimodal puzzle solving, framed within the context of visual question-answering. We present a new dataset, AlgoPuzzleVQA designed to challenge and evaluate the capabilities of multimodal language models in solving algorithmic puzzles that necessitate both visual understanding, language understanding, and complex algorithmic reasoning. We create the puzzles to encompass a diverse array of mathematical and algorithmic topics such as boolean logic, combinatorics, graph theory, optimization, search, etc., aiming to evaluate the gap between visual data interpretation and algorithmic problem-solving skills. The dataset is generated automatically from code authored by humans. All our puzzles have exact solutions that can be found from the algorithm without tedious human calculations. It ensures that our dataset can be scaled up arbitrarily in terms of reasoning complexity and dataset size. Our investigation reveals that large language models (LLMs) such as GPT4V and Gemini exhibit limited performance in puzzle-solving tasks. We find that their performance is near random in a multi-choice question-answering setup for a significant number of puzzles. The findings emphasize the challenges of integrating visual, language, and algorithmic knowledge for solving complex reasoning problems.","creator":"Deepanway Ghosal, Vernon Toh Yan Han, Chia Yew Ken, Soujanya Poria"},{"id":"2403.03874","slug":"impoverished-language-technology-the-lack-of-social-class-in-nlp","title":"Impoverished Language Technology: The Lack of (Social) Class in NLP","link":"https://arxiv.org/abs/2403.03874","abstract":"arXiv:2403.03874v1 Announce Type: cross  Abstract: Since Labov's (1964) foundational work on the social stratification of language, linguistics has dedicated concerted efforts towards understanding the relationships between socio-demographic factors and language production and perception. Despite the large body of evidence identifying significant relationships between socio-demographic factors and language production, relatively few of these factors have been investigated in the context of NLP technology. While age and gender are well covered, Labov's initial target, socio-economic class, is largely absent. We survey the existing Natural Language Processing (NLP) literature and find that only 20 papers even mention socio-economic status. However, the majority of those papers do not engage with class beyond collecting information of annotator-demographics. Given this research lacuna, we provide a definition of class that can be operationalised by NLP researchers, and argue for including socio-economic class in future language technologies.","creator":"Amanda Cercas Curry, Zeerak Talat, Dirk Hovy"},{"id":"2403.03879","slug":"redefining-cystoscopy-with-ai-bladder-cancer-diagnosis-using-an-efficient-hybrid-cnn-transformer-model","title":"Redefining cystoscopy with ai: bladder cancer diagnosis using an efficient hybrid cnn-transformer model","link":"https://arxiv.org/abs/2403.03879","abstract":"arXiv:2403.03879v1 Announce Type: cross  Abstract: Bladder cancer ranks within the top 10 most diagnosed cancers worldwide and is among the most expensive cancers to treat due to the high recurrence rates which require lifetime follow-ups. The primary tool for diagnosis is cystoscopy, which heavily relies on doctors' expertise and interpretation. Therefore, annually, numerous cases are either undiagnosed or misdiagnosed and treated as urinary infections. To address this, we suggest a deep learning approach for bladder cancer detection and segmentation which combines CNNs with a lightweight positional-encoding-free transformer and dual attention gates that fuse self and spatial attention for feature enhancement. The architecture suggested in this paper is efficient making it suitable for medical scenarios that require real time inference. Experiments have proven that this model addresses the critical need for a balance between computational efficiency and diagnostic accuracy in cystoscopic imaging as despite its small size it rivals large models in performance.","creator":"Meryem Amaouche, Ouassim Karrakchou, Mounir Ghogho, Anouar El Ghazzaly, Mohamed Alami, Ahmed Ameur"},{"id":"2403.03881","slug":"latent-dataset-distillation-with-diffusion-models","title":"Latent Dataset Distillation with Diffusion Models","link":"https://arxiv.org/abs/2403.03881","abstract":"arXiv:2403.03881v1 Announce Type: cross  Abstract: The efficacy of machine learning has traditionally relied on the availability of increasingly larger datasets. However, large datasets pose storage challenges and contain non-influential samples, which could be ignored during training without impacting the final accuracy of the model. In response to these limitations, the concept of distilling the information on a dataset into a condensed set of (synthetic) samples, namely a distilled dataset, emerged. One crucial aspect is the selected architecture (usually ConvNet) for linking the original and synthetic datasets. However, the final accuracy is lower if the employed model architecture differs from the model used during distillation. Another challenge is the generation of high-resolution images, e.g., 128x128 and higher. In this paper, we propose Latent Dataset Distillation with Diffusion Models (LD3M) that combine diffusion in latent space with dataset distillation to tackle both challenges. LD3M incorporates a novel diffusion process tailored for dataset distillation, which improves the gradient norms for learning synthetic images. By adjusting the number of diffusion steps, LD3M also offers a straightforward way of controlling the trade-off between speed and accuracy. We evaluate our approach in several ImageNet subsets and for high-resolution images (128x128 and 256x256). As a result, LD3M consistently outperforms state-of-the-art distillation techniques by up to 4.8 p.p. and 4.2 p.p. for 1 and 10 images per class, respectively.","creator":"Brian B. Moser, Federico Raue, Sebastian Palacio, Stanislav Frolov, Andreas Dengel"},{"id":"2403.03890","slug":"hierarchical-diffusion-policy-for-kinematics-aware-multi-task-robotic-manipulation","title":"Hierarchical Diffusion Policy for Kinematics-Aware Multi-Task Robotic Manipulation","link":"https://arxiv.org/abs/2403.03890","abstract":"arXiv:2403.03890v1 Announce Type: cross  Abstract: This paper introduces Hierarchical Diffusion Policy (HDP), a hierarchical agent for multi-task robotic manipulation. HDP factorises a manipulation policy into a hierarchical structure: a high-level task-planning agent which predicts a distant next-best end-effector pose (NBP), and a low-level goal-conditioned diffusion policy which generates optimal motion trajectories. The factorised policy representation allows HDP to tackle both long-horizon task planning while generating fine-grained low-level actions. To generate context-aware motion trajectories while satisfying robot kinematics constraints, we present a novel kinematics-aware goal-conditioned control agent, Robot Kinematics Diffuser (RK-Diffuser). Specifically, RK-Diffuser learns to generate both the end-effector pose and joint position trajectories, and distill the accurate but kinematics-unaware end-effector pose diffuser to the kinematics-aware but less accurate joint position diffuser via differentiable kinematics. Empirically, we show that HDP achieves a significantly higher success rate than the state-of-the-art methods in both simulation and real-world.","creator":"Xiao Ma, Sumit Patidar, Iain Haughton, Stephen James"},{"id":"2403.03893","slug":"from-one-to-many-expanding-the-scope-of-toxicity-mitigation-in-language-models","title":"From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models","link":"https://arxiv.org/abs/2403.03893","abstract":"arXiv:2403.03893v1 Announce Type: cross  Abstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it's crucial our safety measures keep pace. Recognizing this research gap, our approach expands the scope of conventional toxicity mitigation to address the complexities presented by multiple languages. In the absence of sufficient annotated datasets across languages, we employ translated data to evaluate and enhance our mitigation techniques. We also compare finetuning mitigation approaches against retrieval-augmented techniques under both static and continual toxicity mitigation scenarios. This allows us to examine the effects of translation quality and the cross-lingual transfer on toxicity mitigation. We also explore how model size and data quantity affect the success of these mitigation efforts. Covering nine languages, our study represents a broad array of linguistic families and levels of resource availability, ranging from high to mid-resource languages. Through comprehensive experiments, we provide insights into the complexities of multilingual toxicity mitigation, offering valuable insights and paving the way for future research in this increasingly important field. Code and data are available at https://github.com/for-ai/goodtriever.","creator":"Luiza Pozzobon, Patrick Lewis, Sara Hooker, Beyza Ermis"},{"id":"2403.03925","slug":"consciousness-qua-mortal-computation","title":"Consciousness qua Mortal Computation","link":"https://arxiv.org/abs/2403.03925","abstract":"arXiv:2403.03925v1 Announce Type: cross  Abstract: Computational functionalism posits that consciousness is a computation. Here we show, perhaps surprisingly, that it cannot be a Turing computation. Rather, computational functionalism implies that consciousness is a novel type of computation that has recently been proposed by Geoffrey Hinton, called mortal computation.","creator":"Johannes Kleiner"},{"id":"2403.03929","slug":"extreme-precipitation-nowcasting-using-transformer-based-generative-models","title":"Extreme Precipitation Nowcasting using Transformer-based Generative Models","link":"https://arxiv.org/abs/2403.03929","abstract":"arXiv:2403.03929v1 Announce Type: cross  Abstract: This paper presents an innovative approach to extreme precipitation nowcasting by employing Transformer-based generative models, namely NowcastingGPT with Extreme Value Loss (EVL) regularization. Leveraging a comprehensive dataset from the Royal Netherlands Meteorological Institute (KNMI), our study focuses on predicting short-term precipitation with high accuracy. We introduce a novel method for computing EVL without assuming fixed extreme representations, addressing the limitations of current models in capturing extreme weather events. We present both qualitative and quantitative analyses, demonstrating the superior performance of the proposed NowcastingGPT-EVL in generating accurate precipitation forecasts, especially when dealing with extreme precipitation events. The code is available at \\url{https://github.com/Cmeo97/NowcastingGPT}.","creator":"Cristian Meo, Ankush Roy, Mircea Lic\\u{a}, Junzhe Yin, Zeineb Bou Che, Yanbo Wang, Ruben Imhoff, Remko Uijlenhoet, Justin Dauwels"},{"id":"2403.03949","slug":"reconciling-reality-through-simulation-a-real-to-sim-to-real-approach-for-robust-manipulation","title":"Reconciling Reality through Simulation: A Real-to-Sim-to-Real Approach for Robust Manipulation","link":"https://arxiv.org/abs/2403.03949","abstract":"arXiv:2403.03949v1 Announce Type: cross  Abstract: Imitation learning methods need significant human supervision to learn policies robust to changes in object poses, physical disturbances, and visual distractors. Reinforcement learning, on the other hand, can explore the environment autonomously to learn robust behaviors but may require impractical amounts of unsafe real-world data collection. To learn performant, robust policies without the burden of unsafe real-world data collection or extensive human supervision, we propose RialTo, a system for robustifying real-world imitation learning policies via reinforcement learning in \"digital twin\" simulation environments constructed on the fly from small amounts of real-world data. To enable this real-to-sim-to-real pipeline, RialTo proposes an easy-to-use interface for quickly scanning and constructing digital twins of real-world environments. We also introduce a novel \"inverse distillation\" procedure for bringing real-world demonstrations into simulated environments for efficient fine-tuning, with minimal human intervention and engineering required. We evaluate RialTo across a variety of robotic manipulation problems in the real world, such as robustly stacking dishes on a rack, placing books on a shelf, and six other tasks. RialTo increases (over 67%) in policy robustness without requiring extensive human data collection. Project website and videos at https://real-to-sim-to-real.github.io/RialTo/","creator":"Marcel Torne, Anthony Simeonov, Zechu Li, April Chan, Tao Chen, Abhishek Gupta, Pulkit Agrawal"},{"id":"2403.03950","slug":"stop-regressing-training-value-functions-via-classification-for-scalable-deep-rl","title":"Stop Regressing: Training Value Functions via Classification for Scalable Deep RL","link":"https://arxiv.org/abs/2403.03950","abstract":"arXiv:2403.03950v1 Announce Type: cross  Abstract: Value functions are a central component of deep reinforcement learning (RL). These functions, parameterized by neural networks, are trained using a mean squared error regression objective to match bootstrapped target values. However, scaling value-based RL methods that use regression to large networks, such as high-capacity Transformers, has proven challenging. This difficulty is in stark contrast to supervised learning: by leveraging a cross-entropy classification loss, supervised methods have scaled reliably to massive networks. Observing this discrepancy, in this paper, we investigate whether the scalability of deep RL can also be improved simply by using classification in place of regression for training value functions. We demonstrate that value functions trained with categorical cross-entropy significantly improves performance and scalability in a variety of domains. These include: single-task RL on Atari 2600 games with SoftMoEs, multi-task RL on Atari with large-scale ResNets, robotic manipulation with Q-transformers, playing Chess without search, and a language-agent Wordle task with high-capacity Transformers, achieving state-of-the-art results on these domains. Through careful analysis, we show that the benefits of categorical cross-entropy primarily stem from its ability to mitigate issues inherent to value-based RL, such as noisy targets and non-stationarity. Overall, we argue that a simple shift to training value functions with categorical cross-entropy can yield substantial improvements in the scalability of deep RL at little-to-no cost.","creator":"Jesse Farebrother, Jordi Orbay, Quan Vuong, Adrien Ali Ta\\\"iga, Yevgen Chebotar, Ted Xiao, Alex Irpan, Sergey Levine, Pablo Samuel Castro, Aleksandra Faust, Aviral Kumar, Rishabh Agarwal"},{"id":"2211.11940","slug":"decision-making-with-speculative-opponent-models","title":"Decision-making with Speculative Opponent Models","link":"https://arxiv.org/abs/2211.11940","abstract":"arXiv:2211.11940v2 Announce Type: replace  Abstract: Opponent modeling has benefited a controlled agent's decision-making by constructing models of other agents. Existing methods commonly assume access to opponents' observations and actions, which is infeasible when opponents' behaviors are unobservable or hard to obtain. We propose a novel multi-agent distributional actor-critic algorithm to achieve speculative opponent modeling with purely local information (i.e., the controlled agent's observations, actions, and rewards). Specifically, the actor maintains a speculated belief of the opponents, which we call the speculative opponent models, to predict opponent actions using local observations and makes decisions accordingly. Further, the distributional critic models the return distribution of the policy. It reflects the quality of the actor and thus can guide the training of the speculative opponent model that the actor relies on. Extensive experiments confirm that our method successfully models opponents' behaviors without their data and delivers superior performance against baseline methods with a faster convergence speed.","creator":"Jing Sun, Shuo Chen, Cong Zhang, Jie Zhang"},{"id":"2307.08424","slug":"unstoppable-attack-label-only-model-inversion-via-conditional-diffusion-model","title":"Unstoppable Attack: Label-Only Model Inversion via Conditional Diffusion Model","link":"https://arxiv.org/abs/2307.08424","abstract":"arXiv:2307.08424v3 Announce Type: replace  Abstract: Model inversion attacks (MIAs) aim to recover private data from inaccessible training sets of deep learning models, posing a privacy threat. MIAs primarily focus on the white-box scenario where attackers have full access to the model's structure and parameters. However, practical applications are usually in black-box scenarios or label-only scenarios, i.e., the attackers can only obtain the output confidence vectors or labels by accessing the model. Therefore, the attack models in existing MIAs are difficult to effectively train with the knowledge of the target model, resulting in sub-optimal attacks. To the best of our knowledge, we pioneer the research of a powerful and practical attack model in the label-only scenario.   In this paper, we develop a novel MIA method, leveraging a conditional diffusion model (CDM) to recover representative samples under the target label from the training set. Two techniques are introduced: selecting an auxiliary dataset relevant to the target model task and using predicted labels as conditions to guide training CDM; and inputting target label, pre-defined guidance strength, and random noise into the trained attack model to generate and correct multiple results for final selection. This method is evaluated using Learned Perceptual Image Patch Similarity as a new metric and as a judgment basis for deciding the values of hyper-parameters. Experimental results show that this method can generate similar and accurate samples to the target label, outperforming generators of previous approaches.","creator":"Rongke Liu, Dong Wang, Yizhi Ren, Zhen Wang, Kaitian Guo, Qianqian Qin, Xiaolei Liu"},{"id":"2308.01154","slug":"arithmetic-with-language-models-from-memorization-to-computation","title":"Arithmetic with Language Models: from Memorization to Computation","link":"https://arxiv.org/abs/2308.01154","abstract":"arXiv:2308.01154v3 Announce Type: replace  Abstract: A better understanding of the emergent computation and problem-solving capabilities of recent large language models is of paramount importance to further improve them and broaden their applicability. This work investigates how a language model, trained to predict the next token, can perform arithmetic computations generalizing beyond training data. Binary addition and multiplication constitute a good testbed for this purpose, since they require a very small vocabulary and exhibit relevant input/output discontinuities making smooth input interpolation ineffective for novel data. We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing. Our findings support the hypothesis that the language model works as an Encoding-Regression-Decoding machine where the computation takes place in the value space once the input token representation is mapped to an appropriate internal representation.","creator":"Davide Maltoni, Matteo Ferrara"},{"id":"2309.03685","slug":"pygraft-configurable-generation-of-synthetic-schemas-and-knowledge-graphs-at-your-fingertips","title":"PyGraft: Configurable Generation of Synthetic Schemas and Knowledge Graphs at Your Fingertips","link":"https://arxiv.org/abs/2309.03685","abstract":"arXiv:2309.03685v2 Announce Type: replace  Abstract: Knowledge graphs (KGs) have emerged as a prominent data representation and management paradigm. Being usually underpinned by a schema (e.g., an ontology), KGs capture not only factual information but also contextual knowledge. In some tasks, a few KGs established themselves as standard benchmarks. However, recent works outline that relying on a limited collection of datasets is not sufficient to assess the generalization capability of an approach. In some data-sensitive fields such as education or medicine, access to public datasets is even more limited. To remedy the aforementioned issues, we release PyGraft, a Python-based tool that generates highly customized, domain-agnostic schemas and KGs. The synthesized schemas encompass various RDFS and OWL constructs, while the synthesized KGs emulate the characteristics and scale of real-world KGs. Logical consistency of the generated resources is ultimately ensured by running a description logic (DL) reasoner. By providing a way of generating both a schema and KG in a single pipeline, PyGraft's aim is to empower the generation of a more diverse array of KGs for benchmarking novel approaches in areas such as graph-based machine learning (ML), or more generally KG processing. In graph-based ML in particular, this should foster a more holistic evaluation of model performance and generalization capability, thereby going beyond the limited collection of available benchmarks. PyGraft is available at: https://github.com/nicolas-hbt/pygraft.","creator":"Nicolas Hubert, Pierre Monnin, Mathieu d'Aquin, Davy Monticolo, Armelle Brun"},{"id":"2309.16960","slug":"on-generating-explanations-for-reinforcement-learning-policies-an-empirical-study","title":"On Generating Explanations for Reinforcement Learning Policies: An Empirical Study","link":"https://arxiv.org/abs/2309.16960","abstract":"arXiv:2309.16960v2 Announce Type: replace  Abstract: Understanding a \\textit{reinforcement learning} policy, which guides state-to-action mappings to maximize rewards, necessitates an accompanying explanation for human comprehension. In this paper, we introduce a set of \\textit{linear temporal logic} (LTL) formulae designed to provide explanations for policies, and an algorithm for searching through those formulae for the one that best explains a given policy. Our focus is on crafting explanations that elucidate both the ultimate objectives accomplished by the policy and the prerequisite conditions it upholds throughout its execution. These LTL-based explanations feature a structured representation, which is particularly well-suited for local-search techniques. The effectiveness of our proposed approach is illustrated through a simulated game of capture the flag and a car-parking environment. The paper concludes with suggested directions for future","creator":"Mikihisa Yuasa, Huy T. Tran, Ramavarapu S. Sreenivas"},{"id":"2310.00194","slug":"a-prefrontal-cortex-inspired-architecture-for-planning-in-large-language-models","title":"A Prefrontal Cortex-inspired Architecture for Planning in Large Language Models","link":"https://arxiv.org/abs/2310.00194","abstract":"arXiv:2310.00194v3 Announce Type: replace  Abstract: Large language models (LLMs) demonstrate impressive performance on a wide variety of tasks, but they often struggle with tasks that require multi-step reasoning or goal-directed planning. To address this, we take inspiration from the human brain, in which planning is accomplished via the recurrent interaction of specialized modules in the prefrontal cortex (PFC). These modules perform functions such as conflict monitoring, state prediction, state evaluation, task decomposition, and task coordination. We find that LLMs are sometimes capable of carrying out these functions in isolation, but struggle to autonomously coordinate them in the service of a goal. Therefore, we propose a black box architecture with multiple LLM-based (GPT-4) modules. The architecture improves planning through the interaction of specialized PFC-inspired modules that break down a larger problem into multiple brief automated calls to the LLM. We evaluate the combined architecture on three challenging planning tasks -- graph traversal, Tower of Hanoi, and logistics -- finding that it yields significant improvements over standard LLM methods (e.g., zero-shot prompting, in-context learning, and chain-of-thought). These results demonstrate the benefit of utilizing knowledge from cognitive neuroscience to improve planning in LLMs.","creator":"Taylor Webb, Shanka Subhra Mondal, Chi Wang, Brian Krabach, Ida Momennejad"},{"id":"2311.12472","slug":"self-supervised-deconfounding-against-spatio-temporal-shifts-theory-and-modeling","title":"Self-Supervised Deconfounding Against Spatio-Temporal Shifts: Theory and Modeling","link":"https://arxiv.org/abs/2311.12472","abstract":"arXiv:2311.12472v2 Announce Type: replace  Abstract: As an important application of spatio-temporal (ST) data, ST traffic forecasting plays a crucial role in improving urban travel efficiency and promoting sustainable development. In practice, the dynamics of traffic data frequently undergo distributional shifts attributed to external factors such as time evolution and spatial differences. This entails forecasting models to handle the out-of-distribution (OOD) issue where test data is distributed differently from training data. In this work, we first formalize the problem by constructing a causal graph of past traffic data, future traffic data, and external ST contexts. We reveal that the failure of prior arts in OOD traffic data is due to ST contexts acting as a confounder, i.e., the common cause for past data and future ones. Then, we propose a theoretical solution named Disentangled Contextual Adjustment (DCA) from a causal lens. It differentiates invariant causal correlations against variant spurious ones and deconfounds the effect of ST contexts. On top of that, we devise a Spatio-Temporal sElf-superVised dEconfounding (STEVE) framework. It first encodes traffic data into two disentangled representations for associating invariant and variant ST contexts. Then, we use representative ST contexts from three conceptually different perspectives (i.e., temporal, spatial, and semantic) as self-supervised signals to inject context information into both representations. In this way, we improve the generalization ability of the learned context-oriented representations to OOD ST traffic forecasting. Comprehensive experiments on four large-scale benchmark datasets demonstrate that our STEVE consistently outperforms the state-of-the-art baselines across various ST OOD scenarios.","creator":"Jiahao Ji, Wentao Zhang, Jingyuan Wang, Yue He, Chao Huang"},{"id":"2401.03093","slug":"explicitly-explainable-ai-solution-to-the-ai-black-box-problem","title":"Explicitly explainable AI solution to the AI black box problem","link":"https://arxiv.org/abs/2401.03093","abstract":"arXiv:2401.03093v2 Announce Type: replace  Abstract: Artificial intelligence based on neural networks has made significant progress. However, there are concerns about the reliability and security of this approach due to its lack of transparency. This is the black box problem of AI. Here we show how this problem can be solved using symbolic AI, which has a transparent white box nature. The widespread use of symbolic AI is hindered by the opacity of mathematical models and natural language terms, the lack of a unified ontology, and the combinatorial explosion of search options. To solve the AI black box problem and to implement general-purpose symbolic AI, we propose to use deterministic logic cellular automata with rules based on first principles of the general theory of the relevant domain. In this case, the general theory of the relevant domain plays the role of a knowledge base for the cellular automaton inference. A cellular automaton implements automatic parallel logical inference at three levels of organization of a complex system. Our verification of several ecological hypotheses provides a successful precedent for the implementation of white-box AI. Finally, we discuss a program for creating a general-purpose symbolic AI capable of processing knowledge and ensuring the reliability and safety of automated decisions.","creator":"V. L. Kalmykov, L. V. Kalmykov"},{"id":"2402.02547","slug":"integration-of-cognitive-tasks-into-artificial-general-intelligence-test-for-large-models","title":"Integration of cognitive tasks into artificial general intelligence test for large models","link":"https://arxiv.org/abs/2402.02547","abstract":"arXiv:2402.02547v2 Announce Type: replace  Abstract: During the evolution of large models, performance evaluation is necessarily performed to assess their capabilities and ensure safety before practical application. However, current model evaluations mainly rely on specific tasks and datasets, lacking a united framework for assessing the multidimensional intelligence of large models. In this perspective, we advocate for a comprehensive framework of cognitive science-inspired artificial general intelligence (AGI) tests, aimed at fulfilling the testing needs of large models with enhanced capabilities. The cognitive science-inspired AGI tests encompass the full spectrum of intelligence facets, including crystallized intelligence, fluid intelligence, social intelligence, and embodied intelligence. To assess the multidimensional intelligence of large models, the AGI tests consist of a battery of well-designed cognitive tests adopted from human intelligence tests, and then naturally encapsulates into an immersive virtual community. We propose increasing the complexity of AGI testing tasks commensurate with advancements in large models and emphasizing the necessity for the interpretation of test results to avoid false negatives and false positives. We believe that cognitive science-inspired AGI tests will effectively guide the targeted improvement of large models in specific dimensions of intelligence and accelerate the integration of large models into human society.","creator":"Youzhi Qu, Chen Wei, Penghui Du, Wenxin Che, Chi Zhang, Wanli Ouyang, Yatao Bian, Feiyang Xu, Bin Hu, Kai Du, Haiyan Wu, Jia Liu, Quanying Liu"},{"id":"2402.04154","slug":"read-to-play-r2-play-decision-transformer-with-multimodal-game-instruction","title":"Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction","link":"https://arxiv.org/abs/2402.04154","abstract":"arXiv:2402.04154v3 Announce Type: replace  Abstract: Developing a generalist agent is a longstanding objective in artificial intelligence. Previous efforts utilizing extensive offline datasets from various tasks demonstrate remarkable performance in multitasking scenarios within Reinforcement Learning. However, these works encounter challenges in extending their capabilities to new tasks. Recent approaches integrate textual guidance or visual trajectory into decision networks to provide task-specific contextual cues, representing a promising direction. However, it is observed that relying solely on textual guidance or visual trajectory is insufficient for accurately conveying the contextual information of tasks. This paper explores enhanced forms of task guidance for agents, enabling them to comprehend gameplay instructions, thereby facilitating a \"read-to-play\" capability. Drawing inspiration from the success of multimodal instruction tuning in visual tasks, we treat the visual-based RL task as a long-horizon vision task and construct a set of multimodal game instructions to incorporate instruction tuning into a decision transformer. Experimental results demonstrate that incorporating multimodal game instructions significantly enhances the decision transformer's multitasking and generalization capabilities.","creator":"Yonggang Jin, Ge Zhang, Hao Zhao, Tianyu Zheng, Jiawei Guo, Liuyu Xiang, Shawn Yue, Stephen W. Huang, Wenhu Chen, Zhaofeng He, Jie Fu"},{"id":"2402.06326","slug":"prompt-learning-on-temporal-interaction-graphs","title":"Prompt Learning on Temporal Interaction Graphs","link":"https://arxiv.org/abs/2402.06326","abstract":"arXiv:2402.06326v2 Announce Type: replace  Abstract: Temporal Interaction Graphs (TIGs) are widely utilized to represent real-world systems. To facilitate representation learning on TIGs, researchers have proposed a series of TIG models. However, these models are still facing two tough gaps between the pre-training and downstream predictions in their ``pre-train, predict'' training paradigm. First, the temporal discrepancy between the pre-training and inference data severely undermines the models' applicability in distant future predictions on the dynamically evolving data. Second, the semantic divergence between pretext and downstream tasks hinders their practical applications, as they struggle to align with their learning and prediction capabilities across application scenarios.   Recently, the ``pre-train, prompt'' paradigm has emerged as a lightweight mechanism for model generalization. Applying this paradigm is a potential solution to solve the aforementioned challenges. However, the adaptation of this paradigm to TIGs is not straightforward. The application of prompting in static graph contexts falls short in temporal settings due to a lack of consideration for time-sensitive dynamics and a deficiency in expressive power. To address this issue, we introduce Temporal Interaction Graph Prompting (TIGPrompt), a versatile framework that seamlessly integrates with TIG models, bridging both the temporal and semantic gaps. In detail, we propose a temporal prompt generator to offer temporally-aware prompts for different tasks. These prompts stand out for their minimalistic design, relying solely on the tuning of the prompt generator with very little supervision data. To cater to varying computational resource demands, we propose an extended ``pre-train, prompt-based fine-tune'' paradigm, offering greater flexibility. Through extensive experiments, the TIGPrompt demonstrates the SOTA performance and remarkable efficiency advantages.","creator":"Xi Chen, Siwei Zhang, Yun Xiong, Xixi Wu, Jiawei Zhang, Xiangguo Sun, Yao Zhang, Feng Zhao, Yulin Kang"},{"id":"2107.13509","slug":"the-who-in-xai-how-ai-background-shapes-perceptions-of-ai-explanations","title":"The Who in XAI: How AI Background Shapes Perceptions of AI Explanations","link":"https://arxiv.org/abs/2107.13509","abstract":"arXiv:2107.13509v2 Announce Type: replace-cross  Abstract: Explainability of AI systems is critical for users to take informed actions. Understanding \"who\" opens the black-box of AI is just as important as opening it. We conduct a mixed-methods study of how two different groups--people with and without AI background--perceive different types of AI explanations. Quantitatively, we share user perceptions along five dimensions. Qualitatively, we describe how AI background can influence interpretations, elucidating the differences through lenses of appropriation and cognitive heuristics. We find that (1) both groups showed unwarranted faith in numbers for different reasons and (2) each group found value in different explanations beyond their intended design. Carrying critical implications for the field of XAI, our findings showcase how AI generated explanations can have negative consequences despite best intentions and how that could lead to harmful manipulation of trust. We propose design interventions to mitigate them.","creator":"Upol Ehsan, Samir Passi, Q. Vera Liao, Larry Chan, I-Hsiang Lee, Michael Muller, Mark O. Riedl"},{"id":"2209.00381","slug":"semsegdepth-a-combined-model-for-semantic-segmentation-and-depth-completion","title":"SemSegDepth: A Combined Model for Semantic Segmentation and Depth Completion","link":"https://arxiv.org/abs/2209.00381","abstract":"arXiv:2209.00381v2 Announce Type: replace-cross  Abstract: Holistic scene understanding is pivotal for the performance of autonomous machines. In this paper we propose a new end-to-end model for performing semantic segmentation and depth completion jointly. The vast majority of recent approaches have developed semantic segmentation and depth completion as independent tasks. Our approach relies on RGB and sparse depth as inputs to our model and produces a dense depth map and the corresponding semantic segmentation image. It consists of a feature extractor, a depth completion branch, a semantic segmentation branch and a joint branch which further processes semantic and depth information altogether. The experiments done on Virtual KITTI 2 dataset, demonstrate and provide further evidence, that combining both tasks, semantic segmentation and depth completion, in a multi-task network can effectively improve the performance of each task. Code is available at https://github.com/juanb09111/semantic depth.","creator":"Juan Pablo Lagos, Esa Rahtu"},{"id":"2210.10971","slug":"optimal-settings-for-cryptocurrency-trading-pairs","title":"Optimal Settings for Cryptocurrency Trading Pairs","link":"https://arxiv.org/abs/2210.10971","abstract":"arXiv:2210.10971v3 Announce Type: replace-cross  Abstract: The goal of cryptocurrencies is decentralization. In principle, all currencies have equal status. Unlike traditional stock markets, there is no default currency of denomination (fiat), thus the trading pairs can be set freely. However, it is impractical to set up a trading market between every two currencies. In order to control management costs and ensure sufficient liquidity, we must give priority to covering those large-volume trading pairs and ensure that all coins are reachable. We note that this is an optimization problem. Its particularity lies in: 1) the trading volume between most (>99.5%) possible trading pairs cannot be directly observed. 2) It satisfies the connectivity constraint, that is, all currencies are guaranteed to be tradable.   To solve this problem, we use a two-stage process: 1) Fill in missing values based on a regularized, truncated eigenvalue decomposition, where the regularization term is used to control what extent missing values should be limited to zero. 2) Search for the optimal trading pairs, based on a branch and bound process, with heuristic search and pruning strategies.   The experimental results show that: 1) If the number of denominated coins is not limited, we will get a more decentralized trading pair settings, which advocates the establishment of trading pairs directly between large currency pairs. 2) There is a certain room for optimization in all exchanges. The setting of inappropriate trading pairs is mainly caused by subjectively setting small coins to quote, or failing to track emerging big coins in time. 3) Too few trading pairs will lead to low coverage; too many trading pairs will need to be adjusted with markets frequently. Exchanges should consider striking an appropriate balance between them.","creator":"Di Zhang, Youzhou Zhou"},{"id":"2211.06753","slug":"seamful-xai-operationalizing-seamful-design-in-explainable-ai","title":"Seamful XAI: Operationalizing Seamful Design in Explainable AI","link":"https://arxiv.org/abs/2211.06753","abstract":"arXiv:2211.06753v2 Announce Type: replace-cross  Abstract: Mistakes in AI systems are inevitable, arising from both technical limitations and sociotechnical gaps. While black-boxing AI systems can make the user experience seamless, hiding the seams risks disempowering users to mitigate fallouts from AI mistakes. Instead of hiding these AI imperfections, can we leverage them to help the user? While Explainable AI (XAI) has predominantly tackled algorithmic opaqueness, we propose that seamful design can foster AI explainability by revealing and leveraging sociotechnical and infrastructural mismatches. We introduce the concept of Seamful XAI by (1) conceptually transferring \"seams\" to the AI context and (2) developing a design process that helps stakeholders anticipate and design with seams. We explore this process with 43 AI practitioners and real end-users, using a scenario-based co-design activity informed by real-world use cases. We found that the Seamful XAI design process helped users foresee AI harms, identify underlying reasons (seams), locate them in the AI's lifecycle, learn how to leverage seamful information to improve XAI and user agency. We share empirical insights, implications, and reflections on how this process can help practitioners anticipate and craft seams in AI, how seamfulness can improve explainability, empower end-users, and facilitate Responsible AI.","creator":"Upol Ehsan, Q. Vera Liao, Samir Passi, Mark O. Riedl, Hal Daume III"},{"id":"2212.04475","slug":"spatio-temporal-self-supervised-learning-for-traffic-flow-prediction","title":"Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction","link":"https://arxiv.org/abs/2212.04475","abstract":"arXiv:2212.04475v2 Announce Type: replace-cross  Abstract: Robust prediction of citywide traffic flows at different time periods plays a crucial role in intelligent transportation systems. While previous work has made great efforts to model spatio-temporal correlations, existing methods still suffer from two key limitations: i) Most models collectively predict all regions' flows without accounting for spatial heterogeneity, i.e., different regions may have skewed traffic flow distributions. ii) These models fail to capture the temporal heterogeneity induced by time-varying traffic patterns, as they typically model temporal correlations with a shared parameterized space for all time periods. To tackle these challenges, we propose a novel Spatio-Temporal Self-Supervised Learning (ST-SSL) traffic prediction framework which enhances the traffic pattern representations to be reflective of both spatial and temporal heterogeneity, with auxiliary self-supervised learning paradigms. Specifically, our ST-SSL is built over an integrated module with temporal and spatial convolutions for encoding the information across space and time. To achieve the adaptive spatio-temporal self-supervised learning, our ST-SSL first performs the adaptive augmentation over the traffic flow graph data at both attribute- and structure-levels. On top of the augmented traffic graph, two SSL auxiliary tasks are constructed to supplement the main traffic prediction task with spatial and temporal heterogeneity-aware augmentation. Experiments on four benchmark datasets demonstrate that ST-SSL consistently outperforms various state-of-the-art baselines. Since spatio-temporal heterogeneity widely exists in practical datasets, the proposed framework may also cast light on other spatial-temporal applications. Model implementation is available at https://github.com/Echo-Ji/ST-SSL.","creator":"Jiahao Ji, Jingyuan Wang, Chao Huang, Junjie Wu, Boren Xu, Zhenhe Wu, Junbo Zhang, Yu Zheng"},{"id":"2302.08545","slug":"thc-accelerating-distributed-deep-learning-using-tensor-homomorphic-compression","title":"THC: Accelerating Distributed Deep Learning Using Tensor Homomorphic Compression","link":"https://arxiv.org/abs/2302.08545","abstract":"arXiv:2302.08545v2 Announce Type: replace-cross  Abstract: Deep neural networks (DNNs) are the de facto standard for essential use cases, such as image classification, computer vision, and natural language processing. As DNNs and datasets get larger, they require distributed training on increasingly larger clusters. A main bottleneck is the resulting communication overhead where workers exchange model updates (i.e., gradients) on a per-round basis. To address this bottleneck and accelerate training, a widely-deployed approach is compression. However, previous deployments often apply bi-directional compression schemes by simply using a uni-directional gradient compression scheme in each direction. This results in significant computational overheads at the parameter server and increased compression error, leading to longer training and lower accuracy. We introduce Tensor Homomorphic Compression (THC), a novel bi-directional compression framework that enables the direct aggregation of compressed values and thus eliminating the aforementioned computational overheads. Moreover, THC is compatible with in-network aggregation (INA), which allows for further acceleration. Our evaluation shows that training representative vision and language models with THC reaches target accuracy by 1.40x to 1.47x faster using INA and 1.28x to 1.33x faster using a software PS compared with state-of-the-art systems.","creator":"Minghao LiHarvard University, Ran Ben BasatUniversity College London, Shay VargaftikVMware Research, ChonLam LaoHarvard University, Kevin XuHarvard University, Michael MitzenmacherHarvard University, Minlan YuHarvard University"},{"id":"2303.00286","slug":"treat-different-negatives-differently-enriching-loss-functions-with-domain-and-range-constraints-for-link-prediction","title":"Treat Different Negatives Differently: Enriching Loss Functions with Domain and Range Constraints for Link Prediction","link":"https://arxiv.org/abs/2303.00286","abstract":"arXiv:2303.00286v4 Announce Type: replace-cross  Abstract: Knowledge graph embedding models (KGEMs) are used for various tasks related to knowledge graphs (KGs), including link prediction. They are trained with loss functions that consider batches of true and false triples. However, different kinds of false triples exist and recent works suggest that they should not be valued equally, leading to specific negative sampling procedures. In line with this recent assumption, we posit that negative triples that are semantically valid w.r.t. signatures of relations (domain and range) are high-quality negatives. Hence, we enrich the three main loss functions for link prediction such that all kinds of negatives are sampled but treated differently based on their semantic validity. In an extensive and controlled experimental setting, we show that the proposed loss functions systematically provide satisfying results which demonstrates both the generality and superiority of our proposed approach. In fact, the proposed loss functions (1) lead to better MRR and Hits@10 values, and (2) drive KGEMs towards better semantic correctness as measured by the Sem@K metric. This highlights that relation signatures globally improve KGEMs, and thus should be incorporated into loss functions. Domains and ranges of relations being largely available in schema-defined KGs, this makes our approach both beneficial and widely usable in practice.","creator":"Nicolas Hubert, Pierre Monnin, Armelle Brun, Davy Monticolo"},{"id":"2305.09329","slug":"cwtm-leveraging-contextualized-word-embeddings-from-bert-for-neural-topic-modeling","title":"CWTM: Leveraging Contextualized Word Embeddings from BERT for Neural Topic Modeling","link":"https://arxiv.org/abs/2305.09329","abstract":"arXiv:2305.09329v3 Announce Type: replace-cross  Abstract: Most existing topic models rely on bag-of-words (BOW) representation, which limits their ability to capture word order information and leads to challenges with out-of-vocabulary (OOV) words in new documents. Contextualized word embeddings, however, show superiority in word sense disambiguation and effectively address the OOV issue. In this work, we introduce a novel neural topic model called the Contextlized Word Topic Model (CWTM), which integrates contextualized word embeddings from BERT. The model is capable of learning the topic vector of a document without BOW information. In addition, it can also derive the topic vectors for individual words within a document based on their contextualized word embeddings. Experiments across various datasets show that CWTM generates more coherent and meaningful topics compared to existing topic models, while also accommodating unseen words in newly encountered documents.","creator":"Zheng Fang, Yulan He, Rob Procter"},{"id":"2308.00071","slug":"interpretable-stereotype-identification-through-reasoning","title":"Interpretable Stereotype Identification through Reasoning","link":"https://arxiv.org/abs/2308.00071","abstract":"arXiv:2308.00071v2 Announce Type: replace-cross  Abstract: Given that language models are trained on vast datasets that may contain inherent biases, there is a potential danger of inadvertently perpetuating systemic discrimination. Consequently, it becomes essential to examine and address biases in language models, integrating fairness into their development to ensure these models are equitable and free from bias. In this work, we demonstrate the importance of reasoning in zero-shot stereotype identification based on Vicuna-13B-v1.3. While we do observe improved accuracy by scaling from 13B to 33B, we show that the performance gain from reasoning significantly exceeds the gain from scaling up. Our findings suggest that reasoning could be a key factor that enables LLMs to trescend the scaling law on out-of-domain tasks such as stereotype identification. Additionally, through a qualitative analysis of select reasoning traces, we highlight how reasoning enhances not just accuracy but also the interpretability of the decision.","creator":"Jacob-Junqi Tian, Omkar Dige, David Emerson, Faiza Khan Khattak"},{"id":"2308.02117","slug":"vqgraph-rethinking-graph-representation-space-for-bridging-gnns-and-mlps","title":"VQGraph: Rethinking Graph Representation Space for Bridging GNNs and MLPs","link":"https://arxiv.org/abs/2308.02117","abstract":"arXiv:2308.02117v3 Announce Type: replace-cross  Abstract: GNN-to-MLP distillation aims to utilize knowledge distillation (KD) to learn computationally-efficient multi-layer perceptron (student MLP) on graph data by mimicking the output representations of teacher GNN. Existing methods mainly make the MLP to mimic the GNN predictions over a few class labels. However, the class space may not be expressive enough for covering numerous diverse local graph structures, thus limiting the performance of knowledge transfer from GNN to MLP. To address this issue, we propose to learn a new powerful graph representation space by directly labeling nodes' diverse local structures for GNN-to-MLP distillation. Specifically, we propose a variant of VQ-VAE to learn a structure-aware tokenizer on graph data that can encode each node's local substructure as a discrete code. The discrete codes constitute a codebook as a new graph representation space that is able to identify different local graph structures of nodes with the corresponding code indices. Then, based on the learned codebook, we propose a new distillation target, namely soft code assignments, to directly transfer the structural knowledge of each node from GNN to MLP. The resulting framework VQGraph achieves new state-of-the-art performance on GNN-to-MLP distillation in both transductive and inductive settings across seven graph datasets. We show that VQGraph with better performance infers faster than GNNs by 828x, and also achieves accuracy improvement over GNNs and stand-alone MLPs by 3.90% and 28.05% on average, respectively. Code: https://github.com/YangLing0818/VQGraph.","creator":"Ling Yang, Ye Tian, Minkai Xu, Zhongyi Liu, Shenda Hong, Wei Qu, Wentao Zhang, Bin Cui, Muhan Zhang, Jure Leskovec"},{"id":"2308.11155","slug":"beyond-md17-the-reactive-xxmd-dataset","title":"Beyond MD17: the reactive xxMD dataset","link":"https://arxiv.org/abs/2308.11155","abstract":"arXiv:2308.11155v3 Announce Type: replace-cross  Abstract: System specific neural force fields (NFFs) have gained popularity in computational chemistry. One of the most popular datasets as a bencharmk to develop NFFs models is the MD17 dataset and its subsequent extension. These datasets comprise geometries from the equilibrium region of the ground electronic state potential energy surface, sampled from direct adiabatic dynamics. However, many chemical reactions involve significant molecular geometrical deformations, for example, bond breaking. Therefore, MD17 is inadequate to represent a chemical reaction. To address this limitation in MD17, we introduce a new dataset, called Extended Excited-state Molecular Dynamics (xxMD) dataset. The xxMD dataset involves geometries sampled from direct non-adiabatic dynamics, and the energies are computed at both multireference wavefunction theory and density functional theory. We show that the xxMD dataset involves diverse geometries which represent chemical reactions. Assessment of NFF models on xxMD dataset reveals significantly higher predictive errors than those reported for MD17 and its variants. This work underscores the challenges faced in crafting a generalizable NFF model with extrapolation capability.","creator":"Zihan Pengmei, Junyu Liu, Yinan Shu"},{"id":"2309.08776","slug":"projected-task-specific-layers-for-multi-task-reinforcement-learning","title":"Projected Task-Specific Layers for Multi-Task Reinforcement Learning","link":"https://arxiv.org/abs/2309.08776","abstract":"arXiv:2309.08776v2 Announce Type: replace-cross  Abstract: Multi-task reinforcement learning could enable robots to scale across a wide variety of manipulation tasks in homes and workplaces. However, generalizing from one task to another and mitigating negative task interference still remains a challenge. Addressing this challenge by successfully sharing information across tasks will depend on how well the structure underlying the tasks is captured. In this work, we introduce our new architecture, Projected Task-Specific Layers (PTSL), that leverages a common policy with dense task-specific corrections through task-specific layers to better express shared and variable task information. We then show that our model outperforms the state of the art on the MT10 and MT50 benchmarks of Meta-World consisting of 10 and 50 goal-conditioned tasks for a Sawyer arm.","creator":"Josselin Somerville Roberts, Julia Di"},{"id":"2309.09553","slug":"causal-story-local-causal-attention-utilizing-parameter-efficient-tuning-for-visual-story-synthesis","title":"Causal-Story: Local Causal Attention Utilizing Parameter-Efficient Tuning For Visual Story Synthesis","link":"https://arxiv.org/abs/2309.09553","abstract":"arXiv:2309.09553v4 Announce Type: replace-cross  Abstract: The excellent text-to-image synthesis capability of diffusion models has driven progress in synthesizing coherent visual stories. The current state-of-the-art method combines the features of historical captions, historical frames, and the current captions as conditions for generating the current frame. However, this method treats each historical frame and caption as the same contribution. It connects them in order with equal weights, ignoring that not all historical conditions are associated with the generation of the current frame. To address this issue, we propose Causal-Story. This model incorporates a local causal attention mechanism that considers the causal relationship between previous captions, frames, and current captions. By assigning weights based on this relationship, Causal-Story generates the current frame, thereby improving the global consistency of story generation. We evaluated our model on the PororoSV and FlintstonesSV datasets and obtained state-of-the-art FID scores, and the generated frames also demonstrate better storytelling in visuals.","creator":"Tianyi Song, Jiuxin Cao, Kun Wang, Bo Liu, Xiaofeng Zhang"},{"id":"2309.13734","slug":"prompting-and-fine-tuning-open-sourced-large-language-models-for-stance-classification","title":"Prompting and Fine-Tuning Open-Sourced Large Language Models for Stance Classification","link":"https://arxiv.org/abs/2309.13734","abstract":"arXiv:2309.13734v2 Announce Type: replace-cross  Abstract: Stance classification, the task of predicting the viewpoint of an author on a subject of interest, has long been a focal point of research in domains ranging from social science to machine learning. Current stance detection methods rely predominantly on manual annotation of sentences, followed by training a supervised machine learning model. However, this manual annotation process requires laborious annotation effort, and thus hampers its potential to generalize across different contexts. In this work, we investigate the use of Large Language Models (LLMs) as a stance detection methodology that can reduce or even eliminate the need for manual annotations. We investigate 10 open-source models and 7 prompting schemes, finding that LLMs are competitive with in-domain supervised models but are not necessarily consistent in their performance. We also fine-tuned the LLMs, but discovered that fine-tuning process does not necessarily lead to better performance. In general, we discover that LLMs do not routinely outperform their smaller supervised machine learning models, and thus call for stance detection to be a benchmark for which LLMs also optimize for. The code used in this study is available at \\url{https://github.com/ijcruic/LLM-Stance-Labeling}","creator":"Iain J. Cruickshank, Lynnette Hui Xian Ng"},{"id":"2309.14209","slug":"continual-driving-policy-optimization-with-closed-loop-individualized-curricula","title":"Continual Driving Policy Optimization with Closed-Loop Individualized Curricula","link":"https://arxiv.org/abs/2309.14209","abstract":"arXiv:2309.14209v3 Announce Type: replace-cross  Abstract: The safety of autonomous vehicles (AV) has been a long-standing top concern, stemming from the absence of rare and safety-critical scenarios in the long-tail naturalistic driving distribution. To tackle this challenge, a surge of research in scenario-based autonomous driving has emerged, with a focus on generating high-risk driving scenarios and applying them to conduct safety-critical testing of AV models. However, limited work has been explored on the reuse of these extensive scenarios to iteratively improve AV models. Moreover, it remains intractable and challenging to filter through gigantic scenario libraries collected from other AV models with distinct behaviors, attempting to extract transferable information for current AV improvement. Therefore, we develop a continual driving policy optimization framework featuring Closed-Loop Individualized Curricula (CLIC), which we factorize into a set of standardized sub-modules for flexible implementation choices: AV Evaluation, Scenario Selection, and AV Training. CLIC frames AV Evaluation as a collision prediction task, where it estimates the chance of AV failures in these scenarios at each iteration. Subsequently, by re-sampling from historical scenarios based on these failure probabilities, CLIC tailors individualized curricula for downstream training, aligning them with the evaluated capability of AV. Accordingly, CLIC not only maximizes the utilization of the vast pre-collected scenario library for closed-loop driving policy optimization but also facilitates AV improvement by individualizing its training with more challenging cases out of those poorly organized scenarios. Experimental results clearly indicate that CLIC surpasses other curriculum-based training strategies, showing substantial improvement in managing risky scenarios, while still maintaining proficiency in handling simpler cases.","creator":"Haoyi Niu, Yizhou Xu, Xingjian Jiang, Jianming Hu"},{"id":"2310.00354","slug":"ai-dentify-deep-learning-for-proximal-caries-detection-on-bitewing-x-ray-hunt4-oral-health-study","title":"AI-Dentify: Deep learning for proximal caries detection on bitewing x-ray -- HUNT4 Oral Health Study","link":"https://arxiv.org/abs/2310.00354","abstract":"arXiv:2310.00354v2 Announce Type: replace-cross  Abstract: Background: Dental caries diagnosis requires the manual inspection of diagnostic bitewing images of the patient, followed by a visual inspection and probing of the identified dental pieces with potential lesions. Yet the use of artificial intelligence, and in particular deep-learning, has the potential to aid in the diagnosis by providing a quick and informative analysis of the bitewing images.   Methods: A dataset of 13,887 bitewings from the HUNT4 Oral Health Study were annotated individually by six different experts, and used to train three different object detection deep-learning architectures: RetinaNet (ResNet50), YOLOv5 (M size), and EfficientDet (D0 and D1 sizes). A consensus dataset of 197 images, annotated jointly by the same six dentist, was used for evaluation. A five-fold cross validation scheme was used to evaluate the performance of the AI models.   Results: he trained models show an increase in average precision and F1-score, and decrease of false negative rate, with respect to the dental clinicians. When compared against the dental clinicians, the YOLOv5 model shows the largest improvement, reporting 0.647 mean average precision, 0.548 mean F1-score, and 0.149 mean false negative rate. Whereas the best annotators on each of these metrics reported 0.299, 0.495, and 0.164 respectively.   Conclusion: Deep-learning models have shown the potential to assist dental professionals in the diagnosis of caries. Yet, the task remains challenging due to the artifacts natural to the bitewing images.","creator":"Javier P\\'erez de Frutos, Ragnhild Holden Helland, Shreya Desai, Line Cathrine Nymoen, Thomas Lang{\\o}, Theodor Remman, Abhijit Sen"},{"id":"2310.04687","slug":"improving-adversarial-attacks-on-latent-diffusion-model","title":"Improving Adversarial Attacks on Latent Diffusion Model","link":"https://arxiv.org/abs/2310.04687","abstract":"arXiv:2310.04687v3 Announce Type: replace-cross  Abstract: Adversarial attacks on Latent Diffusion Model (LDM), the state-of-the-art image generative model, have been adopted as effective protection against malicious finetuning of LDM on unauthorized images. We show that these attacks add an extra error to the score function of adversarial examples predicted by LDM. LDM finetuned on these adversarial examples learns to lower the error by a bias, from which the model is attacked and predicts the score function with biases.   Based on the dynamics, we propose to improve the adversarial attack on LDM by Attacking with Consistent score-function Errors (ACE). ACE unifies the pattern of the extra error added to the predicted score function. This induces the finetuned LDM to learn the same pattern as a bias in predicting the score function. We then introduce a well-crafted pattern to improve the attack. Our method outperforms state-of-the-art methods in adversarial attacks on LDM.","creator":"Boyang Zheng, Chumeng Liang, Xiaoyu Wu, Yan Liu"},{"id":"2310.13225","slug":"scalable-neural-network-kernels","title":"Scalable Neural Network Kernels","link":"https://arxiv.org/abs/2310.13225","abstract":"arXiv:2310.13225v2 Announce Type: replace-cross  Abstract: We introduce the concept of scalable neural network kernels (SNNKs), the replacements of regular feedforward layers (FFLs), capable of approximating the latter, but with favorable computational properties. SNNKs effectively disentangle the inputs from the parameters of the neural network in the FFL, only to connect them in the final computation via the dot-product kernel. They are also strictly more expressive, as allowing to model complicated relationships beyond the functions of the dot-products of parameter-input vectors. We also introduce the neural network bundling process that applies SNNKs to compactify deep neural network architectures, resulting in additional compression gains. In its extreme version, it leads to the fully bundled network whose optimal parameters can be expressed via explicit formulae for several loss functions (e.g. mean squared error), opening a possibility to bypass backpropagation. As a by-product of our analysis, we introduce the mechanism of the universal random features (or URFs), applied to instantiate several SNNK variants, and interesting on its own in the context of scalable kernel methods. We provide rigorous theoretical analysis of all these concepts as well as an extensive empirical evaluation, ranging from point-wise kernel estimation to Transformers' fine-tuning with novel adapter layers inspired by SNNKs. Our mechanism provides up to 5x reduction in the number of trainable parameters, while maintaining competitive accuracy.","creator":"Arijit Sehanobish, Krzysztof Choromanski, Yunfan Zhao, Avinava Dubey, Valerii Likhosherstov"},{"id":"2310.14814","slug":"leveraging-ensemble-diversity-for-robust-self-training-in-the-presence-of-sample-selection-bias","title":"Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias","link":"https://arxiv.org/abs/2310.14814","abstract":"arXiv:2310.14814v3 Announce Type: replace-cross  Abstract: Self-training is a well-known approach for semi-supervised learning. It consists of iteratively assigning pseudo-labels to unlabeled data for which the model is confident and treating them as labeled examples. For neural networks, softmax prediction probabilities are often used as a confidence measure, although they are known to be overconfident, even for wrong predictions. This phenomenon is particularly intensified in the presence of sample selection bias, i.e., when data labeling is subject to some constraint. To address this issue, we propose a novel confidence measure, called $\\mathcal{T}$-similarity, built upon the prediction diversity of an ensemble of linear classifiers. We provide the theoretical analysis of our approach by studying stationary points and describing the relationship between the diversity of the individual members and their performance. We empirically demonstrate the benefit of our confidence measure for three different pseudo-labeling policies on classification datasets of various data modalities. The code is available at https://github.com/ambroiseodt/tsim.","creator":"Ambroise Odonnat, Vasilii Feofanov, Ievgen Redko"},{"id":"2311.03260","slug":"from-coupled-oscillators-to-graph-neural-networks-reducing-over-smoothing-via-a-kuramoto-model-based-approach","title":"From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a Kuramoto Model-based Approach","link":"https://arxiv.org/abs/2311.03260","abstract":"arXiv:2311.03260v2 Announce Type: replace-cross  Abstract: We propose the Kuramoto Graph Neural Network (KuramotoGNN), a novel class of continuous-depth graph neural networks (GNNs) that employs the Kuramoto model to mitigate the over-smoothing phenomenon, in which node features in GNNs become indistinguishable as the number of layers increases. The Kuramoto model captures the synchronization behavior of non-linear coupled oscillators. Under the view of coupled oscillators, we first show the connection between Kuramoto model and basic GNN and then over-smoothing phenomenon in GNNs can be interpreted as phase synchronization in Kuramoto model. The KuramotoGNN replaces this phase synchronization with frequency synchronization to prevent the node features from converging into each other while allowing the system to reach a stable synchronized state. We experimentally verify the advantages of the KuramotoGNN over the baseline GNNs and existing methods in reducing over-smoothing on various graph deep learning benchmark tasks.","creator":"Tuan Nguyen, Hirotada Honda, Takashi Sano, Vinh Nguyen, Shugo Nakamura, Tan M. Nguyen"},{"id":"2311.17695","slug":"fair-text-to-image-diffusion-via-fair-mapping","title":"Fair Text-to-Image Diffusion via Fair Mapping","link":"https://arxiv.org/abs/2311.17695","abstract":"arXiv:2311.17695v2 Announce Type: replace-cross  Abstract: In this paper, we address the limitations of existing text-to-image diffusion models in generating demographically fair results when given human-related descriptions. These models often struggle to disentangle the target language context from sociocultural biases, resulting in biased image generation. To overcome this challenge, we propose Fair Mapping, a flexible, model-agnostic, and lightweight approach that modifies a pre-trained text-to-image diffusion model by controlling the prompt to achieve fair image generation. One key advantage of our approach is its high efficiency. It only requires updating an additional linear network with few parameters at a low computational cost. By developing a linear network that maps conditioning embeddings into a debiased space, we enable the generation of relatively balanced demographic results based on the specified text condition. With comprehensive experiments on face image generation, we show that our method significantly improves image generation fairness with almost the same image quality compared to conventional diffusion models when prompted with descriptions related to humans. By effectively addressing the issue of implicit language bias, our method produces more fair and diverse image outputs.","creator":"Jia Li, Lijie Hu, Jingfeng Zhang, Tianhang Zheng, Hua Zhang, Di Wang"},{"id":"2312.05409","slug":"large-scale-training-of-foundation-models-for-wearable-biosignals","title":"Large-scale Training of Foundation Models for Wearable Biosignals","link":"https://arxiv.org/abs/2312.05409","abstract":"arXiv:2312.05409v2 Announce Type: replace-cross  Abstract: Tracking biosignals is crucial for monitoring wellness and preempting the development of severe medical conditions. Today, wearable devices can conveniently record various biosignals, creating the opportunity to monitor health status without disruption to one's daily routine. Despite widespread use of wearable devices and existing digital biomarkers, the absence of curated data with annotated medical labels hinders the development of new biomarkers to measure common health conditions. In fact, medical datasets are usually small in comparison to other domains, which is an obstacle for developing neural network models for biosignals. To address this challenge, we have employed self-supervised learning using the unlabeled sensor data collected under informed consent from the large longitudinal Apple Heart and Movement Study (AHMS) to train foundation models for two common biosignals: photoplethysmography (PPG) and electrocardiogram (ECG) recorded on Apple Watch. We curated PPG and ECG datasets from AHMS that include data from ~141K participants spanning ~3 years. Our self-supervised learning framework includes participant level positive pair selection, stochastic augmentation module and a regularized contrastive loss optimized with momentum training, and generalizes well to both PPG and ECG modalities. We show that the pre-trained foundation models readily encode information regarding participants' demographics and health conditions. To the best of our knowledge, this is the first study that builds foundation models using large-scale PPG and ECG data collected via wearable consumer devices $\\unicode{x2013}$ prior works have commonly used smaller-size datasets collected in clinical and experimental settings. We believe PPG and ECG foundation models can enhance future wearable devices by reducing the reliance on labeled data and hold the potential to help the users improve their health.","creator":"Salar Abbaspourazad, Oussama Elachqar, Andrew C. Miller, Saba Emrani, Udhyakumar Nallasamy, Ian Shapiro"},{"id":"2312.07932","slug":"a-novel-image-classification-framework-based-on-variational-quantum-algorithms","title":"A Novel Image Classification Framework Based on Variational Quantum Algorithms","link":"https://arxiv.org/abs/2312.07932","abstract":"arXiv:2312.07932v2 Announce Type: replace-cross  Abstract: Image classification is a crucial task in machine learning with widespread practical applications. The existing classical framework for image classification typically utilizes a global pooling operation at the end of the network to reduce computational complexity and mitigate overfitting. However, this operation often results in a significant loss of information, which can affect the performance of classification models. To overcome this limitation, we introduce a novel image classification framework that leverages variational quantum algorithms (VQAs)-hybrid approaches combining quantum and classical computing paradigms within quantum machine learning. The major advantage of our framework is the elimination of the need for the global pooling operation at the end of the network. In this way, our approach preserves more discriminative features and fine-grained details in the images, which enhances classification performance. Additionally, employing VQAs enables our framework to have fewer parameters than the classical framework, even in the absence of global pooling, which makes it more advantageous in preventing overfitting. We apply our method to different state-of-the-art image classification models and demonstrate the superiority of the proposed quantum architecture over its classical counterpart through a series of experiments on public datasets. Our experiments show that the proposed quantum framework achieves up to a 9.21% increase in accuracy and up to a 15.79% improvement in F1 score, compared to the classical framework.","creator":"Yixiong Chen"},{"id":"2312.12869","slug":"parameterized-projected-bellman-operator","title":"Parameterized Projected Bellman Operator","link":"https://arxiv.org/abs/2312.12869","abstract":"arXiv:2312.12869v3 Announce Type: replace-cross  Abstract: Approximate value iteration (AVI) is a family of algorithms for reinforcement learning (RL) that aims to obtain an approximation of the optimal value function. Generally, AVI algorithms implement an iterated procedure where each step consists of (i) an application of the Bellman operator and (ii) a projection step into a considered function space. Notoriously, the Bellman operator leverages transition samples, which strongly determine its behavior, as uninformative samples can result in negligible updates or long detours, whose detrimental effects are further exacerbated by the computationally intensive projection step. To address these issues, we propose a novel alternative approach based on learning an approximate version of the Bellman operator rather than estimating it through samples as in AVI approaches. This way, we are able to (i) generalize across transition samples and (ii) avoid the computationally intensive projection step. For this reason, we call our novel operator projected Bellman operator (PBO). We formulate an optimization problem to learn PBO for generic sequential decision-making problems, and we theoretically analyze its properties in two representative classes of RL problems. Furthermore, we theoretically study our approach under the lens of AVI and devise algorithmic implementations to learn PBO in offline and online settings by leveraging neural network parameterizations. Finally, we empirically showcase the benefits of PBO w.r.t. the regular Bellman operator on several RL problems.","creator":"Th\\'eo Vincent, Alberto Maria Metelli, Boris Belousov, Jan Peters, Marcello Restelli, Carlo D'Eramo"},{"id":"2312.14197","slug":"benchmarking-and-defending-against-indirect-prompt-injection-attacks-on-large-language-models","title":"Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models","link":"https://arxiv.org/abs/2312.14197","abstract":"arXiv:2312.14197v2 Announce Type: replace-cross  Abstract: The integration of large language models (LLMs) with external content has enabled more up-to-date and wide-ranging applications of LLMs, such as Microsoft Copilot. However, this integration has also exposed LLMs to the risk of indirect prompt injection attacks, where an attacker can embed malicious instructions within external content, compromising LLM output and causing responses to deviate from user expectations. To investigate this important but underexplored issue, we introduce the first benchmark for indirect prompt injection attacks, named BIPIA, to evaluate the risk of such attacks. Based on the evaluation, our work makes a key analysis of the underlying reason for the success of the attack, namely the inability of LLMs to distinguish between instructions and external content and the absence of LLMs' awareness to not execute instructions within external content. Building upon this analysis, we develop two black-box methods based on prompt learning and a white-box defense method based on fine-tuning with adversarial training accordingly. Experimental results demonstrate that black-box defenses are highly effective in mitigating these attacks, while the white-box defense reduces the attack success rate to near-zero levels. Overall, our work systematically investigates indirect prompt injection attacks by introducing a benchmark, analyzing the underlying reason for the success of the attack, and developing an initial set of defenses.","creator":"Jingwei Yi, Yueqi Xie, Bin Zhu, Emre Kiciman, Guangzhong Sun, Xing Xie, Fangzhao Wu"},{"id":"2312.17285","slug":"understanding-distributed-representations-of-concepts-in-deep-neural-networks-without-supervision","title":"Understanding Distributed Representations of Concepts in Deep Neural Networks without Supervision","link":"https://arxiv.org/abs/2312.17285","abstract":"arXiv:2312.17285v2 Announce Type: replace-cross  Abstract: Understanding intermediate representations of the concepts learned by deep learning classifiers is indispensable for interpreting general model behaviors. Existing approaches to reveal learned concepts often rely on human supervision, such as pre-defined concept sets or segmentation processes. In this paper, we propose a novel unsupervised method for discovering distributed representations of concepts by selecting a principal subset of neurons. Our empirical findings demonstrate that instances with similar neuron activation states tend to share coherent concepts. Based on the observations, the proposed method selects principal neurons that construct an interpretable region, namely a Relaxed Decision Region (RDR), encompassing instances with coherent concepts in the feature space. It can be utilized to identify unlabeled subclasses within data and to detect the causes of misclassifications. Furthermore, the applicability of our method across various layers discloses distinct distributed representations over the layers, which provides deeper insights into the internal mechanisms of the deep learning model.","creator":"Wonjoon Chang, Dahee Kwon, Jaesik Choi"},{"id":"2401.04575","slug":"let-s-go-shopping-lgs-web-scale-image-text-dataset-for-visual-concept-understanding","title":"Let's Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual Concept Understanding","link":"https://arxiv.org/abs/2401.04575","abstract":"arXiv:2401.04575v2 Announce Type: replace-cross  Abstract: Vision and vision-language applications of neural networks, such as image classification and captioning, rely on large-scale annotated datasets that require non-trivial data-collecting processes. This time-consuming endeavor hinders the emergence of large-scale datasets, limiting researchers and practitioners to a small number of choices. Therefore, we seek more efficient ways to collect and annotate images. Previous initiatives have gathered captions from HTML alt-texts and crawled social media postings, but these data sources suffer from noise, sparsity, or subjectivity. For this reason, we turn to commercial shopping websites whose data meet three criteria: cleanliness, informativeness, and fluency. We introduce the Let's Go Shopping (LGS) dataset, a large-scale public dataset with 15 million image-caption pairs from publicly available e-commerce websites. When compared with existing general-domain datasets, the LGS images focus on the foreground object and have less complex backgrounds. Our experiments on LGS show that the classifiers trained on existing benchmark datasets do not readily generalize to e-commerce data, while specific self-supervised visual feature extractors can better generalize. Furthermore, LGS's high-quality e-commerce-focused images and bimodal nature make it advantageous for vision-language bi-modal tasks: LGS enables image-captioning models to generate richer captions and helps text-to-image generation models achieve e-commerce style transfer.","creator":"Yatong Bai, Utsav Garg, Apaar Shanker, Haoming Zhang, Samyak Parajuli, Erhan Bas, Isidora Filipovic, Amelia N. Chu, Eugenia D Fomitcheva, Elliot Branson, Aerin Kim, Somayeh Sojoudi, Kyunghyun Cho"},{"id":"2401.06401","slug":"deveval-evaluating-code-generation-in-practical-software-projects","title":"DevEval: Evaluating Code Generation in Practical Software Projects","link":"https://arxiv.org/abs/2401.06401","abstract":"arXiv:2401.06401v4 Announce Type: replace-cross  Abstract: How to evaluate Large Language Models (LLMs) in code generation is an open question. Many benchmarks have been proposed but are inconsistent with practical software projects, e.g., unreal program distributions, insufficient dependencies, and small-scale project contexts. Thus, the capabilities of LLMs in practical projects are still unclear. In this paper, we propose a new benchmark named DevEval, aligned with Developers' experiences in practical projects. DevEval is collected through a rigorous pipeline, containing 2,690 samples from 119 practical projects and covering 10 domains. Compared to previous benchmarks, DevEval aligns to practical projects in multiple dimensions, e.g., real program distributions, sufficient dependencies, and enough-scale project contexts. We assess five popular LLMs on DevEval (e.g., gpt-4, gpt-3.5-turbo, CodeLLaMa, and StarCoder) and reveal their actual abilities in code generation. For instance, the highest Pass@1 of gpt-3.5-turbo only is 42 in our experiments. We also discuss the challenges and future directions of code generation in practical projects. We open-source DevEval and hope it can facilitate the development of code generation in practical projects.","creator":"Jia Li, Ge Li, Yunfei Zhao, Yongmin Li, Zhi Jin, Hao Zhu, Huanyu Liu, Kaibo Liu, Lecheng Wang, Zheng Fang, Lanshen Wang, Jiazheng Ding, Xuanming Zhang, Yihong Dong, Yuqi Zhu, Bin Gu, Mengfei Yang"},{"id":"2401.09340","slug":"sceneverse-scaling-3d-vision-language-learning-for-grounded-scene-understanding","title":"SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding","link":"https://arxiv.org/abs/2401.09340","abstract":"arXiv:2401.09340v2 Announce Type: replace-cross  Abstract: 3D vision-language grounding, which focuses on aligning language with the 3D physical environment, stands as a cornerstone in the development of embodied agents. In comparison to recent advancements in the 2D domain, grounding language in 3D scenes faces several significant challenges: (i) the inherent complexity of 3D scenes due to the diverse object configurations, their rich attributes, and intricate relationships; (ii) the scarcity of paired 3D vision-language data to support grounded learning; and (iii) the absence of a unified learning framework to distill knowledge from grounded 3D data. In this work, we aim to address these three major challenges in 3D vision-language by examining the potential of systematically upscaling 3D vision-language learning in indoor environments. We introduce the first million-scale 3D vision-language dataset, SceneVerse, encompassing about 68K 3D indoor scenes and comprising 2.5M vision-language pairs derived from both human annotations and our scalable scene-graph-based generation approach. We demonstrate that this scaling allows for a unified pre-training framework, Grounded Pre-training for Scenes (GPS), for 3D vision-language learning. Through extensive experiments, we showcase the effectiveness of GPS by achieving state-of-the-art performance on all existing 3D visual grounding benchmarks. The vast potential of SceneVerse and GPS is unveiled through zero-shot transfer experiments in the challenging 3D vision-language tasks. Project website: https://scene-verse.github.io.","creator":"Baoxiong Jia, Yixin Chen, Huangyue Yu, Yan Wang, Xuesong Niu, Tengyu Liu, Qing Li, Siyuan Huang"},{"id":"2401.10712","slug":"q-a-prompts-discovering-rich-visual-clues-through-mining-question-answer-prompts-for-vqa-requiring-diverse-world-knowledge","title":"Q&A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA requiring Diverse World Knowledge","link":"https://arxiv.org/abs/2401.10712","abstract":"arXiv:2401.10712v2 Announce Type: replace-cross  Abstract: With the breakthrough of multi-modal large language models, answering complex visual questions that demand advanced reasoning abilities and world knowledge has become a much more important testbed for developing AI models than ever. However, equipping AI models with robust cross-modality reasoning ability remains challenging since the cognition scheme of humans has not been understood systematically. In this paper, we believe that if we can collect visual clues in the given image as much as possible, we will recognize the image more accurately, understand the question better, recall relevant knowledge more easily, and finally reason out the answer. We discover these rich visual clues by mining question-answer pairs in images and sending them into multi-modal large language models as prompts. We call the proposed method Q&A Prompts. Specifically, we first use the image-answer pairs and the corresponding questions in the training set as inputs and outputs to train a visual question generation model. Then, we use an image tagging model to identify various instances and send packaged image-tag pairs into the visual question generation model to generate relevant questions with the extracted image tags as answers. Finally, we encode these generated question-answer pairs as prompts with a visual-aware prompting module and send them into pre-trained multi-modal large language models to reason out the final answers. Experimental results show that, compared with state-of-the-art methods, our Q&A Prompts achieves substantial improvements on the challenging visual question answering datasets requiring reasoning over diverse world knowledge, such as OK-VQA and A-OKVQA.","creator":"Haibi Wang, Weifeng Ge"},{"id":"2401.11389","slug":"medlm-exploring-language-models-for-medical-question-answering-systems","title":"MedLM: Exploring Language Models for Medical Question Answering Systems","link":"https://arxiv.org/abs/2401.11389","abstract":"arXiv:2401.11389v2 Announce Type: replace-cross  Abstract: In the face of rapidly expanding online medical literature, automated systems for aggregating and summarizing information are becoming increasingly crucial for healthcare professionals and patients. Large Language Models (LLMs), with their advanced generative capabilities, have shown promise in various NLP tasks, and their potential in the healthcare domain, particularly for Closed-Book Generative QnA, is significant. However, the performance of these models in domain-specific tasks such as medical Q&A remains largely unexplored. This study aims to fill this gap by comparing the performance of general and medical-specific distilled LMs for medical Q&A. We aim to evaluate the effectiveness of fine-tuning domain-specific LMs and compare the performance of different families of Language Models. The study will address critical questions about these models' reliability, comparative performance, and effectiveness in the context of medical Q&A. The findings will provide valuable insights into the suitability of different LMs for specific applications in the medical domain.","creator":"Niraj Yagnik, Jay Jhaveri, Vivek Sharma, Gabriel Pila"},{"id":"2401.16553","slug":"selectllm-can-llms-select-important-instructions-to-annotate","title":"SelectLLM: Can LLMs Select Important Instructions to Annotate?","link":"https://arxiv.org/abs/2401.16553","abstract":"arXiv:2401.16553v4 Announce Type: replace-cross  Abstract: Instruction tuning benefits from large and diverse datasets, however creating such datasets involves a high cost of human labeling. While synthetic datasets generated by large language models (LLMs) have partly solved this issue, they often contain low-quality data. One effective solution is selectively annotating unlabelled instructions, especially given the relative ease of acquiring unlabeled instructions or texts from various sources. However, how to select unlabelled instructions is not well-explored, especially in the context of LLMs. Further, traditional data selection methods, relying on input embedding space density, tend to underestimate instruction sample complexity, whereas those based on model prediction uncertainty often struggle with synthetic label quality. Therefore, we introduce SelectLLM, an alternative framework that leverages the capabilities of LLMs to more effectively select unlabeled instructions. SelectLLM consists of two key steps: Coreset-based clustering of unlabelled instructions for diversity and then prompting a LLM to identify the most beneficial instructions within each cluster. Our experiments demonstrate that SelectLLM matches or outperforms other state-of-the-art methods in instruction tuning benchmarks. It exhibits remarkable consistency across human and synthetic datasets, along with better cross-dataset generalization, as evidenced by a 10% performance improvement on the Cleaned Alpaca test set when trained on Dolly data. All code and data are publicly available (https://github.com/minnesotanlp/select-llm).","creator":"Ritik Sachin Parkar, Jaehyung Kim, Jong Inn Park, Dongyeop Kang"},{"id":"2402.07153","slug":"error-estimation-for-physics-informed-neural-networks-approximating-semilinear-wave-equations","title":"Error Estimation for Physics-informed Neural Networks Approximating Semilinear Wave Equations","link":"https://arxiv.org/abs/2402.07153","abstract":"arXiv:2402.07153v2 Announce Type: replace-cross  Abstract: This paper provides rigorous error bounds for physics-informed neural networks approximating the semilinear wave equation. We provide bounds for the generalization and training error in terms of the width of the network's layers and the number of training points for a tanh neural network with two hidden layers. Our main result is a bound of the total error in the $H^1([0,T];L^2(\\Omega))$-norm in terms of the training error and the number of training points, which can be made arbitrarily small under some assumptions. We illustrate our theoretical bounds with numerical experiments.","creator":"Beatrice Lorenz, Aras Bacho, Gitta Kutyniok"},{"id":"2402.08144","slug":"average-case-analysis-of-iterative-voting","title":"Average-Case Analysis of Iterative Voting","link":"https://arxiv.org/abs/2402.08144","abstract":"arXiv:2402.08144v2 Announce Type: replace-cross  Abstract: Iterative voting is a natural model of repeated strategic decision-making in social choice when agents have the opportunity to update their votes prior to finalizing the group decision. Prior work has analyzed the efficacy of iterative plurality on the welfare of the chosen outcome at equilibrium, relative to the truthful vote profile, via an adaptation of the price of anarchy. However, prior analyses have only studied the worst- and average-case performances when agents' preferences are distributed by the impartial culture. This work extends average-case analysis to a wider class of distributions and distinguishes when iterative plurality improves or degrades asymptotic welfare.","creator":"Joshua Kavner, Lirong Xia"},{"id":"2402.10251","slug":"brant-2-foundation-model-for-brain-signals","title":"Brant-2: Foundation Model for Brain Signals","link":"https://arxiv.org/abs/2402.10251","abstract":"arXiv:2402.10251v3 Announce Type: replace-cross  Abstract: Foundational models benefit from pre-training on large amounts of unlabeled data and enable strong performance in a wide variety of applications with a small amount of labeled data. Such models can be particularly effective in analyzing brain signals, as this field encompasses numerous application scenarios, and it is costly to perform large-scale annotation. In this work, we present the largest foundation model in brain signals, Brant-2. Compared to Brant, a foundation model designed for intracranial neural signals, Brant-2 not only exhibits robustness towards data variations and modeling scales but also can be applied to a broader range of brain neural data. By experimenting on an extensive range of tasks, we demonstrate that Brant-2 is adaptive to various application scenarios in brain signals. Further analyses reveal the scalability of the Brant-2, validate each component's effectiveness, and showcase our model's ability to maintain performance in scenarios with scarce labels. The source code and pre-trained weights are available at: https://github.com/yzz673/Brant-2.","creator":"Zhizhang Yuan, Daoze Zhang, Junru Chen, Gefei Gu, Yang Yang"},{"id":"2402.16073","slug":"pfeed-generating-near-real-time-personalized-feeds-using-precomputed-embedding-similarities","title":"Pfeed: Generating near real-time personalized feeds using precomputed embedding similarities","link":"https://arxiv.org/abs/2402.16073","abstract":"arXiv:2402.16073v2 Announce Type: replace-cross  Abstract: In personalized recommender systems, embeddings are often used to encode customer actions and items, and retrieval is then performed in the embedding space using approximate nearest neighbor search. However, this approach can lead to two challenges: 1) user embeddings can restrict the diversity of interests captured and 2) the need to keep them up-to-date requires an expensive, real-time infrastructure. In this paper, we propose a method that overcomes these challenges in a practical, industrial setting. The method dynamically updates customer profiles and composes a feed every two minutes, employing precomputed embeddings and their respective similarities. We tested and deployed this method to personalise promotional items at Bol, one of the largest e-commerce platforms of the Netherlands and Belgium. The method enhanced customer engagement and experience, leading to a significant 4.9% uplift in conversions.","creator":"Binyam Gebre, Karoliina Ranta, Stef van den Elzen, Ernst Kuiper, Thijs Baars, Tom Heskes"},{"id":"2402.16899","slug":"a-priori-estimates-for-deep-residual-network-in-continuous-time-reinforcement-learning","title":"A priori Estimates for Deep Residual Network in Continuous-time Reinforcement Learning","link":"https://arxiv.org/abs/2402.16899","abstract":"arXiv:2402.16899v2 Announce Type: replace-cross  Abstract: Deep reinforcement learning excels in numerous large-scale practical applications. However, existing performance analyses ignores the unique characteristics of continuous-time control problems, is unable to directly estimate the generalization error of the Bellman optimal loss and require a boundedness assumption. Our work focuses on continuous-time control problems and proposes a method that is applicable to all such problems where the transition function satisfies semi-group and Lipschitz properties. Under this method, we can directly analyze the \\emph{a priori} generalization error of the Bellman optimal loss. The core of this method lies in two transformations of the loss function. To complete the transformation, we propose a decomposition method for the maximum operator. Additionally, this analysis method does not require a boundedness assumption. Finally, we obtain an \\emph{a priori} generalization error without the curse of dimensionality.","creator":"Shuyu Yin, Qixuan Zhou, Fei Wen, Tao Luo"},{"id":"2402.18061","slug":"on-the-use-of-silver-standard-data-for-zero-shot-classification-tasks-in-information-extraction","title":"On the use of Silver Standard Data for Zero-shot Classification Tasks in Information Extraction","link":"https://arxiv.org/abs/2402.18061","abstract":"arXiv:2402.18061v2 Announce Type: replace-cross  Abstract: The superior performance of supervised classification methods in the information extraction (IE) area heavily relies on a large amount of gold standard data. Recent zero-shot classification methods converted the task to other NLP tasks (e.g., textual entailment) and used off-the-shelf models of these NLP tasks to directly perform inference on the test data without using a large amount of IE annotation data. A potentially valuable by-product of these methods is the large-scale silver standard data, i.e., pseudo-labeled data by the off-the-shelf models of other NLP tasks. However, there is no further investigation into the use of these data. In this paper, we propose a new framework, Clean-LaVe, which aims to utilize silver standard data to enhance the zero-shot performance. Clean-LaVe includes four phases: (1) Obtaining silver data; (2) Identifying relatively clean data from silver data; (3) Finetuning the off-the-shelf model using clean data; (4) Inference on the test data. The experimental results show that Clean-LaVe can outperform the baseline by 5% and 6% on TACRED and Wiki80 dataset in the zero-shot relation classification task, and by 3%-7% on Smile (Korean and Polish) in the zero-shot cross-lingual relation classification task, and by 8% on ACE05-E+ in the zero-shot event argument classification task. The code is share in https://github.com/wjw136/Clean_LaVe.git.","creator":"Jianwei Wang, Tianyin Wang, Ziqian Zeng"},{"id":"2402.18571","slug":"arithmetic-control-of-llms-for-diverse-user-preferences-directional-preference-alignment-with-multi-objective-rewards","title":"Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards","link":"https://arxiv.org/abs/2402.18571","abstract":"arXiv:2402.18571v3 Announce Type: replace-cross  Abstract: Fine-grained control over large language models (LLMs) remains a significant challenge, hindering their adaptability to diverse user needs. While Reinforcement Learning from Human Feedback (RLHF) shows promise in aligning LLMs, its reliance on scalar rewards often limits its ability to capture diverse user preferences in real-world applications. To address this limitation, we introduce the Directional Preference Alignment (DPA) framework. Unlike the scalar-reward RLHF, DPA incorporates multi-objective reward modeling to represent diverse preference profiles. Additionally, DPA models user preferences as directions (i.e., unit vectors) in the reward space to achieve user-dependent preference control. Our method involves training a multi-objective reward model and then fine-tuning the LLM with a preference-conditioned variant of Rejection Sampling Finetuning (RSF), an RLHF method adopted by Llama 2. This method enjoys a better performance trade-off across various reward objectives. In comparison with the scalar-reward RLHF, DPA offers users intuitive control over LLM generation: they can arithmetically specify their desired trade-offs (e.g., more helpfulness with less verbosity). We also validate the effectiveness of DPA with real-world alignment experiments on Mistral-7B. Our method provides straightforward arithmetic control over the trade-off between helpfulness and verbosity while maintaining competitive performance with strong baselines such as Direct Preference Optimization (DPO).","creator":"Haoxiang Wang, Yong Lin, Wei Xiong, Rui Yang, Shizhe Diao, Shuang Qiu, Han Zhao, Tong Zhang"},{"id":"2402.18759","slug":"learning-with-language-guided-state-abstractions","title":"Learning with Language-Guided State Abstractions","link":"https://arxiv.org/abs/2402.18759","abstract":"arXiv:2402.18759v2 Announce Type: replace-cross  Abstract: We describe a framework for using natural language to design state abstractions for imitation learning. Generalizable policy learning in high-dimensional observation spaces is facilitated by well-designed state representations, which can surface important features of an environment and hide irrelevant ones. These state representations are typically manually specified, or derived from other labor-intensive labeling procedures. Our method, LGA (language-guided abstraction), uses a combination of natural language supervision and background knowledge from language models (LMs) to automatically build state representations tailored to unseen tasks. In LGA, a user first provides a (possibly incomplete) description of a target task in natural language; next, a pre-trained LM translates this task description into a state abstraction function that masks out irrelevant features; finally, an imitation policy is trained using a small number of demonstrations and LGA-generated abstract states. Experiments on simulated robotic tasks show that LGA yields state abstractions similar to those designed by humans, but in a fraction of the time, and that these abstractions improve generalization and robustness in the presence of spurious correlations and ambiguous specifications. We illustrate the utility of the learned abstractions on mobile manipulation tasks with a Spot robot.","creator":"Andi Peng, Ilia Sucholutsky, Belinda Z. Li, Theodore R. Sumers, Thomas L. Griffiths, Jacob Andreas, Julie A. Shah"},{"id":"2402.19379","slug":"wisdom-of-the-silicon-crowd-llm-ensemble-prediction-capabilities-rival-human-crowd-accuracy","title":"Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Rival Human Crowd Accuracy","link":"https://arxiv.org/abs/2402.19379","abstract":"arXiv:2402.19379v2 Announce Type: replace-cross  Abstract: Human forecasting accuracy in practice relies on the 'wisdom of the crowd' effect, in which predictions about future events are significantly improved by aggregating across a crowd of individual forecasters. Past work on the forecasting ability of large language models (LLMs) suggests that frontier LLMs, as individual forecasters, underperform compared to the gold standard of a human crowd forecasting tournament aggregate. In Study 1, we expand this research by using an LLM ensemble approach consisting of a crowd of twelve LLMs. We compare the aggregated LLM predictions on 31 binary questions to that of a crowd of 925 human forecasters from a three-month forecasting tournament. Our preregistered main analysis shows that the LLM crowd outperforms a simple no-information benchmark and is not statistically different from the human crowd. In exploratory analyses, we find that these two approaches are equivalent with respect to medium-effect-size equivalence bounds. We also observe an acquiescence effect, with mean model predictions being significantly above 50%, despite an almost even split of positive and negative resolutions. Moreover, in Study 2, we test whether LLM predictions (of GPT-4 and Claude 2) can be improved by drawing on human cognitive output. We find that both models' forecasting accuracy benefits from exposure to the median human prediction as information, improving accuracy by between 17% and 28%: though this leads to less accurate predictions than simply averaging human and machine forecasts. Our results suggest that LLMs can achieve forecasting accuracy rivaling that of human crowd forecasting tournaments: via the simple, practically applicable method of forecast aggregation. This replicates the 'wisdom of the crowd' effect for LLMs, and opens up their use for a variety of applications throughout society.","creator":"Philipp Schoenegger, Indre Tuminauskaite, Peter S. Park, Philip E. Tetlock"},{"id":"2403.01818","slug":"allspark-reborn-labeled-features-from-unlabeled-in-transformer-for-semi-supervised-semantic-segmentation","title":"AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation","link":"https://arxiv.org/abs/2403.01818","abstract":"arXiv:2403.01818v2 Announce Type: replace-cross  Abstract: Semi-supervised semantic segmentation (SSSS) has been proposed to alleviate the burden of time-consuming pixel-level manual labeling, which leverages limited labeled data along with larger amounts of unlabeled data. Current state-of-the-art methods train the labeled data with ground truths and unlabeled data with pseudo labels. However, the two training flows are separate, which allows labeled data to dominate the training process, resulting in low-quality pseudo labels and, consequently, sub-optimal results. To alleviate this issue, we present AllSpark, which reborns the labeled features from unlabeled ones with the channel-wise cross-attention mechanism. We further introduce a Semantic Memory along with a Channel Semantic Grouping strategy to ensure that unlabeled features adequately represent labeled features. The AllSpark shed new light on the architecture level designs of SSSS rather than framework level, which avoids increasingly complicated training pipeline designs. It can also be regarded as a flexible bottleneck module that can be seamlessly integrated into a general transformer-based segmentation model. The proposed AllSpark outperforms existing methods across all evaluation protocols on Pascal, Cityscapes and COCO benchmarks without bells-and-whistles. Code and model weights are available at: https://github.com/xmed-lab/AllSpark.","creator":"Haonan Wang, Qixiang Zhang, Yi Li, Xiaomeng Li"},{"id":"2403.02118","slug":"towards-implicit-prompt-for-text-to-image-models","title":"Towards Implicit Prompt For Text-To-Image Models","link":"https://arxiv.org/abs/2403.02118","abstract":"arXiv:2403.02118v2 Announce Type: replace-cross  Abstract: Recent text-to-image (T2I) models have had great success, and many benchmarks have been proposed to evaluate their performance and safety. However, they only consider explicit prompts while neglecting implicit prompts (hint at a target without explicitly mentioning it). These prompts may get rid of safety constraints and pose potential threats to the applications of these models. This position paper highlights the current state of T2I models toward implicit prompts. We present a benchmark named ImplicitBench and conduct an investigation on the performance and impacts of implicit prompts with popular T2I models. Specifically, we design and collect more than 2,000 implicit prompts of three aspects: General Symbols, Celebrity Privacy, and Not-Safe-For-Work (NSFW) Issues, and evaluate six well-known T2I models' capabilities under these implicit prompts. Experiment results show that (1) T2I models are able to accurately create various target symbols indicated by implicit prompts; (2) Implicit prompts bring potential risks of privacy leakage for T2I models. (3) Constraints of NSFW in most of the evaluated T2I models can be bypassed with implicit prompts. We call for increased attention to the potential and risks of implicit prompts in the T2I community and further investigation into the capabilities and impacts of implicit prompts, advocating for a balanced approach that harnesses their benefits while mitigating their risks.","creator":"Yue Yang, Yuqi lin, Hong Liu, Wenqi Shao, Runjian Chen, Hailong Shang, Yu Wang, Yu Qiao, Kaipeng Zhang, Ping Luo"},{"id":"2403.02131","slug":"deep-reinforcement-learning-for-dynamic-algorithm-selection-a-proof-of-principle-study-on-differential-evolution","title":"Deep Reinforcement Learning for Dynamic Algorithm Selection: A Proof-of-Principle Study on Differential Evolution","link":"https://arxiv.org/abs/2403.02131","abstract":"arXiv:2403.02131v2 Announce Type: replace-cross  Abstract: Evolutionary algorithms, such as Differential Evolution, excel in solving real-parameter optimization challenges. However, the effectiveness of a single algorithm varies across different problem instances, necessitating considerable efforts in algorithm selection or configuration. This paper aims to address the limitation by leveraging the complementary strengths of a group of algorithms and dynamically scheduling them throughout the optimization progress for specific problems. We propose a deep reinforcement learning-based dynamic algorithm selection framework to accomplish this task. Our approach models the dynamic algorithm selection a Markov Decision Process, training an agent in a policy gradient manner to select the most suitable algorithm according to the features observed during the optimization process. To empower the agent with the necessary information, our framework incorporates a thoughtful design of landscape and algorithmic features. Meanwhile, we employ a sophisticated deep neural network model to infer the optimal action, ensuring informed algorithm selections. Additionally, an algorithm context restoration mechanism is embedded to facilitate smooth switching among different algorithms. These mechanisms together enable our framework to seamlessly select and switch algorithms in a dynamic online fashion. Notably, the proposed framework is simple and generic, offering potential improvements across a broad spectrum of evolutionary algorithms. As a proof-of-principle study, we apply this framework to a group of Differential Evolution algorithms. The experimental results showcase the remarkable effectiveness of the proposed framework, not only enhancing the overall optimization performance but also demonstrating favorable generalization ability across different problem classes.","creator":"Hongshu Guo, Yining Ma, Zeyuan Ma, Jiacheng Chen, Xinglin Zhang, Zhiguang Cao, Jun Zhang, Yue-Jiao Gong"},{"id":"2403.02371","slug":"neurovoz-a-castillian-spanish-corpus-of-parkinsonian-speech","title":"NeuroVoz: a Castillian Spanish corpus of parkinsonian speech","link":"https://arxiv.org/abs/2403.02371","abstract":"arXiv:2403.02371v2 Announce Type: replace-cross  Abstract: The advancement of Parkinson's Disease (PD) diagnosis through speech analysis is hindered by a notable lack of publicly available, diverse language datasets, limiting the reproducibility and further exploration of existing research.   In response to this gap, we introduce a comprehensive corpus from 108 native Castilian Spanish speakers, comprising 55 healthy controls and 53 individuals diagnosed with PD, all of whom were under pharmacological treatment and recorded in their medication-optimized state. This unique dataset features a wide array of speech tasks, including sustained phonation of the five Spanish vowels, diadochokinetic tests, 16 listen-and-repeat utterances, and free monologues. The dataset emphasizes accuracy and reliability through specialist manual transcriptions of the listen-and-repeat tasks and utilizes Whisper for automated monologue transcriptions, making it the most complete public corpus of Parkinsonian speech, and the first in Castillian Spanish.   NeuroVoz is composed by 2,903 audio recordings averaging $26.88 \\pm 3.35$ recordings per participant, offering a substantial resource for the scientific exploration of PD's impact on speech. This dataset has already underpinned several studies, achieving a benchmark accuracy of 89% in PD speech pattern identification, indicating marked speech alterations attributable to PD. Despite these advances, the broader challenge of conducting a language-agnostic, cross-corpora analysis of Parkinsonian speech patterns remains an open area for future research. This contribution not only fills a critical void in PD speech analysis resources but also sets a new standard for the global research community in leveraging speech as a diagnostic tool for neurodegenerative diseases.","creator":"Jana\\'ina Mendes-Laureano, Jorge A. G\\'omez-Garc\\'ia, Alejandro Guerrero-L\\'opez, Elisa Luque-Buzo, Juli\\'an D. Arias-Londo\\~no, Francisco J. Grandas-P\\'erez, Juan I. Godino-Llorente"},{"id":"2403.02910","slug":"imgtrojan-jailbreaking-vision-language-models-with-one-image","title":"ImgTrojan: Jailbreaking Vision-Language Models with ONE Image","link":"https://arxiv.org/abs/2403.02910","abstract":"arXiv:2403.02910v2 Announce Type: replace-cross  Abstract: There has been an increasing interest in the alignment of large language models (LLMs) with human values. However, the safety issues of their integration with a vision module, or vision language models (VLMs), remain relatively underexplored. In this paper, we propose a novel jailbreaking attack against VLMs, aiming to bypass their safety barrier when a user inputs harmful instructions. A scenario where our poisoned (image, text) data pairs are included in the training data is assumed. By replacing the original textual captions with malicious jailbreak prompts, our method can perform jailbreak attacks with the poisoned images. Moreover, we analyze the effect of poison ratios and positions of trainable parameters on our attack's success rate. For evaluation, we design two metrics to quantify the success rate and the stealthiness of our attack. Together with a list of curated harmful instructions, a benchmark for measuring attack efficacy is provided. We demonstrate the efficacy of our attack by comparing it with baseline methods.","creator":"Xijia Tao, Shuai Zhong, Lei Li, Qi Liu, Lingpeng Kong"},{"id":"2403.02951","slug":"benchmarking-the-text-to-sql-capability-of-large-language-models-a-comprehensive-evaluation","title":"Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation","link":"https://arxiv.org/abs/2403.02951","abstract":"arXiv:2403.02951v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have emerged as a powerful tool in advancing the Text-to-SQL task, significantly outperforming traditional methods. Nevertheless, as a nascent research field, there is still no consensus on the optimal prompt templates and design frameworks. Additionally, existing benchmarks inadequately explore the performance of LLMs across the various sub-tasks of the Text-to-SQL process, which hinders the assessment of LLMs' cognitive capabilities and the optimization of LLM-based solutions. To address the aforementioned issues, we firstly construct a new dataset designed to mitigate the risk of overfitting in LLMs. Then we formulate five evaluation tasks to comprehensively assess the performance of diverse methods across various LLMs throughout the Text-to-SQL process.Our study highlights the performance disparities among LLMs and proposes optimal in-context learning solutions tailored to each task. These findings offer valuable insights for enhancing the development of LLM-based Text-to-SQL systems.","creator":"Bin Zhang, Yuxiao Ye, Guoqing Du, Xiaoru Hu, Zhishuai Li, Sun Yang, Chi Harold Liu, Rui Zhao, Ziyue Li, Hangyu Mao"}]},{"name":"Plant Biology","feed":[{"id":"2024.03.04.583280v1","slug":"microbe-tree-metabolite-interactions-in-the-soil-phyllosphere-continuum-of-poplar-tree-when-microbes-rewire-poplar-root-exudate-and-metabolome","title":"Microbe tree metabolite interactions in the soil - phyllosphere continuum of poplar tree: when microbes rewire poplar root exudate and metabolome","link":"http://biorxiv.org/cgi/content/short/2024.03.04.583280v1?rss=1","abstract":"Trees are associated with a broad range of microorganisms colonising the diverse tissues of their host. However, the early dynamics of the assembly of the microbiota from the root to shoot axis and how it is linked to root exudates and metabolite contents of tissues remain unclear. Here, we characterized how fungal and bacterial communities are altering root exudates as well as root and shoot metabolomes in parallel with their establishment in poplar cuttings (Populus tremula x tremuloides clone T89) over 30 days of growth. Sterile poplar cuttings were planted in natural or gamma-irradiated soils. Bulk and rhizospheric soils, root and shoot tissues were collected from day 1 to day 30 to track the dynamic changes of fungal and bacterial communities in the different habitats by DNA metabarcoding. Root exudates and root and shoot metabolites were analysed in parallel by gas chromatography-mass spectrometry. Our study reveals that microbial colonization triggered rapid and substantial alterations in both the composition and quantity of root exudates, with over 70 metabolites exclusively identified in remarkably high abundances in the 32 absence of microorganisms. Noteworthy among these were lipid-related 33 metabolites and defence compounds. The microbial colonization of both roots and shoots exhibited a similar dynamic response, initially involving saprophytic microorganisms and later transitioning to endophytes and symbionts. Key constituents of the shoot microbiota were also discernible at earlier time points in the rhizosphere and roots, indicating that the soil constituted a primary source for shoot microbiota. Furthermore, the microbial colonization of belowground and aerial compartments induced a reconfiguration of plant metabolism. Specifically, microbial colonization predominantly instigated alterations in primary metabolism in roots, while in shoots, it primarily influenced defence metabolism. This highlighted the profound impact of microbial interactions on metabolic pathways of plants, shedding light on the intricate interplay between plants and their associated microbial communities.","creator":"Fracchia, F., Guinet, F., Engle, N., Tschaplinski, T., Veneault-Fourrey, C., Deveau, A."},{"id":"2024.03.04.583414v1","slug":"large-scale-single-cell-profiling-of-stem-cells-uncovers-redundant-regulators-of-shoot-development-and-yield-trait-variation","title":"Large-scale single-cell profiling of stem cells uncovers redundant regulators of shoot development and yield trait variation","link":"http://biorxiv.org/cgi/content/short/2024.03.04.583414v1?rss=1","abstract":"Stem cells in plant shoots are a rare population of cells that produce leaves, fruits and seeds, vital sources for food and bioethanol. Uncovering regulators expressed in these stem cells will inform crop engineering to boost productivity. Single-cell analysis is a powerful tool for identifying regulators expressed in specific groups of cells. However, accessing plant shoot stem cells is challenging. Recent single-cell analyses of plant shoots have not captured these cells, and failed to detect stem cell regulators like CLAVATA3 and WUSCHEL. In this study, we finely dissected stem cell-enriched shoot tissues from both maize and arabidopsis for single-cell RNA-seq profiling. We optimized protocols to efficiently recover thousands of CLAVATA3 and WUSCHEL expressed cells. A cross-species comparison identified conserved stem cell regulators between maize and arabidopsis. We also performed single-cell RNA-seq on maize stem cell overproliferation mutants to find additional candidate regulators. Expression of candidate stem cell genes was validated using spatial transcriptomics, and we functionally confirmed roles in shoot development. These candidates include a family of ribosome-associated RNA-binding proteins, and two families of sugar kinase genes related to hypoxia signaling and cytokinin hormone homeostasis. These large-scale single-cell profiling of stem cells provide a resource for mining stem cell regulators, which show significant association with yield traits. Overall, our discoveries advance the understanding of shoot development and open avenues for manipulating diverse crops to enhance food and energy security.","creator":"Xu, X., Passalacqua, M., Rice, B., Demesa-Arevalo, E., Kojima, M., Takebayashi, Y., Harris, B., Sakakibara, H., Gallavotti, A., Gillis, J., Jackson, D."},{"id":"2024.03.05.583564v1","slug":"high-throughput-phenotyping-of-seed-quality-traits-using-imaging-and-deep-learning-in-dry-pea","title":"High-Throughput Phenotyping of Seed Quality Traits Using Imaging and Deep Learning in Dry Pea","link":"http://biorxiv.org/cgi/content/short/2024.03.05.583564v1?rss=1","abstract":"Seed traits, such as seed color and seed size, directly impact seed quality, affecting the marketability and value of dry peas [1]. Assessing seed quality is integral to a plant breeding programs to ensure optimal seed standards. This research introduced a phenotyping tool to assess seed quality traits specifically tailored for pulse crops, which integrates image processing with cutting-edge deep learning models. The proposed method is designed for automation, seamlessly processing a sequence of images while minimizing human intervention. The pipeline standardized red-green-blue (RGB) images captured from a color light box and used deep learning models to segment and detect seed features. Our method extracted up to 86 distinct seed characteristics, ranging from basic size metrics to intricate texture details and color nuances. Compared to traditional methods, our pipeline demonstrated a 95 percent similarity in seed quality assessment and increased time efficiency (from 2 weeks to 30 minutes for processing time). Specifically, we observed an improvement in the accuracy of seed trait identification by simply using an RGB value instead of a categorical, non-standard description, which allowed for an increase in the range of detectable seed quality characteristics. By integrating conventional image processing techniques with foundational deep learning models, this approach emerges as a pivotal instrument in pulse breeding programs, guaranteeing the maintenance of superior seed quality standards.","creator":"Morales, M., Worral, H., Piche, L., Atanda, S. A., Dariva, F., Ramos, C., Hoang, K., Yan, C., Flores, P., Bandillo, N."},{"id":"2024.03.04.583290v1","slug":"disentangling-plant-response-to-biotic-and-abiotic-stress-using-hive-a-novel-tool-to-perform-unpaired-multi-omics-integration","title":"Disentangling plant response to biotic and abiotic stress using HIVE, a novel tool to perform unpaired multi-omics integration","link":"http://biorxiv.org/cgi/content/short/2024.03.04.583290v1?rss=1","abstract":"Plants live in a constantly changing environment that is often unfavorable or even hostile. Indeed, they developed high phenotypic plasticity that includes rapid responses to aggressive biotic and abiotic factors and adaptations to changing environments. Multiple stresses can occur at the same time, requiring the plants to activate appropriate signaling pathways to respond to both or by prioritising the response to one stress factor. While several studies have been conducted to individual stress factors, only very few studies focus on the simultaneous plant response to multiple stressors. Currently used methods to integrate unpaired experiments consist of performing meta-analysis or finding differentially expressed genes for each condition separately and then selecting the common ones. Although these approaches allowed to find valuable results, they cannot identify non-specific conserved mechanisms that may hold promise for a broader understanding of plant defence response mechanisms. For this purpose, we developed HIVE (Horizontal Integration analysis using Variational AutoEncoders) to analyse horizontally integrated multi-omics datasets composed of unpaired and/or longitudinal experiments. Briefly, we coupled a variational autoencoder, that captures non-linear relationships and encoded them in the latent space, with a random forest regression and the SHAP explainer to select relevant genes for the studied phenotype. We illustrate the functionality of HIVE to study the transcriptional changes of two peanut wild relatives plants during root-knot nematode Meloidogyne arenaria infection and/or drought stress from seven unpaired experiments. HIVE performed better than the meta-analysis and the state-of-the-art tool and identified novel promising candidates responsible for triggering effective defense responses to biotic and abiotic stress.","creator":"Calia, G., Zotta Mota, A. P., Seynabou, M., Nguyen, H. T., Ghat, A., Schuler, H., Gwizdek, C., Brasileiro, A., Guimares, P., BOTTINI, S."},{"id":"2024.03.04.582885v1","slug":"identification-of-rack1a-as-a-component-of-the-auxin-ethylene-crosstalk-regulating-apical-hook-development-in-arabidopsis-thaliana","title":"Identification of RACK1A as a component of the auxin-ethylene crosstalk regulating apical hook development in Arabidopsis thaliana","link":"http://biorxiv.org/cgi/content/short/2024.03.04.582885v1?rss=1","abstract":"Apical hook development is an ideal model for studying differential growth in plants, and is controlled by complex hormonal crosstalk, with auxin and ethylene being the major players. Here, we identified a bioactive small molecule that decelerates apical hook opening in Arabidopsis thaliana. Our genetic studies suggest that this molecule enhances or maintains the auxin maximum found in the inner hook side and requires certain auxin and ethylene signaling components to modulate apical hook opening. Using biochemical approaches, we then revealed the WD40 repeat scaffold protein RECEPTOR FOR ACTIVATED C KINASE 1A (RACK1A) as a direct target of this compound. We present data in support of RACK1A playing a positive role in apical hook opening by negatively regulating the differential auxin response gradient across the hook via specific auxin and ethylene signaling mechanisms and thereby adjusting differential cell growth, an essential process for organ structure and function in plants. We have thus identified a role for RACK1A and auxin-ethylene crosstalk in negatively regulating differential cell growth to promote apical hook opening.","creator":"Ma, Q., Liu, S., Raggi, S., Doyle, S. M., Parizkova, B., Barange, D. K., Wilkinson, E. G., Crespo Garcia, I., Bygdell, J., Wingsle, G., Boer, D. R., Strader, L. C., Almqvist, F., Novak, O., Robert, S."},{"id":"2024.03.04.583282v1","slug":"regulation-of-arabidopsis-polyamine-acetylation-by-nata1-and-nata2","title":"Regulation of Arabidopsis polyamine acetylation by NATA1 and NATA2","link":"http://biorxiv.org/cgi/content/short/2024.03.04.583282v1?rss=1","abstract":"Polyamines have vital functions in organisms, including bacteria, plants, and animals, with key roles in growth, development, and stress responses. Spermine/spermidine N1-acetyl transferases (SSATs) regulate polyamine abundance by catalysing their N-acetylation, thereby reducing the pool of polyamines and producing other bioactive components. The regulatory mechanisms controlling SSAT enzymes are incompletely understood. Here, we investigate the biological role and regulation of the two SSAT isoforms present in Arabidopsis thaliana, N-ACETYLTRANSFERASE ACTIVITY (NATA) 1 and 2. We show that NATA2 is a heat-stable isoform, induced in response to heat. Intriguingly, a nata2 knockout mutation proved beneficial for growth and pathogen defence under heat stress in Arabidopsis, aligning with the stress-mitigating effect of polyamines. In contrast, the double knockout of nata1 and nata2 was lethal, highlighting the essential role of basal SSAT activity. Our numerous crystal structures of both NATAs, supported by functional assays, revealed that stress-produced acidic metabolites can selectively inhibit polyamine acetylation by occupying the NATA substrate-binding pocket. This environment-responsive regulation mechanism may allow Arabidopsis to adjust the deleterious action of NATAs under stress conditions, without eliminating the enzyme. More generally, metabolite-ensemble inhibition may be a novel paradigm for non-genetic feedback regulation of plant enzymes.","creator":"Hameed, U. F. S., Luo, Y.-R., Yan, J., Guzman-Vega, F. J., Aleksenko, E., Briozzo, P., MORERA, S., Jander, G., Arold, S. T."},{"id":"2024.03.04.583436v1","slug":"small-but-mitey-investigating-the-molecular-genetic-basis-for-mite-domatia-development-and-intraspecific-variation-in-vitis-riparia-using-transcriptomics","title":"Small, but mitey: Investigating the molecular genetic basis for mite domatia development and intraspecific variation in Vitis riparia using transcriptomics","link":"http://biorxiv.org/cgi/content/short/2024.03.04.583436v1?rss=1","abstract":"* Here, we investigated the molecular genetic basis of mite domatia, structures on the underside of leaves that house mutualistic mites, and intraspecific variation in domatia size in Vitis riparia (riverbank grape).  * Domatia and leaf traits were measured, and the transcriptomes of mite domatia from two genotypes of V. riparia with distinct domatia sizes were sequenced to investigate the molecular genetic pathways that regulate domatia development and intraspecific variation in domatia traits.  * Key trichome regulators as well as auxin and jasmonic acid are involved in domatia development. Genes involved in cell wall biosynthesis, biotic interactions, and molecule transport/metabolism are upregulated in domatia, consistent with their role in domatia development and function.  * This work is one of the first to date that provides insight into the molecular genetic bases of mite domatia. We identified key genetic pathways involved in domatia development and function, and uncovered unexpected pathways that provide an avenue for future investigation. We also found that intraspecific variation in domatia size in V. riparia seems to be driven by differences in overall leaf development between genotypes.","creator":"Ritter, E. J., Graham, C. D. K., Niederhuth, C., Weber, M. G."},{"id":"2024.03.04.583427v1","slug":"identification-of-new-resistance-qtl-regions-in-loquat-cultivar-champagne-against-pseudomonas-syringae-pv-eriobotryae-group-c","title":"Identification of new resistance QTL regions in loquat cultivar Champagne against  Pseudomonas syringae  pv.  eriobotryae  group C","link":"http://biorxiv.org/cgi/content/short/2024.03.04.583427v1?rss=1","abstract":"Loquat canker, caused by Pseudomonas syringae pv. eriobotryae, is a bacterial disease that infects loquat (Eriobotrya japonica) and has been reported in several countries. Three pathotypes, A, B, and C, have been reported in Japan. The loquat cultivar Champagne is resistant to the loquat canker group C and possesses a qualitative trait governed by a recessive homozygous pse-c gene located on Linkage Group 3 (LG3), and quantitative traits located at unidentified loci. In this study, we identified novel quantitative trait loci (QTL) regions for resistance to group C in this cultivar. A seedling population with Tanaka (Pse-c/Pse-c) crossed with Champagne (pse-c/pse-c) was tested. The genetic map of Champagne includes a total of 1,016 SNP markers mapped across 17 LGs, covering a total distance of 1,301 cM and an average marker density of 1.4 cM/locus. In addition to minor potential QTLs, the major QTL for resistance to loquat canker group C was detected in the upper region of LG14, with the QTL contributing 6.9% to the disease index. The results of this study open new possibilities for resistance breeding against this disease.","creator":"Koga, S., Kawaguchi, R., Tanaka, T., Moriya, S., Hiehata, N., Kabashima, K., Nagano, A. J., Nagano, Y., Fukuda, S."},{"id":"2024.03.05.583495v1","slug":"biological-control-of-green-mold-in-simulated-post-harvest-chain-of-citrus-fruit-efficacy-of-candida-oleophila-strain-o-and-molecular-insight-into-elicitation-of-host-immune-system","title":"Biological Control of Green Mold in Simulated Post-harvest Chain of Citrus Fruit: Efficacy of Candida oleophila Strain O and Molecular Insight into Elicitation of Host Immune System","link":"http://biorxiv.org/cgi/content/short/2024.03.05.583495v1?rss=1","abstract":"Managing post-harvest decays in citrus fruit without relying on conventional pesticides presents a significant challenge in modern Plant Pathology. This study aimed to evaluate the efficacy of the biological control agent Candida oleophila strain O in controlling green mold caused by Penicillium digitatum throughout various stages of the post-harvest supply chain. Using a series of in vivo experiments, different scenarios of P. digitatum infections in clementine tangerine, orange, and lemon fruit were examined, with treatments applied before, during or after infection. The study simulated typical conditions of the citrus supply chain, including picking, processing in packinghouses, and transportation, as well as cold storage and shelf-life phases. Results indicated that C. oleophila exhibited significant efficacy in reducing green mold symptoms, even at shelf-life temperatures, making it a practical alternative to conventional fungicides. Additionally, the study provided insights into the molecular mechanisms underlying the defensive response of citrus fruit to C. oleophila treatment, with up-regulation of defense-related genes observed across different fruit types. Overall, this study underscores the potential of C. oleophila as a sustainable and effective solution for managing post-harvest decays in citrus fruit within the complexities of the supply chain.","creator":"Rovetto, E. I., La Spada, F., El Boumlasy, S., Conti Taguali, S., Riolo, M., Pane, A., Cacciola, S. O."},{"id":"2024.03.03.583219v1","slug":"viral-delivery-of-recombinases-to-activate-heritable-genetic-switches-in-plants","title":"Viral delivery of recombinases to activate heritable genetic switches in plants","link":"http://biorxiv.org/cgi/content/short/2024.03.03.583219v1?rss=1","abstract":"Viral vectors provide an increasingly versatile platform for transformation-free reagent delivery to plants. RNA viral vectors can be used to induce gene silencing, overexpress proteins, or introduce gene editing reagents, but they are often constrained by carrying capacity or restricted tropism in germline cells. Site-specific recombinases that catalyze precise genetic rearrangements are powerful tools for genome engineering that vary in size and, potentially, efficacy in plants. In this work, we show that viral vectors based on Tobacco rattle virus (TRV) deliver and stably express four recombinases ranging in size from [~]0.6kb to [~]1.5kb, and achieve simultaneous marker removal and reporter activation through targeted excision in transgenic Nicotiana benthamiana target lines. TRV vectors with Cre, FLP, CinH, and Integrase13 efficiently mediated recombination in infected somatic tissue, and also led to heritable modifications at high frequency. An excision-activated Ruby reporter enabled simple and high-resolution tracing of infected cell lineages, without the need for molecular genotyping. Together, our experiments broaden the scope of viral recombinase delivery, and offer insights into infection dynamics that may be useful in the development of future viral vectors.","creator":"Chamness, J. C., Cody, J. P., Cruz, A. J., Voytas, D."},{"id":"2024.03.05.583474v1","slug":"spray-induced-gene-silencing-sigs-as-a-tool-for-the-management-of-pine-pitch-canker-forest-disease","title":"Spray-induced gene silencing (SIGS) as a tool for the management of Pine Pitch Canker forest disease","link":"http://biorxiv.org/cgi/content/short/2024.03.05.583474v1?rss=1","abstract":"Global change is exacerbating the prevalence of plant diseases caused by pathogenic fungi in forests worldwide. The conventional use of chemical fungicides, which is commonplace in agricultural settings, is not sanctioned for application in forest ecosystems, so novel control strategies are imperative. The promising approach SIGS (Spray-Induced Gene Silencing) involves the external application of specific double-stranded RNA (dsRNA), which can modulate the expression of target genes through environmental RNA interference in eukaryotes. SIGS exhibited notable success in reducing virulence when deployed against some crop fungal pathogens, such as Fusarium graminearum, Botrytis cinerea and Sclerotinia sclerotiorum, among others. However, there is a conspicuous dearth of studies evaluating the applicability of SIGS for managing forest pathogens. This research aimed to determine whether SIGS could be used to control Fusarium circinatum, a widely impactful forest pathogen that causes Pine Pitch Canker disease. To achieve this, we designed and produced though a bacterial synthesis, dsRNA molecules to target fungal essential genes involved to vesicle trafficking (Vps51, DCTN1, and SAC1), signal transduction (Pp2a, Sit4, Ppg1, and Tap42), and cell wall biogenesis (Chs1, Chs2, Chs3b, Gls1) metabolic pathways. We confirmed that F. circinatum is able to uptake externally applied dsRNA, triggering an inhibition of the pathogens virulence. Furthermore, this study pioneers the demonstration that recurrent applications of dsRNAs in SIGS are more effective in protecting plants than single applications. Therefore, SIGS emerges as an effective and sustainable approach for managing plant pathogens, showcasing its efficacy in controlling a globally significant forest pathogen subject to quarantine measures.","creator":"Bocos Asenjo, I. T., Amin, H., Mosquera, S., Diez Hermano, S., Ginesy, M., Diez, J. J., Nino Sanchez, J."},{"id":"2024.03.03.583192v1","slug":"overexpression-of-ppgl2-from-prunus-persica-enhanced-soybean-drought-tolerance","title":"Overexpression of PpGL2 from Prunus persica enhanced soybean drought tolerance","link":"http://biorxiv.org/cgi/content/short/2024.03.03.583192v1?rss=1","abstract":"The HD-ZIP transcription factor family plays crucial roles in plant growth and abiotic stress responses. While its diverse functions and regulatory mechanisms are well-documented, its role in conferring abiotic stress tolerance in peaches remains largely unexplored. Here, we report the bioinformatics profile of PpGL2, a member of the HD-ZIP transcription factor family, and its integration into the soybean genome to assess its potential impact on drought tolerance. Localization studies in onion cells revealed nuclear localization of PpGL2-GFP fusion protein, while yeast hybridization experiments demonstrated its transactivation and DNA binding abilities. PpGL2 overexpression under drought conditions led to reduced accumulation of reactive oxygen species and malondialdehyde compared to wild-type, decreased water loss rate, and increased chlorophyll content and relative water content. Additionally, PpGL2 overexpression promoted plant height and root length under drought stress, accompanied by altered transcription levels of stress-related genes across different plant genotypes. Furthermore, PpGL2 overexpression enhanced oxidative tolerance. Therefore, our findings suggest that PpGL2 overexpression holds promise for enhancing soybean drought resistance, offering a novel approach to improving soybean drought resistance.","creator":"Li, W., Li, D., Zhao, L., Li, H."},{"id":"2024.03.03.582478v1","slug":"unveiling-the-intricate-sinking-behavior-of-large-diatoms-insights-from-time-frequency-analysis-of-palmerina-hardmaniana-sinking-under-silicate-depleted-conditions","title":"Unveiling the Intricate Sinking behavior of Large Diatoms: Insights from Time-Frequency Analysis of Palmerina hardmaniana Sinking under Silicate-Depleted Conditions","link":"http://biorxiv.org/cgi/content/short/2024.03.03.582478v1?rss=1","abstract":"Nutrient limits impact diatom sinking in time domain, but response in time-frequency domain is unclear. Studying the response of large diatoms to nutrients exclusively in the time domain fails to fully capture the complete impact of nutrient limitations on sinking behavior due to the absence of crucial information, including period and frequency. Wavelet analysis provides valuable insights into the period and frequency of signals and unveils their positions in the time. This study investigated the sinking behavior response of the large diatom Palmerina hardmaniana to silicate-depleted conditions in the time-frequency domain using wavelet analysis. The results showed that P. hardmaniana was capable of regulating its sinking speed, and this regulation occurred intermittently in time. The predominant frequency of intermittent regulation fell within the range of 0.13-0.50 Hz (equivalent to a period of 2-8 s) for both control and silicate-depleted conditions. The similarity in the frequency range of regulation between the two groups suggests the involvement of shared physiological mechanisms. P. hardmaniana responded to silicate depletion by intensifying the regulation of 0.13-0.50 Hz, which was reflected in the time domain as a change in the proportion of different instantaneous sinking speeds and consequently lead to a significant increase or decrease in the mean sinking speed (p<0.05). Additionally, the regulation of P. hardmaniana sinking behavior was also influenced by the physiological state of the cells. Short-term silicate stress (30 min) enhanced the oscillation power of sinking regulation, while prolonged silicate stress (greater than or equal to 3 d) led to a decline in oscillation power.","creator":"Ping, Z., Lu, J., Li, L., Zhuang, J., Lai, J., Shi, T., Li, J."},{"id":"2024.03.04.583410v1","slug":"variations-of-floral-temperature-in-changing-weather-conditions","title":"Variations of floral temperature in changing weather conditions","link":"http://biorxiv.org/cgi/content/short/2024.03.04.583410v1?rss=1","abstract":"O_LIFloral temperature is a flower characteristic that has the potential to impact the fitness of flowering plants and their pollinators. Likewise, the presence of floral temperature patterns, areas of contrasting temperature across the flower, can have similar impacts on the fitness of both mutualists. C_LIO_LIIt is currently poorly understood how floral temperature changes under the influence of different weather conditions, and how floral traits may moderate these changes. Such weather dependency will impact how stable floral temperatures are over time and their utility to plant and pollinator. The stability of floral temperature cues is likely to facilitate effective plant-pollinator interactions and play a role in the plants reproductive success. C_LIO_LIWe use thermal imaging to monitor how floral temperatures and temperature patterns of four plant species (Cistus  snow fire and  snow white, Coreopsis verticillata and Geranium psilostemon) change with several weather variables (illumination, temperature; windspeed; cloud cover; humidity and pressure) during times that pollinators are active. C_LIO_LIAll weather variables influenced floral temperature in one or more species. The directionality of these relationships were similar across species. In all species light conditions (illumination) had the greatest influence on floral temperature overall, and in generation of contrasting temperatures between parts of the flower, temperature patterns. The effect sizes of other weather variables were lower and more varied across the four species. Most likely, floral traits such as pigmentation and structure influence these relationships between weather conditions and generation of floral temperature. C_LIO_LISynthesis: Floral temperature and the extent to which flowers showed contrasting temperature patterns were influenced predominantly by light conditions. However, several weather variables had additional, lesser, influences. Furthermore, differences in floral traits, pigmentation and structure, likely resulted in differences in temperature responses to given conditions between species and different parts of the same flower. However, floral temperatures and contrasting temperature patterns that are sufficiently elevated for detection by pollinators were maintained across most conditions if flowers received moderate illumination. This suggests the presence of elevated floral temperature and contrasting temperature patterns are fairly constant and may have potential to influence plant-pollinator interactions across weather conditions. C_LI","creator":"Harrap, M. J. M., de Vere, N., Hempel de Ibarra, N., Whitney, H. M., Rands, S. A."},{"id":"2024.03.04.583368v1","slug":"periplasmic-carbonic-anhydrase-cah1-contributes-to-high-inorganic-carbon-affinity-in-chlamydomonas-reinhardtii","title":"Periplasmic carbonic anhydrase CAH1 contributes to high inorganic carbon affinity in Chlamydomonas reinhardtii","link":"http://biorxiv.org/cgi/content/short/2024.03.04.583368v1?rss=1","abstract":"Carbonic anhydrase (CA), an enzyme conserved across species, is pivotal in the interconversion of inorganic carbon (Ci; CO2 and HCO3-). Compared to the well-studied intracellular CA, the specific role of extracellular CA in photosynthetic organisms is still not well understood. In the green alga Chlamydomonas reinhardtii, CAH1, located at the periplasmic space, is strongly induced under CO2-limiting conditions by the Myb transcription factor LCR1. While it has been observed that the lcr1 mutant shows decreased Ci-affinity, the detailed mechanisms behind this phenomenon are yet to be elucidated. In this study, we aimed to unravel the LCR1-dependent genes essential for maintaining high Ci-affinity. To achieve this, we identified a total of 12 LCR1-dependent inducible genes under CO2-limiting conditions, focusing specifically on the most prominent ones - CAH1, LCI1, LCI6, and Cre10.g426800. We then created mutants of these genes using the CRISPR-Cas9 system, all from the same parental strain, and compared their Ci-affinity. Contrary to earlier findings (Van and Spalding, 1999) that reported no reduction in Ci-affinity in the cah1 mutant, our newly created cah1-1 mutant exhibited a significant decrease in Ci-affinity under high HCO3-/CO2-ratio conditions. Additionally, when we treated wild-type cells with a CA inhibitor with low membrane permeability, a similar reduction in Ci-affinity was observed. Moreover, the addition of exogenous CA to the cah1 mutant restored the decreased Ci-affinity. These results, highlighting the crucial function of the periplasmic CAH1 in maintaining high Ci-affinity in Chlamydomonas cells, provide new insights into the functions of periplasmic CA in algal carbon assimilation.  One-sentence summaryCAH1, a periplasmic carbonic anhydrase in Chlamydomonas reinhardtii, plays a crucial role in maintaining a high affinity for inorganic carbon, particularly under CO2-limiting conditions.","creator":"Shimamura, D., Ikeuchi, T., Tsuji, Y., Fukuzawa, H., Yamano, T."},{"id":"2024.03.01.583049v1","slug":"lhp1-and-ino80-cooperate-with-ethylene-signaling-for-warm-ambient-temperature-response-by-activating-specific-bivalent-genes","title":"LHP1 and INO80 cooperate with ethylene signaling for warm ambient temperature response by activating specific bivalent genes","link":"http://biorxiv.org/cgi/content/short/2024.03.01.583049v1?rss=1","abstract":"Ethylene signaling has been indicated as a potential positive regulator of plant warm ambient temperature response but its underlying molecular mechanisms are largely unknown. Here, we show that LHP1 and INO80 cooperate with ethylene signaling for warm ambient temperature response by activating specific bivalent genes. We found that the presence of warm ambient temperature activates ethylene signaling through EIN2 and EIN3, leading to an interaction between LHP1 and accumulated EIN2-C to co-regulate a subset of LHP1-bound genes marked by H3K27me3 and H3K4me3 bivalency. Furthermore, we demonstrate that INO80 is recruited to bivalent genes by interacting with EIN2-C and EIN3, promoting H3K4me3 enrichment and facilitating transcriptional activation in response to warm ambient temperature. Together, our findings illustrate a novel mechanism wherein ethylene signaling orchestrates LHP1 and INO80 to regulate warm ambient temperature response through activating specific bivalent genes in Arabidopsis.","creator":"Shao, Z., Bai, Y., Huq, E., Qiao, H."},{"id":"2024.02.29.582853v1","slug":"impact-of-alternative-splicing-on-arabidopsis-proteome","title":"Impact of alternative splicing on Arabidopsis proteome","link":"http://biorxiv.org/cgi/content/short/2024.02.29.582853v1?rss=1","abstract":"Alternative splicing is an important regulatory process in eukaryotes. In plants, the major form of alternative splicing is intron retention. Despite its importance, the global impact of AS on the Arabidopsis proteome has not been investigated. In this study, we address this gap by performing a comprehensive integrated analysis of how changes in AS can affect the Arabidopsis proteome using mutants that disrupt ACINUS and PININ, two evolutionarily conserved alternative splicing factors. We used tandem mass tagging (TMT) with real-time search MS3 (RTS-SPS-MS3) coupled with extensive sample fractionations to achieve very high coverage and accurate protein quantification. We then integrated our proteomic data with transcriptomic data to assess how transcript changes and increased intron retention (IIR) affect the proteome. For differentially expressed transcripts, we have observed a weak to moderate correlation between transcript changes and protein changes. Our studies revealed that some IIRs have no effect on either transcript or protein levels, while some IIRs can significantly affect protein levels. Surprisingly, we found that IIRs have a much smaller effect on increasing protein diversity. Notably, the increased intron retention events detected in the double mutant are also detected in the WT under various biotic or abiotic stresses. We further investigated the characteristics of the retained introns. Our extensive proteomic data help to guide the phenotypic analysis and reveal that collective protein changes contribute to the observed phenotypes of the increased anthocyanin, pale green, reduced growth, and short root observed in the acinus pnn double mutant. Overall, our study provides insight into the intricate regulatory mechanism of intron retention and its impact on protein abundance in plants.","creator":"Reyes, A. V., Shrestha, R., Grismer, T. S., Byun, D., Xu, S."},{"id":"2024.02.29.582862v1","slug":"atg6-interacting-with-npr1-increases-arabidopsis-thaliana-resistance-to-pst-dc3000-avrrps4-by-increasing-its-nuclear-accumulation-and-stability","title":"ATG6 interacting with NPR1 increases Arabidopsis thaliana resistance to Pst DC3000/avrRps4 by increasing its nuclear accumulation and stability","link":"http://biorxiv.org/cgi/content/short/2024.02.29.582862v1?rss=1","abstract":"Autophagy-related gene 6 (ATG6) plays a crucial role in plant immunity. Nonexpressor of pathogenesis-related genes1 (NPR1) acts as a signaling hub of plant immunity. However, the relationship between ATG6 and NPR1 is unclear. Here, we find that ATG6 directly interacts with NPR1. ATG6 overexpression significantly increased nuclear accumulation of NPR1. Furthermore, we demonstrate that ATG6 increases NPR1 protein levels and improves its stability. Interestingly, ATG6 promotes the formation of SINCs (SA-induced NPR1 condensates)-like condensates. Additionally, ATG6 and NPR1 synergistically promote the expression of pathogenesis-related genes. Further results showed that silencing ATG6 in NPR1-GFP exacerbates Pst DC3000/avrRps4 invasion, while double overexpression of ATG6 and NPR1 synergistically inhibits Pst DC3000/avrRps4 invasion. In summary, our findings unveil an interplay of NPR1 with ATG6 and elucidate important molecular mechanisms for enhancing plant immunity.  HighlightWe unveil a novel relationship in which ATG6 positively regulates NPR1 in plant immunity.","creator":"Zhang, B., Huang, S., Guo, S., Meng, Y., Tian, Y., Zhou, Y., Chen, H., Li, X., Zhou, J., Chen, W."},{"id":"2024.03.01.582956v1","slug":"ptac3-and-ptac14-are-required-for-binding-of-plastid-encoded-rna-polymerase-to-dna","title":"pTAC3 and pTAC14 are required for binding of plastid-encoded RNA polymerase to DNA","link":"http://biorxiv.org/cgi/content/short/2024.03.01.582956v1?rss=1","abstract":"Plastid-encoded RNA polymerase (PEP) is a bacterial-type multisubunit RNA polymerase responsible for the majority of transcription in chloroplasts. PEP consists of four core subunits, which are orthologs of their cyanobacterial counterparts. In Arabidopsis thaliana, PEP associates with 12 PEP-associated proteins (PAPs), which serve as peripheral subunits of the RNA polymerase. The exact contributions of PAPs to PEP function are still poorly understood. We use ptChIP-seq to show that PAP1/pTAC3, a peripheral subunit of PEP, binds to the same genomic loci as RpoB, a core subunit of PEP. The pap1/ptac3 mutant shows a complete loss of RpoB binding to DNA throughout the genome, indicating that PAP1/pTAC3 is necessary for RpoB binding to DNA. A similar loss of RpoB binding to DNA is observed in the pap7/ptac14 mutant, which is defective in another peripheral PEP subunit. We propose that the peripheral subunits of PEP are required for the recruitment of core PEP subunits to DNA.  KEY MESSAGEThe peripheral subunits of plastid-encoded RNA polymerase play a crucial role in recruiting the core PEP subunits to DNA in Arabidopsis chloroplasts.","creator":"Wang, J., Palomar, M., Min, J.-H., Wierzbicki, A."},{"id":"2024.02.29.582824v1","slug":"redox-regulation-by-the-cdsp32-thioredoxin-of-atp-synthase-activity-and-enzymatic-antioxidant-network-in-solanum-tuberosum","title":"Redox regulation by the CDSP32 thioredoxin of ATP-synthase activity and enzymatic antioxidant network in Solanum tuberosum","link":"http://biorxiv.org/cgi/content/short/2024.02.29.582824v1?rss=1","abstract":"Plant thioredoxins (TRXs) form a complex family involved in numerous metabolic and signalling pathways, such as the regulation of photosynthetic metabolism in relation with light conditions. The atypical CDSP32, chloroplastic drought-induced stress protein of 32 kDa, TRX includes two TRX-fold domains, one of which has an atypical redox-active HCGPC motif, and has been initially reported to participate in responses to oxidative stress as an electron donor to peroxiredoxins and methionine sulfoxide reductases. Here, we further characterized potato lines modified for CDSP32 expression to clarify the physiological roles of the TRX. Upon high salt treatments, modified lines displayed changes in the abundance and redox status of CDSP32 antioxidant partners, and exhibited sensitivity to NaHCO3, but not to NaCl. In non-stressed plants overexpressing CDSP32, a lower abundance of photosystem II PsbO and D1 subunits and ATP-synthase {gamma} subunit was noticed. The CDSP32 co-suppressed line showed altered chlorophyll a fluorescence induction and modified regulation of the plastidial ATP-synthase activity during dark/light and light/dark transitions, revealing the involvement of CDSP32 in the control of the photosynthetic machinery. In agreement with the previously reported interaction in planta between CDSP32 and the ATP-synthase {gamma} subunit, our data show that CDSP32 participates in the regulation of the transthylakoid membrane potential. Consistently, modeling of protein complex 3-D structure indicates that the CDSP32 TRX constitutes a suitable partner of ATP-synthase {gamma} subunit. We discuss the roles of CDSP32 in chloroplast redox homeostasis through the regulation of both photosynthetic activity and enzymatic antioxidant network.","creator":"Rey, P., Henri, P., Alric, J., Blanchard, L., Viola, S."},{"id":"2024.03.03.583161v1","slug":"two-pyridoxal-phosphate-homeostasis-proteins-are-essential-for-management-of-the-coenzyme-in-plants","title":"Two PYRIDOXAL PHOSPHATE HOMEOSTASIS PROTEINs are essential for management of the coenzyme in plants","link":"http://biorxiv.org/cgi/content/short/2024.03.03.583161v1?rss=1","abstract":"Coenzyme management is believed to be important for the required pool of active enzymes driving metabolic routes to facilitate homeostasis and match environmental circumstance. The coenzyme pyridoxal 5-phosphate (PLP) (a vitamin B6 derivative) is involved in a diverse array of enzyme reactions spanning amino acid to hormone metabolism. However, dedicated proteins that contribute to PLP homeostasis have not yet been studied in plants. Here we demonstrate the importance of proteins annotated PLP HOMEOSTASIS PROTEINs (PLPHPs) for control of PLP in Arabidopsis. A systematic analysis indicates that while most kingdoms have a single PLPHP homolog, Angiosperms within the plant kingdom have two. PLPHPs from Arabidopsis bind PLP and exist as monomers in solution in contrast to reported PLP-dependent enzymes from all kingdoms. Disrupting functionality of both homologs perturbs vitamin B6 content including a PLP deficit accompanied by impaired and light hypersensitive root growth, unlike biosynthesis mutants. Micrografting studies show that the PLP deficit can be relieved distally between shoots and roots. Yet, supplementation experiments do not restore vitamin B6 homeostasis in the absence of PLPHP. A series of chemical treatments probing PLP-dependent reactions, notably those for auxin and ethylene, provide evidence that the physiological role of PLPHPs is dynamic management of PLP. Assays in vitro show that Arabidopsis PLPHP can coordinate both PLP transfer and withdrawal. This study expands our broader knowledge of vitamin B6 biology and highlights the importance of PLP coenzyme homeostasis in plants, providing a platform for further investigations in boosting adaptive responses.  One sentence summaryPLPHPs contribute to surveillance of vitamin B6 homeostasis, likely acting as a rheostat in adaptive responses as a function of the use of the coenzyme PLP.","creator":"Farkas, P., Fitzpatrick, T. B."},{"id":"2024.02.29.582789v1","slug":"the-early-dodder-gets-the-host-decoding-the-coiling-patterns-of-cuscuta-campestris-with-automated-image-processing","title":"The Early Dodder Gets the Host: Decoding the Coiling Patterns of Cuscuta campestris with Automated Image Processing","link":"http://biorxiv.org/cgi/content/short/2024.02.29.582789v1?rss=1","abstract":"Cuscuta spp., (dodder) is a rootless and leafless parasitic plant posing significant agricultural challenges. In this study, we aimed to elucidate the dynamics of the coiling patterns in Cuscuta campestris and examine the role of circadian rhythms in its host-seeking ability. Using time-lapse photography, we recorded the circumnutation and coiling movements of C. campestris at different inoculation times on non-living hosts. Subsequent image analyses were facilitated through an in-house Python-based image analysis pipeline. We observed that the coiling efficacy of C. campestris varied with the inoculation time of day, showing higher success and faster initiation in morning than in evening. These observations suggest that Cuscuta, despite lacking leaves and a developed chloroplast, can discern photoperiod changes, which significantly determine its parasitic efficiency. The automated image analysis confirmed the reliability of our Python pipeline, aligning closely with manual annotations. This study provides significant insights into the parasitic strategies of C. campestris and demonstrates the potential of integrating computational image analysis in plant biology for exploring complex plant behaviors. Furthermore, this method provides an efficient tool for investigating plant movement dynamics, laying the foundation for future studies on mitigating the economic impacts of parasitic plants.","creator":"Bentelspacher, M., Amezquita, E. J., Adhikari, S., Barros-Rios, J., Park, S."},{"id":"2024.03.03.582138v1","slug":"systematics-of-the-fleshy-fruited-sonerileae-melastomataceae","title":"Systematics of the fleshy-fruited Sonerileae (Melastomataceae)","link":"http://biorxiv.org/cgi/content/short/2024.03.03.582138v1?rss=1","abstract":"With approximately 1080 species, Sonerileae is the second largest tribe in the Melastomataceae. Approximately 40% of Sonerileae species belong to fleshy-fruited genera (Catanthera, Heteroblemma, Kendrickia, Medinilla, Pachycentria, and Plethiandra). Relatively few species, especially of the fleshy-fruited taxa, have been sampled for phylogenetic study. Consequently, there is huge uncertainty resulting in many unanswered questions about their evolutionary history, including the monophyly of the largest genus, Medinilla. In this study, the phylogeny of the fleshy-fruited Sonerileae was reconstructed using 385 nuclear and 81 plastid protein-coding loci recovered from target capture. Our study revealed that the fleshy fruited Sonerileae are polyphyletic and belong to three lineages. Kendrickia is sister to an Afrotropical endemic clade. Heteroblemma and Catanthera belong to a second clade and are most closely related to some Phyllagathis and Driessenia species. Medinilla forms a third clade, and includes Pachycentria and Plethiandra. Within Medinilla, fifteen clades are identified and characterized. To make Medinilla monophyletic, the genus is redefined to include Pachycentria and Plethiandra. Major lineages identified within Medinilla lay the groundwork for an infrageneric classification system. Areas of the phylogenetic tree with high conflict or weak sampling are identified to aid further studies in the tribe.","creator":"Quakenbush, J. P., Chen, L., Penneys, D. S., Barkman, T. J., Liu, Y., Yakandawala, D., Libalah, M. C. V. E., Kadereit, G."},{"id":"2024.02.29.582735v1","slug":"cold-stress-induces-a-rapid-redistribution-of-the-antagonistic-marks-h3k4me3-and-h3k27me3-in-arabidopsis-thaliana","title":"Cold stress induces a rapid redistribution of the antagonistic marks H3K4me3 and H3K27me3 in Arabidopsis thaliana","link":"http://biorxiv.org/cgi/content/short/2024.02.29.582735v1?rss=1","abstract":"When exposed to low temperatures, plants undergo a drastic reprogramming of their transcriptome in order to adapt to their new environmental conditions, which primes them for potential freezing temperatures. While the involvement of transcription factors in this process, termed cold acclimation, has been deeply investigated, the potential contribution of chromatin regulation remains largely unclear. A large proportion of cold-inducible genes carries the repressive mark histone 3 lysine 27 trimethylation (H3K27me3), which has been hypothesized as maintaining them in a silenced state in the absence of stress, but which would need to be removed or counteracted upon stress perception. However, the fate of H3K27me3 during cold exposure has not been studied genome-wide. In this study, we offer an epigenome profiling of H3K27me3 and its antagonistic active mark H3K4me3 during short-term cold exposure. Both chromatin marks undergo rapid redistribution upon cold exposure, however, the gene sets undergoing H3K4me3 or H3K27me3 differential methylation are distinct, refuting the simplistic idea that gene activation relies on a switch from an H3K27me3 repressed chromatin to an active form enriched in H3K4me3. Coupling the ChIP-seq experiments with transcriptome profiling reveals that differential histone methylation correlates with changes in expression. Interestingly, only a subset of cold-regulated genes lose H3K27me3 during their induction, indicating that H3K27me3 is not an obstacle to transcriptional activation. In the H3K27me3 methyltransferase curly leaf (clf) mutant, many cold regulated genes display reduced H3K27me3 levels but their transcriptional activity is not altered prior or during a cold exposure, suggesting that H3K27me3 may serve a more intricate role in the cold response than simply repressing the cold-inducible genes in naive conditions.","creator":"Faivre, L. A. C., Kinscher, N. F., Kuhlmann, A. B., Xu, X., Kaufmann, K., Schubert, D."},{"id":"2024.02.29.582690v1","slug":"brassinosteroid-and-gibberellin-signaling-are-required-for-tomato-internode-elongation-in-response-to-low-red-far-red-light","title":"Brassinosteroid and gibberellin signaling are required for Tomato internode elongation in response to low red: far-red light","link":"http://biorxiv.org/cgi/content/short/2024.02.29.582690v1?rss=1","abstract":"In this study, we explore the dynamic interplay between the plant hormones gibberellins (GA), brassinosteroids (BR), and Indole-3-Acetic Acid (IAA) in their collective impact on plant shade avoidance elongation under varying light conditions. We focus particularly on low Red: Far-red (R:FR) light conditions achieved by supplementing the background light with FR. Our research delves into how these hormones individually and synergistically influence stem elongation in tomato plants. Through meticulous experimental modulations of GA, IAA, and BR, we demonstrate that GA and BR are sufficient but also necessary for inducing stem elongation under low R:FR light conditions. Intriguingly, while IAA alone shows limited effects, its combination with GA yields significant elongation, suggesting a nuanced hormonal balance. Furthermore, we unveil the complex interplay of these hormones under light with low R:FR, where the suppression of one hormones effect can be compensated by the others. This study provides insights into the hormonal mechanisms governing plant adaptation to light, highlighting the intricate and adaptable nature of plant growth responses. Our findings have far-reaching implications for agricultural practices, offering potential strategies for optimizing plant growth and productivity in various lighting environments.  HighlightThis study unveils the interplay of brassinosteroids and gibberellins in shade avoidance elongation, revealing how tomatoes acclimate in response to far-red enriched light conditions.","creator":"Li, L., Helming, T., Wonder, J., van Asselt, G., Pantazopoulou, C. K., van de Kaa, Y. T. R., Kohlen, W., Pierik, R., Kajala, K."},{"id":"2024.02.28.582521v1","slug":"the-trade-off-between-grain-weight-and-grain-number-in-wheat-is-explained-by-the-overlapping-of-the-key-phases-determining-these-major-yield-components","title":"The trade-off between grain weight and grain number in wheat is explained by the overlapping of the key phases determining these major yield components","link":"http://biorxiv.org/cgi/content/short/2024.02.28.582521v1?rss=1","abstract":"Enhancing grain yield is a primary goal in the cultivation of major staple crops, including wheat. Recent research has focused on identifying the physiological and molecular factors that influence grain weight, a critical determinant of crop yield. However, a bottleneck has arisen due to the trade-off between grain weight and grain number, whose underlying causes remain elusive. In a novel approach, a wheat expansin gene, TaExpA6, known for its expression in root tissues, was engineered to express in the grains of the spring wheat cultivar Fielder. This modification led to increases in both grain weight and yield without adversely affecting grain number. Conversely, a triple mutant line targeting the gene TaGW2, a known negative regulator of grain weight, resulted in increased grain weight but decreased grain number, potentially offsetting yield gains. This study aimed to evaluate four wheat genotypes: (i) a transgenic line expressing TaExpA6, (ii) its wild-type counterpart (Fielder), (iii) a TaGW2 triple mutant line, and (iv) its wild-type. Conducted in southern Chile, the study employed a Complete Randomized Block Design with four replications, under well-managed field conditions including fertilization, irrigation, and pest control. The primary metrics assessed were grain yield, grain number, and average grain weight per spike, along with detailed measurements of grain weight and dimensions across the spike, and ovary weight at pollination (Waddingtons scale 10). The expression levels of TaExpA6 and TaGW2 were also monitored post-anthesis. Results indicated that both the TaExpA6 line and the triple mutant line achieved significantly higher average grain weights compared to their respective wild types. Notably, the TaExpA6 line did not exhibit a reduction in grain number, thereby enhancing grain yield per spike. In contrast, the triple mutant line showed a reduced grain number per spike, with no significant change in overall yield. Analysis of ovary size, grain weight dynamics, and gene expression patterns suggests that the trade-off between grain weight and number could be attributed to the overlapping of the critical periods for the determination of these traits.","creator":"Vicentin, L., Canales, J., Calderini, D. F."},{"id":"2024.02.28.582661v1","slug":"hy5-and-cop1-function-antagonistically-in-the-light-dependent-regulation-of-nicotine-biosynthesis-in-tobacco","title":"HY5 and COP1 function antagonistically in the light-dependent regulation of nicotine biosynthesis in tobacco","link":"http://biorxiv.org/cgi/content/short/2024.02.28.582661v1?rss=1","abstract":"Nicotine constitutes approximately 90% of the total alkaloid content within the Nicotiana species, rendering it the most prevalent alkaloid. While the majority of genes responsible for nicotine biosynthesis express in root tissue, the influence of light on this process through shoot-to-root mobile ELONGATED HYPOCOTYL 5 (HY5) has been recognized. CONSTITUTIVE PHOTOMORPHOGENIC1 (COP1), a key regulator of light-associated responses, known for its role in modulating HY5 accumulation, remains largely unexplored in its relationship to light-dependent nicotine accumulation. Here, we identified NtCOP1, a COP1 homolog in Nicotiana tabacum, and demonstrated its ability to complement the cop1 mutant in Arabidopsis thaliana at molecular, morphological, and biochemical levels. Through the development of NtCOP1 overexpression (NtCOP1OX) plants, we observed a significant reduction in nicotine and flavonol content, inversely correlated with the down-regulation of nicotine and phenylpropanoid pathway. Conversely, CRISPR/Cas9-based knockout mutant plants (NtCOP1CR) exhibited an increase in nicotine levels. Further investigations, including yeast-two hybrid assays, grafting experiments, and western blot analyses, revealed that NtCOP1 modulates nicotine biosynthesis by targeting NtHY5, thereby impeding its transport from shoot-to-root. We conclude that the interplay between HY5 and COP1 functions antagonistically in the light-dependent regulation of nicotine biosynthesis in tobacco.  HighlightCharacterization of CONSTITUTIVE PHOTOMORPHOGENIC1 (COP1) overexpressing and CRISPR/Cas9-based mutant plants suggests the intricate role of COP1 in modulating nicotine biosynthesis in tobacco.","creator":"Singh, D., Dwivedi, S., Singh, N., Trivedi, P."},{"id":"2024.02.28.582481v1","slug":"a-novel-tomato-inter-specific-solanum-lycopersicum-var-cerasiforme-and-s-pimpinellifolium-magic-population-facilitates-trait-association-and-candidate-gene-discovery-in-untapped-exotic-germplasm","title":"A novel tomato inter-specific (Solanum lycopersicum var. cerasiforme and S. pimpinellifolium) MAGIC population facilitates trait association and candidate gene discovery in untapped exotic germplasm","link":"http://biorxiv.org/cgi/content/short/2024.02.28.582481v1?rss=1","abstract":"We developed a novel eight-way tomato multi-parental advanced generation inter-cross (MAGIC) population to improve the accessibility of the genetic resources of tomato relatives to geneticists and breeders. The inter-specific MAGIC population (ToMAGIC) was obtained by inter-crossing four accessions each of Solanum lycopersicum var. cerasiforme (SLC) and S. pimpinellifolium (SP), which respectively are the weedy relative and the ancestor of cultivated tomato. The eight exotic ToMAGIC founders were selected based on a representation of the genetic diversity and geographical distribution of the two taxa. The resulting MAGIC population comprises 354 lines which were genotyped using a new 12k tomato Single Primer Enrichment Technology (SPET) panel and yielded 6,488 high-quality SNPs. The genotyping data revealed a high degree of homozygosity (average 93.69%), an absence of genetic structure, and a balanced representation (11.62% to 14.16%) of the founder genomes. To evaluate the potential of the ToMAGIC population for tomato genetics and breeding, a proof-of-concept was conducted by phenotyping it for fruit size, plant pigmentation, leaf morphology, and earliness traits. Genome-wide association studies (GWAS) identified strong associations for the studied traits, pinpointing both previously identified and novel candidate genes near or within the linkage disequilibrium blocks. Domesticated alleles for fruit size were recessive and were found, at low frequencies, in wild/ancestral populations. Our findings demonstrate that the newly developed ToMAGIC population is a valuable resource for genetic research in tomato, offering significant potential for identifying new genes that govern key traits in tomato breeding. ToMAGIC lines displaying a pyramiding of traits of interest could have direct applicability for integration into breeding pipelines providing untapped variation for tomato breeding.","creator":"Arrones, A., Antar, O., Pereira-Dias, L., Solana, A., Ferrante, P., Aprea, G., Plazas, M., Prohens, J., Diez, M. J., Giuliano, G., Gramazio, P., Vilanova, S."},{"id":"2024.02.28.582440v1","slug":"super-pangenome-of-grapevines-empowers-improvement-of-the-oldest-domesticated-fruit","title":"Super Pangenome of Grapevines Empowers Improvement of the Oldest Domesticated Fruit","link":"http://biorxiv.org/cgi/content/short/2024.02.28.582440v1?rss=1","abstract":"Grapevine (Vitis) is the oldest domesticated fruit crop with great cultural and economic importance. Here, we assemble and annotate haplotype-resolved genomes of 72 Vitis accessions including 25 wild and 47 cultivated grapevines, and a haplotype-resolved complete genome of V. vinifera. Coalescent phylogenomics of 142 haplotype genomes disentangles the mysterious hybridization history of grapevines, revealing enormous genetic diversity among species. Pangenome analysis together with phenotyping data reveals that European cultivars, more susceptible to the most destructive disease downy mildew (DM), had a smaller repertoire of disease resistance genes of NLR family. Through extensive structural variation (SV) characterization, phenotyping, transcriptome profiling of 113 Vitis accessions, and SV-eQTL analysis, we have identified over 79 SVs and their relevant genes significantly associated with DM resistance, exemplified by a lysine histidine transporter, VvLHT8. This haplotype-resolved complete genome and pangenome of Vitis genus will accelerate grapevine breeding and enrich our understanding of the evolution and biology of grapevines.","creator":"Guo, L., Wang, X., Ayhan, D. H., Rhaman, M. S., Yan, M., Jiang, J., Wang, D., Zheng, W., Mei, J., Ji, W., Jiao, J., Chen, S., Sun, J., Yi, S., Meng, D., Wang, J., Bhuiyan, M. N., Qin, G., Guo, L., Yang, Q., Zhang, X., Sun, H., Liu, C., Ye, W."},{"id":"2024.02.27.582216v1","slug":"seminal-root-angle-is-associated-with-root-system-architecture-in-durum-wheat","title":"Seminal root angle is associated with root system architecture in durum wheat","link":"http://biorxiv.org/cgi/content/short/2024.02.27.582216v1?rss=1","abstract":"Optimal root system architecture (RSA) is critical for efficient resource capture in soils, hence being an interest in crop breeding. Seminal root angle (SRA) at the seedling stage in durum wheat has been suggested to be a good indicator of RSA. However, research on correlating such lab-based seedling root phenotyping to RSA at later phases of plant growth is limited, resulting in the importance of root trait variation seen in seedlings often being overstated. To explore the role of SRA in modifying RSA at later phases of plant growth, we assessed 11 genotypes contrasting in SRA (wide and narrow), grown in a rhizobox designed for phenotyping root systems of plants during late-tillering. Above-ground traits and root dry mass in different soil depths and across the entire soil volume were measured manually, while root architectural traits were extracted using image analysis and summarised by multiple factor analysis to describe RSA. When comparing the wide and narrow genotypes, no differences were detected for above-ground traits and total root dry mass. However, differences were observed in the allocation of root dry mass at different depths. The wide and narrow genotypes showed distinct RSAs, particularly in the upper soil (0 - 30 cm). The wide genotypes exhibited a  spread-out root system with dense and thin roots, whereas the narrow genotypes had a compact root system with fewer but thicker roots. Our study demonstrated a clear difference in RSA between the wide and narrow genotypes, highlighting the association between SRA on the direction and distribution of root growth in plants at later growth stages.","creator":"Kang, Y., Rambla, C., Haeften, S., Fu, B., Akinlade, O., Potgieter, A., Borrell, A., Mace, E., Jordan, D., Alahmad, S., Hickey, L."}]},{"name":"Economics","feed":[{"id":"2403.03317","slug":"competing-mechanisms-in-games-played-through-agents-theory-and-experiment","title":"Competing Mechanisms in Games Played Through Agents: Theory and Experiment","link":"https://arxiv.org/abs/2403.03317","abstract":"Abstract: This paper proposes Competing Mechanism Games Played Through Agent (CMGPTA), an extension of the GPTA (Prat and Rustichini (2003)), where a Principal can offer any arbitrary mechanism that specifies a transfer schedule for each agent conditional on all Agents' messages. We identify the set of equilibrium allocations using deviator-reporting mechanisms (DRMs) on the path and single transfer schedules off the path. We design a lab experiment implementing DRMs. We observe that implemented outcomes are efficient more often than random. A majority of the time, Agents do tell the truth on the identity of a deviating Principal, despite potential gains from (tacit) collusion on false reports. As play progresses, Agents learn to play with their counterparty Agent with the average predicted probability of collusion on false reports across groups increasing from about 9% at the beginning of the experiment to just under 20% by the end. However, group heterogeneity is significant.","creator":"Seungjin Han, Andrew Leal"},{"id":"2403.03597","slug":"the-must-stock-challenge-in-academic-publishing-pricing-implications-of-transformative-agreements","title":"The 'Must Stock' Challenge in Academic Publishing: Pricing Implications of Transformative Agreements","link":"https://arxiv.org/abs/2403.03597","abstract":"Abstract: The high relevance of top-notch academic journals turns them into 'must stock' products that assign its often commercial owners with extraordinary market power. Intended to tackle this, university consortia around the globe negotiate so-called 'transformative agreements' with many publishing houses. It shall pave the way towards standard open-access publishing. While several contract designs exist, the 'publish-and-read' (PAR) scheme is the one that comes closest to the ideal of an entirely open access environment: Publishers are paid a fixed case-by-case rate for each publication, which includes a fee for their extensive libraries. In turn, all subscription payments are waived. I theoretically derive that this contract design benefits the included publishers regardless of whether the number of publications in these publishers' journals grows or declines. Consequently, widespread PAR contracts are likely to raise entry barriers for new (open-access) competitors even further. Intending to lower costs for the universities, their libraries, and, ultimately, the taxpayers, this PAR fee contract design of transformative agreements might cause the opposite.","creator":"W. Benedikt Schmal"},{"id":"2403.03610","slug":"paying-for-privacy-pay-or-tracking-walls","title":"Paying for Privacy: Pay-or-Tracking Walls","link":"https://arxiv.org/abs/2403.03610","abstract":"Abstract: Prestigious news publishers, and more recently, Meta, have begun to request that users pay for privacy. Specifically, users receive a notification banner, referred to as a pay-or-tracking wall, that requires them to (i) pay money to avoid being tracked or (ii) consent to being tracked. These walls have invited concerns that privacy might become a luxury. However, little is known about pay-or-tracking walls, which prevents a meaningful discussion about their appropriateness. This paper conducts several empirical studies and finds that top EU publishers use pay-or-tracking walls. Their implementations involve various approaches, including bundling the pay option with advertising-free access or additional content. The price for not being tracked exceeds the advertising revenue that publishers generate from a user who consents to being tracked. Notably, publishers' traffic does not decline when implementing a pay-or-tracking wall and most users consent to being tracked; only a few users pay. In short, pay-or-tracking walls seem to provide the means for expanding the practice of tracking. Publishers profit from pay-or-tracking walls and may observe a revenue increase of 16.4% due to tracking more users than under a cookie consent banner.","creator":"Timo Mueller-Tribbensee, Klaus M. Miller, Bernd Skiera"},{"id":"2403.03612","slug":"using-the-dual-privacy-framework-to-understand-consumers-perceived-privacy-violations-under-different-firm-practices-in-online-advertising","title":"Using the Dual-Privacy Framework to Understand Consumers' Perceived Privacy Violations Under Different Firm Practices in Online Advertising","link":"https://arxiv.org/abs/2403.03612","abstract":"Abstract: In response to privacy concerns about collecting and using personal data, the online advertising industry has been developing privacy-enhancing technologies (PETs), e.g., under Google's Privacy Sandbox initiative. In this research, we use the dual-privacy framework, which postulates that consumers have intrinsic and instrumental preferences for privacy, to understand consumers' perceived privacy violations (PPVs) for current and proposed online advertising practices. The key idea is that different practices differ in whether individual data leaves the consumer's machine or not and in how they track and target consumers; these affect, respectively, the intrinsic and instrumental components of privacy preferences differently, leading to different PPVs for different practices. We conducted online studies focused on consumers in the United States to elicit PPVs for various advertising practices. Our findings confirm the intuition that tracking and targeting consumers under the industry status quo of behavioral targeting leads to high PPV. New technologies or proposals that ensure that data are kept on the consumer's machine lower PPV relative to behavioral targeting but, importantly, this decrease is small. Furthermore, group-level targeting does not differ significantly from individual-level targeting in reducing PPV. Under contextual targeting, where there is no tracking, PPV is significantly reduced. Interestingly, with respect to PPV, consumers are indifferent between seeing untargeted ads and no ads when they are not being tracked. We find that consumer perceptions of privacy violations under different tracking and targeting practices may differ from what technical definitions suggest. Therefore, rather than relying solely on technical perspectives, a consumer-centric approach to privacy is needed, based on, for instance, the dual-privacy framework.","creator":"Kinshuk Jerath, Klaus M. Miller"},{"id":"2403.03649","slug":"the-cost-of-coming-out","title":"The Cost of Coming Out","link":"https://arxiv.org/abs/2403.03649","abstract":"Abstract: The fear of social stigma and discrimination leads many individuals worldwide to hesitate in openly disclosing their sexual orientation. Due to the large costs of concealing identity, it is crucial to understand the extent of anti-LGB sentiments and reactions to coming out. However, disclosing one's sexual orientation is a personal choice, complicating data access and introducing endogeneity issues. This paper tackles these challenges by using an innovative data source from a popular online video game together with a natural experiment. We exploit exogenous variation in the identity of a playable character to identify the effects of disclosure on players' revealed preferences for that character. Leveraging detailed daily data, we monitor players' preferences for the character across diverse regions globally and employ synthetic control methods to isolate the effect of the disclosure on players' preferences. Our findings reveal a substantial and persistent negative impact of coming out. To strengthen the plausibility of social stigma as the primary explanation for the estimated effects, we systematically address and eliminate several alternative game-related channels.","creator":"Enzo Brox, Riccardo Di Francesco"},{"id":"2403.03240","slug":"triple-debiased-lasso-for-statistical-inference-of-conditional-average-treatment-effects","title":"Triple/Debiased Lasso for Statistical Inference of Conditional Average Treatment Effects","link":"https://arxiv.org/abs/2403.03240","abstract":"arXiv:2403.03240v1 Announce Type: cross  Abstract: This study investigates the estimation and the statistical inference about Conditional Average Treatment Effects (CATEs), which have garnered attention as a metric representing individualized causal effects. In our data-generating process, we assume linear models for the outcomes associated with binary treatments and define the CATE as a difference between the expected outcomes of these linear models. This study allows the linear models to be high-dimensional, and our interest lies in consistent estimation and statistical inference for the CATE. In high-dimensional linear regression, one typical approach is to assume sparsity. However, in our study, we do not assume sparsity directly. Instead, we consider sparsity only in the difference of the linear models. We first use a doubly robust estimator to approximate this difference and then regress the difference on covariates with Lasso regularization. Although this regression estimator is consistent for the CATE, we further reduce the bias using the techniques in double/debiased machine learning (DML) and debiased Lasso, leading to $\\sqrt{n}$-consistency and confidence intervals. We refer to the debiased estimator as the triple/debiased Lasso (TDL), applying both DML and debiased Lasso techniques. We confirm the soundness of our proposed method through simulation studies.","creator":"Masahiro Kato"},{"id":"2403.03299","slug":"understanding-and-avoiding-the-weights-of-regression-heterogeneous-effects-misspecification-and-longstanding-solutions","title":"Understanding and avoiding the \"weights of regression\": Heterogeneous effects, misspecification, and longstanding solutions","link":"https://arxiv.org/abs/2403.03299","abstract":"arXiv:2403.03299v1 Announce Type: cross  Abstract: Researchers in many fields endeavor to estimate treatment effects by regressing outcome data (Y) on a treatment (D) and observed confounders (X). Even absent unobserved confounding, the regression coefficient on the treatment reports a weighted average of strata-specific treatment effects (Angrist, 1998). Where heterogeneous treatment effects cannot be ruled out, the resulting coefficient is thus not generally equal to the average treatment effect (ATE), and is unlikely to be the quantity of direct scientific or policy interest. The difference between the coefficient and the ATE has led researchers to propose various interpretational, bounding, and diagnostic aids (Humphreys, 2009; Aronow and Samii, 2016; Sloczynski, 2022; Chattopadhyay and Zubizarreta, 2023). We note that the linear regression of Y on D and X can be misspecified when the treatment effect is heterogeneous in X. The \"weights of regression\", for which we provide a new (more general) expression, simply characterize how the OLS coefficient will depart from the ATE under the misspecification resulting from unmodeled treatment effect heterogeneity. Consequently, a natural alternative to suffering these weights is to address the misspecification that gives rise to them. For investigators committed to linear approaches, we propose relying on the slightly weaker assumption that the potential outcomes are linear in X. Numerous well-known estimators are unbiased for the ATE under this assumption, namely regression-imputation/g-computation/T-learner, regression with an interaction of the treatment and covariates (Lin, 2013), and balancing weights. Any of these approaches avoid the apparent weighting problem of the misspecified linear regression, at an efficiency cost that will be small when there are few covariates relative to sample size. We demonstrate these lessons using simulations in observational and experimental settings.","creator":"Chad Hazlett, Tanvi Shinkre"},{"id":"2403.03589","slug":"active-adaptive-experimental-design-for-treatment-effect-estimation-with-covariate-choices","title":"Active Adaptive Experimental Design for Treatment Effect Estimation with Covariate Choices","link":"https://arxiv.org/abs/2403.03589","abstract":"arXiv:2403.03589v1 Announce Type: cross  Abstract: This study designs an adaptive experiment for efficiently estimating average treatment effect (ATEs). We consider an adaptive experiment where an experimenter sequentially samples an experimental unit from a covariate density decided by the experimenter and assigns a treatment. After assigning a treatment, the experimenter observes the corresponding outcome immediately. At the end of the experiment, the experimenter estimates an ATE using gathered samples. The objective of the experimenter is to estimate the ATE with a smaller asymptotic variance. Existing studies have designed experiments that adaptively optimize the propensity score (treatment-assignment probability). As a generalization of such an approach, we propose a framework under which an experimenter optimizes the covariate density, as well as the propensity score, and find that optimizing both covariate density and propensity score reduces the asymptotic variance more than optimizing only the propensity score. Based on this idea, in each round of our experiment, the experimenter optimizes the covariate density and propensity score based on past observations. To design an adaptive experiment, we first derive the efficient covariate density and propensity score that minimizes the semiparametric efficiency bound, a lower bound for the asymptotic variance given a fixed covariate density and a fixed propensity score. Next, we design an adaptive experiment using the efficient covariate density and propensity score sequentially estimated during the experiment. Lastly, we propose an ATE estimator whose asymptotic variance aligns with the minimized semiparametric efficiency bound.","creator":"Masahiro Kato, Akihiro Oga, Wataru Komatsubara, Ryo Inokuchi"},{"id":"2208.05316","slug":"welfare-ordering-of-voting-weight-allocations","title":"Welfare ordering of voting weight allocations","link":"https://arxiv.org/abs/2208.05316","abstract":"arXiv:2208.05316v3 Announce Type: replace  Abstract: This paper studies the allocation of voting weights in a committee representing groups of different sizes. We introduce a partial ordering of weight allocations based on stochastic comparison of social welfare. We show that when the number of groups is sufficiently large, this ordering asymptotically coincides with the total ordering induced by the cosine proportionality between the weights and the group sizes. A corollary is that a class of expectation-form objective functions, including expected welfare, the mean majority deficit and the probability of inversions, are asymptotically monotone in the cosine proportionality.","creator":"Kazuya Kikuchi"},{"id":"2303.05968","slug":"a-general-impossibility-theorem-on-pareto-efficiency-and-bayesian-incentive-compatibility","title":"A General Impossibility Theorem on Pareto Efficiency and Bayesian Incentive Compatibility","link":"https://arxiv.org/abs/2303.05968","abstract":"arXiv:2303.05968v3 Announce Type: replace  Abstract: This paper studies a general class of social choice problems in which agents' payoff functions (or types) are privately observable random variables, and monetary transfers are not available. We consider cardinal social choice functions which may respond to agents' preference intensities as well as preference rankings. We show that a social choice function is ex ante Pareto efficient and Bayesian incentive compatible if and only if it is dictatorial. The result holds for arbitrary numbers of agents and alternatives, and under a fairly weak assumption on the joint distribution of types, which allows for arbitrary correlations and asymmetries.","creator":"Kazuya Kikuchi, Yukio Koriyama"},{"id":"2308.10131","slug":"agree-to-disagree-measuring-hidden-dissents-in-fomc-meetings","title":"Agree to Disagree: Measuring Hidden Dissents in FOMC Meetings","link":"https://arxiv.org/abs/2308.10131","abstract":"arXiv:2308.10131v5 Announce Type: replace  Abstract: Based on a record of dissents on FOMC votes and transcripts of the meetings from 1976 to 2017, we develop a deep learning model based on self-attention mechanism to create a measure of disagreement for members in each meeting. While dissents are rare, we find that members often have reservations with the policy decision, and the level of disagreement is mostly driven by current or predicted macroeconomic data. Using our model to evaluate speeches made by members between meetings, we find that the informational content of speeches is low if we can only compare them to speeches made by the chair. Disagreement strongly correlates with data from the Summary of Economic Projections and a measure of monetary policy sub-optimality, suggesting that disagreement is driven by both members' different preferences and their different views about the future.","creator":"Kwok Ping Tsang, Zichao Yang"},{"id":"2312.01209","slug":"a-method-of-moments-approach-to-asymptotically-unbiased-synthetic-controls","title":"A Method of Moments Approach to Asymptotically Unbiased Synthetic Controls","link":"https://arxiv.org/abs/2312.01209","abstract":"arXiv:2312.01209v2 Announce Type: replace  Abstract: A common approach to constructing a Synthetic Control unit is to fit on the outcome variable and covariates in pre-treatment time periods, but it has been shown by Ferman and Pinto (2019) that this approach does not provide asymptotic unbiasedness when the fit is imperfect and the number of controls is fixed. Many related panel methods have a similar limitation when the number of units is fixed. I introduce and evaluate a new method in which the Synthetic Control is constructed using a General Method of Moments approach where units not being included in the Synthetic Control are used as instruments. I show that a Synthetic Control Estimator of this form will be asymptotically unbiased as the number of pre-treatment time periods goes to infinity, even when pre-treatment fit is imperfect and the number of units is fixed. Furthermore, if both the number of pre-treatment and post-treatment time periods go to infinity, then averages of treatment effects can be consistently estimated. I conduct simulations and an empirical application to compare the performance of this method with existing approaches in the literature.","creator":"Joseph Fry"},{"id":"2402.16309","slug":"collective-evaluation-problem","title":"Collective Evaluation Problem","link":"https://arxiv.org/abs/2402.16309","abstract":"arXiv:2402.16309v2 Announce Type: replace  Abstract: This study focuses on situations where a finite set of alternatives is evaluated by collecting evaluations from several individuals, some of whom may not evaluate specific alternatives. The collection of subsets of alternatives that individuals (can) evaluate is referred to as an evaluability profile. For a given evaluability profile, we define a collective evaluation function whose inputs are the evaluation orders of individuals on the subsets of alternatives that they evaluate. We investigate the properties of collective evaluation functions, which are modifications of those introduced in previous studies. We identify the necessary and sufficient conditions on the evaluability profile that ensure the existence of collective evaluation functions satisfying four different combinations of these properties.","creator":"Yasunori Okumura"},{"id":"2402.19399","slug":"an-empirical-analysis-of-scam-tokens-on-ethereum-blockchain","title":"An Empirical Analysis of Scam Tokens on Ethereum Blockchain","link":"https://arxiv.org/abs/2402.19399","abstract":"arXiv:2402.19399v3 Announce Type: replace-cross  Abstract: This article presents an empirical investigation into the determinants of total revenue generated by counterfeit tokens on Uniswap. It offers a detailed overview of the counterfeit token fraud process, along with a systematic summary of characteristics associated with such fraudulent activities observed in Uniswap. The study primarily examines the relationship between revenue from counterfeit token scams and their defining characteristics, and analyzes the influence of market economic factors such as return on market capitalization and price return on Ethereum. Key findings include a significant increase in overall transactions of counterfeit tokens on their first day of fraud, and a rise in upfront fraud costs leading to corresponding increases in revenue. Furthermore, a negative correlation is identified between the total revenue of counterfeit tokens and the volatility of Ethereum market capitalization return, while price return volatility on Ethereum is found to have a positive impact on counterfeit token revenue, albeit requiring further investigation for a comprehensive understanding. Additionally, the number of subscribers for the real token correlates positively with the realized volume of scam tokens, indicating that a larger community following the legitimate token may inadvertently contribute to the visibility and success of counterfeit tokens. Conversely, the number of Telegram subscribers exhibits a negative impact on the realized volume of scam tokens, suggesting that a higher level of scrutiny or awareness within Telegram communities may act as a deterrent to fraudulent activities. Finally, the timing of when the scam token is introduced on the Ethereum blockchain may have a negative impact on its success. Notably, the cumulative amount scammed by only 42 counterfeit tokens amounted to almost 11214 Ether.","creator":"Vahidin Jeleskovic"}]}]