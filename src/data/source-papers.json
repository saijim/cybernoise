[
  {
    "name": "Artificial Intelligence",
    "feed": [
      {
        "id": "2309.04478",
        "slug": "multimodal-machine-learning-for-materials-science-composition-structure-bimodal-learning-for-experimentally-measured-properties-arxiv-2309-04478v1-cond-mat-mtrl-sci",
        "title": "Multimodal machine learning for materials science: composition-structure bimodal learning for experimentally measured properties.",
        "link": "http://arxiv.org/abs/2309.04478",
        "abstract": "The widespread application of multimodal machine learning models like GPT-4 has revolutionized various research fields including computer vision and natural language processing. However, its implementation in materials informatics remains underexplored, despite the presence of materials data across diverse modalities, such as composition and structure. The effectiveness of machine learning models trained on large calculated datasets depends on the accuracy of calculations, while experimental datasets often have limited data availability and incomplete information. This paper introduces a novel approach to multimodal machine learning in materials science via composition-structure bimodal learning. The proposed COmposition-Structure Bimodal Network (COSNet) is designed to enhance learning and predictions of experimentally measured materials properties that have incomplete structure information. Bimodal learning significantly reduces prediction errors across distinct materials properties including Li conductivity in solid electrolyte, band gap, refractive index, dielectric constant, energy, and magnetic moment, surpassing composition-only learning methods. Furthermore, we identified that data augmentation based on modal availability plays a pivotal role in the success of bimodal learning.",
        "creator": "Sheng Gong, Shuo Wang, Taishan Zhu, Yang Shao-Horn, Jeffrey C. Grossman"
      },
      {
        "id": "2309.04487",
        "slug": "penalization-framework-for-autonomous-agents-using-answer-set-programming-arxiv-2309-04487v1-cs-ai",
        "title": "Penalization Framework For Autonomous Agents Using Answer Set Programming.",
        "link": "http://arxiv.org/abs/2309.04487",
        "abstract": "This paper presents a framework for enforcing penalties on intelligent agents that do not comply with authorization or obligation policies in a changing environment. A framework is proposed to represent and reason about penalties in plans, and an algorithm is proposed to penalize an agent's actions based on their level of compliance with respect to authorization and obligation policies. Being aware of penalties an agent can choose a plan with a minimal total penalty, unless there is an emergency goal like saving a human's life. The paper concludes that this framework can reprimand insubordinate agents.",
        "creator": "Vineel S. K. Tummala"
      },
      {
        "id": "2309.04491",
        "slug": "a-context-sensitive-approach-to-xai-in-music-performance-arxiv-2309-04491v1-cs-hc",
        "title": "A Context-Sensitive Approach to XAI in Music Performance.",
        "link": "http://arxiv.org/abs/2309.04491",
        "abstract": "The rapidly evolving field of Explainable Artificial Intelligence (XAI) has generated significant interest in developing methods to make AI systems more transparent and understandable. However, the problem of explainability cannot be exhaustively solved in the abstract, as there is no single approach that can be universally applied to generate adequate explanations for any given AI system, and this is especially true in the arts. In this position paper, we propose an Explanatory Pragmatism (EP) framework for XAI in music performance, emphasising the importance of context and audience in the development of explainability requirements. By tailoring explanations to specific audiences and continuously refining them based on feedback, EP offers a promising direction for enhancing the transparency and interpretability of AI systems in broad artistic applications and more specifically to music performance.",
        "creator": "Nicola Privato, Jack Armitage"
      },
      {
        "id": "2309.04504",
        "slug": "compositional-learning-of-visually-grounded-concepts-using-reinforcement-arxiv-2309-04504v1-cs-lg",
        "title": "Compositional Learning of Visually-Grounded Concepts Using Reinforcement.",
        "link": "http://arxiv.org/abs/2309.04504",
        "abstract": "Deep reinforcement learning agents need to be trained over millions of episodes to decently solve navigation tasks grounded to instructions. Furthermore, their ability to generalize to novel combinations of instructions is unclear. Interestingly however, children can decompose language-based instructions and navigate to the referred object, even if they have not seen the combination of queries prior. Hence, we created three 3D environments to investigate how deep RL agents learn and compose color-shape based combinatorial instructions to solve novel combinations in a spatial navigation task. First, we explore if agents can perform compositional learning, and whether they can leverage on frozen text encoders (e.g. CLIP, BERT) to learn word combinations in fewer episodes. Next, we demonstrate that when agents are pretrained on the shape or color concepts separately, they show a 20 times decrease in training episodes needed to solve unseen combinations of instructions. Lastly, we show that agents pretrained on concept and compositional learning achieve significantly higher reward when evaluated zero-shot on novel color-shape1-shape2 visual object combinations. Overall, our results highlight the foundations needed to increase an agent's proficiency in composing word groups through reinforcement learning and its ability for zero-shot generalization to new combinations.",
        "creator": "Zijun Lin, Haidi Azaman, M Ganesh Kumar, Cheston Tan"
      },
      {
        "id": "2309.04508",
        "slug": "spatial-temporal-graph-attention-fuser-for-calibration-in-iot-air-pollution-monitoring-systems-arxiv-2309-04508v1-cs-lg",
        "title": "Spatial-Temporal Graph Attention Fuser for Calibration in IoT Air Pollution Monitoring Systems.",
        "link": "http://arxiv.org/abs/2309.04508",
        "abstract": "The use of Internet of Things (IoT) sensors for air pollution monitoring has significantly increased, resulting in the deployment of low-cost sensors. Despite this advancement, accurately calibrating these sensors in uncontrolled environmental conditions remains a challenge. To address this, we propose a novel approach that leverages graph neural networks, specifically the graph attention network module, to enhance the calibration process by fusing data from sensor arrays. Through our experiments, we demonstrate the effectiveness of our approach in significantly improving the calibration accuracy of sensors in IoT air pollution monitoring platforms.",
        "creator": "Keivan Faghih Niresi, Mengjie Zhao, Hugo Bissig, Henri Baumann, Olga Fink"
      },
      {
        "id": "2309.04511",
        "slug": "systematic-review-of-techniques-in-brain-image-synthesis-using-deep-learning-arxiv-2309-04511v1-eess-iv",
        "title": "Systematic Review of Techniques in Brain Image Synthesis using Deep Learning.",
        "link": "http://arxiv.org/abs/2309.04511",
        "abstract": "This review paper delves into the present state of medical imaging, with a specific focus on the use of deep learning techniques for brain image synthesis. The need for medical image synthesis to improve diagnostic accuracy and decrease invasiveness in medical procedures is emphasized, along with the role of deep learning in enabling these advancements. The paper examines various methods and techniques for brain image synthesis, including 2D to 3D constructions, MRI synthesis, and the use of transformers. It also addresses limitations and challenges faced in these methods, such as obtaining well-curated training data and addressing brain ultrasound issues. The review concludes by exploring the future potential of this field and the opportunities for further advancements in medical imaging using deep learning techniques. The significance of transformers and their potential to revolutionize the medical imaging field is highlighted. Additionally, the paper discusses the potential solutions to the shortcomings and limitations faced in this field. The review provides researchers with an updated reference on the present state of the field and aims to inspire further research and bridge the gap between the present state of medical imaging and the future possibilities offered by deep learning techniques.",
        "creator": "Shubham Singh, Ammar Ranapurwala, Mrunal Bewoor, Sheetal Patil, Satyam Rai"
      },
      {
        "id": "2309.04515",
        "slug": "privacy-preserving-federated-learning-with-convolutional-variational-bottlenecks-arxiv-2309-04515v1-cs-lg",
        "title": "Privacy Preserving Federated Learning with Convolutional Variational Bottlenecks.",
        "link": "http://arxiv.org/abs/2309.04515",
        "abstract": "Gradient inversion attacks are an ubiquitous threat in federated learning as they exploit gradient leakage to reconstruct supposedly private training data. Recent work has proposed to prevent gradient leakage without loss of model utility by incorporating a PRivacy EnhanCing mODulE (PRECODE) based on variational modeling. Without further analysis, it was shown that PRECODE successfully protects against gradient inversion attacks. In this paper, we make multiple contributions. First, we investigate the effect of PRECODE on gradient inversion attacks to reveal its underlying working principle. We show that variational modeling introduces stochasticity into the gradients of PRECODE and the subsequent layers in a neural network. The stochastic gradients of these layers prevent iterative gradient inversion attacks from converging. Second, we formulate an attack that disables the privacy preserving effect of PRECODE by purposefully omitting stochastic gradients during attack optimization. To preserve the privacy preserving effect of PRECODE, our analysis reveals that variational modeling must be placed early in the network. However, early placement of PRECODE is typically not feasible due to reduced model utility and the exploding number of additional model parameters. Therefore, as a third contribution, we propose a novel privacy module -- the Convolutional Variational Bottleneck (CVB) -- that can be placed early in a neural network without suffering from these drawbacks. We conduct an extensive empirical study on three seminal model architectures and six image classification datasets. We find that all architectures are susceptible to gradient leakage attacks, which can be prevented by our proposed CVB. Compared to PRECODE, we show that our novel privacy module requires fewer trainable parameters, and thus computational and communication costs, to effectively preserve privacy.",
        "creator": "Daniel Scheliga, Patrick M&#xe4;der, Marco Seeland"
      },
      {
        "id": "2309.04522",
        "slug": "connecting-ntk-and-nngp-a-unified-theoretical-framework-for-neural-network-learning-dynamics-in-the-kernel-regime-arxiv-2309-04522v1-cs-lg",
        "title": "Connecting NTK and NNGP: A Unified Theoretical Framework for Neural Network Learning Dynamics in the Kernel Regime.",
        "link": "http://arxiv.org/abs/2309.04522",
        "abstract": "Artificial neural networks have revolutionized machine learning in recent years, but a complete theoretical framework for their learning process is still lacking. Substantial progress has been made for infinitely wide networks. In this regime, two disparate theoretical frameworks have been used, in which the network's output is described using kernels: one framework is based on the Neural Tangent Kernel (NTK) which assumes linearized gradient descent dynamics, while the Neural Network Gaussian Process (NNGP) kernel assumes a Bayesian framework. However, the relation between these two frameworks has remained elusive. This work unifies these two distinct theories using a Markov proximal learning model for learning dynamics in an ensemble of randomly initialized infinitely wide deep networks. We derive an exact analytical expression for the network input-output function during and after learning, and introduce a new time-dependent Neural Dynamical Kernel (NDK) from which both NTK and NNGP kernels can be derived. We identify two learning phases characterized by different time scales: gradient-driven and diffusive learning. In the initial gradient-driven learning phase, the dynamics is dominated by deterministic gradient descent, and is described by the NTK theory. This phase is followed by the diffusive learning stage, during which the network parameters sample the solution space, ultimately approaching the equilibrium distribution corresponding to NNGP. Combined with numerical evaluations on synthetic and benchmark datasets, we provide novel insights into the different roles of initialization, regularization, and network depth, as well as phenomena such as early stopping and representational drift. This work closes the gap between the NTK and NNGP theories, providing a comprehensive framework for understanding the learning process of deep neural networks in the infinite width limit.",
        "creator": "Yehonatan Avidan, Qianyi Li, Haim Sompolinsky"
      },
      {
        "id": "2309.04565",
        "slug": "unleashing-the-power-of-graph-learning-through-llm-based-autonomous-agents-arxiv-2309-04565v1-cs-lg",
        "title": "Unleashing the Power of Graph Learning through LLM-based Autonomous Agents.",
        "link": "http://arxiv.org/abs/2309.04565",
        "abstract": "Graph structured data are widely existed and applied in the real-world applications, while it is a challenge to handling these diverse data and learning tasks on graph in an efficient manner. When facing the complicated graph learning tasks, experts have designed diverse Graph Neural Networks (GNNs) in recent years. They have also implemented AutoML in Graph, also known as AutoGraph, to automatically generate data-specific solutions. Despite their success, they encounter limitations in (1) managing diverse learning tasks at various levels, (2) dealing with different procedures in graph learning beyond architecture design, and (3) the huge requirements on the prior knowledge when using AutoGraph. In this paper, we propose to use Large Language Models (LLMs) as autonomous agents to simplify the learning process on diverse real-world graphs. Specifically, in response to a user request which may contain varying data and learning targets at the node, edge, or graph levels, the complex graph learning task is decomposed into three components following the agent planning, namely, detecting the learning intent, configuring solutions based on AutoGraph, and generating a response. The AutoGraph agents manage crucial procedures in automated graph learning, including data-processing, AutoML configuration, searching architectures, and hyper-parameter fine-tuning. With these agents, those components are processed by decomposing and completing step by step, thereby generating a solution for the given data automatically, regardless of the learning task on node or graph. The proposed method is dubbed Auto$^2$Graph, and the comparable performance on different datasets and learning tasks. Its effectiveness is demonstrated by its comparable performance on different datasets and learning tasks, as well as the human-like decisions made by the agents.",
        "creator": "Lanning Wei, Zhiqiang He, Huan Zhao, Quanming Yao"
      },
      {
        "id": "2309.04579",
        "slug": "egofalls-a-visual-audio-dataset-and-benchmark-for-fall-detection-using-egocentric-cameras-arxiv-2309-04579v1-cs-cv",
        "title": "EGOFALLS: A visual-audio dataset and benchmark for fall detection using egocentric cameras.",
        "link": "http://arxiv.org/abs/2309.04579",
        "abstract": "Falls are significant and often fatal for vulnerable populations such as the elderly. Previous works have addressed the detection of falls by relying on data capture by a single sensor, images or accelerometers. In this work, we rely on multimodal descriptors extracted from videos captured by egocentric cameras. Our proposed method includes a late decision fusion layer that builds on top of the extracted descriptors. Furthermore, we collect a new dataset on which we assess our proposed approach. We believe this is the first public dataset of its kind. The dataset comprises 10,948 video samples by 14 subjects. We conducted ablation experiments to assess the performance of individual feature extractors, fusion of visual information, and fusion of both visual and audio information. Moreover, we experimented with internal and external cross-validation. Our results demonstrate that the fusion of audio and visual information through late decision fusion improves detection performance, making it a promising tool for fall prevention and mitigation.",
        "creator": "Xueyi Wang"
      },
      {
        "id": "2309.04607",
        "slug": "linking-symptom-inventories-using-semantic-textual-similarity-arxiv-2309-04607v1-cs-cl",
        "title": "Linking Symptom Inventories using Semantic Textual Similarity.",
        "link": "http://arxiv.org/abs/2309.04607",
        "abstract": "An extensive library of symptom inventories has been developed over time to measure clinical symptoms, but this variety has led to several long standing issues. Most notably, results drawn from different settings and studies are not comparable, which limits reproducibility. Here, we present an artificial intelligence (AI) approach using semantic textual similarity (STS) to link symptoms and scores across previously incongruous symptom inventories. We tested the ability of four pre-trained STS models to screen thousands of symptom description pairs for related content - a challenging task typically requiring expert panels. Models were tasked to predict symptom severity across four different inventories for 6,607 participants drawn from 16 international data sources. The STS approach achieved 74.8% accuracy across five tasks, outperforming other models tested. This work suggests that incorporating contextual, semantic information can assist expert decision-making processes, yielding gains for both general and disease-specific clinical assessment.",
        "creator": "Eamonn Kennedy, Shashank Vadlamani, Hannah M Lindsey, Kelly S Peterson, Kristen Dams OConnor, Kenton Murray, Ronak Agarwal, Houshang H Amiri, Raeda K Andersen, Talin Babikian, David A Baron, Erin D Bigler, Karen Caeyenberghs, Lisa Delano-Wood, Seth G Disner, Ekaterina Dobryakova, Blessen C Eapen, Rachel M Edelstein, Carrie Esopenko, Helen M Genova, Elbert Geuze, Naomi J Goodrich-Hunsaker, Jordan Grafman, Asta K Haberg, Cooper B Hodges, Kristen R Hoskinson, Elizabeth S Hovenden, Andrei Irimia, Neda Jahanshad, Ruchira M Jha, Finian Keleher, Kimbra Kenney, Inga K Koerte, Spencer W Liebel, Abigail Livny, Marianne Lovstad, Sarah L Martindale, Jeffrey E Max, Andrew R Mayer, Timothy B Meier, Deleene S Menefee, Abdalla Z Mohamed, Stefania Mondello, Martin M Monti, Rajendra A Morey, Virginia Newcombe, et al. (36 additional authors not shown)"
      },
      {
        "id": "2309.04615",
        "slug": "leveraging-world-model-disentanglement-in-value-based-multi-agent-reinforcement-learning-arxiv-2309-04615v1-cs-lg",
        "title": "Leveraging World Model Disentanglement in Value-Based Multi-Agent Reinforcement Learning.",
        "link": "http://arxiv.org/abs/2309.04615",
        "abstract": "In this paper, we propose a novel model-based multi-agent reinforcement learning approach named Value Decomposition Framework with Disentangled World Model to address the challenge of achieving a common goal of multiple agents interacting in the same environment with reduced sample complexity. Due to scalability and non-stationarity problems posed by multi-agent systems, model-free methods rely on a considerable number of samples for training. In contrast, we use a modularized world model, composed of action-conditioned, action-free, and static branches, to unravel the environment dynamics and produce imagined outcomes based on past experience, without sampling directly from the real environment. We employ variational auto-encoders and variational graph auto-encoders to learn the latent representations for the world model, which is merged with a value-based framework to predict the joint action-value function and optimize the overall training objective. We present experimental results in Easy, Hard, and Super-Hard StarCraft II micro-management challenges to demonstrate that our method achieves high sample efficiency and exhibits superior performance in defeating the enemy armies compared to other baselines.",
        "creator": "Zhizun Wang, David Meger"
      },
      {
        "id": "2309.04626",
        "slug": "perceptual-adjustment-queries-and-an-inverted-measurement-paradigm-for-low-rank-metric-learning-arxiv-2309-04626v1-stat-ml",
        "title": "Perceptual adjustment queries and an inverted measurement paradigm for low-rank metric learning.",
        "link": "http://arxiv.org/abs/2309.04626",
        "abstract": "We introduce a new type of query mechanism for collecting human feedback, called the perceptual adjustment query ( PAQ). Being both informative and cognitively lightweight, the PAQ adopts an inverted measurement scheme, and combines advantages from both cardinal and ordinal queries. We showcase the PAQ in the metric learning problem, where we collect PAQ measurements to learn an unknown Mahalanobis distance. This gives rise to a high-dimensional, low-rank matrix estimation problem to which standard matrix estimators cannot be applied. Consequently, we develop a two-stage estimator for metric learning from PAQs, and provide sample complexity guarantees for this estimator. We present numerical simulations demonstrating the performance of the estimator and its notable properties.",
        "creator": "Austin Xu, Andrew D. McRae, Jingyan Wang, Mark A. Davenport, Ashwin Pananjady"
      },
      {
        "id": "2309.04640",
        "slug": "few-shot-learning-of-force-based-motions-from-demonstration-through-pre-training-of-haptic-representation-arxiv-2309-04640v1-cs-ro",
        "title": "Few-Shot Learning of Force-Based Motions From Demonstration Through Pre-training of Haptic Representation.",
        "link": "http://arxiv.org/abs/2309.04640",
        "abstract": "In many contact-rich tasks, force sensing plays an essential role in adapting the motion to the physical properties of the manipulated object. To enable robots to capture the underlying distribution of object properties necessary for generalising learnt manipulation tasks to unseen objects, existing Learning from Demonstration (LfD) approaches require a large number of costly human demonstrations. Our proposed semi-supervised LfD approach decouples the learnt model into an haptic representation encoder and a motion generation decoder. This enables us to pre-train the first using large amount of unsupervised data, easily accessible, while using few-shot LfD to train the second, leveraging the benefits of learning skills from humans. We validate the approach on the wiping task using sponges with different stiffness and surface friction. Our results demonstrate that pre-training significantly improves the ability of the LfD model to recognise physical properties and generate desired wiping motions for unseen sponges, outperforming the LfD method without pre-training. We validate the motion generated by our semi-supervised LfD model on the physical robot hardware using the KUKA iiwa robot arm. We also validate that the haptic representation encoder, pre-trained in simulation, captures the properties of real objects, explaining its contribution to improving the generalisation of the downstream task.",
        "creator": "Marina Y. Aoyama, Jo&#xe3;o Moura, Namiko Saito, Sethu Vijayakumar"
      },
      {
        "id": "2309.04646",
        "slug": "efficient-finetuning-large-language-models-for-vietnamese-chatbot-arxiv-2309-04646v1-cs-cl",
        "title": "Efficient Finetuning Large Language Models For Vietnamese Chatbot.",
        "link": "http://arxiv.org/abs/2309.04646",
        "abstract": "Large language models (LLMs), such as GPT-4, PaLM, and LLaMa, have been shown to achieve remarkable performance across a variety of natural language tasks. Recent advancements in instruction tuning bring LLMs with ability in following user's instructions and producing human-like responses. However, the high costs associated with training and implementing LLMs pose challenges to academic research. Furthermore, the availability of pretrained LLMs and instruction-tune datasets for Vietnamese language is limited. To tackle these concerns, we leverage large-scale instruction-following datasets from open-source projects, namely Alpaca, GPT4All, and Chat-Doctor, which cover general domain and specific medical domain. To the best of our knowledge, these are the first instructional dataset for Vietnamese. Subsequently, we utilize parameter-efficient tuning through Low-Rank Adaptation (LoRA) on two open LLMs: Bloomz (Multilingual) and GPTJ-6B (Vietnamese), resulting four models: Bloomz-Chat, Bloomz-Doctor, GPTJ-Chat, GPTJ-Doctor.Finally, we assess the effectiveness of our methodology on a per-sample basis, taking into consideration the helpfulness, relevance, accuracy, level of detail in their responses. This evaluation process entails the utilization of GPT-4 as an automated scoring mechanism. Despite utilizing a low-cost setup, our method demonstrates about 20-30\\% improvement over the original models in our evaluation tasks.",
        "creator": "Vu-Thuan Doan, Quoc-Truong Truong, Duc-Vu Nguyen, Vinh-Tiep Nguyen, Thuy-Ngan Nguyen Luu"
      },
      {
        "id": "2309.04651",
        "slug": "video-and-synthetic-mri-pre-training-of-3d-vision-architectures-for-neuroimage-analysis-arxiv-2309-04651v1-eess-iv",
        "title": "Video and Synthetic MRI Pre-training of 3D Vision Architectures for Neuroimage Analysis.",
        "link": "http://arxiv.org/abs/2309.04651",
        "abstract": "Transfer learning represents a recent paradigm shift in the way we build artificial intelligence (AI) systems. In contrast to training task-specific models, transfer learning involves pre-training deep learning models on a large corpus of data and minimally fine-tuning them for adaptation to specific tasks. Even so, for 3D medical imaging tasks, we do not know if it is best to pre-train models on natural images, medical images, or even synthetically generated MRI scans or video data. To evaluate these alternatives, here we benchmarked vision transformers (ViTs) and convolutional neural networks (CNNs), initialized with varied upstream pre-training approaches. These methods were then adapted to three unique downstream neuroimaging tasks with a range of difficulty: Alzheimer's disease (AD) and Parkinson's disease (PD) classification, \"brain age\" prediction. Experimental tests led to the following key observations: 1. Pre-training improved performance across all tasks including a boost of 7.4% for AD classification and 4.6% for PD classification for the ViT and 19.1% for PD classification and reduction in brain age prediction error by 1.26 years for CNNs, 2. Pre-training on large-scale video or synthetic MRI data boosted performance of ViTs, 3. CNNs were robust in limited-data settings, and in-domain pretraining enhanced their performances, 4. Pre-training improved generalization to out-of-distribution datasets and sites. Overall, we benchmarked different vision architectures, revealing the value of pre-training them with emerging datasets for model initialization. The resulting pre-trained models can be adapted to a range of downstream neuroimaging tasks, even when training data for the target task is limited.",
        "creator": "Nikhil J. Dhinagar, Amit Singh, Saket Ozarkar, Ketaki Buwa, Sophia I. Thomopoulos, Conor Owens-Walton, Emily Laltoo, Yao-Liang Chen, Philip Cook, Corey McMillan, Chih-Chien Tsai, J-J Wang, Yih-Ru Wu, Paul M. Thompson"
      },
      {
        "id": "2309.04663",
        "slug": "fiat-fusing-learning-paradigms-with-instruction-accelerated-tuning-arxiv-2309-04663v1-cs-cl",
        "title": "FIAT: Fusing learning paradigms with Instruction-Accelerated Tuning.",
        "link": "http://arxiv.org/abs/2309.04663",
        "abstract": "Learning paradigms for large language models (LLMs) currently tend to fall within either in-context learning (ICL) or full fine-tuning. Each of these comes with their own trade-offs based on available data, model size, compute cost, ease-of-use, and final quality with neither solution performing well across-the-board. In this article, we first describe ICL and fine-tuning paradigms in a way that highlights their natural connections. Based on these connections, we propose a new learning paradigm called FIAT that fuses the best of these paradigms together, enabling prompt-engineered instructions and chain-of-thought reasoning with the very largest models while also using similar methods to perform parameter updates on a modestly-sized LLM with parameter-efficient tuning. We evaluate FIAT's effectiveness on a variety of multilingual tasks and observe that FIAT performs better than both ICL and fine-tuning at scales ranging from 100-10,000 training examples. We hope that FIAT provides a practical way of harnessing the full potential of LLMs without needing to make a hard choice between learning paradigms.",
        "creator": "Xinyi Wang, John Wieting, Jonathan H. Clark"
      },
      {
        "id": "2309.04676",
        "slug": "flexible-and-robust-counterfactual-explanations-with-minimal-satisfiable-perturbations-arxiv-2309-04676v1-cs-lg",
        "title": "Flexible and Robust Counterfactual Explanations with Minimal Satisfiable Perturbations.",
        "link": "http://arxiv.org/abs/2309.04676",
        "abstract": "Counterfactual explanations (CFEs) exemplify how to minimally modify a feature vector to achieve a different prediction for an instance. CFEs can enhance informational fairness and trustworthiness, and provide suggestions for users who receive adverse predictions. However, recent research has shown that multiple CFEs can be offered for the same instance or instances with slight differences. Multiple CFEs provide flexible choices and cover diverse desiderata for user selection. However, individual fairness and model reliability will be damaged if unstable CFEs with different costs are returned. Existing methods fail to exploit flexibility and address the concerns of non-robustness simultaneously. To address these issues, we propose a conceptually simple yet effective solution named Counterfactual Explanations with Minimal Satisfiable Perturbations (CEMSP). Specifically, CEMSP constrains changing values of abnormal features with the help of their semantically meaningful normal ranges. For efficiency, we model the problem as a Boolean satisfiability problem to modify as few features as possible. Additionally, CEMSP is a general framework and can easily accommodate more practical requirements, e.g., casualty and actionability. Compared to existing methods, we conduct comprehensive experiments on both synthetic and real-world datasets to demonstrate that our method provides more robust explanations while preserving flexibility.",
        "creator": "Yongjie Wang, Hangwei Qian, Yongjie Liu, Wei Guo, Chunyan Miao"
      },
      {
        "id": "2309.04695",
        "slug": "code-style-in-context-learning-for-knowledge-based-question-answering-arxiv-2309-04695v1-cs-cl",
        "title": "Code-Style In-Context Learning for Knowledge-Based Question Answering.",
        "link": "http://arxiv.org/abs/2309.04695",
        "abstract": "Current methods for Knowledge-Based Question Answering (KBQA) usually rely on complex training techniques and model frameworks, leading to many limitations in practical applications. Recently, the emergence of In-Context Learning (ICL) capabilities in Large Language Models (LLMs) provides a simple and training-free semantic parsing paradigm for KBQA: Given a small number of questions and their labeled logical forms as demo examples, LLMs can understand the task intent and generate the logic form for a new question. However, current powerful LLMs have little exposure to logic forms during pre-training, resulting in a high format error rate. To solve this problem, we propose a code-style in-context learning method for KBQA, which converts the generation process of unfamiliar logical form into the more familiar code generation process for LLMs. Experimental results on three mainstream datasets show that our method dramatically mitigated the formatting error problem in generating logic forms while realizing a new SOTA on WebQSP, GrailQA, and GraphQ under the few-shot setting.",
        "creator": "Zhijie Nie, Richong Zhang, Zhongyuan Wang, Xudong Liu"
      },
      {
        "id": "2309.04698",
        "slug": "advancements-in-upper-body-exoskeleton-implementing-active-gravity-compensation-with-a-feedforward-controller-arxiv-2309-04698v1-cs-ro",
        "title": "Advancements in Upper Body Exoskeleton: Implementing Active Gravity Compensation with a Feedforward Controller.",
        "link": "http://arxiv.org/abs/2309.04698",
        "abstract": "In this study, we present a feedforward control system designed for active gravity compensation on an upper body exoskeleton. The system utilizes only positional data from internal motor sensors to calculate torque, employing analytical control equations based on Newton-Euler Inverse Dynamics. Compared to feedback control systems, the feedforward approach offers several advantages. It eliminates the need for external torque sensors, resulting in reduced hardware complexity and weight. Moreover, the feedforward control exhibits a more proactive response, leading to enhanced performance. The exoskeleton used in the experiments is lightweight and comprises 4 Degrees of Freedom, closely mimicking human upper body kinematics and three-dimensional range of motion. We conducted tests on both hardware and simulations of the exoskeleton, demonstrating stable performance. The system maintained its position over an extended period, exhibiting minimal friction and avoiding undesired slewing.",
        "creator": "Muhammad Ayaz Hussain, Ioannis Iossifidis"
      },
      {
        "id": "2309.04704",
        "slug": "analysis-of-disinformation-and-fake-news-detection-using-fine-tuned-large-language-model-arxiv-2309-04704v1-cs-cl",
        "title": "Analysis of Disinformation and Fake News Detection Using Fine-Tuned Large Language Model.",
        "link": "http://arxiv.org/abs/2309.04704",
        "abstract": "The paper considers the possibility of fine-tuning Llama 2 large language model (LLM) for the disinformation analysis and fake news detection. For fine-tuning, the PEFT/LoRA based approach was used. In the study, the model was fine-tuned for the following tasks: analysing a text on revealing disinformation and propaganda narratives, fact checking, fake news detection, manipulation analytics, extracting named entities with their sentiments. The obtained results show that the fine-tuned Llama 2 model can perform a deep analysis of texts and reveal complex styles and narratives. Extracted sentiments for named entities can be considered as predictive features in supervised machine learning models.",
        "creator": "Bohdan M. Pavlyshenko"
      },
      {
        "id": "2309.04707",
        "slug": "advantage-actor-critic-with-reasoner-explaining-the-agent-s-behavior-from-an-exploratory-perspective-arxiv-2309-04707v1-cs-ai",
        "title": "Advantage Actor-Critic with Reasoner: Explaining the Agent's Behavior from an Exploratory Perspective.",
        "link": "http://arxiv.org/abs/2309.04707",
        "abstract": "Reinforcement learning (RL) is a powerful tool for solving complex decision-making problems, but its lack of transparency and interpretability has been a major challenge in domains where decisions have significant real-world consequences. In this paper, we propose a novel Advantage Actor-Critic with Reasoner (A2CR), which can be easily applied to Actor-Critic-based RL models and make them interpretable. A2CR consists of three interconnected networks: the Policy Network, the Value Network, and the Reasoner Network. By predefining and classifying the underlying purpose of the actor's actions, A2CR automatically generates a more comprehensive and interpretable paradigm for understanding the agent's decision-making process. It offers a range of functionalities such as purpose-based saliency, early failure detection, and model supervision, thereby promoting responsible and trustworthy RL. Evaluations conducted in action-rich Super Mario Bros environments yield intriguing findings: Reasoner-predicted label proportions decrease for ``Breakout\" and increase for ``Hovering\" as the exploration level of the RL algorithm intensifies. Additionally, purpose-based saliencies are more focused and comprehensible.",
        "creator": "Muzhe Guo, Feixu Yu, Tian Lan, Fang Jin"
      },
      {
        "id": "2309.04710",
        "slug": "jade-a-differentiable-physics-engine-for-articulated-rigid-bodies-with-intersection-free-frictional-contact-arxiv-2309-04710v1-cs-ro",
        "title": "Jade: A Differentiable Physics Engine for Articulated Rigid Bodies with Intersection-Free Frictional Contact.",
        "link": "http://arxiv.org/abs/2309.04710",
        "abstract": "We present Jade, a differentiable physics engine for articulated rigid bodies. Jade models contacts as the Linear Complementarity Problem (LCP). Compared to existing differentiable simulations, Jade offers features including intersection-free collision simulation and stable LCP solutions for multiple frictional contacts. We use continuous collision detection to detect the time of impact and adopt the backtracking strategy to prevent intersection between bodies with complex geometry shapes. We derive the gradient calculation to ensure the whole simulation process is differentiable under the backtracking mechanism. We modify the popular Dantzig algorithm to get valid solutions under multiple frictional contacts. We conduct extensive experiments to demonstrate the effectiveness of our differentiable physics simulation over a variety of contact-rich tasks.",
        "creator": "Gang Yang, Siyuan Luo, Lin Shao"
      },
      {
        "id": "2309.04716",
        "slug": "toward-reproducing-network-research-results-using-large-language-models-arxiv-2309-04716v1-cs-lg",
        "title": "Toward Reproducing Network Research Results Using Large Language Models.",
        "link": "http://arxiv.org/abs/2309.04716",
        "abstract": "Reproducing research results in the networking community is important for both academia and industry. The current best practice typically resorts to three approaches: (1) looking for publicly available prototypes; (2) contacting the authors to get a private prototype; and (3) manually implementing a prototype following the description of the publication. However, most published network research does not have public prototypes and private prototypes are hard to get. As such, most reproducing efforts are spent on manual implementation based on the publications, which is both time and labor consuming and error-prone. In this paper, we boldly propose reproducing network research results using the emerging large language models (LLMs). In particular, we first prove its feasibility with a small-scale experiment, in which four students with essential networking knowledge each reproduces a different networking system published in prominent conferences and journals by prompt engineering ChatGPT. We report the experiment's observations and lessons and discuss future open research questions of this proposal. This work raises no ethical issue.",
        "creator": "Qiao Xiang, Yuling Lin, Mingjun Fang, Bang Huang, Siyong Huang, Ridi Wen, Franck Le, Linghe Kong, Jiwu Shu"
      },
      {
        "id": "2309.04728",
        "slug": "transitions-in-echo-index-and-dependence-on-input-repetitions-arxiv-2309-04728v1-math-ds",
        "title": "Transitions in echo index and dependence on input repetitions.",
        "link": "http://arxiv.org/abs/2309.04728",
        "abstract": "The echo index counts the number of simultaneously stable asymptotic responses of a nonautonomous (i.e. input-driven) dynamical system. It generalizes the well-known echo state property for recurrent neural networks - this corresponds to the echo index being equal to one. In this paper, we investigate how the echo index depends on parameters that govern typical responses to a finite-state ergodic external input that forces the dynamics. We consider the echo index for a nonautonomous system that switches between a finite set of maps, where we assume that each map possesses a finite set of hyperbolic equilibrium attractors. We find the minimum and maximum repetitions of each map are crucial for the resulting echo index. Casting our theoretical findings in the RNN computing framework, we obtain that for small amplitude forcing the echo index corresponds to the number of attractors for the input-free system, while for large amplitude forcing, the echo index reduces to one. The intermediate regime is the most interesting; in this region the echo index depends not just on the amplitude of forcing but also on more subtle properties of the input.",
        "creator": "Peter Ashwin, Andrea Ceni"
      },
      {
        "id": "2309.04732",
        "slug": "tcgan-convolutional-generative-adversarial-network-for-time-series-classification-and-clustering-arxiv-2309-04732v1-cs-lg",
        "title": "TCGAN: Convolutional Generative Adversarial Network for Time Series Classification and Clustering.",
        "link": "http://arxiv.org/abs/2309.04732",
        "abstract": "Recent works have demonstrated the superiority of supervised Convolutional Neural Networks (CNNs) in learning hierarchical representations from time series data for successful classification. These methods require sufficiently large labeled data for stable learning, however acquiring high-quality labeled time series data can be costly and potentially infeasible. Generative Adversarial Networks (GANs) have achieved great success in enhancing unsupervised and semi-supervised learning. Nonetheless, to our best knowledge, it remains unclear how effectively GANs can serve as a general-purpose solution to learn representations for time series recognition, i.e., classification and clustering. The above considerations inspire us to introduce a Time-series Convolutional GAN (TCGAN). TCGAN learns by playing an adversarial game between two one-dimensional CNNs (i.e., a generator and a discriminator) in the absence of label information. Parts of the trained TCGAN are then reused to construct a representation encoder to empower linear recognition methods. We conducted comprehensive experiments on synthetic and real-world datasets. The results demonstrate that TCGAN is faster and more accurate than existing time-series GANs. The learned representations enable simple classification and clustering methods to achieve superior and stable performance. Furthermore, TCGAN retains high efficacy in scenarios with few-labeled and imbalanced-labeled data. Our work provides a promising path to effectively utilize abundant unlabeled time series data.",
        "creator": "Fanling Huang, Yangdong Deng"
      },
      {
        "id": "2309.04733",
        "slug": "a-spatiotemporal-deep-neural-network-for-fine-grained-multi-horizon-wind-prediction-arxiv-2309-04733v1-cs-lg",
        "title": "A Spatiotemporal Deep Neural Network for Fine-Grained Multi-Horizon Wind Prediction.",
        "link": "http://arxiv.org/abs/2309.04733",
        "abstract": "The prediction of wind in terms of both wind speed and direction, which has a crucial impact on many real-world applications like aviation and wind power generation, is extremely challenging due to the high stochasticity and complicated correlation in the weather data. Existing methods typically focus on a sub-set of influential factors and thus lack a systematic treatment of the problem. In addition, fine-grained forecasting is essential for efficient industry operations, but has been less attended in the literature. In this work, we propose a novel data-driven model, Multi-Horizon SpatioTemporal Network (MHSTN), generally for accurate and efficient fine-grained wind prediction. MHSTN integrates multiple deep neural networks targeting different factors in a sequence-to-sequence (Seq2Seq) backbone to effectively extract features from various data sources and produce multi-horizon predictions for all sites within a given region. MHSTN is composed of four major modules. First, a temporal module fuses coarse-grained forecasts derived by Numerical Weather Prediction (NWP) and historical on-site observation data at stations so as to leverage both global and local atmospheric information. Second, a spatial module exploits spatial correlation by modeling the joint representation of all stations. Third, an ensemble module weighs the above two modules for final predictions. Furthermore, a covariate selection module automatically choose influential meteorological variables as initial input. MHSTN is already integrated into the scheduling platform of one of the busiest international airports of China. The evaluation results demonstrate that our model outperforms competitors by a significant margin.",
        "creator": "Fanling Huang, Yangdong Deng"
      },
      {
        "id": "2309.04755",
        "slug": "towards-real-time-training-of-physics-informed-neural-networks-applications-in-ultrafast-ultrasound-blood-flow-imaging-arxiv-2309-04755v1-cs-ce",
        "title": "Towards Real-time Training of Physics-informed Neural Networks: Applications in Ultrafast Ultrasound Blood Flow Imaging.",
        "link": "http://arxiv.org/abs/2309.04755",
        "abstract": "Physics-informed Neural Network (PINN) is one of the most preeminent solvers of Navier-Stokes equations, which are widely used as the governing equation of blood flow. However, current approaches, relying on full Navier-Stokes equations, are impractical for ultrafast Doppler ultrasound, the state-of-the-art technique for depiction of complex blood flow dynamics \\emph{in vivo} through acquired thousands of frames (or, timestamps) per second. In this article, we first propose a novel training framework of PINN for solving Navier-Stokes equations by discretizing Navier-Stokes equations into steady state and sequentially solving steady-state Navier-Stokes equations with transfer learning. The novel training framework is coined as SeqPINN. Upon the success of SeqPINN, we adopt the idea of averaged constant stochastic gradient descent (SGD) as initialization and propose a parallel training scheme for all timestamps. To ensure an initialization that generalizes well, we borrow the concept of Stochastic Weight Averaging Gaussian to perform uncertainty estimation as an indicator of generalizability of the initialization. This algorithm, named SP-PINN, further expedites training of PINN while achieving comparable accuracy with SeqPINN. Finite-element simulations and \\emph{in vitro} phantoms of single-branch and trifurcate blood vessels are used to evaluate the performance of SeqPINN and SP-PINN. Results show that both SeqPINN and SP-PINN are manyfold faster than the original design of PINN, while respectively achieving Root Mean Square Errors (RMSEs) of 1.01 cm/s and 1.26 cm/s on the straight vessel and 1.91 cm/s and 2.56 cm/s on the trifurcate blood vessel when recovering blood flow velocities.",
        "creator": "Haotian Guan, Jinping Dong, Wei-Ning Lee"
      },
      {
        "id": "2309.04760",
        "slug": "rr-cp-reliable-region-based-conformal-prediction-for-trustworthy-medical-image-classification-arxiv-2309-04760v1-cs-lg",
        "title": "RR-CP: Reliable-Region-Based Conformal Prediction for Trustworthy Medical Image Classification.",
        "link": "http://arxiv.org/abs/2309.04760",
        "abstract": "Conformal prediction (CP) generates a set of predictions for a given test sample such that the prediction set almost always contains the true label (e.g., 99.5\\% of the time). CP provides comprehensive predictions on possible labels of a given test sample, and the size of the set indicates how certain the predictions are (e.g., a set larger than one is `uncertain'). Such distinct properties of CP enable effective collaborations between human experts and medical AI models, allowing efficient intervention and quality check in clinical decision-making. In this paper, we propose a new method called Reliable-Region-Based Conformal Prediction (RR-CP), which aims to impose a stronger statistical guarantee so that the user-specified error rate (e.g., 0.5\\%) can be achieved in the test time, and under this constraint, the size of the prediction set is optimized (to be small). We consider a small prediction set size an important measure only when the user-specified error rate is achieved. Experiments on five public datasets show that our RR-CP performs well: with a reasonably small-sized prediction set, it achieves the user-specified error rate (e.g., 0.5\\%) significantly more frequently than exiting CP methods.",
        "creator": "Yizhe Zhang, Shuo Wang, Yejia Zhang, Danny Z. Chen"
      },
      {
        "id": "2309.04762",
        "slug": "audrandaug-random-image-augmentations-for-audio-classification-arxiv-2309-04762v1-cs-sd",
        "title": "AudRandAug: Random Image Augmentations for Audio Classification.",
        "link": "http://arxiv.org/abs/2309.04762",
        "abstract": "Data augmentation has proven to be effective in training neural networks. Recently, a method called RandAug was proposed, randomly selecting data augmentation techniques from a predefined search space. RandAug has demonstrated significant performance improvements for image-related tasks while imposing minimal computational overhead. However, no prior research has explored the application of RandAug specifically for audio data augmentation, which converts audio into an image-like pattern. To address this gap, we introduce AudRandAug, an adaptation of RandAug for audio data. AudRandAug selects data augmentation policies from a dedicated audio search space. To evaluate the effectiveness of AudRandAug, we conducted experiments using various models and datasets. Our findings indicate that AudRandAug outperforms other existing data augmentation methods regarding accuracy performance.",
        "creator": "Teerath Kumar, Muhammad Turab, Alessandra Mileo, Malika Bendechache, Takfarinas Saber"
      },
      {
        "id": "2309.04766",
        "slug": "seaeval-for-multilingual-foundation-models-from-cross-lingual-alignment-to-cultural-reasoning-arxiv-2309-04766v1-cs-cl",
        "title": "SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning.",
        "link": "http://arxiv.org/abs/2309.04766",
        "abstract": "We present SeaEval, a benchmark for multilingual foundation models. In addition to characterizing how these models understand and reason with natural language, we also investigate how well they comprehend cultural practices, nuances, and values. Alongside standard accuracy metrics, we investigate the brittleness of foundation models in the dimensions of semantics and multilinguality. Our analyses span both open-sourced and closed models, leading to empirical results across classic NLP tasks, reasoning, and cultural comprehension. Key findings indicate (1) Most models exhibit varied behavior when given paraphrased instructions. (2) Many models still suffer from exposure bias (e.g., positional bias, majority label bias). (3) For questions rooted in factual, scientific, and commonsense knowledge, consistent responses are expected across multilingual queries that are semantically equivalent. Yet, most models surprisingly demonstrate inconsistent performance on these queries. (4) Multilingually-trained models have not attained \"balanced multilingual\" capabilities. Our endeavors underscore the need for more generalizable semantic representations and enhanced multilingual contextualization. SeaEval can serve as a launchpad for more thorough investigations and evaluations for multilingual and multicultural scenarios.",
        "creator": "Bin Wang, Zhengyuan Liu, Xin Huang, Fangkai Jiao, Yang Ding, Ai Ti Aw, Nancy F. Chen"
      },
      {
        "id": "2309.04777",
        "slug": "towards-robust-model-watermark-via-reducing-parametric-vulnerability-arxiv-2309-04777v1-cs-cr",
        "title": "Towards Robust Model Watermark via Reducing Parametric Vulnerability.",
        "link": "http://arxiv.org/abs/2309.04777",
        "abstract": "Deep neural networks are valuable assets considering their commercial benefits and huge demands for costly annotation and computation resources. To protect the copyright of DNNs, backdoor-based ownership verification becomes popular recently, in which the model owner can watermark the model by embedding a specific backdoor behavior before releasing it. The defenders (usually the model owners) can identify whether a suspicious third-party model is ``stolen'' from them based on the presence of the behavior. Unfortunately, these watermarks are proven to be vulnerable to removal attacks even like fine-tuning. To further explore this vulnerability, we investigate the parameter space and find there exist many watermark-removed models in the vicinity of the watermarked one, which may be easily used by removal attacks. Inspired by this finding, we propose a mini-max formulation to find these watermark-removed models and recover their watermark behavior. Extensive experiments demonstrate that our method improves the robustness of the model watermarking against parametric changes and numerous watermark-removal attacks. The codes for reproducing our main experiments are available at \\url{https://github.com/GuanhaoGan/robust-model-watermarking}.",
        "creator": "Guanhao Gan, Yiming Li, Dongxian Wu, Shu-Tao Xia"
      },
      {
        "id": "2309.04797",
        "slug": "a-full-fledged-commit-message-quality-checker-based-on-machine-learning-arxiv-2309-04797v1-cs-se",
        "title": "A Full-fledged Commit Message Quality Checker Based on Machine Learning.",
        "link": "http://arxiv.org/abs/2309.04797",
        "abstract": "Commit messages (CMs) are an essential part of version control. By providing important context in regard to what has changed and why, they strongly support software maintenance and evolution. But writing good CMs is difficult and often neglected by developers. So far, there is no tool suitable for practice that automatically assesses how well a CM is written, including its meaning and context. Since this task is challenging, we ask the research question: how well can the CM quality, including semantics and context, be measured with machine learning methods? By considering all rules from the most popular CM quality guideline, creating datasets for those rules, and training and evaluating state-of-the-art machine learning models to check those rules, we can answer the research question with: sufficiently well for practice, with the lowest F$_1$ score of 82.9\\%, for the most challenging task. We develop a full-fledged open-source framework that checks all these CM quality rules. It is useful for research, e.g., automatic CM generation, but most importantly for software practitioners to raise the quality of CMs and thus the maintainability and evolution speed of their software.",
        "creator": "David Farag&#xf3;, Michael F&#xe4;rber, Christian Petrov"
      },
      {
        "id": "2309.04801",
        "slug": "tmcomposites-plug-and-play-collaboration-between-specialized-tsetlin-machines-arxiv-2309-04801v1-cs-cv",
        "title": "TMComposites: Plug-and-Play Collaboration Between Specialized Tsetlin Machines.",
        "link": "http://arxiv.org/abs/2309.04801",
        "abstract": "Tsetlin Machines (TMs) provide a fundamental shift from arithmetic-based to logic-based machine learning. Supporting convolution, they deal successfully with image classification datasets like MNIST, Fashion-MNIST, and CIFAR-2. However, the TM struggles with getting state-of-the-art performance on CIFAR-10 and CIFAR-100, representing more complex tasks. This paper introduces plug-and-play collaboration between specialized TMs, referred to as TM Composites. The collaboration relies on a TM's ability to specialize during learning and to assess its competence during inference. When teaming up, the most confident TMs make the decisions, relieving the uncertain ones. In this manner, a TM Composite becomes more competent than its members, benefiting from their specializations. The collaboration is plug-and-play in that members can be combined in any way, at any time, without fine-tuning. We implement three TM specializations in our empirical evaluation: Histogram of Gradients, Adaptive Gaussian Thresholding, and Color Thermometers. The resulting TM Composite increases accuracy on Fashion-MNIST by two percentage points, CIFAR-10 by twelve points, and CIFAR-100 by nine points, yielding new state-of-the-art results for TMs. Overall, we envision that TM Composites will enable an ultra-low energy and transparent alternative to state-of-the-art deep learning on more tasks and datasets.",
        "creator": "Ole-Christoffer Granmo"
      },
      {
        "id": "2309.04802",
        "slug": "cpmr-context-aware-incremental-sequential-recommendation-with-pseudo-multi-task-learning-arxiv-2309-04802v1-cs-ir",
        "title": "CPMR: Context-Aware Incremental Sequential Recommendation with Pseudo-Multi-Task Learning.",
        "link": "http://arxiv.org/abs/2309.04802",
        "abstract": "The motivations of users to make interactions can be divided into static preference and dynamic interest. To accurately model user representations over time, recent studies in sequential recommendation utilize information propagation and evolution to mine from batches of arriving interactions. However, they ignore the fact that people are easily influenced by the recent actions of other users in the contextual scenario, and applying evolution across all historical interactions dilutes the importance of recent ones, thus failing to model the evolution of dynamic interest accurately. To address this issue, we propose a Context-Aware Pseudo-Multi-Task Recommender System (CPMR) to model the evolution in both historical and contextual scenarios by creating three representations for each user and item under different dynamics: static embedding, historical temporal states, and contextual temporal states. To dually improve the performance of temporal states evolution and incremental recommendation, we design a Pseudo-Multi-Task Learning (PMTL) paradigm by stacking the incremental single-target recommendations into one multi-target task for joint optimization. Within the PMTL paradigm, CPMR employs a shared-bottom network to conduct the evolution of temporal states across historical and contextual scenarios, as well as the fusion of them at the user-item level. In addition, CPMR incorporates one real tower for incremental predictions, and two pseudo towers dedicated to updating the respective temporal states based on new batches of interactions. Experimental results on four benchmark recommendation datasets show that CPMR consistently outperforms state-of-the-art baselines and achieves significant gains on three of them. The code is available at: https://github.com/DiMarzioBian/CPMR.",
        "creator": "Qingtian Bian, Jiaxing Xu, Hui Fang, Yiping Ke"
      },
      {
        "id": "2309.04803",
        "slug": "towards-real-world-burst-image-super-resolution-benchmark-and-method-arxiv-2309-04803v1-cs-cv",
        "title": "Towards Real-World Burst Image Super-Resolution: Benchmark and Method.",
        "link": "http://arxiv.org/abs/2309.04803",
        "abstract": "Despite substantial advances, single-image super-resolution (SISR) is always in a dilemma to reconstruct high-quality images with limited information from one input image, especially in realistic scenarios. In this paper, we establish a large-scale real-world burst super-resolution dataset, i.e., RealBSR, to explore the faithful reconstruction of image details from multiple frames. Furthermore, we introduce a Federated Burst Affinity network (FBAnet) to investigate non-trivial pixel-wise displacements among images under real-world image degradation. Specifically, rather than using pixel-wise alignment, our FBAnet employs a simple homography alignment from a structural geometry aspect and a Federated Affinity Fusion (FAF) strategy to aggregate the complementary information among frames. Those fused informative representations are fed to a Transformer-based module of burst representation decoding. Besides, we have conducted extensive experiments on two versions of our datasets, i.e., RealBSR-RAW and RealBSR-RGB. Experimental results demonstrate that our FBAnet outperforms existing state-of-the-art burst SR methods and also achieves visually-pleasant SR image predictions with model details. Our dataset, codes, and models are publicly available at https://github.com/yjsunnn/FBANet.",
        "creator": "Pengxu Wei, Yujing Sun, Xingbei Guo, Chang Liu, Jie Chen, Xiangyang Ji, Liang Lin"
      },
      {
        "id": "2309.04806",
        "slug": "timely-fusion-of-surround-radar-lidar-for-object-detection-in-autonomous-driving-systems-arxiv-2309-04806v1-cs-cv",
        "title": "Timely Fusion of Surround Radar/Lidar for Object Detection in Autonomous Driving Systems.",
        "link": "http://arxiv.org/abs/2309.04806",
        "abstract": "Fusing Radar and Lidar sensor data can fully utilize their complementary advantages and provide more accurate reconstruction of the surrounding for autonomous driving systems. Surround Radar/Lidar can provide 360-degree view sampling with the minimal cost, which are promising sensing hardware solutions for autonomous driving systems. However, due to the intrinsic physical constraints, the rotating speed of surround Radar, and thus the frequency to generate Radar data frames, is much lower than surround Lidar. Existing Radar/Lidar fusion methods have to work at the low frequency of surround Radar, which cannot meet the high responsiveness requirement of autonomous driving systems.This paper develops techniques to fuse surround Radar/Lidar with working frequency only limited by the faster surround Lidar instead of the slower surround Radar, based on the state-of-the-art object detection model MVDNet. The basic idea of our approach is simple: we let MVDNet work with temporally unaligned data from Radar/Lidar, so that fusion can take place at any time when a new Lidar data frame arrives, instead of waiting for the slow Radar data frame. However, directly applying MVDNet to temporally unaligned Radar/Lidar data greatly degrades its object detection accuracy. The key information revealed in this paper is that we can achieve high output frequency with little accuracy loss by enhancing the training procedure to explore the temporal redundancy in MVDNet so that it can tolerate the temporal unalignment of input data. We explore several different ways of training enhancement and compare them quantitatively with experiments.",
        "creator": "Wenjing Xie, Tao Hu, Neiwen Ling, Guoliang Xing, Shaoshan Liu, Nan Guan"
      },
      {
        "id": "2309.04831",
        "slug": "global-convergence-of-receding-horizon-policy-search-in-learning-estimator-designs-arxiv-2309-04831v1-math-oc",
        "title": "Global Convergence of Receding-Horizon Policy Search in Learning Estimator Designs.",
        "link": "http://arxiv.org/abs/2309.04831",
        "abstract": "We introduce the receding-horizon policy gradient (RHPG) algorithm, the first PG algorithm with provable global convergence in learning the optimal linear estimator designs, i.e., the Kalman filter (KF). Notably, the RHPG algorithm does not require any prior knowledge of the system for initialization and does not require the target system to be open-loop stable. The key of RHPG is that we integrate vanilla PG (or any other policy search directions) into a dynamic programming outer loop, which iteratively decomposes the infinite-horizon KF problem that is constrained and non-convex in the policy parameter into a sequence of static estimation problems that are unconstrained and strongly-convex, thus enabling global convergence. We further provide fine-grained analyses of the optimization landscape under RHPG and detail the convergence and sample complexity guarantees of the algorithm. This work serves as an initial attempt to develop reinforcement learning algorithms specifically for control applications with performance guarantees by utilizing classic control theory in both algorithmic design and theoretical analyses. Lastly, we validate our theories by deploying the RHPG algorithm to learn the Kalman filter design of a large-scale convection-diffusion model. We open-source the code repository at \\url{https://github.com/xiangyuan-zhang/LearningKF}.",
        "creator": "Xiangyuan Zhang, Saviz Mowlavi, Mouhacine Benosman, Tamer Ba&#x15f;ar"
      },
      {
        "id": "2309.04849",
        "slug": "speech-emotion-recognition-with-distilled-prosodic-and-linguistic-affect-representations-arxiv-2309-04849v1-cs-cl",
        "title": "Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect Representations.",
        "link": "http://arxiv.org/abs/2309.04849",
        "abstract": "We propose EmoDistill, a novel speech emotion recognition (SER) framework that leverages cross-modal knowledge distillation during training to learn strong linguistic and prosodic representations of emotion from speech. During inference, our method only uses a stream of speech signals to perform unimodal SER thus reducing computation overhead and avoiding run-time transcription and prosodic feature extraction errors. During training, our method distills information at both embedding and logit levels from a pair of pre-trained Prosodic and Linguistic teachers that are fine-tuned for SER. Experiments on the IEMOCAP benchmark demonstrate that our method outperforms other unimodal and multimodal techniques by a considerable margin, and achieves state-of-the-art performance of 77.49% unweighted accuracy and 78.91% weighted accuracy. Detailed ablation studies demonstrate the impact of each component of our method.",
        "creator": "Debaditya Shome, Ali Etemad"
      },
      {
        "id": "2309.04856",
        "slug": "ambientflow-invertible-generative-models-from-incomplete-noisy-measurements-arxiv-2309-04856v1-cs-lg",
        "title": "AmbientFlow: Invertible generative models from incomplete, noisy measurements.",
        "link": "http://arxiv.org/abs/2309.04856",
        "abstract": "Generative models have gained popularity for their potential applications in imaging science, such as image reconstruction, posterior sampling and data sharing. Flow-based generative models are particularly attractive due to their ability to tractably provide exact density estimates along with fast, inexpensive and diverse samples. Training such models, however, requires a large, high quality dataset of objects. In applications such as computed imaging, it is often difficult to acquire such data due to requirements such as long acquisition time or high radiation dose, while acquiring noisy or partially observed measurements of these objects is more feasible. In this work, we propose AmbientFlow, a framework for learning flow-based generative models directly from noisy and incomplete data. Using variational Bayesian methods, a novel framework for establishing flow-based generative models from noisy, incomplete data is proposed. Extensive numerical studies demonstrate the effectiveness of AmbientFlow in correctly learning the object distribution. The utility of AmbientFlow in a downstream inference task of image reconstruction is demonstrated.",
        "creator": "Varun A. Kelkar, Rucha Deshpande, Arindam Banerjee, Mark A. Anastasio"
      },
      {
        "id": "2309.04862",
        "slug": "distributional-data-augmentation-methods-for-low-resource-language-arxiv-2309-04862v1-cs-cl",
        "title": "Distributional Data Augmentation Methods for Low Resource Language.",
        "link": "http://arxiv.org/abs/2309.04862",
        "abstract": "Text augmentation is a technique for constructing synthetic data from an under-resourced corpus to improve predictive performance. Synthetic data generation is common in numerous domains. However, recently text augmentation has emerged in natural language processing (NLP) to improve downstream tasks. One of the current state-of-the-art text augmentation techniques is easy data augmentation (EDA), which augments the training data by injecting and replacing synonyms and randomly permuting sentences. One major obstacle with EDA is the need for versatile and complete synonym dictionaries, which cannot be easily found in low-resource languages. To improve the utility of EDA, we propose two extensions, easy distributional data augmentation (EDDA) and type specific similar word replacement (TSSR), which uses semantic word context information and part-of-speech tags for word replacement and augmentation. In an extensive empirical evaluation, we show the utility of the proposed methods, measured by F1 score, on two representative datasets in Swedish as an example of a low-resource language. With the proposed methods, we show that augmented data improve classification performances in low-resource settings.",
        "creator": "Mosleh Mahamud, Zed Lee, Isak Samsten"
      },
      {
        "id": "2309.04891",
        "slug": "how-to-evaluate-semantic-communications-for-images-with-vitscore-metric-arxiv-2309-04891v1-cs-cv",
        "title": "How to Evaluate Semantic Communications for Images with ViTScore Metric?.",
        "link": "http://arxiv.org/abs/2309.04891",
        "abstract": "Semantic communications (SC) have been expected to be a new paradigm shifting to catalyze the next generation communication, whose main concerns shift from accurate bit transmission to effective semantic information exchange in communications. However, the previous and widely-used metrics for images are not applicable to evaluate the image semantic similarity in SC. Classical metrics to measure the similarity between two images usually rely on the pixel level or the structural level, such as the PSNR and the MS-SSIM. Straightforwardly using some tailored metrics based on deep-learning methods in CV community, such as the LPIPS, is infeasible for SC. To tackle this, inspired by BERTScore in NLP community, we propose a novel metric for evaluating image semantic similarity, named Vision Transformer Score (ViTScore). We prove theoretically that ViTScore has 3 important properties, including symmetry, boundedness, and normalization, which make ViTScore convenient and intuitive for image measurement. To evaluate the performance of ViTScore, we compare ViTScore with 3 typical metrics (PSNR, MS-SSIM, and LPIPS) through 5 classes of experiments. Experimental results demonstrate that ViTScore can better evaluate the image semantic similarity than the other 3 typical metrics, which indicates that ViTScore is an effective performance metric when deployed in SC scenarios.",
        "creator": "Tingting Zhu, Bo Peng, Jifan Liang, Tingchen Han, Hai Wan, Jingqiao Fu, Junjie Chen"
      },
      {
        "id": "2309.04907",
        "slug": "effective-real-image-editing-with-accelerated-iterative-diffusion-inversion-arxiv-2309-04907v1-cs-cv",
        "title": "Effective Real Image Editing with Accelerated Iterative Diffusion Inversion.",
        "link": "http://arxiv.org/abs/2309.04907",
        "abstract": "Despite all recent progress, it is still challenging to edit and manipulate natural images with modern generative models. When using Generative Adversarial Network (GAN), one major hurdle is in the inversion process mapping a real image to its corresponding noise vector in the latent space, since its necessary to be able to reconstruct an image to edit its contents. Likewise for Denoising Diffusion Implicit Models (DDIM), the linearization assumption in each inversion step makes the whole deterministic inversion process unreliable. Existing approaches that have tackled the problem of inversion stability often incur in significant trade-offs in computational efficiency. In this work we propose an Accelerated Iterative Diffusion Inversion method, dubbed AIDI, that significantly improves reconstruction accuracy with minimal additional overhead in space and time complexity. By using a novel blended guidance technique, we show that effective results can be obtained on a large range of image editing tasks without large classifier-free guidance in inversion. Furthermore, when compared with other diffusion inversion based works, our proposed process is shown to be more robust for fast image editing in the 10 and 20 diffusion steps' regimes.",
        "creator": "Zhihong Pan, Riccardo Gherardi, Xiufeng Xie, Stephen Huang"
      },
      {
        "id": "2309.04911",
        "slug": "a-review-of-machine-learning-based-security-in-cloud-computing-arxiv-2309-04911v1-cs-cr",
        "title": "A Review of Machine Learning-based Security in Cloud Computing.",
        "link": "http://arxiv.org/abs/2309.04911",
        "abstract": "Cloud Computing (CC) is revolutionizing the way IT resources are delivered to users, allowing them to access and manage their systems with increased cost-effectiveness and simplified infrastructure. However, with the growth of CC comes a host of security risks, including threats to availability, integrity, and confidentiality. To address these challenges, Machine Learning (ML) is increasingly being used by Cloud Service Providers (CSPs) to reduce the need for human intervention in identifying and resolving security issues. With the ability to analyze vast amounts of data, and make high-accuracy predictions, ML can transform the way CSPs approach security. In this paper, we will explore some of the most recent research in the field of ML-based security in Cloud Computing. We will examine the features and effectiveness of a range of ML algorithms, highlighting their unique strengths and potential limitations. Our goal is to provide a comprehensive overview of the current state of ML in cloud security and to shed light on the exciting possibilities that this emerging field has to offer.",
        "creator": "Aptin Babaei, Parham M. Kebria, Mohsen Moradi Dalvand, Saeid Nahavandi"
      },
      {
        "id": "2309.04914",
        "slug": "mfpnet-multi-scale-feature-propagation-nwtwork-for-lightweight-semantic-segmentation-arxiv-2309-04914v1-cs-cv",
        "title": "MFPNet: Multi-scale Feature Propagation Nwtwork For Lightweight Semantic Segmentation.",
        "link": "http://arxiv.org/abs/2309.04914",
        "abstract": "In contrast to the abundant research focusing on large-scale models, the progress in lightweight semantic segmentation appears to be advancing at a comparatively slower pace. However, existing compact methods often suffer from limited feature representation capability due to the shallowness of their networks. In this paper, we propose a novel lightweight segmentation architecture, called Multi-scale Feature Propagation Network (MFPNet), to address the dilemma. Specifically, we design a robust Encoder-Decoder structure featuring symmetrical residual blocks that consist of flexible bottleneck residual modules (BRMs) to explore deep and rich muti-scale semantic context. Furthermore, taking benefit from their capacity to model latent long-range contextual relationships, we leverage Graph Convolutional Networks (GCNs) to facilitate multi-scale feature propagation between the BRM blocks. When evaluated on benchmark datasets, our proposed approach shows superior segmentation results.",
        "creator": "Guoan Xu, Wenjing Jia, Tao Wu, Ligeng Chen"
      },
      {
        "id": "2309.04951",
        "slug": "multi-document-summarization-a-comparative-evaluation-arxiv-2309-04951v1-cs-cl",
        "title": "Multi-document Summarization: A Comparative Evaluation.",
        "link": "http://arxiv.org/abs/2309.04951",
        "abstract": "This paper is aimed at evaluating state-of-the-art models for Multi-document Summarization (MDS) on different types of datasets in various domains and investigating the limitations of existing models to determine future research directions. To address this gap, we conducted an extensive literature review to identify state-of-the-art models and datasets. We analyzed the performance of PRIMERA and PEGASUS models on BigSurvey-MDS and MS$^2$ datasets, which posed unique challenges due to their varied domains. Our findings show that the General-Purpose Pre-trained Model LED outperforms PRIMERA and PEGASUS on the MS$^2$ dataset. We used the ROUGE score as a performance metric to evaluate the identified models on different datasets. Our study provides valuable insights into the models' strengths and weaknesses, as well as their applicability in different domains. This work serves as a reference for future MDS research and contributes to the development of accurate and robust models which can be utilized on demanding datasets with academically and/or scientifically complex data as well as generalized, relatively simple datasets.",
        "creator": "Kushan Hewapathirana (1 and 2), Nisansa de Silva (1), C.D. Athuraliya (2) ((1) Department of Computer Science &amp; Engineering, University of Moratuwa, Sri Lanka, (2) ConscientAI, Sri Lanka)"
      },
      {
        "id": "2309.04965",
        "slug": "prefix-diffusion-a-lightweight-diffusion-model-for-diverse-image-captioning-arxiv-2309-04965v1-cs-cv",
        "title": "Prefix-diffusion: A Lightweight Diffusion Model for Diverse Image Captioning.",
        "link": "http://arxiv.org/abs/2309.04965",
        "abstract": "While impressive performance has been achieved in image captioning, the limited diversity of the generated captions and the large parameter scale remain major barriers to the real-word application of these systems. In this work, we propose a lightweight image captioning network in combination with continuous diffusion, called Prefix-diffusion. To achieve diversity, we design an efficient method that injects prefix image embeddings into the denoising process of the diffusion model. In order to reduce trainable parameters, we employ a pre-trained model to extract image features and further design an extra mapping network. Prefix-diffusion is able to generate diverse captions with relatively less parameters, while maintaining the fluency and relevance of the captions benefiting from the generative capabilities of the diffusion model. Our work paves the way for scaling up diffusion models for image captioning, and achieves promising performance compared with recent approaches.",
        "creator": "Guisheng Liu, Yi Li, Zhengcong Fei, Haiyan Fu, Xiangyang Luo, Yanqing Guo"
      },
      {
        "id": "2309.04974",
        "slug": "continual-robot-learning-using-self-supervised-task-inference-arxiv-2309-04974v1-cs-ro",
        "title": "Continual Robot Learning using Self-Supervised Task Inference.",
        "link": "http://arxiv.org/abs/2309.04974",
        "abstract": "Endowing robots with the human ability to learn a growing set of skills over the course of a lifetime as opposed to mastering single tasks is an open problem in robot learning. While multi-task learning approaches have been proposed to address this problem, they pay little attention to task inference. In order to continually learn new tasks, the robot first needs to infer the task at hand without requiring predefined task representations. In this paper, we propose a self-supervised task inference approach. Our approach learns action and intention embeddings from self-organization of the observed movement and effect parts of unlabeled demonstrations and a higher-level behavior embedding from self-organization of the joint action-intention embeddings. We construct a behavior-matching self-supervised learning objective to train a novel Task Inference Network (TINet) to map an unlabeled demonstration to its nearest behavior embedding, which we use as the task representation. A multi-task policy is built on top of the TINet and trained with reinforcement learning to optimize performance over tasks. We evaluate our approach in the fixed-set and continual multi-task learning settings with a humanoid robot and compare it to different multi-task learning baselines. The results show that our approach outperforms the other baselines, with the difference being more pronounced in the challenging continual learning setting, and can infer tasks from incomplete demonstrations. Our approach is also shown to generalize to unseen tasks based on a single demonstration in one-shot task generalization experiments.",
        "creator": "Muhammad Burhan Hafez, Stefan Wermter"
      },
      {
        "id": "2309.04976",
        "slug": "avars-alleviating-unexpected-urban-road-traffic-congestion-using-uavs-arxiv-2309-04976v1-cs-lg",
        "title": "AVARS -- Alleviating Unexpected Urban Road Traffic Congestion using UAVs.",
        "link": "http://arxiv.org/abs/2309.04976",
        "abstract": "Reducing unexpected urban traffic congestion caused by en-route events (e.g., road closures, car crashes, etc.) often requires fast and accurate reactions to choose the best-fit traffic signals. Traditional traffic light control systems, such as SCATS and SCOOT, are not efficient as their traffic data provided by induction loops has a low update frequency (i.e., longer than 1 minute). Moreover, the traffic light signal plans used by these systems are selected from a limited set of candidate plans pre-programmed prior to unexpected events' occurrence. Recent research demonstrates that camera-based traffic light systems controlled by deep reinforcement learning (DRL) algorithms are more effective in reducing traffic congestion, in which the cameras can provide high-frequency high-resolution traffic data. However, these systems are costly to deploy in big cities due to the excessive potential upgrades required to road infrastructure. In this paper, we argue that Unmanned Aerial Vehicles (UAVs) can play a crucial role in dealing with unexpected traffic congestion because UAVs with onboard cameras can be economically deployed when and where unexpected congestion occurs. Then, we propose a system called \"AVARS\" that explores the potential of using UAVs to reduce unexpected urban traffic congestion using DRL-based traffic light signal control. This approach is validated on a widely used open-source traffic simulator with practical UAV settings, including its traffic monitoring ranges and battery lifetime. Our simulation results show that AVARS can effectively recover the unexpected traffic congestion in Dublin, Ireland, back to its original un-congested level within the typical battery life duration of a UAV.",
        "creator": "Jiaying Guo, Michael R. Jones, Soufiene Djahel, Shen Wang"
      },
      {
        "id": "2309.04977",
        "slug": "rgat-a-deeper-look-into-syntactic-dependency-information-for-coreference-resolution-arxiv-2309-04977v1-cs-cl",
        "title": "RGAT: A Deeper Look into Syntactic Dependency Information for Coreference Resolution.",
        "link": "http://arxiv.org/abs/2309.04977",
        "abstract": "Although syntactic information is beneficial for many NLP tasks, combining it with contextual information between words to solve the coreference resolution problem needs to be further explored. In this paper, we propose an end-to-end parser that combines pre-trained BERT with a Syntactic Relation Graph Attention Network (RGAT) to take a deeper look into the role of syntactic dependency information for the coreference resolution task. In particular, the RGAT model is first proposed, then used to understand the syntactic dependency graph and learn better task-specific syntactic embeddings. An integrated architecture incorporating BERT embeddings and syntactic embeddings is constructed to generate blending representations for the downstream task. Our experiments on a public Gendered Ambiguous Pronouns (GAP) dataset show that with the supervision learning of the syntactic dependency graph and without fine-tuning the entire BERT, we increased the F1-score of the previous best model (RGCN-with-BERT) from 80.3% to 82.5%, compared to the F1-score by single BERT embeddings from 78.5% to 82.5%. Experimental results on another public dataset - OntoNotes 5.0 demonstrate that the performance of the model is also improved by incorporating syntactic dependency information learned from RGAT.",
        "creator": "Yuan Meng, Xuhao Pan, Jun Chang, Yue Wang"
      },
      {
        "id": "2309.05007",
        "slug": "followupqg-towards-information-seeking-follow-up-question-generation-arxiv-2309-05007v1-cs-cl",
        "title": "FOLLOWUPQG: Towards Information-Seeking Follow-up Question Generation.",
        "link": "http://arxiv.org/abs/2309.05007",
        "abstract": "Humans ask follow-up questions driven by curiosity, which reflects a creative human cognitive process. We introduce the task of real-world information-seeking follow-up question generation (FQG), which aims to generate follow-up questions seeking a more in-depth understanding of an initial question and answer. We construct FOLLOWUPQG, a dataset of over 3K real-world (initial question, answer, follow-up question) tuples collected from a Reddit forum providing layman-friendly explanations for open-ended questions. In contrast to existing datasets, questions in FOLLOWUPQG use more diverse pragmatic strategies to seek information, and they also show higher-order cognitive skills (such as applying and relating). We evaluate current question generation models on their efficacy for generating follow-up questions, exploring how to generate specific types of follow-up questions based on step-by-step demonstrations. Our results validate FOLLOWUPQG as a challenging benchmark, as model-generated questions are adequate but far from human-raised questions in terms of informativeness and complexity.",
        "creator": "Yan Meng, Liangming Pan, Yixin Cao, Min-Yen Kan"
      },
      {
        "id": "2309.05027",
        "slug": "voiceflow-efficient-text-to-speech-with-rectified-flow-matching-arxiv-2309-05027v1-eess-as",
        "title": "VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching.",
        "link": "http://arxiv.org/abs/2309.05027",
        "abstract": "Although diffusion models in text-to-speech have become a popular choice due to their strong generative ability, the intrinsic complexity of sampling from diffusion models harms their efficiency. Alternatively, we propose VoiceFlow, an acoustic model that utilizes a rectified flow matching algorithm to achieve high synthesis quality with a limited number of sampling steps. VoiceFlow formulates the process of generating mel-spectrograms into an ordinary differential equation conditional on text inputs, whose vector field is then estimated. The rectified flow technique then effectively straightens its sampling trajectory for efficient synthesis. Subjective and objective evaluations on both single and multi-speaker corpora showed the superior synthesis quality of VoiceFlow compared to the diffusion counterpart. Ablation studies further verified the validity of the rectified flow technique in VoiceFlow.",
        "creator": "Yiwei Guo, Chenpeng Du, Ziyang Ma, Xie Chen, Kai Yu"
      },
      {
        "id": "2309.05030",
        "slug": "decolonial-ai-alignment-vi-s-esadharma-argument-and-artistic-expression-arxiv-2309-05030v1-cs-cy",
        "title": "Decolonial AI Alignment: Vi\\'{s}esadharma, Argument, and Artistic Expression.",
        "link": "http://arxiv.org/abs/2309.05030",
        "abstract": "Prior work has explicated the coloniality of artificial intelligence (AI) development and deployment. One process that that work has not engaged with much is alignment: the tuning of large language model (LLM) behavior to be in line with desired values based on fine-grained human feedback. In addition to other practices, colonialism has a history of altering the beliefs and values of colonized peoples; this history is recapitulated in current LLM alignment practices. We suggest that AI alignment be decolonialized using three proposals: (a) changing the base moral philosophy from Western philosophy to dharma, (b) permitting traditions of argument and pluralism in alignment technologies, and (c) expanding the epistemology of values beyond instructions or commandments given in natural language.",
        "creator": "Kush R. Varshney"
      },
      {
        "id": "2108.11635",
        "slug": "mcml-a-novel-memory-based-contrastive-meta-learning-method-for-few-shot-slot-tagging-arxiv-2108-11635v3-cs-ai-updated",
        "title": "MCML: A Novel Memory-based Contrastive Meta-Learning Method for Few Shot Slot Tagging.",
        "link": "http://arxiv.org/abs/2108.11635",
        "abstract": "Meta-learning is widely used for few-shot slot tagging in task of few-shot learning. The performance of existing methods is, however, seriously affected by \\textit{sample forgetting issue}, where the model forgets the historically learned meta-training tasks while solely relying on support sets when adapting to new tasks. To overcome this predicament, we propose the \\textbf{M}emory-based \\textbf{C}ontrastive \\textbf{M}eta-\\textbf{L}earning (aka, MCML) method, including \\textit{learn-from-the-memory} and \\textit{adaption-from-the-memory} modules, which bridge the distribution gap between training episodes and between training and testing respectively. Specifically, the former uses an explicit memory bank to keep track of the label representations of previously trained episodes, with a contrastive constraint between the label representations in the current episode with the historical ones stored in the memory. In addition, the \\emph{adaption-from-memory} mechanism is introduced to learn more accurate and robust representations based on the shift between the same labels embedded in the testing episodes and memory. Experimental results show that the MCML outperforms several state-of-the-art methods on both SNIPS and NER datasets and demonstrates strong scalability with consistent improvement when the number of shots gets greater.",
        "creator": "Hongru Wang, Zezhong Wang, Wai Chung Kwan, Kam-Fai Wong"
      },
      {
        "id": "2110.00269",
        "slug": "a-survey-of-knowledge-enhanced-pre-trained-models-arxiv-2110-00269v4-cs-cl-updated",
        "title": "A Survey of Knowledge Enhanced Pre-trained Models.",
        "link": "http://arxiv.org/abs/2110.00269",
        "abstract": "Pre-trained language models learn informative word representations on a large-scale text corpus through self-supervised learning, which has achieved promising performance in fields of natural language processing (NLP) after fine-tuning. These models, however, suffer from poor robustness and lack of interpretability. We refer to pre-trained language models with knowledge injection as knowledge-enhanced pre-trained language models (KEPLMs). These models demonstrate deep understanding and logical reasoning and introduce interpretability. In this survey, we provide a comprehensive overview of KEPLMs in NLP. We first discuss the advancements in pre-trained language models and knowledge representation learning. Then we systematically categorize existing KEPLMs from three different perspectives. Finally, we outline some potential directions of KEPLMs for future research.",
        "creator": "Jian Yang, Xinyu Hu, Gang Xiao, Yulong Shen"
      },
      {
        "id": "2110.03605",
        "slug": "robust-feature-level-adversaries-are-interpretability-tools-arxiv-2110-03605v7-cs-lg-updated",
        "title": "Robust Feature-Level Adversaries are Interpretability Tools.",
        "link": "http://arxiv.org/abs/2110.03605",
        "abstract": "The literature on adversarial attacks in computer vision typically focuses on pixel-level perturbations. These tend to be very difficult to interpret. Recent work that manipulates the latent representations of image generators to create \"feature-level\" adversarial perturbations gives us an opportunity to explore perceptible, interpretable adversarial attacks. We make three contributions. First, we observe that feature-level attacks provide useful classes of inputs for studying representations in models. Second, we show that these adversaries are uniquely versatile and highly robust. We demonstrate that they can be used to produce targeted, universal, disguised, physically-realizable, and black-box attacks at the ImageNet scale. Third, we show how these adversarial images can be used as a practical interpretability tool for identifying bugs in networks. We use these adversaries to make predictions about spurious associations between features and classes which we then test by designing \"copy/paste\" attacks in which one natural image is pasted into another to cause a targeted misclassification. Our results suggest that feature-level attacks are a promising approach for rigorous interpretability research. They support the design of tools to better understand what a model has learned and diagnose brittle feature associations. Code is available at https://github.com/thestephencasper/feature_level_adv",
        "creator": "Stephen Casper, Max Nadeau, Dylan Hadfield-Menell, Gabriel Kreiman"
      },
      {
        "id": "2112.14417",
        "slug": "control-theoretic-analysis-of-temporal-difference-learning-arxiv-2112-14417v6-cs-ai-updated",
        "title": "Control Theoretic Analysis of Temporal Difference Learning.",
        "link": "http://arxiv.org/abs/2112.14417",
        "abstract": "The goal of this manuscript is to conduct a controltheoretic analysis of Temporal Difference (TD) learning algorithms. TD-learning serves as a cornerstone in the realm of reinforcement learning, offering a methodology for approximating the value function associated with a given policy in a Markov Decision Process. Despite several existing works that have contributed to the theoretical understanding of TD-learning, it is only in recent years that researchers have been able to establish concrete guarantees on its statistical efficiency. In this paper, we introduce a finite-time, control-theoretic framework for analyzing TD-learning, leveraging established concepts from the field of linear systems control. Consequently, this paper provides additional insights into the mechanics of TD learning and the broader landscape of reinforcement learning, all while employing straightforward analytical tools derived from control theory.",
        "creator": "Donghwan Lee, Do Wan Kim"
      },
      {
        "id": "2202.03558",
        "slug": "attacking-c-marl-more-effectively-a-data-driven-approach-arxiv-2202-03558v2-cs-lg-updated",
        "title": "Attacking c-MARL More Effectively: A Data Driven Approach.",
        "link": "http://arxiv.org/abs/2202.03558",
        "abstract": "In recent years, a proliferation of methods were developed for cooperative multi-agent reinforcement learning (c-MARL). However, the robustness of c-MARL agents against adversarial attacks has been rarely explored. In this paper, we propose to evaluate the robustness of c-MARL agents via a model-based approach, named c-MBA. Our proposed formulation can craft much stronger adversarial state perturbations of c-MARL agents to lower total team rewards than existing model-free approaches. In addition, we propose the first victim-agent selection strategy and the first data-driven approach to define targeted failure states where each of them allows us to develop even stronger adversarial attack without the expert knowledge to the underlying environment. Our numerical experiments on two representative MARL benchmarks illustrate the advantage of our approach over other baselines: our model-based attack consistently outperforms other baselines in all tested environments.",
        "creator": "Nhan H. Pham, Lam M. Nguyen, Jie Chen, Hoang Thanh Lam, Subhro Das, Tsui-Wei Weng"
      },
      {
        "id": "2206.00979",
        "slug": "multi-scale-wasserstein-shortest-path-filtration-kernels-on-graphs-arxiv-2206-00979v3-cs-lg-updated",
        "title": "Multi-scale Wasserstein Shortest-path Filtration Kernels on Graphs.",
        "link": "http://arxiv.org/abs/2206.00979",
        "abstract": "The traditional shortest-path graph kernel (SP) is one of the most popular graph kernels. It decomposes graphs into shortest paths and computes their frequencies in each graph. However, SP has two main challenges: Firstly, the triplet representation of the shortest path loses information. Secondly, SP compares graphs without considering the multiple different scales of the graph structure which is common in real-world graphs, e.g., the chain-, ring-, and star-structures in social networks. To overcome these two challenges, we develop a novel shortest-path graph kernel called the Multi-scale Wasserstein Shortest-Path Filtration graph kernel (MWSPF). It uses a BFS tree of a certain depth rooted at each vertex to restrict the maximum length of the shortest path considering the small world property. It considers the labels of all the vertices in the shortest path. To facilitate the comparison of graphs at multiple different scales, it augments graphs from both the aspects of the vertex and the graph structure. The distribution (frequency) of the shortest path changes across augmented graphs and the Wasserstein distance is employed to track the changes. We conduct experiments on various benchmark graph datasets to evaluate MWSPF's performance. MWSPF is superior to the state-of-the-art on most datasets.",
        "creator": "Wei Ye, Hao Tian, Qijun Chen"
      },
      {
        "id": "2207.06150",
        "slug": "estimating-the-power-consumption-of-heterogeneous-devices-when-performing-ai-inference-arxiv-2207-06150v2-cs-ar-updated",
        "title": "Estimating the Power Consumption of Heterogeneous Devices when performing AI Inference.",
        "link": "http://arxiv.org/abs/2207.06150",
        "abstract": "Modern-day life is driven by electronic devices connected to the internet. The emerging research field of the Internet-of-Things (IoT) has become popular, just as there has been a steady increase in the number of connected devices. Since many of these devices are utilised to perform CV tasks, it is essential to understand their power consumption against performance. We report the power consumption profile and analysis of the NVIDIA Jetson Nano board while performing object classification. The authors present an extensive analysis regarding power consumption per frame and the output in frames per second using YOLOv5 models. The results show that the YOLOv5n outperforms other YOLOV5 variants in terms of throughput (i.e. 12.34 fps) and low power consumption (i.e. 0.154 mWh/frame).",
        "creator": "Pedro Machado, Ivica Matic, Francisco de Lemos, Isibor Kennedy Ihianle, David Ada Adama"
      },
      {
        "id": "2207.09847",
        "slug": "predicting-word-learning-in-children-from-the-performance-of-computer-vision-systems-arxiv-2207-09847v3-cs-cl-updated",
        "title": "Predicting Word Learning in Children from the Performance of Computer Vision Systems.",
        "link": "http://arxiv.org/abs/2207.09847",
        "abstract": "For human children as well as machine learning systems, a key challenge in learning a word is linking the word to the visual phenomena it describes. We explore this aspect of word learning by using the performance of computer vision systems as a proxy for the difficulty of learning a word from visual cues. We show that the age at which children acquire different categories of words is correlated with the performance of visual classification and captioning systems, over and above the expected effects of word frequency. The performance of the computer vision systems is correlated with human judgments of the concreteness of words, which are in turn a predictor of children's word learning, suggesting that these models are capturing the relationship between words and visual phenomena.",
        "creator": "Sunayana Rane, Mira L. Nencheva, Zeyu Wang, Casey Lew-Williams, Olga Russakovsky, Thomas L. Griffiths"
      },
      {
        "id": "2209.09979",
        "slug": "jsdp-a-java-stochastic-dp-library-arxiv-2209-09979v3-cs-ai-updated",
        "title": "jsdp: a Java Stochastic DP Library.",
        "link": "http://arxiv.org/abs/2209.09979",
        "abstract": "Stochastic Programming is a framework for modelling and solving problems of decision making under uncertainty. Stochastic Dynamic Programming is a branch of Stochastic Programming that takes a \"functional equation\" approach to the discovery of optimal policies. By leveraging constructs - lambda expressions, functional interfaces, collections and aggregate operators - implemented in Java to operationalise the MapReduce framework, jsdp provides a general purpose library for modelling and solving Stochastic Dynamic Programs.",
        "creator": "Roberto Rossi"
      },
      {
        "id": "2210.05918",
        "slug": "finite-time-analysis-of-temporal-difference-learning-with-linear-function-approximation-tail-averaging-and-regularisation-arxiv-2210-05918v2-cs-lg-updated",
        "title": "Finite time analysis of temporal difference learning with linear function approximation: Tail averaging and regularisation.",
        "link": "http://arxiv.org/abs/2210.05918",
        "abstract": "We study the finite-time behaviour of the popular temporal difference (TD) learning algorithm when combined with tail-averaging. We derive finite time bounds on the parameter error of the tail-averaged TD iterate under a step-size choice that does not require information about the eigenvalues of the matrix underlying the projected TD fixed point. Our analysis shows that tail-averaged TD converges at the optimal $O\\left(1/t\\right)$ rate, both in expectation and with high probability. In addition, our bounds exhibit a sharper rate of decay for the initial error (bias), which is an improvement over averaging all iterates. We also propose and analyse a variant of TD that incorporates regularisation. From analysis, we conclude that the regularised version of TD is useful for problems with ill-conditioned features.",
        "creator": "Gandharv Patil, Prashanth L.A., Dheeraj Nagaraj, Doina Precup"
      },
      {
        "id": "2210.16719",
        "slug": "multi-view-multi-label-anomaly-network-traffic-classification-based-on-mlp-mixer-neural-network-arxiv-2210-16719v3-cs-lg-updated",
        "title": "Multi-view Multi-label Anomaly Network Traffic Classification based on MLP-Mixer Neural Network.",
        "link": "http://arxiv.org/abs/2210.16719",
        "abstract": "Network traffic classification is the basis of many network security applications and has attracted enough attention in the field of cyberspace security. Existing network traffic classification based on convolutional neural networks (CNNs) often emphasizes local patterns of traffic data while ignoring global information associations. In this paper, we propose an MLP-Mixer based multi-view multi-label neural network for network traffic classification. Compared with the existing CNN-based methods, our method adopts the MLP-Mixer structure, which is more in line with the structure of the packet than the conventional convolution operation. In our method, one packet is divided into the packet header and the packet body, together with the flow features of the packet as input from different views. We utilize a multi-label setting to learn different scenarios simultaneously to improve the classification performance by exploiting the correlations between different scenarios. Taking advantage of the above characteristics, we propose an end-to-end network traffic classification method. We conduct experiments on three public datasets, and the experimental results show that our method can achieve superior performance.",
        "creator": "Yu Zheng, Zhangxuan Dang, Chunlei Peng, Chao Yang, Xinbo Gao"
      },
      {
        "id": "2211.01120",
        "slug": "variational-hierarchical-mixtures-for-probabilistic-learning-of-inverse-dynamics-arxiv-2211-01120v2-cs-lg-updated",
        "title": "Variational Hierarchical Mixtures for Probabilistic Learning of Inverse Dynamics.",
        "link": "http://arxiv.org/abs/2211.01120",
        "abstract": "Well-calibrated probabilistic regression models are a crucial learning component in robotics applications as datasets grow rapidly and tasks become more complex. Unfortunately, classical regression models are usually either probabilistic kernel machines with a flexible structure that does not scale gracefully with data or deterministic and vastly scalable automata, albeit with a restrictive parametric form and poor regularization. In this paper, we consider a probabilistic hierarchical modeling paradigm that combines the benefits of both worlds to deliver computationally efficient representations with inherent complexity regularization. The presented approaches are probabilistic interpretations of local regression techniques that approximate nonlinear functions through a set of local linear or polynomial units. Importantly, we rely on principles from Bayesian nonparametrics to formulate flexible models that adapt their complexity to the data and can potentially encompass an infinite number of components. We derive two efficient variational inference techniques to learn these representations and highlight the advantages of hierarchical infinite local regression models, such as dealing with non-smooth functions, mitigating catastrophic forgetting, and enabling parameter sharing and fast predictions. Finally, we validate this approach on large inverse dynamics datasets and test the learned models in real-world control scenarios.",
        "creator": "Hany Abdulsamad, Peter Nickl, Pascal Klink, Jan Peters"
      },
      {
        "id": "2211.04476",
        "slug": "discover-explanation-improvement-an-automatic-slice-detection-framework-for-natural-language-processing-arxiv-2211-04476v2-cs-cl-updated",
        "title": "Discover, Explanation, Improvement: An Automatic Slice Detection Framework for Natural Language Processing.",
        "link": "http://arxiv.org/abs/2211.04476",
        "abstract": "Pretrained natural language processing (NLP) models have achieved high overall performance, but they still make systematic errors. Instead of manual error analysis, research on slice detection models (SDM), which automatically identify underperforming groups of datapoints, has caught escalated attention in Computer Vision for both understanding model behaviors and providing insights for future model training and designing. However, little research on SDM and quantitative evaluation of their effectiveness have been conducted on NLP tasks. Our paper fills the gap by proposing a benchmark named \"Discover, Explain, Improve (DEIM)\" for classification NLP tasks along with a new SDM Edisa. Edisa discovers coherent and underperforming groups of datapoints; DEIM then unites them under human-understandable concepts and provides comprehensive evaluation tasks and corresponding quantitative metrics. The evaluation in DEIM shows that Edisa can accurately select error-prone datapoints with informative semantic features that summarize error patterns. Detecting difficult datapoints directly boosts model performance without tuning any original model parameters, showing that discovered slices are actionable for users.",
        "creator": "Wenyue Hua, Lifeng Jin, Linfeng Song, Haitao Mi, Yongfeng Zhang, Dong Yu"
      },
      {
        "id": "2211.08796",
        "slug": "model-based-residual-policy-learning-with-applications-to-antenna-control-arxiv-2211-08796v3-cs-lg-updated",
        "title": "Model Based Residual Policy Learning with Applications to Antenna Control.",
        "link": "http://arxiv.org/abs/2211.08796",
        "abstract": "Non-differentiable controllers and rule-based policies are widely used for controlling real systems such as telecommunication networks and robots. Specifically, parameters of mobile network base station antennas can be dynamically configured by these policies to improve users coverage and quality of service. Motivated by the antenna tilt control problem, we introduce Model-Based Residual Policy Learning (MBRPL), a practical reinforcement learning (RL) method. MBRPL enhances existing policies through a model-based approach, leading to improved sample efficiency and a decreased number of interactions with the actual environment when compared to off-the-shelf RL methods.To the best of our knowledge, this is the first paper that examines a model-based approach for antenna control. Experimental results reveal that our method delivers strong initial performance while improving sample efficiency over previous RL methods, which is one step towards deploying these algorithms in real networks.",
        "creator": "Viktor Eriksson M&#xf6;llerstedt, Alessio Russo, Maxime Bouton"
      },
      {
        "id": "2211.08843",
        "slug": "improving-speech-emotion-recognition-with-unsupervised-speaking-style-transfer-arxiv-2211-08843v2-cs-sd-updated",
        "title": "Improving Speech Emotion Recognition with Unsupervised Speaking Style Transfer.",
        "link": "http://arxiv.org/abs/2211.08843",
        "abstract": "Humans can effortlessly modify various prosodic attributes, such as the placement of stress and the intensity of sentiment, to convey a specific emotion while maintaining consistent linguistic content. Motivated by this capability, we propose EmoAug, a novel style transfer model designed to enhance emotional expression and tackle the data scarcity issue in speech emotion recognition tasks. EmoAug consists of a semantic encoder and a paralinguistic encoder that represent verbal and non-verbal information respectively. Additionally, a decoder reconstructs speech signals by conditioning on the aforementioned two information flows in an unsupervised fashion. Once training is completed, EmoAug enriches expressions of emotional speech with different prosodic attributes, such as stress, rhythm and intensity, by feeding different styles into the paralinguistic encoder. EmoAug enables us to generate similar numbers of samples for each class to tackle the data imbalance issue as well. Experimental results on the IEMOCAP dataset demonstrate that EmoAug can successfully transfer different speaking styles while retaining the speaker identity and semantic content. Furthermore, we train a SER model with data augmented by EmoAug and show that the augmented model not only surpasses the state-of-the-art supervised and self-supervised methods but also overcomes overfitting problems caused by data imbalance. Some audio samples can be found on our demo website.",
        "creator": "Leyuan Qu, Wei Wang, Cornelius Weber, Pengcheng Yue, Taihao Li, Stefan Wermter"
      },
      {
        "id": "2211.09172",
        "slug": "deep-emotion-recognition-in-textual-conversations-a-survey-arxiv-2211-09172v2-cs-cl-updated",
        "title": "Deep Emotion Recognition in Textual Conversations: A Survey.",
        "link": "http://arxiv.org/abs/2211.09172",
        "abstract": "While Emotion Recognition in Conversations (ERC) has seen a tremendous advancement in the last few years, new applications and implementation scenarios present novel challenges and opportunities. These range from leveraging the conversational context, speaker and emotion dynamics modelling, to interpreting common sense expressions, informal language and sarcasm, addressing challenges of real time ERC, recognizing emotion causes, different taxonomies across datasets, multilingual ERC to interpretability. This survey starts by introducing ERC, elaborating on the challenges and opportunities pertaining to this task. It proceeds with a description of the emotion taxonomies and a variety of ERC benchmark datasets employing such taxonomies. This is followed by descriptions of the most prominent works in ERC with explanations of the Deep Learning architectures employed. Then, it provides advisable ERC practices towards better frameworks, elaborating on methods to deal with subjectivity in annotations and modelling and methods to deal with the typically unbalanced ERC datasets. Finally, it presents systematic review tables comparing several works regarding the methods used and their performance. The survey highlights the advantage of leveraging techniques to address unbalanced data, the exploration of mixed emotions and the benefits of incorporating annotation subjectivity in the learning phase.",
        "creator": "Patr&#xed;cia Pereira, Helena Moniz, Joao Paulo Carvalho"
      },
      {
        "id": "2211.12875",
        "slug": "a-survey-of-deep-graph-clustering-taxonomy-challenge-application-and-open-resource-arxiv-2211-12875v3-cs-lg-updated",
        "title": "A Survey of Deep Graph Clustering: Taxonomy, Challenge, Application, and Open Resource.",
        "link": "http://arxiv.org/abs/2211.12875",
        "abstract": "Graph clustering, which aims to divide nodes in the graph into several distinct clusters, is a fundamental yet challenging task. Benefiting from the powerful representation capability of deep learning, deep graph clustering methods have achieved great success in recent years. However, the corresponding survey paper is relatively scarce, and it is imminent to make a summary of this field. From this motivation, we conduct a comprehensive survey of deep graph clustering. Firstly, we introduce formulaic definition, evaluation, and development in this field. Secondly, the taxonomy of deep graph clustering methods is presented based on four different criteria, including graph type, network architecture, learning paradigm, and clustering method. Thirdly, we carefully analyze the existing methods via extensive experiments and summarize the challenges and opportunities from five perspectives, including graph data quality, stability, scalability, discriminative capability, and unknown cluster number. Besides, the applications of deep graph clustering methods in six domains, including computer vision, natural language processing, recommendation systems, social network analyses, bioinformatics, and medical science, are presented. Last but not least, this paper provides open resource supports, including 1) a collection (\\url{https://github.com/yueliu1999/Awesome-Deep-Graph-Clustering}) of state-of-the-art deep graph clustering methods (papers, codes, and datasets) and 2) a unified framework (\\url{https://github.com/Marigoldwu/A-Unified-Framework-for-Deep-Attribute-Graph-Clustering}) of deep graph clustering. We hope this work can serve as a quick guide and help researchers overcome challenges in this vibrant field.",
        "creator": "Yue Liu, Jun Xia, Sihang Zhou, Xihong Yang, Ke Liang, Chenchen Fan, Yan Zhuang, Stan Z. Li, Xinwang Liu, Kunlun He"
      },
      {
        "id": "2212.01173",
        "slug": "dwrseg-rethinking-efficient-acquisition-of-multi-scale-contextual-information-for-real-time-semantic-segmentation-arxiv-2212-01173v2-cs-cv-updated",
        "title": "DWRSeg: Rethinking Efficient Acquisition of Multi-scale Contextual Information for Real-time Semantic Segmentation.",
        "link": "http://arxiv.org/abs/2212.01173",
        "abstract": "Many current works directly adopt multi-rate depth-wise dilated convolutions to capture multi-scale contextual information simultaneously from one input feature map, thus improving the feature extraction efficiency for real-time semantic segmentation. However, this design may lead to difficult access to multi-scale contextual information because of the unreasonable structure and hyperparameters. To lower the difficulty of drawing multi-scale contextual information, we propose a highly efficient multi-scale feature extraction method, which decomposes the original single-step method into two steps, Region Residualization-Semantic Residualization.In this method, the multi-rate depth-wise dilated convolutions take a simpler role in feature extraction: performing simple semantic-based morphological filtering with one desired receptive field in the second step based on each concise feature map of region form provided by the first step, to improve their efficiency. Moreover, the dilation rates and the capacity of dilated convolutions for each network stage are elaborated to fully utilize all the feature maps of region form that can be achieved.Accordingly, we design a novel Dilation-wise Residual (DWR) module and a Simple Inverted Residual (SIR) module for the high and low level network, respectively, and form a powerful DWR Segmentation (DWRSeg) network. Extensive experiments on the Cityscapes and CamVid datasets demonstrate the effectiveness of our method by achieving a state-of-the-art trade-off between accuracy and inference speed, in addition to being lighter weight. Without pretraining or resorting to any training trick, we achieve an mIoU of 72.7% on the Cityscapes test set at a speed of 319.5 FPS on one NVIDIA GeForce GTX 1080 Ti card, which exceeds the latest methods of a speed of 69.5 FPS and 0.8% mIoU. The code and trained models are publicly available.",
        "creator": "Haoran Wei, Xu Liu, Shouchun Xu, Zhongjian Dai, Yaping Dai, Xiangyang Xu"
      },
      {
        "id": "2212.07935",
        "slug": "strong-ai-autoepistemic-robots-build-on-intensional-first-order-logic-arxiv-2212-07935v3-cs-ai-updated",
        "title": "Strong-AI Autoepistemic Robots Build on Intensional First Order Logic.",
        "link": "http://arxiv.org/abs/2212.07935",
        "abstract": "Neuro-symbolic AI attempts to integrate neural and symbolic architectures in a manner that addresses strengths and weaknesses of each, in a complementary fashion, in order to support robust strong AI capable of reasoning, learning, and cognitive modeling. In this paper we consider the intensional First Order Logic (IFOL) as a symbolic architecture of modern robots, able to use natural languages to communicate with humans and to reason about their own knowledge with self-reference and abstraction language property.  We intend to obtain the grounding of robot's language by experience of how it uses its neuronal architectures and hence by associating this experience with the mining (sense) of non-defined language concepts (particulars/individuals and universals) in PRP (Properties/Relations/Propositions) theory of IFOL.\\\\ We consider the robot's four-levels knowledge structure: The syntax level of particular natural language (Italian, French, etc..), two universal language levels: its semantic logic structure (based on virtual predicates of FOL and logic connectives), and its corresponding conceptual PRP structure level which universally represents the composite mining of FOL formulae grounded on the last robot's neuro-system level.  Finally, we provide the general method how to implement in IFOL (by using the abstracted terms) different kinds of modal logic operators and their deductive axioms: we present a particular example of robots autoepistemic deduction capabilities by introduction of the special temporal $Konow$ predicate and deductive axioms for it: reflexive, positive introspection and distributive axiom.",
        "creator": "Zoran Majkic"
      },
      {
        "id": "2212.09993",
        "slug": "are-deep-neural-networks-smarter-than-second-graders-arxiv-2212-09993v6-cs-ai-updated",
        "title": "Are Deep Neural Networks SMARTer than Second Graders?.",
        "link": "http://arxiv.org/abs/2212.09993",
        "abstract": "Recent times have witnessed an increasing number of applications of deep neural networks towards solving tasks that require superior cognitive abilities, e.g., playing Go, generating art, ChatGPT, etc. Such a dramatic progress raises the question: how generalizable are neural networks in solving problems that demand broad skills? To answer this question, we propose SMART: a Simple Multimodal Algorithmic Reasoning Task and the associated SMART-101 dataset, for evaluating the abstraction, deduction, and generalization abilities of neural networks in solving visuo-linguistic puzzles designed specifically for children in the 6--8 age group. Our dataset consists of 101 unique puzzles; each puzzle comprises a picture and a question, and their solution needs a mix of several elementary skills, including arithmetic, algebra, and spatial reasoning, among others. To scale our dataset towards training deep neural networks, we programmatically generate entirely new instances for each puzzle, while retaining their solution algorithm. To benchmark performances on SMART-101, we propose a vision and language meta-learning model using varied state-of-the-art backbones. Our experiments reveal that while powerful deep models offer reasonable performances on puzzles in a supervised setting, they are not better than random accuracy when analyzed for generalization. We also evaluate the recent ChatGPT and other large language models on a subset of SMART-101 and find that while these models show convincing reasoning abilities, the answers are often incorrect.",
        "creator": "Anoop Cherian, Kuan-Chuan Peng, Suhas Lohit, Kevin A. Smith, Joshua B. Tenenbaum"
      },
      {
        "id": "2301.00776",
        "slug": "physics-informed-neural-networks-for-prognostics-and-health-management-of-lithium-ion-batteries-arxiv-2301-00776v2-eess-sp-updated",
        "title": "Physics-Informed Neural Networks for Prognostics and Health Management of Lithium-Ion Batteries.",
        "link": "http://arxiv.org/abs/2301.00776",
        "abstract": "For Prognostics and Health Management (PHM) of Lithium-ion (Li-ion) batteries, many models have been established to characterize their degradation process. The existing empirical or physical models can reveal important information regarding the degradation dynamics. However, there are no general and flexible methods to fuse the information represented by those models. Physics-Informed Neural Network (PINN) is an efficient tool to fuse empirical or physical dynamic models with data-driven models. To take full advantage of various information sources, we propose a model fusion scheme based on PINN. It is implemented by developing a semi-empirical semi-physical Partial Differential Equation (PDE) to model the degradation dynamics of Li-ion batteries. When there is little prior knowledge about the dynamics, we leverage the data-driven Deep Hidden Physics Model (DeepHPM) to discover the underlying governing dynamic models. The uncovered dynamics information is then fused with that mined by the surrogate neural network in the PINN framework. Moreover, an uncertainty-based adaptive weighting method is employed to balance the multiple learning tasks when training the PINN. The proposed methods are verified on a public dataset of Li-ion Phosphate (LFP)/graphite batteries.",
        "creator": "Pengfei Wen, Zhi-Sheng Ye, Yong Li, Shaowei Chen, Pu Xie, Shuai Zhao"
      },
      {
        "id": "2301.08374",
        "slug": "projective-integral-updates-for-high-dimensional-variational-inference-arxiv-2301-08374v2-cs-lg-updated",
        "title": "Projective Integral Updates for High-Dimensional Variational Inference.",
        "link": "http://arxiv.org/abs/2301.08374",
        "abstract": "Variational inference is an approximation framework for Bayesian inference that seeks to improve quantified uncertainty in predictions by optimizing a simplified distribution over parameters to stand in for the full posterior. Capturing model variations that remain consistent with training data enables more robust predictions by reducing parameter sensitivity. This work introduces a fixed-point optimization for variational inference that is applicable when every feasible log density can be expressed as a linear combination of functions from a given basis. In such cases, the optimizer becomes a fixed-point of projective integral updates. When the basis spans univariate quadratics in each parameter, feasible densities are Gaussian and the projective integral updates yield quasi-Newton variational Bayes (QNVB). Other bases and updates are also possible. As these updates require high-dimensional integration, this work first proposes an efficient quasirandom quadrature sequence for mean-field distributions. Each iterate of the sequence contains two evaluation points that combine to correctly integrate all univariate quadratics and, if the mean-field factors are symmetric, all univariate cubics. More importantly, averaging results over short subsequences achieves periodic exactness on a much larger space of multivariate quadratics. The corresponding variational updates require 4 loss evaluations with standard (not second-order) backpropagation to eliminate error terms from over half of all multivariate quadratic basis functions. This integration technique is motivated by first proposing stochastic blocked mean-field quadratures, which may be useful in other contexts. A PyTorch implementation of QNVB allows for better control over model uncertainty during training than competing methods. Experiments demonstrate superior generalizability for multiple learning problems and architectures.",
        "creator": "Jed A. Duersch"
      },
      {
        "id": "2301.12503",
        "slug": "audioldm-text-to-audio-generation-with-latent-diffusion-models-arxiv-2301-12503v3-cs-sd-updated",
        "title": "AudioLDM: Text-to-Audio Generation with Latent Diffusion Models.",
        "link": "http://arxiv.org/abs/2301.12503",
        "abstract": "Text-to-audio (TTA) system has recently gained attention for its ability to synthesize general audio based on text descriptions. However, previous studies in TTA have limited generation quality with high computational costs. In this study, we propose AudioLDM, a TTA system that is built on a latent space to learn the continuous audio representations from contrastive language-audio pretraining (CLAP) latents. The pretrained CLAP models enable us to train LDMs with audio embedding while providing text embedding as a condition during sampling. By learning the latent representations of audio signals and their compositions without modeling the cross-modal relationship, AudioLDM is advantageous in both generation quality and computational efficiency. Trained on AudioCaps with a single GPU, AudioLDM achieves state-of-the-art TTA performance measured by both objective and subjective metrics (e.g., frechet distance). Moreover, AudioLDM is the first TTA system that enables various text-guided audio manipulations (e.g., style transfer) in a zero-shot fashion. Our implementation and demos are available at https://audioldm.github.io.",
        "creator": "Haohe Liu, Zehua Chen, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, Mark D. Plumbley"
      },
      {
        "id": "2302.09893",
        "slug": "efficient-generator-of-mathematical-expressions-for-symbolic-regression-arxiv-2302-09893v2-cs-lg-updated",
        "title": "Efficient Generator of Mathematical Expressions for Symbolic Regression.",
        "link": "http://arxiv.org/abs/2302.09893",
        "abstract": "We propose an approach to symbolic regression based on a novel variational autoencoder for generating hierarchical structures, HVAE. It combines simple atomic units with shared weights to recursively encode and decode the individual nodes in the hierarchy. Encoding is performed bottom-up and decoding top-down. We empirically show that HVAE can be trained efficiently with small corpora of mathematical expressions and can accurately encode expressions into a smooth low-dimensional latent space. The latter can be efficiently explored with various optimization methods to address the task of symbolic regression. Indeed, random search through the latent space of HVAE performs better than random search through expressions generated by manually crafted probabilistic grammars for mathematical expressions. Finally, EDHiE system for symbolic regression, which applies an evolutionary algorithm to the latent space of HVAE, reconstructs equations from a standard symbolic regression benchmark better than a state-of-the-art system based on a similar combination of deep learning and evolutionary algorithms.\\v{z}",
        "creator": "Sebastian Me&#x17e;nar, Sa&#x161;o D&#x17e;eroski, Ljup&#x10d;o Todorovski"
      },
      {
        "id": "2303.06053",
        "slug": "tsmixer-an-all-mlp-architecture-for-time-series-forecasting-arxiv-2303-06053v5-cs-lg-updated",
        "title": "TSMixer: An All-MLP Architecture for Time Series Forecasting.",
        "link": "http://arxiv.org/abs/2303.06053",
        "abstract": "Real-world time-series datasets are often multivariate with complex dynamics. To capture this complexity, high capacity architectures like recurrent- or attention-based sequential deep learning models have become popular. However, recent work demonstrates that simple univariate linear models can outperform such deep learning models on several commonly used academic benchmarks. Extending them, in this paper, we investigate the capabilities of linear models for time-series forecasting and present Time-Series Mixer (TSMixer), a novel architecture designed by stacking multi-layer perceptrons (MLPs). TSMixer is based on mixing operations along both the time and feature dimensions to extract information efficiently. On popular academic benchmarks, the simple-to-implement TSMixer is comparable to specialized state-of-the-art models that leverage the inductive biases of specific benchmarks. On the challenging and large scale M5 benchmark, a real-world retail dataset, TSMixer demonstrates superior performance compared to the state-of-the-art alternatives. Our results underline the importance of efficiently utilizing cross-variate and auxiliary information for improving the performance of time series forecasting. We present various analyses to shed light into the capabilities of TSMixer. The design paradigms utilized in TSMixer are expected to open new horizons for deep learning-based time series forecasting. The implementation is available at https://github.com/google-research/google-research/tree/master/tsmixer",
        "creator": "Si-An Chen, Chun-Liang Li, Nate Yoder, Sercan O. Arik, Tomas Pfister"
      },
      {
        "id": "2303.09026",
        "slug": "commonsense-knowledge-assisted-deep-learning-with-application-to-size-related-fine-grained-object-detection-arxiv-2303-09026v6-cs-cv-updated",
        "title": "Commonsense Knowledge Assisted Deep Learning with Application to Size-Related Fine-Grained Object Detection.",
        "link": "http://arxiv.org/abs/2303.09026",
        "abstract": "In this paper, we focus on a scenario where a single image contains objects of the same category but varying sizes, and we propose a lightweight approach that can not only recognize their category labels but also their real sizes. Our approach utilizes commonsense knowledge to assist a deep neural network (DNN) based coarse-grained object detector to achieve accurate size-related fine-grained detection. Specifically, we introduce a commonsense knowledge inference module (CKIM) that maps the coarse-grained labels produced by the DL detector to size-related fine-grained labels. Experimental results demonstrate that our approach achieves accurate fine-grained detections with a reduced amount of annotated data, and smaller model size, compared with baseline methods. Our code is available at: https://github.com/ZJLAB-AMMI/CKIM.",
        "creator": "Pu Zhang, Bin Liu"
      },
      {
        "id": "2303.17155",
        "slug": "discriminative-class-tokens-for-text-to-image-diffusion-models-arxiv-2303-17155v3-cs-cv-updated",
        "title": "Discriminative Class Tokens for Text-to-Image Diffusion Models.",
        "link": "http://arxiv.org/abs/2303.17155",
        "abstract": "Recent advances in text-to-image diffusion models have enabled the generation of diverse and high-quality images. While impressive, the images often fall short of depicting subtle details and are susceptible to errors due to ambiguity in the input text. One way of alleviating these issues is to train diffusion models on class-labeled datasets. This approach has two disadvantages: (i) supervised datasets are generally small compared to large-scale scraped text-image datasets on which text-to-image models are trained, affecting the quality and diversity of the generated images, or (ii) the input is a hard-coded label, as opposed to free-form text, limiting the control over the generated images.  In this work, we propose a non-invasive fine-tuning technique that capitalizes on the expressive potential of free-form text while achieving high accuracy through discriminative signals from a pretrained classifier. This is done by iteratively modifying the embedding of an added input token of a text-to-image diffusion model, by steering generated images toward a given target class according to a classifier. Our method is fast compared to prior fine-tuning methods and does not require a collection of in-class images or retraining of a noise-tolerant classifier. We evaluate our method extensively, showing that the generated images are: (i) more accurate and of higher quality than standard diffusion models, (ii) can be used to augment training data in a low-resource setting, and (iii) reveal information about the data used to train the guiding classifier. The code is available at \\url{https://github.com/idansc/discriminative_class_tokens}.",
        "creator": "Idan Schwartz, V&#xe9;steinn Sn&#xe6;bjarnarson, Hila Chefer, Ryan Cotterell, Serge Belongie, Lior Wolf, Sagie Benaim"
      },
      {
        "id": "2303.18223",
        "slug": "a-survey-of-large-language-models-arxiv-2303-18223v12-cs-cl-updated",
        "title": "A Survey of Large Language Models.",
        "link": "http://arxiv.org/abs/2303.18223",
        "abstract": "Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale language models. To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size. Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.",
        "creator": "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, Ji-Rong Wen"
      },
      {
        "id": "2304.04321",
        "slug": "arnold-a-benchmark-for-language-grounded-task-learning-with-continuous-states-in-realistic-3d-scenes-arxiv-2304-04321v2-cs-ai-updated",
        "title": "ARNOLD: A Benchmark for Language-Grounded Task Learning With Continuous States in Realistic 3D Scenes.",
        "link": "http://arxiv.org/abs/2304.04321",
        "abstract": "Understanding the continuous states of objects is essential for task learning and planning in the real world. However, most existing task learning benchmarks assume discrete (e.g., binary) object goal states, which poses challenges for the learning of complex tasks and transferring learned policy from simulated environments to the real world. Furthermore, state discretization limits a robot's ability to follow human instructions based on the grounding of actions and states. To tackle these challenges, we present ARNOLD, a benchmark that evaluates language-grounded task learning with continuous states in realistic 3D scenes. ARNOLD is comprised of 8 language-conditioned tasks that involve understanding object states and learning policies for continuous goals. To promote language-instructed learning, we provide expert demonstrations with template-generated language descriptions. We assess task performance by utilizing the latest language-conditioned policy learning models. Our results indicate that current models for language-conditioned manipulations continue to experience significant challenges in novel goal-state generalizations, scene generalizations, and object generalizations. These findings highlight the need to develop new algorithms that address this gap and underscore the potential for further research in this area. Project website: https://arnold-benchmark.github.io.",
        "creator": "Ran Gong, Jiangyong Huang, Yizhou Zhao, Haoran Geng, Xiaofeng Gao, Qingyang Wu, Wensi Ai, Ziheng Zhou, Demetri Terzopoulos, Song-Chun Zhu, Baoxiong Jia, Siyuan Huang"
      },
      {
        "id": "2304.08495",
        "slug": "optimizing-group-utility-in-itinerary-planning-a-strategic-and-crowd-aware-approach-arxiv-2304-08495v4-cs-ai-updated",
        "title": "Optimizing Group Utility in Itinerary Planning: A Strategic and Crowd-Aware Approach.",
        "link": "http://arxiv.org/abs/2304.08495",
        "abstract": "Itinerary recommendation is a complex sequence prediction problem with numerous real-world applications. This task becomes even more challenging when considering the optimization of multiple user queuing times and crowd levels, as well as numerous involved parameters, such as attraction popularity, queuing time, walking time, and operating hours. Existing solutions typically focus on single-person perspectives and fail to address real-world issues resulting from natural crowd behavior, like the Selfish Routing problem. In this paper, we introduce the Strategic and Crowd-Aware Itinerary Recommendation (SCAIR) algorithm, which optimizes group utility in real-world settings. We model the route recommendation strategy as a Markov Decision Process and propose a State Encoding mechanism that enables real-time planning and allocation in linear time. We evaluate our algorithm against various competitive and realistic baselines using a theme park dataset, demonstrating that SCAIR outperforms these baselines in addressing the Selfish Routing problem across four theme parks.",
        "creator": "Junhua Liu, Kwan Hui Lim, Kristin L. Wood, Menglin Li"
      },
      {
        "id": "2304.10749",
        "slug": "multi-scale-evolutionary-neural-architecture-search-for-deep-spiking-neural-networks-arxiv-2304-10749v3-cs-ne-updated",
        "title": "Multi-scale Evolutionary Neural Architecture Search for Deep Spiking Neural Networks.",
        "link": "http://arxiv.org/abs/2304.10749",
        "abstract": "Spiking Neural Networks (SNNs) have received considerable attention not only for their superiority in energy efficiency with discrete signal processing but also for their natural suitability to integrate multi-scale biological plasticity. However, most SNNs directly adopt the structure of the well-established Deep Neural Networks (DNNs), and rarely automatically design Neural Architecture Search (NAS) for SNNs. The neural motifs topology, modular regional structure and global cross-brain region connection of the human brain are the product of natural evolution and can serve as a perfect reference for designing brain-inspired SNN architecture. In this paper, we propose a Multi-Scale Evolutionary Neural Architecture Search (MSE-NAS) for SNN, simultaneously considering micro-, meso- and macro-scale brain topologies as the evolutionary search space. MSE-NAS evolves individual neuron operation, self-organized integration of multiple circuit motifs, and global connectivity across motifs through a brain-inspired indirect evaluation function, Representational Dissimilarity Matrices (RDMs). This training-free fitness function could greatly reduce computational consumption and NAS's time, and its task-independent property enables the searched SNNs to exhibit excellent transferability on multiple datasets. Furthermore, MSE-NAS show robustness against the training method and noise. Extensive experiments demonstrate that the proposed algorithm achieves state-of-the-art (SOTA) performance with shorter simulation steps on static datasets (CIFAR10, CIFAR100) and neuromorphic datasets (CIFAR10-DVS and DVS128-Gesture). The thorough analysis also illustrates the significant performance improvement and consistent bio-interpretability deriving from the topological evolution at different scales and the RDMs fitness function.",
        "creator": "Wenxuan Pan, Feifei Zhao, Guobin Shen, Bing Han, Yi Zeng"
      },
      {
        "id": "2304.13000",
        "slug": "segment-anything-from-space-arxiv-2304-13000v3-cs-cv-updated",
        "title": "Segment anything, from space?.",
        "link": "http://arxiv.org/abs/2304.13000",
        "abstract": "Recently, the first foundation model developed specifically for image segmentation tasks was developed, termed the \"Segment Anything Model\" (SAM). SAM can segment objects in input imagery based on cheap input prompts, such as one (or more) points, a bounding box, or a mask. The authors examined the \\textit{zero-shot} image segmentation accuracy of SAM on a large number of vision benchmark tasks and found that SAM usually achieved recognition accuracy similar to, or sometimes exceeding, vision models that had been trained on the target tasks. The impressive generalization of SAM for segmentation has major implications for vision researchers working on natural imagery. In this work, we examine whether SAM's performance extends to overhead imagery problems and help guide the community's response to its development. We examine SAM's performance on a set of diverse and widely studied benchmark tasks. We find that SAM does often generalize well to overhead imagery, although it fails in some cases due to the unique characteristics of overhead imagery and its common target objects. We report on these unique systematic failure cases for remote sensing imagery that may comprise useful future research for the community.",
        "creator": "Simiao Ren, Francesco Luzi, Saad Lahrichi, Kaleb Kassaw, Leslie M. Collins, Kyle Bradbury, Jordan M. Malof"
      },
      {
        "id": "2304.14298",
        "slug": "instance-segmentation-in-the-dark-arxiv-2304-14298v2-cs-cv-updated",
        "title": "Instance Segmentation in the Dark.",
        "link": "http://arxiv.org/abs/2304.14298",
        "abstract": "Existing instance segmentation techniques are primarily tailored for high-visibility inputs, but their performance significantly deteriorates in extremely low-light environments. In this work, we take a deep look at instance segmentation in the dark and introduce several techniques that substantially boost the low-light inference accuracy. The proposed method is motivated by the observation that noise in low-light images introduces high-frequency disturbances to the feature maps of neural networks, thereby significantly degrading performance. To suppress this ``feature noise\", we propose a novel learning method that relies on an adaptive weighted downsampling layer, a smooth-oriented convolutional block, and disturbance suppression learning. These components effectively reduce feature noise during downsampling and convolution operations, enabling the model to learn disturbance-invariant features. Furthermore, we discover that high-bit-depth RAW images can better preserve richer scene information in low-light conditions compared to typical camera sRGB outputs, thus supporting the use of RAW-input algorithms. Our analysis indicates that high bit-depth can be critical for low-light instance segmentation. To mitigate the scarcity of annotated RAW datasets, we leverage a low-light RAW synthetic pipeline to generate realistic low-light data. In addition, to facilitate further research in this direction, we capture a real-world low-light instance segmentation dataset comprising over two thousand paired low/normal-light images with instance-level pixel-wise annotations. Remarkably, without any image preprocessing, we achieve satisfactory performance on instance segmentation in very low light (4~\\% AP higher than state-of-the-art competitors), meanwhile opening new opportunities for future research.",
        "creator": "Linwei Chen, Ying Fu, Kaixuan Wei, Dezhi Zheng, Felix Heide"
      },
      {
        "id": "2305.04940",
        "slug": "the-earlybird-catches-the-bug-on-exploiting-early-layers-of-encoder-models-for-more-efficient-code-classification-arxiv-2305-04940v2-cs-se-updated",
        "title": "The EarlyBIRD Catches the Bug: On Exploiting Early Layers of Encoder Models for More Efficient Code Classification.",
        "link": "http://arxiv.org/abs/2305.04940",
        "abstract": "The use of modern Natural Language Processing (NLP) techniques has shown to be beneficial for software engineering tasks, such as vulnerability detection and type inference. However, training deep NLP models requires significant computational resources. This paper explores techniques that aim at achieving the best usage of resources and available information in these models.  We propose a generic approach, EarlyBIRD, to build composite representations of code from the early layers of a pre-trained transformer model. We empirically investigate the viability of this approach on the CodeBERT model by comparing the performance of 12 strategies for creating composite representations with the standard practice of only using the last encoder layer.  Our evaluation on four datasets shows that several early layer combinations yield better performance on defect detection, and some combinations improve multi-class classification. More specifically, we obtain a +2 average improvement of detection accuracy on Devign with only 3 out of 12 layers of CodeBERT and a 3.3x speed-up of fine-tuning. These findings show that early layers can be used to obtain better results using the same resources, as well as to reduce resource usage during fine-tuning and inference.",
        "creator": "Anastasiia Grishina, Max Hort, Leon Moonen"
      },
      {
        "id": "2305.17256",
        "slug": "large-language-models-can-be-lazy-learners-analyze-shortcuts-in-in-context-learning-arxiv-2305-17256v2-cs-cl-updated",
        "title": "Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning.",
        "link": "http://arxiv.org/abs/2305.17256",
        "abstract": "Large language models (LLMs) have recently shown great potential for in-context learning, where LLMs learn a new task simply by conditioning on a few input-label pairs (prompts). Despite their potential, our understanding of the factors influencing end-task performance and the robustness of in-context learning remains limited. This paper aims to bridge this knowledge gap by investigating the reliance of LLMs on shortcuts or spurious correlations within prompts. Through comprehensive experiments on classification and extraction tasks, we reveal that LLMs are \"lazy learners\" that tend to exploit shortcuts in prompts for downstream tasks. Additionally, we uncover a surprising finding that larger models are more likely to utilize shortcuts in prompts during inference. Our findings provide a new perspective on evaluating robustness in in-context learning and pose new challenges for detecting and mitigating the use of shortcuts in prompts.",
        "creator": "Ruixiang Tang, Dehan Kong, Longtao Huang, Hui Xue"
      },
      {
        "id": "2305.18365",
        "slug": "what-can-large-language-models-do-in-chemistry-a-comprehensive-benchmark-on-eight-tasks-arxiv-2305-18365v2-cs-cl-updated",
        "title": "What can Large Language Models do in chemistry? A comprehensive benchmark on eight tasks.",
        "link": "http://arxiv.org/abs/2305.18365",
        "abstract": "Large Language Models (LLMs) with strong abilities in natural language processing tasks have emerged and have been applied in various kinds of areas such as science, finance and software engineering. However, the capability of LLMs to advance the field of chemistry remains unclear. In this paper, rather than pursuing state-of-the-art performance, we aim to evaluate capabilities of LLMs in a wide range of tasks across the chemistry domain. We identify three key chemistry-related capabilities including understanding, reasoning and explaining to explore in LLMs and establish a benchmark containing eight chemistry tasks. Our analysis draws on widely recognized datasets facilitating a broad exploration of the capacities of LLMs within the context of practical chemistry. Five LLMs (GPT-4, GPT-3.5, Davinci-003, Llama and Galactica) are evaluated for each chemistry task in zero-shot and few-shot in-context learning settings with carefully selected demonstration examples and specially crafted prompts. Our investigation found that GPT-4 outperformed other models and LLMs exhibit different competitive levels in eight chemistry tasks. In addition to the key findings from the comprehensive benchmark analysis, our work provides insights into the limitation of current LLMs and the impact of in-context learning settings on LLMs' performance across various chemistry tasks. The code and datasets used in this study are available at https://github.com/ChemFoundationModels/ChemLLMBench.",
        "creator": "Taicheng Guo, Kehan Guo, Bozhao Nan, Zhenwen Liang, Zhichun Guo, Nitesh V. Chawla, Olaf Wiest, Xiangliang Zhang"
      },
      {
        "id": "2306.01102",
        "slug": "llmatic-neural-architecture-search-via-large-language-models-and-quality-diversity-optimization-arxiv-2306-01102v3-cs-ne-updated",
        "title": "LLMatic: Neural Architecture Search via Large Language Models and Quality Diversity Optimization.",
        "link": "http://arxiv.org/abs/2306.01102",
        "abstract": "Large Language Models (LLMs) have emerged as powerful tools capable of accomplishing a broad spectrum of tasks. Their abilities span numerous areas, and one area where they have made a significant impact is in the domain of code generation. In this context, we view LLMs as mutation and crossover tools. Meanwhile, Quality-Diversity (QD) algorithms are known to discover diverse and robust solutions. By merging the code-generating abilities of LLMs with the diversity and robustness of QD solutions, we introduce LLMatic, a Neural Architecture Search (NAS) algorithm. While LLMs struggle to conduct NAS directly through prompts, LLMatic uses a procedural approach, leveraging QD for prompts and network architecture to create diverse and highly performant networks. We test LLMatic on the CIFAR-10 image classification benchmark, demonstrating that it can produce competitive networks with just $2,000$ searches, even without prior knowledge of the benchmark domain or exposure to any previous top-performing models for the benchmark.",
        "creator": "Muhammad U. Nasir, Sam Earle, Julian Togelius, Steven James, Christopher Cleghorn"
      },
      {
        "id": "2306.06871",
        "slug": "improving-offline-to-online-reinforcement-learning-with-q-ensembles-arxiv-2306-06871v2-cs-lg-updated",
        "title": "Improving Offline-to-Online Reinforcement Learning with Q-Ensembles.",
        "link": "http://arxiv.org/abs/2306.06871",
        "abstract": "Offline reinforcement learning (RL) is a learning paradigm where an agent learns from a fixed dataset of experience. However, learning solely from a static dataset can limit the performance due to the lack of exploration. To overcome it, offline-to-online RL combines offline pre-training with online fine-tuning, which enables the agent to further refine its policy by interacting with the environment in real-time. Despite its benefits, existing offline-to-online RL methods suffer from performance degradation and slow improvement during the online phase. To tackle these challenges, we propose a novel framework called Ensemble-based Offline-to-Online (E2O) RL. By increasing the number of Q-networks, we seamlessly bridge offline pre-training and online fine-tuning without degrading performance. Moreover, to expedite online performance enhancement, we appropriately loosen the pessimism of Q-value estimation and incorporate ensemble-based exploration mechanisms into our framework. Experimental results demonstrate that E2O can substantially improve the training stability, learning efficiency, and final performance of existing offline RL methods during online fine-tuning on a range of locomotion and navigation tasks, significantly outperforming existing offline-to-online RL methods.",
        "creator": "Kai Zhao, Yi Ma, Jianye Hao, Jinyi Liu, Yan Zheng, Zhaopeng Meng"
      },
      {
        "id": "2306.12001",
        "slug": "an-overview-of-catastrophic-ai-risks-arxiv-2306-12001v5-cs-cy-updated",
        "title": "An Overview of Catastrophic AI Risks.",
        "link": "http://arxiv.org/abs/2306.12001",
        "abstract": "Rapid advancements in artificial intelligence (AI) have sparked growing concerns among experts, policymakers, and world leaders regarding the potential for increasingly advanced AI systems to pose catastrophic risks. Although numerous risks have been detailed separately, there is a pressing need for a systematic discussion and illustration of the potential dangers to better inform efforts to mitigate them. This paper provides an overview of the main sources of catastrophic AI risks, which we organize into four categories: malicious use, in which individuals or groups intentionally use AIs to cause harm; AI race, in which competitive environments compel actors to deploy unsafe AIs or cede control to AIs; organizational risks, highlighting how human factors and complex systems can increase the chances of catastrophic accidents; and rogue AIs, describing the inherent difficulty in controlling agents far more intelligent than humans. For each category of risk, we describe specific hazards, present illustrative stories, envision ideal scenarios, and propose practical suggestions for mitigating these dangers. Our goal is to foster a comprehensive understanding of these risks and inspire collective and proactive efforts to ensure that AIs are developed and deployed in a safe manner. Ultimately, we hope this will allow us to realize the benefits of this powerful technology while minimizing the potential for catastrophic outcomes.",
        "creator": "Dan Hendrycks, Mantas Mazeika, Thomas Woodside"
      },
      {
        "id": "2306.14115",
        "slug": "towards-trustworthy-explanation-on-causal-rationalization-arxiv-2306-14115v2-cs-lg-updated",
        "title": "Towards Trustworthy Explanation: On Causal Rationalization.",
        "link": "http://arxiv.org/abs/2306.14115",
        "abstract": "With recent advances in natural language processing, rationalization becomes an essential self-explaining diagram to disentangle the black box by selecting a subset of input texts to account for the major variation in prediction. Yet, existing association-based approaches on rationalization cannot identify true rationales when two or more snippets are highly inter-correlated and thus provide a similar contribution to prediction accuracy, so-called spuriousness. To address this limitation, we novelly leverage two causal desiderata, non-spuriousness and efficiency, into rationalization from the causal inference perspective. We formally define a series of probabilities of causation based on a newly proposed structural causal model of rationalization, with its theoretical identification established as the main component of learning necessary and sufficient rationales. The superior performance of the proposed causal rationalization is demonstrated on real-world review and medical datasets with extensive experiments compared to state-of-the-art methods.",
        "creator": "Wenbo Zhang, Tong Wu, Yunlong Wang, Yong Cai, Hengrui Cai"
      },
      {
        "id": "2307.03941",
        "slug": "right-to-be-forgotten-in-the-era-of-large-language-models-implications-challenges-and-solutions-arxiv-2307-03941v2-cs-cy-updated",
        "title": "Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions.",
        "link": "http://arxiv.org/abs/2307.03941",
        "abstract": "The Right to be Forgotten (RTBF) was first established as the result of the ruling of Google Spain SL, Google Inc. v AEPD, Mario Costeja Gonz\\'alez, and was later included as the Right to Erasure under the General Data Protection Regulation (GDPR) of European Union to allow individuals the right to request personal data be deleted by organizations. Specifically for search engines, individuals can send requests to organizations to exclude their information from the query results. It was a significant emergent right as the result of the evolution of technology. With the recent development of Large Language Models (LLMs) and their use in chatbots, LLM-enabled software systems have become popular. But they are not excluded from the RTBF. Compared with the indexing approach used by search engines, LLMs store, and process information in a completely different way. This poses new challenges for compliance with the RTBF. In this paper, we explore these challenges and provide our insights on how to implement technical solutions for the RTBF, including the use of differential privacy, machine unlearning, model editing, and prompt engineering. With the rapid advancement of AI and the increasing need of regulating this powerful technology, learning from the case of RTBF can provide valuable lessons for technical practitioners, legal experts, organizations, and authorities.",
        "creator": "Dawen Zhang, Pamela Finckenberg-Broman, Thong Hoang, Shidong Pan, Zhenchang Xing, Mark Staples, Xiwei Xu"
      },
      {
        "id": "2307.07686",
        "slug": "creating-a-dataset-for-high-performance-computing-code-translation-using-llms-a-bridge-between-openmp-fortran-and-c-arxiv-2307-07686v3-cs-se-updated",
        "title": "Creating a Dataset for High-Performance Computing Code Translation using LLMs: A Bridge Between OpenMP Fortran and C++.",
        "link": "http://arxiv.org/abs/2307.07686",
        "abstract": "In this study, we present a novel dataset for training machine learning models translating between OpenMP Fortran and C++ code. To ensure reliability and applicability, the dataset is created from a range of representative open-source OpenMP benchmarks. It is also refined using a meticulous code similarity test. The effectiveness of our dataset is assessed using both quantitative (CodeBLEU) and qualitative (human evaluation) methods. We showcase how this dataset significantly elevates the translation competencies of large language models (LLMs). Specifically, models without prior coding knowledge experienced a boost of $\\mathbf{\\times~5.1}$ in their CodeBLEU scores, while models with some coding familiarity saw an impressive $\\mathbf{\\times~9.9}$-fold increase. The best fine-tuned model using our dataset outperforms GPT-4. It is also reaching human-level accuracy. This work underscores the immense potential of our dataset in propelling advancements in the domain of code translation for high-performance computing. The dataset is accessible at \\href{https://github.com/bin123apple/Fortran-CPP-HPC-code-translation-dataset}{OpenMP-Fortran-CPP-Translation}.",
        "creator": "Bin Lei, Caiwen Ding, Le Chen, Pei-Hung Lin, Chunhua Liao"
      },
      {
        "id": "2307.10404",
        "slug": "interpreting-and-correcting-medical-image-classification-with-pip-net-arxiv-2307-10404v2-cs-cv-updated",
        "title": "Interpreting and Correcting Medical Image Classification with PIP-Net.",
        "link": "http://arxiv.org/abs/2307.10404",
        "abstract": "Part-prototype models are explainable-by-design image classifiers, and a promising alternative to black box AI. This paper explores the applicability and potential of interpretable machine learning, in particular PIP-Net, for automated diagnosis support on real-world medical imaging data. PIP-Net learns human-understandable prototypical image parts and we evaluate its accuracy and interpretability for fracture detection and skin cancer diagnosis. We find that PIP-Net's decision making process is in line with medical classification standards, while only provided with image-level class labels. Because of PIP-Net's unsupervised pretraining of prototypes, data quality problems such as undesired text in an X-ray or labelling errors can be easily identified. Additionally, we are the first to show that humans can manually correct the reasoning of PIP-Net by directly disabling undesired prototypes. We conclude that part-prototype models are promising for medical applications due to their interpretability and potential for advanced model debugging.",
        "creator": "Meike Nauta, Johannes H. Hegeman, Jeroen Geerdink, J&#xf6;rg Schl&#xf6;tterer, Maurice van Keulen, Christin Seifert"
      },
      {
        "id": "2307.11788",
        "slug": "applying-qnlp-to-sentiment-analysis-in-finance-arxiv-2307-11788v3-cs-cl-updated",
        "title": "Applying QNLP to sentiment analysis in finance.",
        "link": "http://arxiv.org/abs/2307.11788",
        "abstract": "As an application domain where the slightest qualitative improvements can yield immense value, finance is a promising candidate for early quantum advantage. Focusing on the rapidly advancing field of Quantum Natural Language Processing (QNLP), we explore the practical applicability of the two central approaches DisCoCat and Quantum-Enhanced Long Short-Term Memory (QLSTM) to the problem of sentiment analysis in finance. Utilizing a novel ChatGPT-based data generation approach, we conduct a case study with more than 1000 realistic sentences and find that QLSTMs can be trained substantially faster than DisCoCat while also achieving close to classical results for their available software implementations.",
        "creator": "Jonas Stein, Ivo Christ, Nicolas Kraus, Maximilian Balthasar Mansky, Robert M&#xfc;ller, Claudia Linnhoff-Popien"
      },
      {
        "id": "2307.15217",
        "slug": "open-problems-and-fundamental-limitations-of-reinforcement-learning-from-human-feedback-arxiv-2307-15217v2-cs-ai-updated",
        "title": "Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback.",
        "link": "http://arxiv.org/abs/2307.15217",
        "abstract": "Reinforcement learning from human feedback (RLHF) is a technique for training AI systems to align with human goals. RLHF has emerged as the central method used to finetune state-of-the-art large language models (LLMs). Despite this popularity, there has been relatively little public work systematizing its flaws. In this paper, we (1) survey open problems and fundamental limitations of RLHF and related methods; (2) overview techniques to understand, improve, and complement RLHF in practice; and (3) propose auditing and disclosure standards to improve societal oversight of RLHF systems. Our work emphasizes the limitations of RLHF and highlights the importance of a multi-faceted approach to the development of safer AI systems.",
        "creator": "Stephen Casper, Xander Davies, Claudia Shi, Thomas Krendl Gilbert, J&#xe9;r&#xe9;my Scheurer, Javier Rando, Rachel Freedman, Tomasz Korbak, David Lindner, Pedro Freire, Tony Wang, Samuel Marks, Charbel-Rapha&#xeb;l Segerie, Micah Carroll, Andi Peng, Phillip Christoffersen, Mehul Damani, Stewart Slocum, Usman Anwar, Anand Siththaranjan, Max Nadeau, Eric J. Michaud, Jacob Pfau, Dmitrii Krasheninnikov, Xin Chen, Lauro Langosco, Peter Hase, Erdem B&#x131;y&#x131;k, Anca Dragan, David Krueger, Dorsa Sadigh, Dylan Hadfield-Menell"
      },
      {
        "id": "2307.15453",
        "slug": "from-probabilistic-programming-to-complexity-based-programming-arxiv-2307-15453v2-cs-ai-updated",
        "title": "From Probabilistic Programming to Complexity-based Programming.",
        "link": "http://arxiv.org/abs/2307.15453",
        "abstract": "The paper presents the main characteristics and a preliminary implementation of a novel computational framework named CompLog. Inspired by probabilistic programming systems like ProbLog, CompLog builds upon the inferential mechanisms proposed by Simplicity Theory, relying on the computation of two Kolmogorov complexities (here implemented as min-path searches via ASP programs) rather than probabilistic inference. The proposed system enables users to compute ex-post and ex-ante measures of unexpectedness of a certain situation, mapping respectively to posterior and prior subjective probabilities. The computation is based on the specification of world and mental models by means of causal and descriptive relations between predicates weighted by complexity. The paper illustrates a few examples of application: generating relevant descriptions, and providing alternative approaches to disjunction and to negation.",
        "creator": "Giovanni Sileno, Jean-Louis Dessalles"
      },
      {
        "id": "2307.15898",
        "slug": "unibrivl-robust-universal-representation-and-generation-of-audio-driven-diffusion-models-arxiv-2307-15898v2-cs-sd-updated",
        "title": "UniBriVL: Robust Universal Representation and Generation of Audio Driven Diffusion Models.",
        "link": "http://arxiv.org/abs/2307.15898",
        "abstract": "Multimodal large models have been recognized for their advantages in various performance and downstream tasks. The development of these models is crucial towards achieving general artificial intelligence in the future. In this paper, we propose a novel universal language representation learning method called UniBriVL, which is based on Bridging-Vision-and-Language (BriVL). Universal BriVL embeds audio, image, and text into a shared space, enabling the realization of various multimodal applications. Our approach addresses major challenges in robust language (both text and audio) representation learning and effectively captures the correlation between audio and image. Additionally, we demonstrate the qualitative evaluation of the generated images from UniBriVL, which serves to highlight the potential of our approach in creating images from audio. Overall, our experimental results demonstrate the efficacy of UniBriVL in downstream tasks and its ability to choose appropriate images from audio. The proposed approach has the potential for various applications such as speech recognition, music signal processing, and captioning systems.",
        "creator": "Sen Fang, Bowen Gao, Yangjian Wu, Teik Toe Teoh"
      },
      {
        "id": "2307.16517",
        "slug": "select2col-leveraging-spatial-temporal-importance-of-semantic-information-for-efficient-collaborative-perception-arxiv-2307-16517v2-cs-cv-updated",
        "title": "Select2Col: Leveraging Spatial-Temporal Importance of Semantic Information for Efficient Collaborative Perception.",
        "link": "http://arxiv.org/abs/2307.16517",
        "abstract": "Collaboration by leveraging the shared semantic information plays a crucial role in overcoming the perception capability limitations of isolated agents. However, existing collaborative perception methods tend to focus solely on the spatial features of semantic information, while neglecting the importance of the temporal dimension. Consequently, the potential benefits of collaboration remain underutilized. In this article, we propose Select2Col, a novel collaborative perception framework that takes into account the {s}patial-t{e}mpora{l} importanc{e} of semanti{c} informa{t}ion. Within the Select2Col, we develop a collaborator selection method that utilizes a lightweight graph neural network (GNN) to estimate the importance of semantic information (IoSI) in enhancing perception performance, thereby identifying contributive collaborators while excluding those that bring negative impact. Moreover, we present a semantic information fusion algorithm called HPHA (historical prior hybrid attention), which integrates multi-scale attention and short-term attention modules to capture the IoSI in feature representation from the spatial and temporal dimensions respectively, and assigns IoSI-consistent weights for efficient fusion of information from selected collaborators. Extensive experiments on two open datasets demonstrate that our proposed Select2Col significantly improves the perception performance compared to state-of-the-art approaches. The code associated with this research is publicly available at https://github.com/huangqzj/Select2Col/.",
        "creator": "Yuntao Liu, Qian Huang, Rongpeng Li, Xianfu Chen, Zhifeng Zhao, Shuyuan Zhao, Yongdong Zhu, Honggang Zhang"
      },
      {
        "id": "2308.03929",
        "slug": "challenging-the-machinery-of-generative-ai-with-fact-checking-ontology-driven-biological-graphs-for-verifying-human-disease-gene-links-arxiv-2308-03929v2-cs-ai-updated",
        "title": "Challenging the Machinery of Generative AI with Fact-Checking: Ontology-Driven Biological Graphs for Verifying Human Disease-Gene Links.",
        "link": "http://arxiv.org/abs/2308.03929",
        "abstract": "Methods: we adopted a biological networks approach that enables the systematic interrogation of ChatGPT's linked entities. In particular, we designed an ontology-driven fact-checking algorithm that compares biological graphs constructed from approximately 200,000 PubMed abstracts with counterparts constructed from a dataset generated using the ChatGPT-3.5 Turbo model. The nodes refer to biological entities (genes and diseases) that occur in the text. The edges represent the co-occurrence relationships of two entities mentioned in the same document, weighted by the proximity distance between these two entities. This research assumes a ``closed-world assumption'', meaning that fact-checking is performed only using the literature dataset as our ground truth. Results: in ten samples of 250 randomly selected records from the ChatGPT dataset of 1000 ``simulated'' articles , the fact-checking link accuracy ranged from 70% to 86%, while the remainder of the links remained unverified. Given the closed world assumption, the fact-checking precision is significant. When measuring and comparing the proximity distances of the edges of literature graphs against ChatGPT graphs we found that the ChatGPT distances were significantly shorter (ranging from 90 to 153) character distance. In contrast, the proximity distance of biological entities identified in the literature ranged from 236 to 765 character distance. This pattern held true for all the relationships among biological entities in the ten samples. Conclusion: this study demonstrated a reasonably high percentage accuracy of aggregate fact-checking of disease-gene relationships found in ChatGPT-generated texts. The strikingly consistent pattern of short proximity distances across all samples offers an illuminating feedback to the biological knowledge we possess in the literature today.",
        "creator": "Ahmed Abdeen Hamed, Byung Suk Lee, Alessandro Crimi, Magdalena M. Misiak"
      },
      {
        "id": "2308.05734",
        "slug": "audioldm-2-learning-holistic-audio-generation-with-self-supervised-pretraining-arxiv-2308-05734v2-cs-sd-updated",
        "title": "AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining.",
        "link": "http://arxiv.org/abs/2308.05734",
        "abstract": "Although audio generation shares commonalities across different types of audio, such as speech, music, and sound effects, designing models for each type requires careful consideration of specific objectives and biases that can significantly differ from those of other types. To bring us closer to a unified perspective of audio generation, this paper proposes a framework that utilizes the same learning method for speech, music, and sound effect generation. Our framework introduces a general representation of audio, called \"language of audio\" (LOA). Any audio can be translated into LOA based on AudioMAE, a self-supervised pre-trained representation learning model. In the generation process, we translate any modalities into LOA by using a GPT-2 model, and we perform self-supervised audio generation learning with a latent diffusion model conditioned on LOA. The proposed framework naturally brings advantages such as in-context learning abilities and reusable self-supervised pretrained AudioMAE and latent diffusion models. Experiments on the major benchmarks of text-to-audio, text-to-music, and text-to-speech demonstrate state-of-the-art or competitive performance against previous approaches. Our code, pretrained model, and demo are available at https://audioldm.github.io/audioldm2.",
        "creator": "Haohe Liu, Qiao Tian, Yi Yuan, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Yuping Wang, Wenwu Wang, Yuxuan Wang, Mark D. Plumbley"
      },
      {
        "id": "2308.07327",
        "slug": "pokerkit-a-comprehensive-python-library-for-fine-grained-multi-variant-poker-game-simulations-arxiv-2308-07327v2-cs-ai-updated",
        "title": "PokerKit: A Comprehensive Python Library for Fine-Grained Multi-Variant Poker Game Simulations.",
        "link": "http://arxiv.org/abs/2308.07327",
        "abstract": "PokerKit is an open-source Python library designed to overcome the restrictions of existing poker game simulation and hand evaluation tools, which typically support only a handful of poker variants and lack flexibility in game state control. In contrast, PokerKit significantly expands this scope by supporting an extensive array of poker variants and it provides a flexible architecture for users to define their custom games. This paper details the design and implementation of PokerKit, including its intuitive programmatic API, multi-variant game support, and a unified hand evaluation suite across different hand types. The flexibility of PokerKit allows for applications in diverse areas, such as poker AI development, tool creation, and online poker casino implementation. PokerKit's reliability has been established through static type checking, extensive doctests, and unit tests, achieving 99% code coverage. The introduction of PokerKit represents a significant contribution to the field of computer poker, fostering future research and advanced AI development for a wide variety of poker games. The source code is available at https://github.com/uoftcprg/pokerkit",
        "creator": "Juho Kim"
      },
      {
        "id": "2308.11224",
        "slug": "evaluating-large-language-models-on-graphs-performance-insights-and-comparative-analysis-arxiv-2308-11224v2-cs-ai-updated",
        "title": "Evaluating Large Language Models on Graphs: Performance Insights and Comparative Analysis.",
        "link": "http://arxiv.org/abs/2308.11224",
        "abstract": "Large Language Models (LLMs) have garnered considerable interest within both academic and industrial. Yet, the application of LLMs to graph data remains under-explored. In this study, we evaluate the capabilities of four LLMs in addressing several analytical problems with graph data. We employ four distinct evaluation metrics: Comprehension, Correctness, Fidelity, and Rectification. Our results show that: 1) LLMs effectively comprehend graph data in natural language and reason with graph topology. 2) GPT models can generate logical and coherent results, outperforming alternatives in correctness. 3) All examined LLMs face challenges in structural reasoning, with techniques like zero-shot chain-of-thought and few-shot prompting showing diminished efficacy. 4) GPT models often produce erroneous answers in multi-answer tasks, raising concerns in fidelity. 5) GPT models exhibit elevated confidence in their outputs, potentially hindering their rectification capacities. Notably, GPT-4 has demonstrated the capacity to rectify responses from GPT-3.5-turbo and its own previous iterations. The code is available at: https://github.com/Ayame1006/LLMtoGraph.",
        "creator": "Chang Liu, Bo Wu"
      },
      {
        "id": "2308.11241",
        "slug": "an-effective-transformer-based-contextual-model-and-temporal-gate-pooling-for-speaker-identification-arxiv-2308-11241v2-cs-sd-updated",
        "title": "An Effective Transformer-based Contextual Model and Temporal Gate Pooling for Speaker Identification.",
        "link": "http://arxiv.org/abs/2308.11241",
        "abstract": "Wav2vec2 has achieved success in applying Transformer architecture and self-supervised learning to speech recognition. Recently, these have come to be used not only for speech recognition but also for the entire speech processing. This paper introduces an effective end-to-end speaker identification model applied Transformer-based contextual model. We explored the relationship between the hyper-parameters and the performance in order to discern the structure of an effective model. Furthermore, we propose a pooling method, Temporal Gate Pooling, with powerful learning ability for speaker identification. We applied Conformer as encoder and BEST-RQ for pre-training and conducted an evaluation utilizing the speaker identification of VoxCeleb1. The proposed method has achieved an accuracy of 87.1% with 28.5M parameters, demonstrating comparable precision to wav2vec2 with 317.7M parameters. Code is available at https://github.com/HarunoriKawano/speaker-identification-with-tgp.",
        "creator": "Harunori Kawano, Sota Shimizu"
      },
      {
        "id": "2308.11974",
        "slug": "blending-nerf-text-driven-localized-editing-in-neural-radiance-fields-arxiv-2308-11974v2-cs-cv-updated",
        "title": "Blending-NeRF: Text-Driven Localized Editing in Neural Radiance Fields.",
        "link": "http://arxiv.org/abs/2308.11974",
        "abstract": "Text-driven localized editing of 3D objects is particularly difficult as locally mixing the original 3D object with the intended new object and style effects without distorting the object's form is not a straightforward process. To address this issue, we propose a novel NeRF-based model, Blending-NeRF, which consists of two NeRF networks: pretrained NeRF and editable NeRF. Additionally, we introduce new blending operations that allow Blending-NeRF to properly edit target regions which are localized by text. By using a pretrained vision-language aligned model, CLIP, we guide Blending-NeRF to add new objects with varying colors and densities, modify textures, and remove parts of the original object. Our extensive experiments demonstrate that Blending-NeRF produces naturally and locally edited 3D objects from various text prompts. Our project page is available at https://seokhunchoi.github.io/Blending-NeRF/",
        "creator": "Hyeonseop Song, Seokhun Choi, Hoseok Do, Chul Lee, Taehyeong Kim"
      },
      {
        "id": "2308.12714",
        "slug": "vigc-visual-instruction-generation-and-correction-arxiv-2308-12714v2-cs-cv-updated",
        "title": "VIGC: Visual Instruction Generation and Correction.",
        "link": "http://arxiv.org/abs/2308.12714",
        "abstract": "The integration of visual encoders and large language models (LLMs) has driven recent progress in multimodal large language models (MLLMs). However, the scarcity of high-quality instruction-tuning data for vision-language tasks remains a challenge. The current leading paradigm, such as LLaVA, relies on language-only GPT-4 to generate data, which requires pre-annotated image captions and detection bounding boxes, suffering from understanding image details. A practical solution to this problem would be to utilize the available multimodal large language models (MLLMs) to generate instruction data for vision-language tasks. However, it's worth noting that the currently accessible MLLMs are not as powerful as their LLM counterparts, as they tend to produce inadequate responses and generate false information. As a solution for addressing the current issue, this paper proposes the Visual Instruction Generation and Correction (VIGC) framework that enables multimodal large language models to generate instruction-tuning data and progressively enhance its quality on-the-fly. Specifically, Visual Instruction Generation (VIG) guides the vision-language model to generate diverse instruction-tuning data. To ensure generation quality, Visual Instruction Correction (VIC) adopts an iterative update mechanism to correct any inaccuracies in data produced by VIG, effectively reducing the risk of hallucination. Leveraging the diverse, high-quality data generated by VIGC, we finetune mainstream models and validate data quality based on various evaluations. Experimental results demonstrate that VIGC not only compensates for the shortcomings of language-only data generation methods, but also effectively enhances the benchmark performance. The models, datasets, and code are available at https://opendatalab.github.io/VIGC.",
        "creator": "Bin Wang, Fan Wu, Xiao Han, Jiahui Peng, Huaping Zhong, Pan Zhang, Xiaoyi Dong, Weijia Li, Wei Li, Jiaqi Wang, Conghui He"
      },
      {
        "id": "2308.13032",
        "slug": "financial-news-analytics-using-fine-tuned-llama-2-gpt-model-arxiv-2308-13032v2-cs-cl-updated",
        "title": "Financial News Analytics Using Fine-Tuned Llama 2 GPT Model.",
        "link": "http://arxiv.org/abs/2308.13032",
        "abstract": "The paper considers the possibility to fine-tune Llama 2 GPT large language model (LLM) for the multitask analysis of financial news. For fine-tuning, the PEFT/LoRA based approach was used. In the study, the model was fine-tuned for the following tasks: analysing a text from financial market perspectives, highlighting main points of a text, summarizing a text and extracting named entities with appropriate sentiments. The obtained results show that the fine-tuned Llama 2 model can perform a multitask financial news analysis with a specified structure of response, part of response can be a structured text and another part of data can have JSON format for further processing. Extracted sentiments for named entities can be considered as predictive features in supervised machine learning models with quantitative target variables.",
        "creator": "Bohdan M. Pavlyshenko"
      },
      {
        "id": "2308.13566",
        "slug": "mllm-dataengine-an-iterative-refinement-approach-for-mllm-arxiv-2308-13566v2-cs-lg-updated",
        "title": "MLLM-DataEngine: An Iterative Refinement Approach for MLLM.",
        "link": "http://arxiv.org/abs/2308.13566",
        "abstract": "Despite the great advance of Multimodal Large Language Models (MLLMs) in both instruction dataset building and benchmarking, the independence of training and evaluation makes current MLLMs hard to further improve their capability under the guidance of evaluation results with a relatively low human cost. In this paper, we propose MLLM-DataEngine, a novel closed-loop system that bridges data generation, model training, and evaluation. Within each loop iteration, the MLLM-DataEngine first analyze the weakness of the model based on the evaluation results, then generate a proper incremental dataset for the next training iteration and enhance the model capability iteratively. Compared with previous data collection methods which are separate from the benchmarking, the data generated by MLLM-DataEngine shows better targeting, quality, and correctness. For targeting, we propose an Adaptive Bad-case Sampling module, which adjusts the ratio of different types of data within each incremental dataset based on the benchmarking results. For quality, we resort to GPT-4 to generate high-quality data with each given data type. For correctness, prompt design is critical for the data generation results. Rather than previous hand-crafted prompt, we propose an Interactive Prompt Optimization strategy, which optimizes the prompt with the multi-round interaction between human and GPT, and improve the correctness of generated data greatly. Through extensive experiments, we find our MLLM-DataEngine could boost the MLLM capability in a targeted and automatic manner, with only a few human participation. We hope it could be a general solution for the following MLLMs building. The MLLM-DataEngine has been open-sourced and is now available at https://github.com/opendatalab/MLLM-DataEngine.",
        "creator": "Zhiyuan Zhao, Linke Ouyang, Bin Wang, Siyuan Huang, Pan Zhang, Xiaoyi Dong, Jiaqi Wang, Conghui He"
      },
      {
        "id": "2308.13570",
        "slug": "stochastic-configuration-machines-for-industrial-artificial-intelligence-arxiv-2308-13570v5-cs-lg-updated",
        "title": "Stochastic Configuration Machines for Industrial Artificial Intelligence.",
        "link": "http://arxiv.org/abs/2308.13570",
        "abstract": "Real-time predictive modelling with desired accuracy is highly expected in industrial artificial intelligence (IAI), where neural networks play a key role. Neural networks in IAI require powerful, high-performance computing devices to operate a large number of floating point data. Based on stochastic configuration networks (SCNs), this paper proposes a new randomized learner model, termed stochastic configuration machines (SCMs), to stress effective modelling and data size saving that are useful and valuable for industrial applications. Compared to SCNs and random vector functional-link (RVFL) nets with binarized implementation, the model storage of SCMs can be significantly compressed while retaining favourable prediction performance. Besides the architecture of the SCM learner model and its learning algorithm, as an important part of this contribution, we also provide a theoretical basis on the learning capacity of SCMs by analysing the model's complexity. Experimental studies are carried out over some benchmark datasets and three industrial applications. The results demonstrate that SCM has great potential for dealing with industrial data analytics.",
        "creator": "Dianhui Wang, Matthew J. Felicetti"
      },
      {
        "id": "2308.13916",
        "slug": "exploring-large-language-models-for-knowledge-graph-completion-arxiv-2308-13916v3-cs-cl-updated",
        "title": "Exploring Large Language Models for Knowledge Graph Completion.",
        "link": "http://arxiv.org/abs/2308.13916",
        "abstract": "Knowledge graphs play a vital role in numerous artificial intelligence tasks, yet they frequently face the issue of incompleteness. In this study, we explore utilizing Large Language Models (LLM) for knowledge graph completion. We consider triples in knowledge graphs as text sequences and introduce an innovative framework called Knowledge Graph LLM (KG-LLM) to model these triples. Our technique employs entity and relation descriptions of a triple as prompts and utilizes the response for predictions. Experiments on various benchmark knowledge graphs demonstrate that our method attains state-of-the-art performance in tasks such as triple classification and relation prediction. We also find that fine-tuning relatively smaller models (e.g., LLaMA-7B, ChatGLM-6B) outperforms recent ChatGPT and GPT-4.",
        "creator": "Liang Yao, Jiazhen Peng, Chengsheng Mao, Yuan Luo"
      },
      {
        "id": "2308.14448",
        "slug": "expclip-bridging-text-and-facial-expressions-via-semantic-alignment-arxiv-2308-14448v2-cs-cv-updated",
        "title": "ExpCLIP: Bridging Text and Facial Expressions via Semantic Alignment.",
        "link": "http://arxiv.org/abs/2308.14448",
        "abstract": "The objective of stylized speech-driven facial animation is to create animations that encapsulate specific emotional expressions. Existing methods often depend on pre-established emotional labels or facial expression templates, which may limit the necessary flexibility for accurately conveying user intent. In this research, we introduce a technique that enables the control of arbitrary styles by leveraging natural language as emotion prompts. This technique presents benefits in terms of both flexibility and user-friendliness. To realize this objective, we initially construct a Text-Expression Alignment Dataset (TEAD), wherein each facial expression is paired with several prompt-like descriptions.We propose an innovative automatic annotation method, supported by Large Language Models (LLMs), to expedite the dataset construction, thereby eliminating the substantial expense of manual annotation. Following this, we utilize TEAD to train a CLIP-based model, termed ExpCLIP, which encodes text and facial expressions into semantically aligned style embeddings. The embeddings are subsequently integrated into the facial animation generator to yield expressive and controllable facial animations. Given the limited diversity of facial emotions in existing speech-driven facial animation training data, we further introduce an effective Expression Prompt Augmentation (EPA) mechanism to enable the animation generator to support unprecedented richness in style control. Comprehensive experiments illustrate that our method accomplishes expressive facial animation generation and offers enhanced flexibility in effectively conveying the desired style.",
        "creator": "Yicheng Zhong, Huawei Wei, Peiji Yang, Zhisheng Wang"
      },
      {
        "id": "2308.15272",
        "slug": "empowering-llm-to-use-smartphone-for-intelligent-task-automation-arxiv-2308-15272v3-cs-ai-updated",
        "title": "Empowering LLM to use Smartphone for Intelligent Task Automation.",
        "link": "http://arxiv.org/abs/2308.15272",
        "abstract": "Mobile task automation is an attractive technique that aims to enable voice-based hands-free user interaction with smartphones. However, existing approaches suffer from poor scalability due to the limited language understanding ability and the non-trivial manual efforts required from developers or end-users. The recent advance of large language models (LLMs) in language understanding and reasoning inspires us to rethink the problem from a model-centric perspective, where task preparation, comprehension, and execution are handled by a unified language model. In this work, we introduce AutoDroid, a mobile task automation system that can handle arbitrary tasks on any Android application without manual efforts. The key insight is to combine the commonsense knowledge of LLMs and domain-specific knowledge of apps through automated dynamic analysis. The main components include a functionality-aware UI representation method that bridges the UI with the LLM, exploration-based memory injection techniques that augment the app-specific domain knowledge of LLM, and a multi-granularity query optimization module that reduces the cost of model inference. We integrate AutoDroid with off-the-shelf LLMs including online GPT-4/GPT-3.5 and on-device Vicuna, and evaluate its performance on a new benchmark for memory-augmented Android task automation with 158 common tasks. The results demonstrated that AutoDroid is able to precisely generate actions with an accuracy of 90.9%, and complete tasks with a success rate of 71.3%, outperforming the GPT-4-powered baselines by 36.4% and 39.7%. The demo, benchmark suites, and source code of AutoDroid will be released at url{https://autodroid-sys.github.io/}.",
        "creator": "Hao Wen, Yuanchun Li, Guohong Liu, Shanhui Zhao, Tao Yu, Toby Jia-Jun Li, Shiqi Jiang, Yunhao Liu, Yaqin Zhang, Yunxin Liu"
      },
      {
        "id": "2308.15514",
        "slug": "international-governance-of-civilian-ai-a-jurisdictional-certification-approach-arxiv-2308-15514v2-cs-ai-updated",
        "title": "International Governance of Civilian AI: A Jurisdictional Certification Approach.",
        "link": "http://arxiv.org/abs/2308.15514",
        "abstract": "This report describes trade-offs in the design of international governance arrangements for civilian artificial intelligence (AI) and presents one approach in detail. This approach represents the extension of a standards, licensing, and liability regime to the global level. We propose that states establish an International AI Organization (IAIO) to certify state jurisdictions (not firms or AI projects) for compliance with international oversight standards. States can give force to these international standards by adopting regulations prohibiting the import of goods whose supply chains embody AI from non-IAIO-certified jurisdictions. This borrows attributes from models of existing international organizations, such as the International Civilian Aviation Organization (ICAO), the International Maritime Organization (IMO), and the Financial Action Task Force (FATF). States can also adopt multilateral controls on the export of AI product inputs, such as specialized hardware, to non-certified jurisdictions. Indeed, both the import and export standards could be required for certification. As international actors reach consensus on risks of and minimum standards for advanced AI, a jurisdictional certification regime could mitigate a broad range of potential harms, including threats to public safety.",
        "creator": "Robert Trager, Ben Harack, Anka Reuel, Allison Carnegie, Lennart Heim, Lewis Ho, Sarah Kreps, Ranjit Lall, Owen Larter, Se&#xe1;n &#xd3; h&#xc9;igeartaigh, Simon Staffell, Jos&#xe9; Jaime Villalobos"
      },
      {
        "id": "2308.16775",
        "slug": "efficacy-of-neural-prediction-based-zero-shot-nas-arxiv-2308-16775v2-cs-lg-updated",
        "title": "Efficacy of Neural Prediction-Based Zero-Shot NAS.",
        "link": "http://arxiv.org/abs/2308.16775",
        "abstract": "In prediction-based Neural Architecture Search (NAS), performance indicators derived from graph convolutional networks have shown significant success. These indicators, achieved by representing feed-forward structures as component graphs through one-hot encoding, face a limitation: their inability to evaluate architecture performance across varying search spaces. In contrast, handcrafted performance indicators (zero-shot NAS), which use the same architecture with random initialization, can generalize across multiple search spaces. Addressing this limitation, we propose a novel approach for zero-shot NAS using deep learning. Our method employs Fourier sum of sines encoding for convolutional kernels, enabling the construction of a computational feed-forward graph with a structure similar to the architecture under evaluation. These encodings are learnable and offer a comprehensive view of the architecture's topological information. An accompanying multi-layer perceptron (MLP) then ranks these architectures based on their encodings. Experimental results show that our approach surpasses previous methods using graph convolutional networks in terms of correlation on the NAS-Bench-201 dataset and exhibits a higher convergence rate. Moreover, our extracted feature representation trained on each NAS-Benchmark is transferable to other NAS-Benchmarks, showing promising generalizability across multiple search spaces. The code is available at: https://github.com/minh1409/DFT-NPZS-NAS",
        "creator": "Minh Le, Nhan Nguyen, Ngoc Hoang Luong"
      },
      {
        "id": "2309.00417",
        "slug": "area-norm-cobra-on-conditional-survival-prediction-arxiv-2309-00417v2-cs-lg-updated",
        "title": "Area-norm COBRA on Conditional Survival Prediction.",
        "link": "http://arxiv.org/abs/2309.00417",
        "abstract": "The paper explores a different variation of combined regression strategy to calculate the conditional survival function. We use regression based weak learners to create the proposed ensemble technique. The proposed combined regression strategy uses proximity measure as area between two survival curves. The proposed model shows a construction which ensures that it performs better than the Random Survival Forest. The paper discusses a novel technique to select the most important variable in the combined regression setup. We perform a simulation study to show that our proposition for finding relevance of the variables works quite well. We also use three real-life datasets to illustrate the model.",
        "creator": "Rahul Goswami, Arabin Kr. Dey"
      },
      {
        "id": "2309.01592",
        "slug": "les-houches-lectures-on-deep-learning-at-large-infinite-width-arxiv-2309-01592v2-stat-ml-updated",
        "title": "Les Houches Lectures on Deep Learning at Large & Infinite Width.",
        "link": "http://arxiv.org/abs/2309.01592",
        "abstract": "These lectures, presented at the 2022 Les Houches Summer School on Statistical Physics and Machine Learning, focus on the infinite-width limit and large-width regime of deep neural networks. Topics covered include various statistical and dynamical properties of these networks. In particular, the lecturers discuss properties of random deep neural networks; connections between trained deep neural networks, linear models, kernels, and Gaussian processes that arise in the infinite-width limit; and perturbative and non-perturbative treatments of large but finite-width networks, at initialization and after training.",
        "creator": "Yasaman Bahri, Boris Hanin, Antonin Brossollet, Vittorio Erba, Christian Keup, Rosalba Pacelli, James B. Simon"
      },
      {
        "id": "2309.01717",
        "slug": "interdisciplinary-fairness-in-imbalanced-research-proposal-topic-inference-a-hierarchical-transformer-based-method-with-selective-interpolation-arxiv-2309-01717v2-cs-cl-updated",
        "title": "Interdisciplinary Fairness in Imbalanced Research Proposal Topic Inference: A Hierarchical Transformer-based Method with Selective Interpolation.",
        "link": "http://arxiv.org/abs/2309.01717",
        "abstract": "The objective of topic inference in research proposals aims to obtain the most suitable disciplinary division from the discipline system defined by a funding agency. The agency will subsequently find appropriate peer review experts from their database based on this division. Automated topic inference can reduce human errors caused by manual topic filling, bridge the knowledge gap between funding agencies and project applicants, and improve system efficiency. Existing methods focus on modeling this as a hierarchical multi-label classification problem, using generative models to iteratively infer the most appropriate topic information. However, these methods overlook the gap in scale between interdisciplinary research proposals and non-interdisciplinary ones, leading to an unjust phenomenon where the automated inference system categorizes interdisciplinary proposals as non-interdisciplinary, causing unfairness during the expert assignment. How can we address this data imbalance issue under a complex discipline system and hence resolve this unfairness? In this paper, we implement a topic label inference system based on a Transformer encoder-decoder architecture. Furthermore, we utilize interpolation techniques to create a series of pseudo-interdisciplinary proposals from non-interdisciplinary ones during training based on non-parametric indicators such as cross-topic probabilities and topic occurrence probabilities. This approach aims to reduce the bias of the system during model training. Finally, we conduct extensive experiments on a real-world dataset to verify the effectiveness of the proposed method. The experimental results demonstrate that our training strategy can significantly mitigate the unfairness generated in the topic inference task.",
        "creator": "Meng Xiao, Min Wu, Ziyue Qiao, Yanjie Fu, Zhiyuan Ning, Yi Du, Yuanchun Zhou"
      },
      {
        "id": "2309.01838",
        "slug": "efficient-defense-against-model-stealing-attacks-on-convolutional-neural-networks-arxiv-2309-01838v2-cs-lg-updated",
        "title": "Efficient Defense Against Model Stealing Attacks on Convolutional Neural Networks.",
        "link": "http://arxiv.org/abs/2309.01838",
        "abstract": "Model stealing attacks have become a serious concern for deep learning models, where an attacker can steal a trained model by querying its black-box API. This can lead to intellectual property theft and other security and privacy risks. The current state-of-the-art defenses against model stealing attacks suggest adding perturbations to the prediction probabilities. However, they suffer from heavy computations and make impracticable assumptions about the adversary. They often require the training of auxiliary models. This can be time-consuming and resource-intensive which hinders the deployment of these defenses in real-world applications. In this paper, we propose a simple yet effective and efficient defense alternative. We introduce a heuristic approach to perturb the output probabilities. The proposed defense can be easily integrated into models without additional training. We show that our defense is effective in defending against three state-of-the-art stealing attacks. We evaluate our approach on large and quantized (i.e., compressed) Convolutional Neural Networks (CNNs) trained on several vision datasets. Our technique outperforms the state-of-the-art defenses with a $\\times37$ faster inference latency without requiring any additional model and with a low impact on the model's performance. We validate that our defense is also effective for quantized CNNs targeting edge devices.",
        "creator": "Kacem Khaled, Mouna Dhaouadi, Felipe Gohring de Magalh&#xe3;es, Gabriela Nicolescu"
      },
      {
        "id": "2309.01940",
        "slug": "codeapex-a-bilingual-programming-evaluation-benchmark-for-large-language-models-arxiv-2309-01940v3-cs-cl-updated",
        "title": "CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models.",
        "link": "http://arxiv.org/abs/2309.01940",
        "abstract": "With the emergence of Large Language Models (LLMs), there has been a significant improvement in the programming capabilities of models, attracting growing attention from researchers. We propose CodeApex, a bilingual benchmark dataset focusing on the programming comprehension and code generation abilities of LLMs. CodeApex comprises three types of multiple-choice questions: conceptual understanding, commonsense reasoning, and multi-hop reasoning, designed to evaluate LLMs on programming comprehension tasks. Additionally, CodeApex utilizes algorithmic questions and corresponding test cases to assess the code quality generated by LLMs. We evaluate 14 state-of-the-art LLMs, including both general-purpose and specialized models. GPT exhibits the best programming capabilities, achieving approximate accuracies of 50% and 56% on the two tasks, respectively. There is still significant room for improvement in programming tasks. We hope that CodeApex can serve as a reference for evaluating the coding capabilities of LLMs, further promoting their development and growth. Datasets are released at https://github.com/APEXLAB/CodeApex.git. CodeApex submission website is https://apex.sjtu.edu.cn/codeapex/.",
        "creator": "Lingyue Fu, Huacan Chai, Shuang Luo, Kounianhua Du, Weiming Zhang, Longteng Fan, Jiayi Lei, Renting Rui, Jianghao Lin, Yuchen Fang, Yifan Liu, Jingkuan Wang, Siyuan Qi, Kangning Zhang, Weinan Zhang, Yong Yu"
      },
      {
        "id": "2309.03224",
        "slug": "no-train-still-gain-unleash-mathematical-reasoning-of-large-language-models-with-monte-carlo-tree-search-guided-by-energy-function-arxiv-2309-03224v2-cs-ai-updated",
        "title": "No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function.",
        "link": "http://arxiv.org/abs/2309.03224",
        "abstract": "Large language models (LLMs) demonstrate impressive language understanding and contextual learning abilities, making them suitable for natural language processing (NLP) tasks and complex mathematical reasoning. However, when applied to mathematical reasoning tasks, LLMs often struggle to generate correct reasoning steps and answers despite having high probabilities for the solutions. To overcome this limitation and enhance the mathematical reasoning capabilities of fine-tuned LLMs without additional fine-tuning steps, we propose a method that incorporates Monte Carlo Tree Search (MCTS) and a lightweight energy function to rank decision steps and enable immediate reaction and precise reasoning. Specifically, we re-formulate the fine-tuned LLMs into a Residual-based Energy Model (Residual-EBM) and employ noise contrastive estimation to estimate the energy function's parameters. We then utilize MCTS with the energy function as a path verifier to search the output space and evaluate the reasoning path. Through extensive experiments on two mathematical reasoning benchmarks, GSM8k and AQUA-RAT, we demonstrate the exceptional capabilities of our method, which significantly improves the pass@1 metric of the fine-tuned model without requiring additional fine-tuning or reinforcement learning with human feedback alignment.",
        "creator": "Haotian Xu"
      },
      {
        "id": "2309.04077",
        "slug": "saynav-grounding-large-language-models-for-dynamic-planning-to-navigation-in-new-environments-arxiv-2309-04077v2-cs-ro-updated",
        "title": "SayNav: Grounding Large Language Models for Dynamic Planning to Navigation in New Environments.",
        "link": "http://arxiv.org/abs/2309.04077",
        "abstract": "Semantic reasoning and dynamic planning capabilities are crucial for an autonomous agent to perform complex navigation tasks in unknown environments. It requires a large amount of common-sense knowledge, that humans possess, to succeed in these tasks. We present SayNav, a new approach that leverages human knowledge from Large Language Models (LLMs) for efficient generalization to complex navigation tasks in unknown large-scale environments. SayNav uses a novel grounding mechanism, that incrementally builds a 3D scene graph of the explored environment as inputs to LLMs, for generating feasible and contextually appropriate high-level plans for navigation. The LLM-generated plan is then executed by a pre-trained low-level planner, that treats each planned step as a short-distance point-goal navigation sub-task. SayNav dynamically generates step-by-step instructions during navigation and continuously refines future steps based on newly perceived information. We evaluate SayNav on a new multi-object navigation task, that requires the agent to utilize a massive amount of human knowledge to efficiently search multiple different objects in an unknown environment. SayNav outperforms an oracle based Point-nav baseline, achieving a success rate of 95.35% (vs 56.06% for the baseline), under the ideal settings on this task, highlighting its ability to generate dynamic plans for successfully locating objects in large-scale new environments. In addition, SayNav also enables efficient generalization from simulation to real environments.",
        "creator": "Abhinav Rajvanshi, Karan Sikka, Xiao Lin, Bhoram Lee, Han-Pang Chiu, Alvaro Velasquez"
      },
      {
        "id": "2005.04513",
        "slug": "intelligent-gps-spoofing-attack-detection-in-power-grids-arxiv-2005-04513v1-eess-sy-cross-listed",
        "title": "Intelligent GPS Spoofing Attack Detection in Power Grids.",
        "link": "http://arxiv.org/abs/2005.04513",
        "abstract": "The GPS is vulnerable to GPS spoofing attack (GSA), which leads to disorder in time and position results of the GPS receiver. In power grids, phasor measurement units (PMUs) use GPS to build time-tagged measurements, so they are susceptible to this attack. As a result of this attack, sampling time and phase angle of the PMU measurements change. In this paper, a neural network GPS spoofing detection (NNGSD) with employing PMU data from the dynamic power system is presented to detect GSAs. Numerical results in different conditions show the real-time performance of the proposed detection method.",
        "creator": "Mohammad Sabouri, Sara Siamak, Maryam Dehghani, Mohsen Mohammadi, Mohammad Hassan Asemani"
      }
    ]
  },
  {
    "name": "Plant Biology",
    "feed": [
      {
        "id": "2023.09.12.557332v1",
        "slug": "sterol-3-beta-glucosyltransferase-transparent-testa15-controls-seed-development-and-flavanol-accumulation-through-its-role-in-vacuole-biogenesis-and-maintenance-in-arabidopsis",
        "title": "Sterol 3-beta-Glucosyltransferase TRANSPARENT TESTA15 Controls Seed Development and Flavanol Accumulation through its Role in Vacuole Biogenesis and Maintenance in Arabidopsis",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.12.557332v1",
        "abstract": "The Arabidopsis sterol 3-beta-glucosyltransferase UGT80B1/TRANSPARENT TESTA15 (TT15) catalyzes sterol glucoside biosynthesis. Its loss of function causes reduced seed size, defective flavanol, polysaccharide and lipid polyester deposition at the seed coat and reduced seed dormancy. How TT15 controls seed development and physiology is unknown. Here we show that tt15 mutants exhibit seed lethality with incomplete penetrance and maternal determinism that is correlated with endosperm cellularization defects, together with an increased sensitivity of seed germination to exogenous abscisic acid and paclobutrazol. We also reveal that flavanol deposition in the vacuole during tt15 seed development triggers premature endothelium cell death. An autoimmune-like syndrome characterized by callose and H2O2 accumulation was detected in endothelium at the seed abaxial pole. Similar phenotypes were observed with tt9/gfs9, a mutant defective in endomembrane trafficking and homotypic vacuole fusion. Double mutant analysis showed that tt9 partially rescued tt15 endothelium phenotypes. Consistent with seed mutant phenotypes, TT15 promoter activity was detected in endothelium and endosperm and TT15 protein was located mainly at the vacuolar membrane (tonoplast). Using fluorescence recovery after photobleaching, we demonstrated that tonoplast fluidity was increased in tt15 roots. Altogether our data suggest that TT15 regulates seed development and flavanol accumulation by modulating vacuole biogenesis and maintenance.",
        "creator": "Akary, E., Berger, A., Perreau, F., Frey, A., To, A., Citerne, S., Schaller, H., Vernhettes, S., Grandjean, O., Nesi, N., Marion-Poll, A., Lepiniec, L., Debeaujon, I."
      },
      {
        "id": "2023.09.12.557336v1",
        "slug": "a-mathematical-model-of-photoinhibition-exploring-the-impact-of-quenching-processes",
        "title": "A mathematical model of photoinhibition: exploring the impact of quenching processes",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.12.557336v1",
        "abstract": "Plants are constantly exposed to changing environments, sometimes leading to extreme conditions and stress. For example, sudden exposure to high light leads to excess absorbed light energy, causing reactive oxygen species (ROS) formation. ROS damage the photosynthetic machinery, particularly the D1 protein in photosystem II (PSII), which therefore needs to be continuously repaired and replaced. The effect of the damage inflicted by high light is a prolonged decrease in photosynthetic efficiency. Hence, it is not surprising that photoinhibition has been subject to numerous experimental studies investigating its effects in the context of crop productivity. However, it has become apparent that classical measures of photoinhibition, i.e., changes in the chlorophyll fluorescence parameter Fv/Fm, are not only determined by the loss of PSII core function but also by processes such as energy transfer and quenching. Mathematical models can help dissect the influences on such fluorescence signals and quantify the contributions of various interacting mechanisms. We present a mathematical model with a dynamic description of the photosynthetic electron transport chain (PETC), non-photochemical quenching, and photoinhibition. With our model, we investigate the interconnection between quenching, photoprotection, and fluorescence using simulations and experimental data. We found that different energy-dissipating properties of intact and damaged PSIIs, as well as energy transfer between PSIIs, are critical components that need to be included in the model to ensure a satisfactory fit to the experimental data. We envisage that our model provides a framework for future investigations of photoinhibition dynamics and its importance for plant growth and yield.",
        "creator": "Nies, T., Matsubara, S., Ebenhoeh, O."
      },
      {
        "id": "2023.09.11.557125v1",
        "slug": "a-novel-workflow-for-unbiased-quantification-of-autophagosomes-in-3d-in-arabidopsis-thaliana-roots",
        "title": "A novel workflow for unbiased quantification of autophagosomes in 3D in Arabidopsis thaliana roots",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.11.557125v1",
        "abstract": "Macroautophagy is frequently quantified by live imaging of autophagosomes decorated with a marker of fluorescently tagged ATG8 protein (FT-ATG8) in Arabidopsis thaliana. This requires generation of suitable plant material by time-consuming crossing or transformation with FT-ATG8 marker. Autophagosome quantification by image analysis often relies on their counting in individual focal planes. This approach is prone to deliver biased results due to inappropriate sampling of the regions of interest in the Z-direction, as the actual 3D distribution of autophagosomes is usually not taken into account. To overcome such drawbacks, we have developed and tested a workflow consisting of immunofluorescence microscopy of autophagosomes labelled with anti-ATG8 antibody followed by stereological image analysis employing the optical disector and the Cavalieri principle. Our immunolabelling protocol specifically recognized autophagosomes in epidermal cells of A. thaliana root. Higher numbers of immunolabelled autophagosomes were observed when compared with those recognized with FT-AtATG8e marker, suggesting that single AtATG8 isoform markers cannot detect all autophagosomes in a cell. Therefore, immunolabelling provides more precise information as the anti-ATG8 antibody recognizes virtually all AtATG8 isoforms. The number of autophagosomes per tissue volume determined by stereological methods correlated with the intensity of autophagy induction treatment. Compared to autophagosome quantifications in maximum intensity projections, stereological methods detected autophagosomes present in a given volume with higher accuracy. Our novel application of immunolabelling combined with stereological methods constitutes a powerful toolbox for unbiased and reproducible quantification of autophagosomes and offers a convenient alternative to the standard of live imaging using FP-ATG8 marker.",
        "creator": "Danek, M., Kocourkova, D., Podmanicka, T., Eliasova, K., Nesvadbova, K., Krupar, P., Martinec, J."
      },
      {
        "id": "2023.09.12.555306v1",
        "slug": "carotenoid-metabolism-negatively-regulates-auxin-mediated-root-growth",
        "title": "Carotenoid metabolism negatively regulates auxin-mediated root growth",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.12.555306v1",
        "abstract": "Carotenoids support plant developmental activities as photosynthesis and photoprotective pigments, and also provide precursors for production of phytohormone abscisic acid and strigolactones, or bioactive apocarotenoids. Herein, we examined the role of carotenoid as a source of apocarotenoids, which control endogenous auxin levels and plant root architecture. Inhibiting {beta}-carotene biosynthesis by phytoene desaturase (PDS) inhibitor fluridone suppresses root growth, consequently inducing lateral root growth. PDS was confirmed to be the target of fluridone via the expression of the fluridone-insensitive trait 35S::mHvPDS in an Arabidopsis plant. Inhibiting {beta}-carotene biosynthesis elevated endogenous auxin levels and activated auxin signaling, thereby suppressing root growth. In addition, the root growth of the auxin-deficient mutant yucQ was partially restored via fluridone treatment. These results indicate that suppressing PDS activity increases endogenous auxin levels and suppresses root growth. Conversely, the carotenoid pool indirectly suppresses endogenous auxin levels. Exogenous application of retinal, apocarotenoid derived from {beta}-carotene, complemented fluridone-mediated root growth inhibition and partially recovered auxin-mediated growth inhibition. Moreover, retinal inhibited the induction of the auxin-inducible reporter pIAA19::ElucPEST, indicating an antagonistic effect of retinal on endogenous auxin levels. Interestingly, the auxin-deficient mutants wei2 wei7 and yucQ accumulated more {beta}-carotene compared with the wild type. The expression of CCDs, which converts {beta}-carotene into apocarotenoids, is auxin-inducible and increases following fluridone treatment. These results indicate feedback regulation during apocarotenoid biosynthesis in plant tissue. Thus, we conclude carotenoid regulates auxin levels and response, and this regulation is intermediated by apocarotenoid retinal.",
        "creator": "Xu, K., Zeng, H., Yumoto, E., Asahina, M., Hayashi, K.-i., Fukaki, H., Ito, H., Watahiki, M. K."
      },
      {
        "id": "2023.09.11.557157v1",
        "slug": "single-plant-omics-reveals-the-cascade-of-transcriptional-changes-during-the-vegetative-to-reproductive-transition",
        "title": "Single-plant-omics reveals the cascade of transcriptional changes during the vegetative-to-reproductive transition",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.11.557157v1",
        "abstract": "Plants undergo rapid developmental transitions, as well as gradual developmental processes. Moreover, individual plants within a population will undergo the developmental transitions asynchronously, so it is difficult to assemble a time series to resolve the sequence of transcriptional changes that take place during these rapid transitions. Single-plant-omics has the potential to distinguish between transcriptional events that are associated with these binary and continuous processes. Furthermore, we can utilise single-plant-omics to exploit this developmental asynchrony to order individual plants by their developmental trajectory, revealing a detailed cascade of transcriptional events. Here, we utilise single-plant-transcriptomics to resolve the transcriptional events that coincide with the onset of bolting. We performed RNA-seq on the leaves of individual plants from a large population of wild type Arabidopsis thaliana replicated at one time point during the vegetative-to-reproductive transition. Even though more than half of transcripts were differentially expressed between bolted and unbolted plants, we were able to find a subset of regulators that were more closely associated with gradual developmental traits like leaf size and biomass. Using a novel pseudotime inference algorithm, we determined that some senescence-associated processes, such as the reduction in ribosome biogenesis, are evident in the transcriptome before a bolt is visible. These results show the potential of single-plant-omics to reveal the detailed sequence of events that occur during rapid developmental transitions.",
        "creator": "Redmond, E. J., Ronald, J., Davis, S. J., Ezer, D."
      },
      {
        "id": "2023.09.10.556599v1",
        "slug": "evolutionarily-conserved-cki1-mediated-two-component-signaling-is-required-for-female-germline-specification-in-marchantia-polymorpha",
        "title": "Evolutionarily Conserved CKI1-Mediated Two-Component Signaling is Required for Female Germline Specification in Marchantia polymorpha",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.10.556599v1",
        "abstract": "In land plants, gametes derive from a small number of dedicated haploid cells. In angiosperms, one central cell and one egg cell are differentiated in the embryo sac as female gametes for double fertilization, while in non-flowering plants, only one egg cell is generated in the female sexual organ, called the archegonium. The central cell specification of Arabidopsis thaliana is controlled by the histidine kinase CYTOKININ-INDEPENDENT 1 (CKI1), which is a two-component signaling (TCS) activator sharing downstream regulatory components with the cytokinin signaling pathway. Our phylogenetic analysis suggested that CKI1 orthologs broadly exist in land plants. However, the role of CKI1 in the archegonium-bearing non-flowering plants remains unclear. Here we found that the sole CKI1 ortholog in the liverwort Marchantia polymorpha, MpCKI1, which functions through conserved downstream TCS components, regulates the female germline specification for egg cell development in the archegonium. In M. polymorpha, the archegonium develops three-dimensionally from a single cell, accumulating MpBONOBO (MpBNB), a master regulator for germline initiation and differentiation. We visualized female germline specification by capturing the distribution pattern of MpBNB in the discrete stages of early archegonium development, and found that the MpBNB accumulation is restricted to female germline cells. MpCKI1 is required for the proper MpBNB accumulation in the female germline, and is critical for the asymmetric cell divisions that specify the female germline cells. These results suggest that CKI1-mediated TCS originated during early land plant evolution and participates in female germ cell specification in deeply-diverged plant lineages.",
        "creator": "Bao, H., Sun, R., Iwano, M., Yoshitake, Y., Aki, S. S., Umeda, M., Nishihama, R., Yamaoka, S., Kohchi, T."
      },
      {
        "id": "2023.09.10.557017v1",
        "slug": "adapting-to-heat-stress-by-sowing-summer-grain-crops-early-in-late-winter-sorghum-root-growth-water-use-and-yield",
        "title": "Adapting to heat stress by sowing summer grain crops early in late winter: Sorghum root growth, water use, and yield",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.10.557017v1",
        "abstract": "CONTEXT: Drought and extreme heat at flowering are common stresses limiting the yield of summer crops, which are likely to intensify and become more frequent as projected under climate change. OBJECTIVE: This study explores the idea that adaptation to these stresses could be increased by sowing summer crops early in late winter or spring, to avoid the overlap with critical crop stages around flowering. Here we report on the impacts of early sowing i.e., in late winter and spring on sorghum crop and root growth and function (i.e., water use), and final grain yield. METHODS: Two seasons of on-farm genotype (G) by environment (E) by management (M) sorghum experimentation were conducted in the Darling Downs region of Queensland, Australia. Each trial consisted of a factorial combination of three times of sowing (TOS, referred to as late winter, spring, and summer), two levels of irrigation, four target plant populations, and six commercial genotypes. Treatments were replicated three times. Crop roots and shoot were sampled at the flag leaf stage for each TOS. Crop water use across the growing season was monitored using time-lapse electromagnetic induction (EMI) surveys. EMI was also used to calculate a root activity factor. Final grain yield and yield components were determined at maturity. RESULTS: Results showed that TOS, irrigation levels, and their interactions significantly influenced crop root and shoot traits, water use, and yield, though results were not always consistent across seasons. In the first season which was dry and had large temperature contrasts between TOS, crop growth in the early sown crops was primarily limited by temperature. In contrast, the second season was much warmer and crop growth was instead primarily limited by water availability. Cold air and soil temperatures in the early sowing dates during the first season i.e., late winter and spring, lead to smaller crops with smaller rooting systems and root-to-shoot ratios, and roots having a larger average root diameter. In general terms, root length growth and root length density responded positively to increasing pre-flowering mean air temperatures ranging between 16 and 20C, while root average diameters were larger below 19 or above 21C. Early sowing advanced flowering and therefore decreased the risk of extreme heat during the critical stages around flowering and affected water use before and after flowering. The root activity factor was directly related to the crop root length density. The early sown crops increased yield by transferring water use from vegetative to reproductive stages. The larger yield of early sown sorghum was associated with larger grain numbers. Early sown crops had larger values of water use efficiency associated with larger total grain numbers, particularly for the tillers. As expected, the lowest values of water use efficiency were observed in irrigated and summer sown crops. The early sowing times left more water in the soil profile at maturity, particularly under irrigated conditions and with small plant populations. CONCLUSIONS: We conclude that early sown sorghum is a potential option to increase crop adaptation to hotter and drier environments. Here we propose that in the race to increase crop adaptation to heat stresses, plant breeding efforts should consider cold tolerance traits during crop germination, emergence, and early vegetative stages so that sorghum sowing windows could be significantly advanced.",
        "creator": "Zhao, D., deVoil, P., G. Rognoni, B., Wilkus, E., Eyre, J., Broad, I., Rodriguez, D."
      },
      {
        "id": "2023.09.08.556755v1",
        "slug": "transcriptional-modulation-during-photomorphogenesis-in-rice-seedlings",
        "title": "Transcriptional modulation during photomorphogenesis in rice seedlings",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.08.556755v1",
        "abstract": "Light is one of the most important factors regulating plant gene expression patterns, metabolism, physiology, growth, and development. To explore how light may induce or alter transcript splicing, we conducted RNA-Seq-based transcriptome analyses by comparing the samples harvested as etiolated seedlings grown under continuous dark conditions vs. the light-treated green seedlings. We identified 14,766 differentially expressed genes, of which 4369 genes showed alternative splicing. We observed that genes mapped to the plastid-localized methyl-erythritol-phosphate (MEP) pathway were upregulated in light compared to the cytosolic mevalonate (MVA) pathway genes. Many of these genes also undergo splicing. These pathways provide crucial metabolite precursors for the biosynthesis of secondary metabolic compounds needed for chloroplast biogenesis, the establishment of successful photosynthetic apparatus, and photomorphogenesis. In the chromosome-wide survey of the light-induced transcriptome, we observed intron retention as the most predominant splicing event. In addition, we identified 1709 novel lncRNA transcripts in our transcriptome data.",
        "creator": "Jaiswal, P., Gupta, P."
      },
      {
        "id": "2023.09.09.556983v1",
        "slug": "a-key-role-of-pectin-demethylation-mediated-cell-wall-na-retention-in-regulating-differential-salt-stress-resistance-in-allotetraploid-rapeseed-genotypes",
        "title": "A key role of pectin demethylation-mediated cell wall Na+ retention in regulating differential salt stress resistance in allotetraploid rapeseed genotypes",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.09.556983v1",
        "abstract": "Allotetraploid rapeseed (Brassica napus L.) is highly susceptible to salt stress, a worldwide limiting factor that causes severe losses in seed yield. Genetic variations in the resistance against salt stress found in rapeseed genotypes emphasizes the complex response architecture. Westar is ubiquitously used as a major transgenic receptor, and ZS11 is widely grown as a high production and good quality cultivar. In this study, Westar was identified to outperform than ZS11 under salt stress. Through cell component isolation, non-invasive micro-test, X-ray energy spectrum analysis, and ionomic profiling characterization, pectin demethylation was found to be a major regulator for differential salt resistance between Westar and ZS11. Integrated analyses of genome-wide DNA variations, differentially expression profiling, and gene co-expression network identified BnaC9.PME47, encoding pectin methyl esterase, as a positive regulator mainly responsible for salt stress resistance. BnaC9.PME47, located in two reported QTLs regions for salt resistance, was strongly induced by salt stress and localized on the cell wall. Natural variation of the promoter regions conferred higher expression of BnaC9.PME47 in Westar than in other salt-sensitive rapeseed genotypes. Loss-of-function of AtPME47 resulted in the hypersensitivity of Arabidopsis plants to salt stress. This study facilitates a more comprehensive understanding of the differential morpho-physiological and molecular responses to salt stress and abundant genetic diversity in rapeseed genotypes, and the integrated multiomics analyses provide novel insights regarding the rapid dissection of quantitative trait genes responsible for nutrient stresses in plant species with complex genomes.",
        "creator": "Zhou, T., Wu, P.-j., Chen, J.-f., Du, X.-q., Feng, Y.-n., Yue, C.-p., Huang, J.-y., Hua, Y.-p."
      },
      {
        "id": "2023.09.09.556968v1",
        "slug": "comparison-of-the-microbiome-and-mycobiome-in-tissues-of-the-tropical-carnivorous-epiphytic-herb-utricularia-jamesoniana",
        "title": "Comparison of the microbiome and mycobiome in tissues of the tropical carnivorous epiphytic herb Utricularia jamesoniana",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.09.556968v1",
        "abstract": "Utricularia jamesoniana, a small epiphytic plant found in wet tropical forests, stands out for its carnivorous habit, intricate trap system, and small but beautiful and complex flowers. This species remains relatively understudied despite its wide geographical distribution and curious adaptations. In this study, we employed 16S rRNA and ITS sequencing to compare the prokaryotic and fungal communities within leaves and traps of U. jamesoniana. The analysis of amplicon sequence variants (ASVs) unveiled notable differences in community composition depending on the plant tissue and type of microorganism. Prokaryotic communities predominantly comprised Proteobacteria and Actinobacteriota, featuring genera such as Acidocella, Bradyrhizobium, Ferritrophicum, and Ferrovum. Fungal communities were dominated by Ascomycota and Basidiomycota, encompassing representatives of Dothideomycetes, Sordariomycetes, Eurotiomycetes, and Agaricomycetes, as well as ASVs related to Mycosphaerellaceae, Colletotrichum, Aspergillus, and Thanatephorus. We determined that the prokaryotic diversity has higher in the bladders with respect to the leaves. Fungal communities, in turn, were more diverse in leaves than in bladders. This study sheds light on the microbial communities associated with this carnivorous epiphyte and provides valuable insights into the intricate relationships between the plant and its microbial inhabitants across different tissues.",
        "creator": "Naranjo, V., Mora, R. A., Morera, J., Acuna-Castillo, R., Rojas-Jimenez, K."
      },
      {
        "id": "2023.09.07.556738v1",
        "slug": "stacking-of-prrs-in-potato-to-achieve-enhanced-resistance-against-phytophthora-infestans",
        "title": "Stacking of PRRs in potato to achieve enhanced resistance against Phytophthora infestans",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.07.556738v1",
        "abstract": "Plants employ pattern recognition receptors (PRRs) to sense pathogen-associated molecular patterns (PAMPs) or apoplastic effectors at the plant cell surface, as well as nucleotide-binding domain leucine-rich-repeat-containing receptors (NLRs) to sense effectors inside the plant cell. Breeding for potato resistance to P. infestans has focused on the use of NLRs, however, these genes are typically quickly overcome since the matching avirulence genes evolve exceptionally quickly. Here, we stacked two PRRs, PERU and RLP23, that recognize the rather conserved Phytophthora PAMPs Pep-13/25 and nlp20, respectively, in the potato cultivar Atlantic, and evaluated their effect on P. infestans resistance. We found that PERU and RLP23 cooperate for the early immune responses like the accumulation of reactive oxygen species (ROS) and production of ethylene by recognizing their corresponding PAMPs. Furthermore, we show that potato plants overexpressing these two PRRs are slightly less affected by P. infestans compared to the single transformants. Together, our data suggest that pyramiding of surface receptors can provide additional enhanced resistance against pathogens, however, more effective or synergistic combinations that may include intracellular NLR receptors should be explored.",
        "creator": "Ascurra, Y. C. T., Wouters, D., Visser, R., Nuernberger, T., Vleeshouwers, V."
      },
      {
        "id": "2023.09.09.556951v1",
        "slug": "control-of-cell-fate-specification-and-patterning-by-an-ancestral-microrna",
        "title": "Control of cell fate specification and patterning by an ancestral microRNA",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.09.556951v1",
        "abstract": "The formation of an organized body requires the establishment and maintenance of cells with structural and functional distinctive characteristics. A central question in developmental biology is how changes in the regulation of genes drive cell specification and patterning1. microRNAs (miRNAs) are small non-coding RNAs that regulate development through mRNA cleavage and/or translational repression2. In plants, miRNAs regulate key aspects including growth, development, stem cell maintenance, vegetative phase change, leaf morphogenesis, floral organ formation and flowering time3. Biogenesis of plant miRNAs depends on the activity of DICER-LIKE 1 (DCL1), an RNase type III endonuclease that processes double stranded RNA to give rise to mature miRNAs 4 . The genomes of today's flora contain at least one bona fide copy of DCL1 5,6. Using Marchantia polymorpha -a model bryophyte that allows comparative approaches to infer characteristics of the ancestral land plant-, we demonstrate that MpDCL1a is required for the biogenesis of miRNAs and uncovered a central role for miR166/Homeodomain Zipper Class III-regulated auxin synthesis in the specification of cell identity, patterning, meristem function, laminar expansion and the development of the body in the last common ancestor of extant land plants.",
        "creator": "Aguilar-Cruz, A., Flores-Sandoval, E., Gutierrez-Ramos, X., Oltehua-Lopez, O., Dorantes-Acosta, A. E., Trujillo, J. T., Kato, H., Ishizaki, K., Mosher, R. A., Dolan, L., Grimanelli, D., Haseloff, J., Bowman, J. L., Arteaga-Vazquez, M. A."
      },
      {
        "id": "2023.09.10.557053v1",
        "slug": "genome-size-is-positively-correlated-with-extinction-risk-in-herbaceous-angiosperms",
        "title": "Genome size is positively correlated with extinction risk in herbaceous angiosperms",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.10.557053v1",
        "abstract": "Angiosperms with large genomes experience nuclear-, cellular- and organism-level constraints that may limit their phenotypic plasticity and ecological niche. These constraints have been documented to vary across lineages, life-history strategies, ecogeographic patterns and environmental conditions. Therefore, we test the hypotheses that extinction risk is higher in large-genomed compared to small-genomed species, and that the effect of genome size varies across three selected covariates: life form, endemism, and climatic zones. We collated genome size and extinction risk information for a representative sample of angiosperms comprising 3,250 species, which we analyzed alongside life form, endemism and climate variables using a phylogenetic framework. Angiosperm genome size is positively correlated with extinction risk, a pattern driven by a signal in herbaceous but not woody species, regardless of climate and endemism. The influence of genome size is stronger in endemic herbaceous species, but is relatively homogenous across different climates. Beyond its indirect link via endemism and climate, genome size also influences extinction risk directly and significantly. Genome size may serve as a proxy for difficult-to-measure parameters associated with resilience and vulnerability in herbaceous angiosperms. Therefore, it merits further exploration as a useful biological attribute for understanding intrinsic extinction risk and augmenting plant conservation efforts.",
        "creator": "Gomez, M. S., Brown, M. J., Pironon, S., Vesely, P., Bures, P., Elliott, T. L., Zedek, F., Pellicer, J., Forest, F., Lughadha, E. N., Leitch, I. J."
      },
      {
        "id": "2023.09.09.556959v1",
        "slug": "cellular-gibberellin-dynamics-govern-indeterminate-nodule-development-morphologyand-function",
        "title": "Cellular gibberellin dynamics govern indeterminate nodule development, morphologyand function",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.09.556959v1",
        "abstract": "During nutrient scarcity, plants can adapt their developmental strategy to maximize their chance of survival. Such plasticity in development is underpinned by hormonal regulation, which mediates the relationship between environmental cues and developmental outputs. In legumes, endosymbiosis with nitrogen fixing bacteria (rhizobia) is a key adaptation for supplying the plant with nitrogen in the form of ammonium. Rhizobia are housed in lateral root-derived organs termed nodules that maintain an environment conducive to Nitrogenase in these bacteria. Several phytohormones are important for regulating the formation of nodules, with both positive and negative roles proposed for gibberellin (GA). In this study, we determined the cellular location and function of bioactive GA during nodule organogenesis using a genetically-encoded second generation GA biosensor, GPS2. We found endogenous bioactive GA accumulates locally at the site of nodule primordia, increasing dramatically in the cortical cell layers, persisting through cell divisions and maintaining accumulation in the mature nodule meristem. We show, through mis-expression of GA catabolic enzymes that suppress GA accumulation, that GA acts as a positive regulator of nodule growth and development. Furthermore, increasing or decreasing GA through perturbation of biosynthesis gene expression can increase or decrease the size of nodules, respectively. This is unique from lateral root formation, a developmental program that shares common organogenesis regulators. We link GA to a wider gene regulatory program by showing that cytokinin as well as nodule-identity genes induce and sustain GA accumulation necessary for nodule function.",
        "creator": "Drapek, C., Radzman-Mohd, N. A., Rizza, A., Schiessl, K., Dos Santos Barbosa, F., Wen, J., Oldroyd, G. E. D., Jones, A. M."
      },
      {
        "id": "2023.09.08.556869v1",
        "slug": "the-chloroplastic-phosphate-transporter-crpht4-7-supports-phosphate-homeostasis-and-photosynthesis-in-chlamydomonas",
        "title": "The chloroplastic phosphate transporter CrPHT4-7 supports phosphate homeostasis and photosynthesis in Chlamydomonas",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.08.556869v1",
        "abstract": "In eukaryotic cells, phosphorus is assimilated and utilized primarily as phosphate (Pi). Pi homeostasis is mediated by transporters that have not yet been adequately characterized in green algae. This study reports on CrPHT4-7 from Chlamydomonas reinhardtii, a member of the PHT4 transporter family, which exhibits remarkable similarity to AtPHT4;4 from Arabidopsis thaliana, a chloroplastic ascorbate transporter. Using fluorescent protein tagging we show that CrPHT4-7 resides in the chloroplast envelope membrane. Crpht4-7 mutants, generated by the CRISPR/Cas12a-mediated single- strand templated repair, show retarded growth especially in high light, enhanced sensitivity to phosphorus limitation, reduced ATP level, strong ascorbate accumulation and diminished non-photochemical quenching in high light. Conversely, CrPHT4-7 overexpressing lines exhibit enhanced biomass accumulation under high light conditions in comparison with the wild-type strain. Expressing CrPHT4-7 in a yeast strain lacking Pi transporters substantially recovered its slow growth phenotype demonstrating that it transports Pi. Even though CrPHT4-7 shows a high degree of similarity to AtPHT4;4, it does not display any significant ascorbate transport activity in yeast or intact algal cells. Thus, the results demonstrate that CrPHT4-7 functions as a chloroplastic Pi transporter essential for maintaining Pi homeostasis and photosynthesis in Chlamydomonas reinhardtii.",
        "creator": "Toth, D., Kuntam, S., Ferenczi, A., Vidal-Meireles, A., Kovacs, L., Wang, L., Sarkadi, Z., Migh, E., Szentmihalyi, K., Tengolics, R., Neupert, J., Bock, R., Jonikas, M. C., Molnar, A., Toth, S. Z."
      },
      {
        "id": "2023.09.07.556601v1",
        "slug": "nbptr1-confers-resistance-against-pseudomonas-syringae-pv-actinidiae-in-kiwifruit",
        "title": "NbPTR1 confers resistance against Pseudomonas syringae pv. actinidiae in kiwifruit",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.07.556601v1",
        "abstract": "Pseudomonas syringae pv. actinidiae biovar 3 (Psa3) causes a devastating canker disease in yellow-fleshed kiwifruit (Actinidia chinensis). The effector HopZ5, which is present in all isolates of Psa3 causing global outbreaks of pandemic kiwifruit canker disease, triggers immunity in Nicotiana benthamiana and is not recognised in susceptible A. chinensis cultivars. In a search for N. benthamiana non-host resistance genes against HopZ5, we found that the nucleotide-binding leucine-rich repeat receptor NbPTR1 recognised HopZ5. RPM1-interacting protein 4 (RIN4) orthologues from multiple plants, including kiwifruit, were associated with NbPTR1-mediated autoimmunity suppression and recognition of HopZ5. No functional orthologues of NbPTR1 were found in A. chinensis. NbPTR1 transformed into Psa3-susceptible A. chinensis var. chinensis Hort16A plants introduced HopZ5-specific resistance against Psa3. Altogether, this study suggested that expressing NbPTR1 in Psa3-susceptible kiwifruit is a viable approach to acquiring resistance to Psa3 and it provides valuable information for engineering resistance in otherwise susceptible kiwifruit genotypes.",
        "creator": "Yeh, S.-M., Yoon, M., Scott, S., Chatterjee, A., Hemara, L., Chen, R., Wang, T., Templeton, K., Rikkerink, E., Jayaraman, J., Brendolise, C."
      },
      {
        "id": "2023.09.08.556846v1",
        "slug": "yerba-mate-ilex-paraguariensis-genome-provides-new-insights-into-convergent-evolution-of-caffeine-biosynthesis",
        "title": "Yerba mate (Ilex paraguariensis) genome provides new insights into convergent evolution of caffeine biosynthesis",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.08.556846v1",
        "abstract": "Yerba mate (Ilex paraguariensis) is an economically important crop marketed for the elaboration of mate, the third-most widely consumed caffeine-containing infusion worldwide. Here we report the first genome assembly of this species, which has a total length of 1.06 Gb and contains 53,390 protein-coding genes. Comparative analyses revealed that the large yerba mate genome size is partly due to a whole-genome duplication (Ip-) during the early evolutionary history of Ilex, in addition to the hexaploidization event ({gamma}) shared by core eudicots. Characterization of the genome allowed us to clone the genes encoding methyltransferase enzymes that catalyse multiple reactions required for caffeine production. To our surprise, this species has converged upon a different biochemical pathway compared to that of its relatives, coffee and tea. In order to gain insight into the structural basis for the convergent enzyme activities, we obtained a crystal structure for the terminal enzyme in the pathway that forms caffeine. The structure reveals that convergent solutions have evolved for substrate positioning because different amino acid residues facilitate a different substrate orientation such that efficient methylation occurs in the independently evolved enzymes in yerba mate and coffee. While our results show phylogenomic constraint limits the genes coopted for convergence of caffeine biosynthesis, the x-ray diffraction data suggests structural constraints are minimal for the convergent evolution of individual reactions.",
        "creator": "Vignale, F. A., Hernandez Garcia, A., Modenutti, C. P., Sosa, E. J., Defelipe, L. A., Oliveira, R. R. M., Nunes, G. L., Acevedo, R. M., Burguener, G. F., Rossi, M., Zapata, P. D., Marti, D. A., Oliveira, G., Smith, M. N., Dubs, N. M., Nair, S., Barkman, T. J., Turjanski, A. G."
      },
      {
        "id": "2023.09.06.556598v1",
        "slug": "atdreb2g-is-a-novel-regulator-of-riboflavin-biosynthesis-under-low-temperature-stress-and-abscisic-acid-treatment-in-arabidopsis-thaliana",
        "title": "AtDREB2G is a novel regulator of riboflavin biosynthesis under low-temperature stress and abscisic acid treatment in Arabidopsis thaliana",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.06.556598v1",
        "abstract": "Riboflavin (RF) serves as a precursor to FMN and FAD, crucial cofactors in various metabolic processes. Strict regulation of cellular flavin homeostasis is imperative, yet information regarding the factors governing this regulation remains largely elusive. In this study, we first examined the impact of external flavin treatment on the Arabidopsis transcriptome to identify novel regulators of cellular flavin levels. Our analysis revealed alterations in the expression of 49 putative transcription factors. Subsequent reverse genetic screening highlighted a member of the Dehydration-Responsive Element Binding (DREB) family, AtDREB2G, as a potential regulator of cellular flavin levels. Knockout mutants of AtDREB2G (dreb2g) exhibited reduced flavin levels and decreased expression of RF biosynthetic genes compared to wild-type plants. Conversely, conditional overexpression of AtDREB2G led to an increase in the expression of RF biosynthetic genes and elevated flavin levels. In wild-type plants, exposure to low temperatures and abscisic acid treatment stimulated enhanced flavin levels and upregulated the expression of RF biosynthetic genes, concomitant with the induction of AtDREB2G. Notably, these responses were significantly attenuated in dreb2g mutants. Our findings establish AtDREB2G as a novel positive regulator of flavin biosynthesis in Arabidopsis, particularly under conditions of low temperature and abscisic acid treatment.",
        "creator": "Namba, J., Harada, M., Toda, Y., Maruta, T., Ishikawa, T., Shigeoka, S., Yoshimura, K., Ogawa, T."
      },
      {
        "id": "2023.09.07.556260v1",
        "slug": "a-soybean-rust-effector-protease-suppresses-host-immunity-and-cleaves-a-3-deoxy-7-phosphoheptulonate-synthase",
        "title": "A soybean rust effector protease suppresses host immunity and cleaves a 3-deoxy-7-phosphoheptulonate synthase",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.07.556260v1",
        "abstract": "The devastating soybean rust (SBR) pathogen, Phakopsora pachyrhizi, encodes many secreted proteins, but only two have been functionally characterized for their roles in rust virulence. Here, we demonstrate that transient expression of P. pachyrhizi effector candidate 15 (PpEC15), an aspartic protease, leads to enhanced bacterial growth in planta, suppression of callose deposition, reduced expression of plant defense-related marker genes and suppression of pathogen-associated molecular pattern (PAMP)-induced reactive oxygen species (ROS). Stable expression of PpEC15 in soybean suppresses PAMP-induced ROS production and enhances bacterial growth, indicating that, collectively, PpEC15 suppresses host and non-host innate immune responses. Yeast-two-hybrid and proximity labeling identified putative PpEC15 interacting partners including a peptide-chain release factor (PCRF), a NAC83 (NAM, ATAF, and CUC) transcription factor, and a DAHP (3-deoxy-7-phosphoheptulonate) synthase. We further show that PpEC15 is able to cleave DAHP, but does not cleave PCRF or NAC83. Virus-induced gene silencing of NAC83, PCRF and DAHP altered PAMP-induced ROS production and salicylic acid production, indicating that these proteins may be involved in immune signaling. Collectively, our data show that PpEC15 is conserved across P. pachyrhizi isolates and other economically important rust species and is involved in the suppression of plant basal defense responses. Understanding the role of PpEC15 in P. pachyrhizi virulence will provide a foundation for designing targeted intervention strategies to generate rust-resistant crops.",
        "creator": "Chicowski, A. S., Qi, M., Variz, H., Bredow, M., Montes-Serey, C., Caiazza, F., Dong, H., Margets, A. C., Mejias, J., Walley, J., Craik, C., Pedley, K. F., Aung, K., Innes, R. W., Whitham, S."
      },
      {
        "id": "2023.09.06.555881v1",
        "slug": "peanut-smut-a-scientometric-analysis-for-a-pathosystem-that-concerns-the-argentine-peanut-industry",
        "title": "Peanut Smut: A scientometric analysis for a pathosystem that concerns the Argentine peanut industry.",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.06.555881v1",
        "abstract": "Since its first report in commercial batches in 1995, the prevalence and yield impact caused by smut disease have increased rapidly in peanut fields. At the same time, various working groups have studied this pathosystem using different approaches, contributing to the scientific knowledge of the disease. By recognizing the importance of a thorough bibliographic review and meticulous organization of information, the process of initiating new research projects becomes more effective. In light of this, the aim of this work was to provide a comprehensive scientometric analysis of the evolution of peanut smut research, spanning from its inception to the current day. For this purpose, we compiled bibliographic data about the disease and extracted information to calculate metrics. We observed that a smaller proportion of the scientific production was presented in peer-reviewed journals, the prevalent topics were epidemiology and breeding, and the collaborative endeavors were crucial for the scientific advancement in the study of this pathosystem. Additionally, the researchers with the most significant presence in the publications, the involved institutions, and the impact of the produced papers, among other trends were identified. Although there have been many scientific-technological advances in peanut smut over the years, this information is not reflected in scientific papers in peer-reviewed journals, which represents a great challenge for researchers involved in this topic. It is crucial to continue generating knowledge that contributes to the integrated management of this complex pathosystem. This will prevent further yield losses and the spread of the pathogen to new production areas.",
        "creator": "Cazon, L. I., Paredes, J. A., Miretti, E., Gonzalez, N. R., Suarez, L., Conforto, E. C., Rago, A. M."
      },
      {
        "id": "2023.09.06.556496v1",
        "slug": "growth-deficiency-and-enhanced-basal-immunity-in-arabidopsis-thaliana-mutants-of-edm2-edm3-and-ibm2-are-genetically-interlinked",
        "title": "Growth deficiency and enhanced basal Immunity in Arabidopsis thaliana mutants of EDM2, EDM3 and IBM2 are genetically interlinked",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.06.556496v1",
        "abstract": "Mutants of the Arabidopsis thaliana genes, EDM2, EDM3 and IBM2 are known to show defects in a diverse set of defense and developmental processes. For example, they jointly exhibit enhanced levels of basal defense and stunted growth. Here we show that these two phenotypes are functionally connected by their dependency on the salicylic acid biosynthesis gene SID2 and the basal defense regulatory gene PAD4. Stunted growth of edm2, edm3 and ibm2 plants is a consequence of up-regulated basal defense. Constitutively enhanced activity of reactive oxygen species-generating peroxidases, we observed in these mutants, appears also to contribute to both, their enhanced basal defense and their growth retardation phenotypes. Furthermore, we found the histone H3 demethylase gene IBM1, a direct regulatory target of EDM2, EDM3 and IBM2, to be at least partially required for the basal defense and growth-related effects observed in these mutants. We recently reported that EDM2, EDM3 and IBM2 coordinate the extent of basal immunity with the timing of the floral transition. Together with these observations, data presented here show that at least some of the diverse phenotypic effects in edm2, edm3 and ibm2 mutants are genetically interlinked and functionally connected.",
        "creator": "Wang, J., Eulgem, T."
      },
      {
        "id": "2023.09.05.556322v1",
        "slug": "hormonal-and-transcriptomic-analysis-reveals-the-role-of-aba-and-br-in-breaking-the-barrier-of-inter-subgeneric-hybridization-in-water-lily-nymphaea",
        "title": "Hormonal and transcriptomic analysis reveals the role of ABA and BR in breaking the barrier of inter-subgeneric hybridization in water lily (Nymphaea)",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.05.556322v1",
        "abstract": "Understanding the process of signal communication between pollen and stigma is of significant importance for plant sexual reproduction. In the case of inter-subgeneric hybridization in water lily, there exists a pre-fertilization hybridization barrier, the regulatory mechanism of which remains unclear. In this study, we conducted hormone and transcriptome analyses of unpollinated stigmas (Mock), self-pollinated stigmas (SP), cross-pollinated stigmas within the same subgenus (CP), and inter-subgenus cross-pollination stigmas (ISCP) in water lily to elucidate the formation mechanism of the inter-subgeneric hybridization barrier. Our results indicated that the lack of ABA and BR in ISCP stigmas are key factors contributing to the formation of the inter-subgeneric hybridization barrier in water lily. Exogenous application of ABA and BR can help overcome the barrier between inter-subgeneric water lily crosses. Through transcriptome analysis, we identified nine candidate genes involved in regulating the inter-subgeneric hybridization barrier in water lily. In addition, we further demonstrated the importance of the NCED2-mediated ABA synthesis pathway in the hybridization process through AS-ODN technology. Our study confirms that ABA and BR are critical for breaking the inter-subgeneric hybridization barrier in water lily. The identification of the nine candidate genes provides important clues for further research on the hybridization recognition mechanism in water lily.",
        "creator": "Zhou, P., Li, J., Jiang, H., Yang, Z., Sun, C., Wang, H., Su, Q., Jin, Q., Wang, Y., Xu, Y."
      },
      {
        "id": "2023.09.05.556231v1",
        "slug": "trials-and-tribulations-of-neotropical-plant-taxonomy-pace-of-tree-species-description",
        "title": "Trials and tribulations of Neotropical plant taxonomy: pace of tree species description",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.05.556231v1",
        "abstract": "O_LIOne of the main aspects of taxonomic research is the description of new species. Identifying how to describe new species more efficiently is key to completing the inventory of the Neotropical flora in an era of massive biodiversity loss. C_LIO_LIHere we calculate the interval between first specimen collection and new species publication for a group of 2126 Neotropical trees, and discuss the historical context surrounding specimen collection and new species publication events. C_LIO_LIOur results reveal that on average, it takes almost 16 years from specimen collection to publication of a new Neotropical tree species, which is considerably shorter than previous estimates for other tropical groups. The central Andes is the region that had the longest average time lags, while the Choco had the shortest. Peru had the longest average time lags by country, while Haiti had the shortest. The average time lags increased until the early 1900s, when a decrease was observed, with the shortest lags between 1941 to 1960. C_LIO_LIWe found that the majority of the species described more rapidly are from plants collected and described by the same researcher. We demonstrate how political instability and conflict can delay or impede the completion of research initiatives in the region. We argue that enhancing international collaboration and training opportunities in Latin American countries, as well as ensuring safe plant collection campaigns, are critical to complete the inventory of the Neotropical flora. C_LI  Societal Impact StatementThis study aims to answer the question of how long it takes to describe a new species of tree in the Neotropics by calculating the time elapsed from collection of the first specimen to the publication of a new species. Given the current unprecedented concerns for global biodiversity loss, it is critical to identify best practices for describing new species more efficiently so we can complete the inventory of the Neotropical flora and implement appropriate conservation strategies in a timely manner.",
        "creator": "Lujan, M., Lucas, E., Michelangeli, F., Prance, G., Rzedowski, J., Aguilar, D. S., Serpell, E., Sothers, C., Zuntini, A., Lemos, R. M."
      },
      {
        "id": "2023.09.06.556499v1",
        "slug": "retrotransposon-driven-environmental-regulation-of-flc-leads-to-adaptive-response-to-herbicide",
        "title": "Retrotransposon-driven environmental regulation of FLC leads to adaptive response to herbicide",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.06.556499v1",
        "abstract": "The mobilization of retrotransposons yields major-effect mutations. Here, we report an adaptive retrotransposon insertion within the first intron of the Arabidopsis floral-repressor locus FLOWERING LOCUS C (FLC). The insertion-mutation augments the environmental sensitivity of FLC by affecting the balance between coding and non-coding transcript isoforms in response to environmental threads. We show that this balance is modulated epigenetically by DNA methylation and orchestrated by IBM2, a factor involved in the processing of intronic heterochromatin. The stress-sensitive allele of FLC has recently spread across populations subjected to recurrent chemical weeding, and we demonstrate that retrotransposon-driven acceleration of life cycle represents a rapid response to herbicide. Our findings illustrate how retrotransposition can create environmentally-sensitive alleles that facilitate adaptation to anthropogenic disturbances of the environment.",
        "creator": "Raingeval, M., Leduque, B., Baduel, P., Edera, A., Roux, F., Colot, V., Quadrana, L."
      },
      {
        "id": "2023.09.04.556251v1",
        "slug": "identifying-the-fungal-diseases-of-african-yam-bean-sphenostylis-stenocarpa-harms-and-their-occurrence-in-south-west-nigeria",
        "title": "Identifying the fungal diseases of African Yam Bean (\tSphenostylis stenocarpa   Harms) and their occurrence in South- West Nigeria",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.04.556251v1",
        "abstract": "Sphenostylis stenocarpa, commonly known as African yam bean (AYB), is an orphan crop with high nutritional properties but low yield production due to diseases. Hence, this study accessed the diversity and pathogenicity of fungi associated with AYB in Southwest (SW) Nigeria as a model area of cultivation. The incidence of fungi infecting AYB were surveyed in Oyo, Ondo, Ekiti, Osun, and Ogun states within SW Nigeria during 2018 planting season. The common field symptoms across all sites were tiny spot, brown spot, leaf blight, brown spot with yellow halo, necrotic lesion, and brown spot on pods. A total of 1005 fungi were isolated from leaf and pod samples, and identified morphologically on pure cultures as Aspergillus sp, Botrytis sp, Colletotrichum gloeosporioides, Curvularia lunata, Trichoderma harzianum, Macrophomina phaseolina, Pestalotia sp, Phoma sp, Fusarium verticillioides, F. oxysporum, F. solani, Botryodiplodia theobromae, and Choanephora curcubitarium and Nigrospora spp. Phoma sp and C. gleosporoides had highest frequency of occurrence 69.9% and 51.9% at early and mature stages, respectively. To conform to Kochs postulates, the pathogenicities of 12 exemplar strains of the most abundant fungal species were confirmed in controlled glasshouse tests. The identities of Colletotrichum sp., Aspergillus sp., Didymella sp., Pestalopsis sp, Lasiodiplodia theobromae, F. solani and F. oxysporum were confirmed based on internal transcribed spacer (ITS) sequencing and comparisons with the Genbank database. AYB germplasm from curated seed banks and farmer donated landraces were grown at the same site in 2020 and identical fungi were isolated. Further, genotypes with reduced disease incidences and incidences were identified. This first study to reveal the diversity of fungi associated with AYB in SW Nigeria that could inform disease management practices.",
        "creator": "Oyedele, T., Kehinde, I., Atanda, H. Y., Oyelakin, A., Popoola, T., Mur, L."
      },
      {
        "id": "2023.09.04.555865v1",
        "slug": "the-association-between-dioscorea-sansibarensis-and-orrella-dioscoreae-as-a-model-for-hereditary-leaf-symbiosis",
        "title": "The association between Dioscorea sansibarensis and Orrella dioscoreae as a model for hereditary leaf symbiosis",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.04.555865v1",
        "abstract": "Hereditary, or vertically-transmitted, symbioses affect a large number of animal species and some plants. The precise mechanisms underlying transmission of functions of these associations are often difficult to describe, due to the difficulty in separating the symbiotic partners. This is especially the case for plant-bacteria hereditary symbioses, which lack experimentally tractable model systems. Here, we demonstrate the potential of the leaf symbiosis between the wild yam Dioscorea sansibarensis and the bacterium Orrella dioscoreae (O. dioscoreae) as a model system for hereditary symbiosis. O. dioscoreae is easy to grow and genetically manipulate, which is unusual for hereditary symbionts. These properties allowed us to design an effective antimicrobial treatment to rid plants of bacteria and generate whole aposymbiotic plants, which can later be re-inoculated with bacterial cultures. Aposymbiotic plants did not differ morphologically from symbiotic plants and the leaf forerunner tip containing the symbiotic glands formed normally even in the absence of bacteria, but microscopic differences between symbiotic and aposymbiotic glands highlight the influence of bacteria on the development of trichomes and secretion of mucilage. This is to our knowledge the first leaf symbiosis where both host and symbiont can be grown separately and where the symbiont can be genetically altered and reintroduced to the host.",
        "creator": "Acar, T., Moreau, S., Jardinaud, M.-F., Houdinet, G., Maviane-Macia, F., De Meyer, F., Hoste, B., Leroux, O., Coen, O., Le Ru, A., Peeters, N., Carlier, A."
      },
      {
        "id": "2023.09.01.555968v1",
        "slug": "a-congestion-downstream-of-psi-causes-the-over-reduction-of-the-electron-transport-chain-in-pgr5-independent-of-membrane-energization",
        "title": "A congestion downstream of PSI causes the over-reduction of the electron transport chain in pgr5 independent of membrane energization",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.01.555968v1",
        "abstract": "The thylakoid protein Proton Gradient Regulation5 (PGR5) is thought to be a key component of cyclic electron flux around photosystem I. The pgr5 mutant is characterized by impaired proton motive force (pmf) formation across the thylakoid membrane, decreased photoprotective non-photochemical quenching (NPQ), and an over-reduction of the PSI acceptor side. This over-reduction has been attributed to impaired photosynthetic control, which down-regulates plastoquinol re-oxidation at the cytochrome b6f complex when the lumen is strongly acidified. Here, using the cgl160 ATP synthase assembly mutant, we show that in cgl160 pgr5 double mutants, both the pmf across the thylakoid membrane and NPQ are fully restored to wild-type levels. However, the acceptor-side limitation of PSI in the double mutants stays comparable to the single pgr5 mutant. This demonstrates that impaired photosynthetic control is not causal for the over-reduction of the PSI acceptor side in pgr5. Instead, we show that both in pgr5 and the clg160 pgr5 mutants, the entire high-potential chain from cytochrome f to PSI remains strongly reduced in high light. This leads to insufficient oxidizing power for plastoquinol re-oxidation by the cytochrome b6f complex, thus impairing pmf formation. We conclude that PGR5 plays a critical role in electron partitioning downstream of PSI.",
        "creator": "Kappel, S., Thiele, W., Gefen-Treves, S., Henze, A., Armbruster, U., Schottler, M. A."
      },
      {
        "id": "2023.09.06.556483v1",
        "slug": "methylosome-and-smn-complexes-are-dispensable-for-snrnp-assembly-in-arabidopsis",
        "title": "Methylosome and SMN complexes are dispensable for snRNP assembly in Arabidopsis",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.06.556483v1",
        "abstract": "The role of RNA splicing as modulator of the molecular responses to stress is well described. In contrast, its importance in the acclimation of plants to changes in ambient temperatures started to emerge only recently. Here, we analyzed the role of temperature in spliceosome assembly, a key step often neglected in studies focusing on splicing. Taking advantage of mutants showing temperature-dependent phenotypes we conducted a comprehensive study of the role that the methylosome and SMN complexes have in plant snRNP assembly. Genetic analyses, as well as in vivo and in vitro evidence suggest a mechanism for snRNP assembly in plants that differs remarkably from vertebrate animals. The SMN complex in plants is apparently reduced to a single protein, GEMIN2, that is not essential for plant development. Similarly, the methylosome has a less crucial role in spliceosome assembly than previously thought. Our results highlight how an evolutionary conserved molecular process like RNA splicing has nevertheless evolved plant specific characteristics.",
        "creator": "Goretti, D., Collani, S., Nardeli, S., Schmid, M."
      },
      {
        "id": "2023.09.03.556139v1",
        "slug": "establishing-a-comprehensive-web-based-analysis-platform-for-nicotiana-benthamiana-genome-and-transcriptome",
        "title": "Establishing a comprehensive web-based analysis platform for Nicotiana benthamiana genome and transcriptome",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.03.556139v1",
        "abstract": "Nicotiana benthamiana has long served as a crucial plant material extensively used in plant physiology research, particularly in the field of plant pathology, because of its high susceptibility to plant viruses. Additionally, it serves as a production platform to test vaccines and other valuable substances. Among its approximately 3.1 Gb genome, 57,583 genes have been annotated within a 61 Mb region. We created a comprehensive and easy-to-use platform to use transcriptomes for modern annotation. These tools allow to visualize gene expression profiles, draw molecular evolutionary phylogenetic trees of gene families, perform functional enrichment analyses, and facilitate output downloads. To demonstrate their utility, we analyzed the gene expression profiles of enzymes within the nicotine biosynthesis pathway, a secondary metabolic pathway characteristic of the Nicotiana genus. Using the developed tool, expression profiles of the nicotine biosynthesis pathway genes were generated. The expression patterns of eight gene groups in the pathway were strongly expressed in the roots and weakly expressed in leaves and flowers of N. benthamiana. The results were consistent with the established gene expression profiles in Nicotiana tabacum and provided insights into gene family composition and expression trends. The compilation of this database tool can facilitate genetic analysis of N. benthamiana in the future.  Significance statementA tool was developed to visualize gene expression profiles, draw molecular evolutionary phylogenetic trees of gene families, perform functional enrichment analyses, and facilitate output downloads of Nicotiana benthamiana. The database developed using the tool can evolve into a comprehensive all-in-one analysis platform by continuously incorporating transcriptome data released to date, newly released RNA-seq data, and annotations in the future.",
        "creator": "Kurotani, K.-i., Hirakawa, H., Shirasawa, K., Tagiri, K., Mori, M., Ichihashi, Y., Suzuki, T., Tanizawa, Y., Nakamura, Y., Isobe, S., Notaguchi, M."
      },
      {
        "id": "2023.09.05.556297v1",
        "slug": "a-transcription-factor-module-mediating-c2-photosynthesis",
        "title": "A transcription factor module mediating C2 photosynthesis",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.05.556297v1",
        "abstract": "C4 photosynthesis has arisen from the ancestral C3 state in over sixty lineages of angio-sperms. It is widely accepted that an early step in C4 evolution is restriction of glycine decarboxylase activity to bundle sheath cells to generate the so-called C2 pathway. In C2 Moricandia species, changes to the cis-regulatory region controlling expression of the P-subunit of GLYCINE DECARBOXYLASE (GLDP) in mesophyll cells enables this trait, but the mechanism underpinning GLDP expression in the bundle sheath is not known. We identify a MYC-MYB transcription factor module previously associated with the control of glucosinolate bio-synthesis as the basis of GLDP expression in bundle sheath cells. In C3 Arabidopsis thaliana this module drives GLDP expression in bundle sheath cells along with as yet unidentified factors driving expression in mesophyll cells. In the C2 species Moricandia arvensis, GLDP expression is lost from mesophyll cells and the MYC-MYB dependent expression in the bundle sheath is revealed. Evolution of C2 photosynthesis is thus associated with a MYC-MYB based transcriptional network already present in the C3 state. This work identifies a molecular genetic mechanism underlying the bundle sheath accumulation of glycine decarboxylase required for C2 photosynthesis and thus a foundational step in the evolution of C4 photosynthesis.",
        "creator": "Dickinson, P. J., Triesch, S., Schluter, U., Weber, A. P. M., Hibberd, J. M."
      }
    ]
  },
  {
    "name": "Economics",
    "feed": [
      {
        "id": "2309.04578",
        "slug": "maintaining-human-wellbeing-as-socio-environmental-systems-undergo-regime-shifts-arxiv-2309-04578v1-econ-th",
        "title": "Maintaining human wellbeing as socio-environmental systems undergo regime shifts.",
        "link": "http://arxiv.org/abs/2309.04578",
        "abstract": "Global environmental change is pushing many socio-environmental systems towards critical thresholds, where ecological systems' states are on the precipice of tipping points and interventions are needed to navigate or avert impending transitions. Flickering, where a system vacillates between alternative stable states, is touted as a useful early warning signal of irreversible transitions to undesirable ecological regimes. However, while flickering may presage an ecological tipping point, these dynamics also pose unique challenges for human adaptation. In this work, we link an ecological model that can exhibit flickering to a model of human adaptation to a changing environment. This allows us to explore the impact of flickering on the utility of adaptive agents in a coupled socio-environmental system. We highlight the conditions under which flickering causes wellbeing to decline disproportionately, and explore how these dynamics impact the optimal timing of a transformational change that partially decouples wellbeing from environmental variability. The implications of flickering on nomadic communities in Mongolia, artisanal fisheries, and wildfire systems are explored as possible case studies. Flickering, driven in part by climate change and changes to governance systems, may already be impacting communities. We argue that governance interventions investing in adaptive capacity could blunt the negative impact of flickering that can occur as socio-environmental systems pass through tipping points, and therefore contribute to the sustainability of these systems.",
        "creator": "Andrew R. Tilman, Elisabeth H. Krueger, Lisa C. McManus, James R. Watson"
      },
      {
        "id": "2309.04793",
        "slug": "interpreting-iv-estimators-in-information-provision-experiments-arxiv-2309-04793v1-econ-em",
        "title": "Interpreting IV Estimators in Information Provision Experiments.",
        "link": "http://arxiv.org/abs/2309.04793",
        "abstract": "A growing literature measures \"belief effects\" -- that is, the effect of a change in beliefs on one's actions -- using information provision experiments, where the provision of information is used as an instrument for beliefs. We show that in passive control design experiments with heterogeneous belief effects, using information provision as an instrument may not produce a positive weighted average of belief effects. We propose a \"mover instrumental variables\" (MIV) framework and estimator that attains a positive weighted average of belief effects by inferring the direction of belief updating using the prior. Relative to our preferred MIV, commonly used specifications in the literature produce a form of MIV that overweights individuals with larger prior errors; additionally, some specifications may require additional assumptions to generate positive weights.",
        "creator": "Vod Vilfort, Whitney Zhang"
      },
      {
        "id": "2309.04821",
        "slug": "non-linear-dimension-reduction-in-factor-augmented-vector-autoregressions-arxiv-2309-04821v1-econ-em",
        "title": "Non-linear dimension reduction in factor-augmented vector autoregressions.",
        "link": "http://arxiv.org/abs/2309.04821",
        "abstract": "This paper introduces non-linear dimension reduction in factor-augmented vector autoregressions to analyze the effects of different economic shocks. I argue that controlling for non-linearities between a large-dimensional dataset and the latent factors is particularly useful during turbulent times of the business cycle. In simulations, I show that non-linear dimension reduction techniques yield good forecasting performance, especially when data is highly volatile. In an empirical application, I identify a monetary policy as well as an uncertainty shock excluding and including observations of the COVID-19 pandemic. Those two applications suggest that the non-linear FAVAR approaches are capable of dealing with the large outliers caused by the COVID-19 pandemic and yield reliable results in both scenarios.",
        "creator": "Karin Klieber"
      },
      {
        "id": "2309.04876",
        "slug": "news-driven-expectations-and-volatility-clustering-arxiv-2309-04876v1-q-fin-gn",
        "title": "News-driven Expectations and Volatility Clustering.",
        "link": "http://arxiv.org/abs/2309.04876",
        "abstract": "Financial volatility obeys two fascinating empirical regularities that apply to various assets, on various markets, and on various time scales: it is fat-tailed (more precisely power-law distributed) and it tends to be clustered in time. Many interesting models have been proposed to account for these regularities, notably agent-based models, which mimic the two empirical laws through a complex mix of nonlinear mechanisms such as traders' switching between trading strategies in highly nonlinear way. This paper explains the two regularities simply in terms of traders' attitudes towards news, an explanation that follows almost by definition of the traditional dichotomy of financial market participants, investors versus speculators, whose behaviors are reduced to their simplest forms. Long-run investors' valuations of an asset are assumed to follow a news-driven random walk, thus capturing the investors' persistent, long memory of fundamental news. Short-term speculators' anticipated returns, on the other hand, are assumed to follow a news-driven autoregressive process, capturing their shorter memory of fundamental news, and, by the same token, the feedback intrinsic to the short-sighted, trend-following (or herding) mindset of speculators. These simple, linear, models of traders' expectations, it is shown, explain the two financial regularities in a generic and robust way. Rational expectations, the dominant model of traders' expectations, is not assumed here, owing to the famous no-speculation, no-trade results",
        "creator": "Sabiou Inoua"
      },
      {
        "id": "2309.04926",
        "slug": "testing-for-stationary-or-persistent-coefficient-randomness-in-predictive-regressions-arxiv-2309-04926v1-econ-em",
        "title": "Testing for Stationary or Persistent Coefficient Randomness in Predictive Regressions.",
        "link": "http://arxiv.org/abs/2309.04926",
        "abstract": "This study considers tests for coefficient randomness in predictive regressions. Our focus is on how tests for coefficient randomness are influenced by the persistence of random coefficient. We find that when the random coefficient is stationary, or I(0), Nyblom's (1989) LM test loses its optimality (in terms of power), which is established against the alternative of integrated, or I(1), random coefficient. We demonstrate this by constructing tests that are more powerful than the LM test when random coefficient is stationary, although these tests are dominated in terms of power by the LM test when random coefficient is integrated. This implies that the best test for coefficient randomness differs from context to context, and practitioners should take into account the persistence of potentially random coefficient and choose from several tests accordingly. In particular, we show through theoretical and numerical investigations that the product of the LM test and a Wald-type test proposed in this paper is preferable when there is no prior information on the persistence of potentially random coefficient. This point is illustrated by an empirical application using the U.S. stock returns data.",
        "creator": "Mikihito Nishi"
      },
      {
        "id": "2309.05639",
        "slug": "forecasted-treatment-effects-arxiv-2309-05639v1-econ-em",
        "title": "Forecasted Treatment Effects.",
        "link": "http://arxiv.org/abs/2309.05639",
        "abstract": "We consider estimation and inference of the effects of a policy in the absence of a control group. We obtain unbiased estimators of individual (heterogeneous) treatment effects and a consistent and asymptotically normal estimator of the average treatment effects, based on forecasting counterfactuals using a short time series of pre-treatment data. We show that the focus should be on forecast unbiasedness rather than accuracy. Correct specification of the forecasting model is not necessary to obtain unbiased estimates of individual treatment effects. Instead, simple basis function (e.g., polynomial time trends) regressions deliver unbiasedness under a broad class of data-generating processes for the individual counterfactuals. Basing the forecasts on a model can introduce misspecification bias and does not necessarily improve performance even under correct specification. Consistency and asymptotic normality of our Forecasted Average Treatment effects (FAT) estimator are attained under an additional assumption that rules out common and unforecastable shocks occurring between the treatment date and the date at which the effect is calculated.",
        "creator": "Irene Botosaru, Raffaella Giacomini, Martin Weidner"
      },
      {
        "id": "2103.12138",
        "slug": "the-shared-cost-of-pursuing-shareholder-value-arxiv-2103-12138v10-econ-gn-updated",
        "title": "The Shared Cost of Pursuing Shareholder Value.",
        "link": "http://arxiv.org/abs/2103.12138",
        "abstract": "Using quasi-experimental variations from the timing of firms' Annual General Meetings (AGMs), we propose a portable framework to infer shareholders' preferences and influences on firms' prosocial decisions and apply it to covid-related donations, recent private sanctions on Russia, and firms' prosocial stances over 2011-21. Image gains from AGMs' media exposure drive shareholders synonymous with a firm, like closely-connected individuals, to support costly prosocial changes, while others, like financial corporations, oppose them. Influence supporting these changes lowers earnings by 3\\%: pursuing the values of (some) shareholders has distributional costs, which the monitoring of large shareholders motivated by heterogeneous preferences could prevent.",
        "creator": "Michele Fioretti, Victor Saint-Jean, Simon C. Smith"
      },
      {
        "id": "2207.00800",
        "slug": "inside-the-west-wing-lobbying-as-a-contest-arxiv-2207-00800v2-econ-th-updated",
        "title": "Inside the West Wing: Lobbying as a contest.",
        "link": "http://arxiv.org/abs/2207.00800",
        "abstract": "When a government makes many different policy decisions, lobbying can be viewed as a contest between the government and many different special interest groups. The government fights lobbying by interest groups with its own political capital. In this world, we find that a government wants to `sell protection' -- give favourable treatment in exchange for contributions -- to certain interest groups. It does this in order to build its own `war chest' of political capital, which improves its position in fights with other interest groups. And it does so until it wins all remaining contests with certainty. This stands in contrast to existing models that often view lobbying as driven by information or agency problems.",
        "creator": "Alastair Langtry"
      },
      {
        "id": "2302.13426",
        "slug": "price-discovery-for-derivatives-arxiv-2302-13426v16-econ-gn-updated",
        "title": "Price Discovery for Derivatives.",
        "link": "http://arxiv.org/abs/2302.13426",
        "abstract": "We obtain a basic theory of price discovery across derivative markets in a general framework where an agent has private information regarding state probabilities and trades state-contingent claims. In an equivalent options formulation, the informed agent has private information regarding arbitrary aspects of an underlying asset's payoff distribution and trades options portfolios. We characterize the informed demand, price impact, and information efficiency of prices. Our results offer a theory of informed trading on higher moments of the underlying payoff as a special case. The closed-form informed demand formula prescribes options strategies for trading on any given moment, thereby rationalizing and extending those used for e.g. volatility trading.",
        "creator": "Christian Keller, Michael C. Tseng"
      },
      {
        "id": "2306.13681",
        "slug": "estimating-the-value-of-evidence-based-decision-making-arxiv-2306-13681v2-stat-me-updated",
        "title": "Estimating the Value of Evidence-Based Decision Making.",
        "link": "http://arxiv.org/abs/2306.13681",
        "abstract": "Business/policy decisions are often based on evidence from randomized experiments and observational studies. In this article we propose an empirical framework to estimate the value of evidence-based decision making (EBDM) and the return on the investment in statistical precision.",
        "creator": "Alberto Abadie, Anish Agarwal, Guido Imbens, Siwei Jia, James McQueen, Serguei Stepaniants"
      },
      {
        "id": "2309.01791",
        "slug": "non-transitivity-of-the-win-ratio-and-the-area-under-the-receiver-operating-characteristics-curve-auc-a-case-for-evaluating-the-strength-of-stochastic-comparisons-arxiv-2309-01791v2-stat-me-updated",
        "title": "Non-Transitivity of the Win Ratio and the Area Under the Receiver Operating Characteristics Curve (AUC): a case for evaluating the strength of stochastic comparisons.",
        "link": "http://arxiv.org/abs/2309.01791",
        "abstract": "The win ratio (WR) is a novel statistic used in randomized controlled trials that can account for hierarchies within event outcomes. In this paper we report and study the long-run non-transitive behavior of the win ratio and the closely related Area Under the Receiver Operating Characteristics Curve (AUC) and argue that their transitivity cannot be taken for granted. Crucially, traditional within-group statistics (i.e., comparison of means) are always transitive, while the WR can detect non-transitivity. Non-transitivity provides valuable information on the stochastic relationship between two treatment groups, which should be tested and reported. We specify the necessary conditions for transitivity, the sufficient conditions for non-transitivity, and demonstrate non-transitivity in a real-life large randomized controlled trial for the WR of time-to-death. Our results can be used to rule out or evaluate the possibility of non-transitivity and show the importance of studying the strength of stochastic relationships.",
        "creator": "Olga V. Demler, Ilona A. Demler"
      }
    ]
  }
]
