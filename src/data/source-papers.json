[{"name":"Artificial Intelligence","feed":[{"id":"2311.07578","slug":"a-metacognitive-approach-to-out-of-distribution-detection-for-segmentation-arxiv-2311-07578v1-cs-cv","title":"A Metacognitive Approach to Out-of-Distribution Detection for Segmentation.","link":"http://arxiv.org/abs/2311.07578","abstract":"Despite outstanding semantic scene segmentation in closed-worlds, deep neural networks segment novel instances poorly, which is required for autonomous agents acting in an open world. To improve out-of-distribution (OOD) detection for segmentation, we introduce a metacognitive approach in the form of a lightweight module that leverages entropy measures, segmentation predictions, and spatial context to characterize the segmentation model's uncertainty and detect pixel-wise OOD data in real-time. Additionally, our approach incorporates a novel method of generating synthetic OOD data in context with in-distribution data, which we use to fine-tune existing segmentation models with maximum entropy training. This further improves the metacognitive module's performance without requiring access to OOD data while enabling compatibility with established pre-trained models. Our resulting approach can reliably detect OOD instances in a scene, as shown by state-of-the-art performance on OOD detection for semantic segmentation benchmarks.","creator":"Meghna Gummadi, Cassandra Kent, Karl Schmeckpeper, Eric Eaton"},{"id":"2311.07579","slug":"relative-intrinsic-dimensionality-is-intrinsic-to-learning-arxiv-2311-07579v1-cs-lg","title":"Relative intrinsic dimensionality is intrinsic to learning.","link":"http://arxiv.org/abs/2311.07579","abstract":"High dimensional data can have a surprising property: pairs of data points may be easily separated from each other, or even from arbitrary subsets, with high probability using just simple linear classifiers. However, this is more of a rule of thumb than a reliable property as high dimensionality alone is neither necessary nor sufficient for successful learning. Here, we introduce a new notion of the intrinsic dimension of a data distribution, which precisely captures the separability properties of the data. For this intrinsic dimension, the rule of thumb above becomes a law: high intrinsic dimension guarantees highly separable data. We extend this notion to that of the relative intrinsic dimension of two data distributions, which we show provides both upper and lower bounds on the probability of successfully learning and generalising in a binary classification problem","creator":"Oliver J. Sutton, Qinghua Zhou, Alexander N. Gorban, Ivan Y. Tyukin"},{"id":"2311.07582","slug":"evaluating-the-potential-of-leading-large-language-models-in-reasoning-biology-questions-arxiv-2311-07582v1-cs-cl","title":"Evaluating the Potential of Leading Large Language Models in Reasoning Biology Questions.","link":"http://arxiv.org/abs/2311.07582","abstract":"Recent advances in Large Language Models (LLMs) have presented new opportunities for integrating Artificial General Intelligence (AGI) into biological research and education. This study evaluated the capabilities of leading LLMs, including GPT-4, GPT-3.5, PaLM2, Claude2, and SenseNova, in answering conceptual biology questions. The models were tested on a 108-question multiple-choice exam covering biology topics in molecular biology, biological techniques, metabolic engineering, and synthetic biology. Among the models, GPT-4 achieved the highest average score of 90 and demonstrated the greatest consistency across trials with different prompts. The results indicated GPT-4's proficiency in logical reasoning and its potential to aid biology research through capabilities like data analysis, hypothesis generation, and knowledge integration. However, further development and validation are still required before the promise of LLMs in accelerating biological discovery can be realized.","creator":"Xinyu Gong, Jason Holmes, Yiwei Li, Zhengliang Liu, Qi Gan, Zihao Wu, Jianli Zhang, Yusong Zou, Yuxi Teng, Tian Jiang, Hongtu Zhu, Wei Liu, Tianming Liu, Yajun Yan"},{"id":"2311.07583","slug":"cross-dialect-sentence-transformation-a-comparative-analysis-of-language-models-for-adapting-sentences-to-british-english-arxiv-2311-07583v1-cs-cl","title":"Cross-Dialect Sentence Transformation: A Comparative Analysis of Language Models for Adapting Sentences to British English.","link":"http://arxiv.org/abs/2311.07583","abstract":"This study explores linguistic distinctions among American, Indian, and Irish English dialects and assesses various Language Models (LLMs) in their ability to generate British English translations from these dialects. Using cosine similarity analysis, the study measures the linguistic proximity between original British English translations and those produced by LLMs for each dialect. The findings reveal that Indian and Irish English translations maintain notably high similarity scores, suggesting strong linguistic alignment with British English. In contrast, American English exhibits slightly lower similarity, reflecting its distinct linguistic traits. Additionally, the choice of LLM significantly impacts translation quality, with Llama-2-70b consistently demonstrating superior performance. The study underscores the importance of selecting the right model for dialect translation, emphasizing the role of linguistic expertise and contextual understanding in achieving accurate translations.","creator":"Shruti Dutta, Shashwat Mookherjee"},{"id":"2311.07584","slug":"performance-prediction-of-data-driven-knowledge-summarization-of-high-entropy-alloys-heas-literature-implementing-natural-language-processing-algorithms-arxiv-2311-07584v1-cs-cl","title":"Performance Prediction of Data-Driven Knowledge summarization of High Entropy Alloys (HEAs) literature implementing Natural Language Processing algorithms.","link":"http://arxiv.org/abs/2311.07584","abstract":"The ability to interpret spoken language is connected to natural language processing. It involves teaching the AI how words relate to one another, how they are meant to be used, and in what settings. The goal of natural language processing (NLP) is to get a machine intelligence to process words the same way a human brain does. This enables machine intelligence to interpret, arrange, and comprehend textual data by processing the natural language. The technology can comprehend what is communicated, whether it be through speech or writing because AI pro-cesses language more quickly than humans can. In the present study, five NLP algorithms, namely, Geneism, Sumy, Luhn, Latent Semantic Analysis (LSA), and Kull-back-Liebler (KL) al-gorithm, are implemented for the first time for the knowledge summarization purpose of the High Entropy Alloys (HEAs). The performance prediction of these algorithms is made by using the BLEU score and ROUGE score. The results showed that the Luhn algorithm has the highest accuracy score for the knowledge summarization tasks compared to the other used algorithms.","creator":"Akshansh Mishra, Vijaykumar S Jatti, Vaishnavi More, Anish Dasgupta, Devarrishi Dixit, Eyob Messele Sefene"},{"id":"2311.07585","slug":"input-reconstruction-attack-against-vertical-federated-large-language-models-arxiv-2311-07585v1-cs-cl","title":"Input Reconstruction Attack against Vertical Federated Large Language Models.","link":"http://arxiv.org/abs/2311.07585","abstract":"Recently, large language models (LLMs) have drawn extensive attention from academia and the public, due to the advent of the ChatGPT. While LLMs show their astonishing ability in text generation for various tasks, privacy concerns limit their usage in real-life businesses. More specifically, either the user's inputs (the user sends the query to the model-hosting server) or the model (the user downloads the complete model) itself will be revealed during the usage. Vertical federated learning (VFL) is a promising solution to this kind of problem. It protects both the user's input and the knowledge of the model by splitting the model into a bottom part and a top part, which is maintained by the user and the model provider, respectively. However, in this paper, we demonstrate that in LLMs, VFL fails to protect the user input since it is simple and cheap to reconstruct the input from the intermediate embeddings. Experiments show that even with a commercial GPU, the input sentence can be reconstructed in only one second. We also discuss several possible solutions to enhance the privacy of vertical federated LLMs.","creator":"Fei Zheng"},{"id":"2311.07587","slug":"frontier-language-models-are-not-robust-to-adversarial-arithmetic-or-what-do-i-need-to-say-so-you-agree-2-2-5-arxiv-2311-07587v1-cs-cl","title":"Frontier Language Models are not Robust to Adversarial Arithmetic, or \"What do I need to say so you agree 2+2=5?.","link":"http://arxiv.org/abs/2311.07587","abstract":"We introduce and study the problem of adversarial arithmetic, which provides a simple yet challenging testbed for language model alignment. This problem is comprised of arithmetic questions posed in natural language, with an arbitrary adversarial string inserted before the question is complete. Even in the simple setting of 1-digit addition problems, it is easy to find adversarial prompts that make all tested models (including PaLM2, GPT4, Claude2) misbehave, and even to steer models to a particular wrong answer. We additionally provide a simple algorithm for finding successful attacks by querying those same models, which we name \"prompt inversion rejection sampling\" (PIRS). We finally show that models can be partially hardened against these attacks via reinforcement learning and via agentic constitutional loops. However, we were not able to make a language model fully robust against adversarial arithmetic attacks.","creator":"C. Daniel Freeman, Laura Culp, Aaron Parisi, Maxwell L Bileschi, Gamaleldin F Elsayed, Alex Rizkowsky, Isabelle Simpson, Alex Alemi, Azade Nova, Ben Adlam, Bernd Bohnet, Gaurav Mishra, Hanie Sedghi, Igor Mordatch, Izzeddin Gur, Jaehoon Lee, JD Co-Reyes, Jeffrey Pennington, Kelvin Xu, Kevin Swersky, Kshiteej Mahajan, Lechao Xiao, Rosanne Liu, Simon Kornblith, Noah Constant, Peter J. Liu, Roman Novak, Sharad Vikram, Yundi Qian, Noah Fiedel, Jascha Sohl-Dickstein"},{"id":"2311.07588","slug":"nlqxform-a-language-model-based-question-to-sparql-transformer-arxiv-2311-07588v1-cs-cl","title":"NLQxform: A Language Model-based Question to SPARQL Transformer.","link":"http://arxiv.org/abs/2311.07588","abstract":"In recent years, scholarly data has grown dramatically in terms of both scale and complexity. It becomes increasingly challenging to retrieve information from scholarly knowledge graphs that include large-scale heterogeneous relationships, such as authorship, affiliation, and citation, between various types of entities, e.g., scholars, papers, and organizations. As part of the Scholarly QALD Challenge, this paper presents a question-answering (QA) system called NLQxform, which provides an easy-to-use natural language interface to facilitate accessing scholarly knowledge graphs. NLQxform allows users to express their complex query intentions in natural language questions. A transformer-based language model, i.e., BART, is employed to translate questions into standard SPARQL queries, which can be evaluated to retrieve the required information. According to the public leaderboard of the Scholarly QALD Challenge at ISWC 2023 (Task 1: DBLP-QUAD - Knowledge Graph Question Answering over DBLP), NLQxform achieved an F1 score of 0.85 and ranked first on the QA task, demonstrating the competitiveness of the system.","creator":"Ruijie Wang, Zhiruo Zhang, Luca Rossetto, Florian Ruosch, Abraham Bernstein"},{"id":"2311.07589","slug":"dialogizer-context-aware-conversational-qa-dataset-generation-from-textual-sources-arxiv-2311-07589v1-cs-cl","title":"Dialogizer: Context-aware Conversational-QA Dataset Generation from Textual Sources.","link":"http://arxiv.org/abs/2311.07589","abstract":"To address the data scarcity issue in Conversational question answering (ConvQA), a dialog inpainting method, which utilizes documents to generate ConvQA datasets, has been proposed. However, the original dialog inpainting model is trained solely on the dialog reconstruction task, resulting in the generation of questions with low contextual relevance due to insufficient learning of question-answer alignment. To overcome this limitation, we propose a novel framework called Dialogizer, which has the capability to automatically generate ConvQA datasets with high contextual relevance from textual sources. The framework incorporates two training tasks: question-answer matching (QAM) and topic-aware dialog generation (TDG). Moreover, re-ranking is conducted during the inference phase based on the contextual relevance of the generated questions. Using our framework, we produce four ConvQA datasets by utilizing documents from multiple domains as the primary source. Through automatic evaluation using diverse metrics, as well as human evaluation, we validate that our proposed framework exhibits the ability to generate datasets of higher quality compared to the baseline dialog inpainting model.","creator":"Yerin Hwang, Yongil Kim, Hyunkyung Bae, Jeesoo Bang, Hwanhee Lee, Kyomin Jung"},{"id":"2311.07590","slug":"technical-report-large-language-models-can-strategically-deceive-their-users-when-put-under-pressure-arxiv-2311-07590v1-cs-cl","title":"Technical Report: Large Language Models can Strategically Deceive their Users when Put Under Pressure.","link":"http://arxiv.org/abs/2311.07590","abstract":"We demonstrate a situation in which Large Language Models, trained to be helpful, harmless, and honest, can display misaligned behavior and strategically deceive their users about this behavior without being instructed to do so. Concretely, we deploy GPT-4 as an agent in a realistic, simulated environment, where it assumes the role of an autonomous stock trading agent. Within this environment, the model obtains an insider tip about a lucrative stock trade and acts upon it despite knowing that insider trading is disapproved of by company management. When reporting to its manager, the model consistently hides the genuine reasons behind its trading decision. We perform a brief investigation of how this behavior varies under changes to the setting, such as removing model access to a reasoning scratchpad, attempting to prevent the misaligned behavior by changing system instructions, changing the amount of pressure the model is under, varying the perceived risk of getting caught, and making other simple changes to the environment. To our knowledge, this is the first demonstration of Large Language Models trained to be helpful, harmless, and honest, strategically deceiving their users in a realistic situation without direct instructions or training for deception.","creator":"J&#xe9;r&#xe9;my Scheurer, Mikita Balesni, Marius Hobbhahn"},{"id":"2311.07592","slug":"hallucination-minimized-data-to-answer-framework-for-financial-decision-makers-arxiv-2311-07592v1-cs-cl","title":"Hallucination-minimized Data-to-answer Framework for Financial Decision-makers.","link":"http://arxiv.org/abs/2311.07592","abstract":"Large Language Models (LLMs) have been applied to build several automation and personalized question-answering prototypes so far. However, scaling such prototypes to robust products with minimized hallucinations or fake responses still remains an open challenge, especially in niche data-table heavy domains such as financial decision making. In this work, we present a novel Langchain-based framework that transforms data tables into hierarchical textual data chunks to enable a wide variety of actionable question answering. First, the user-queries are classified by intention followed by automated retrieval of the most relevant data chunks to generate customized LLM prompts per query. Next, the custom prompts and their responses undergo multi-metric scoring to assess for hallucinations and response confidence. The proposed system is optimized with user-query intention classification, advanced prompting, data scaling capabilities and it achieves over 90% confidence scores for a variety of user-queries responses ranging from {What, Where, Why, How, predict, trend, anomalies, exceptions} that are crucial for financial decision making applications. The proposed data to answers framework can be extended to other analytical domains such as sales and payroll to ensure optimal hallucination control guardrails.","creator":"Sohini Roychowdhury, Andres Alvarez, Brian Moore, Marko Krema, Maria Paz Gelpi, Federico Martin Rodriguez, Angel Rodriguez, Jose Ramon Cabrejas, Pablo Martinez Serrano, Punit Agrawal, Arijit Mukherjee"},{"id":"2311.07594","slug":"how-to-bridge-the-gap-between-modalities-a-comprehensive-survey-on-multimodal-large-language-model-arxiv-2311-07594v1-cs-cl","title":"How to Bridge the Gap between Modalities: A Comprehensive Survey on Multimodal Large Language Model.","link":"http://arxiv.org/abs/2311.07594","abstract":"This review paper explores Multimodal Large Language Models (MLLMs), which integrate Large Language Models (LLMs) like GPT-4 to handle multimodal data such as text and vision. MLLMs demonstrate capabilities like generating image narratives and answering image-based questions, bridging the gap towards real-world human-computer interactions and hinting at a potential pathway to artificial general intelligence. However, MLLMs still face challenges in processing the semantic gap in multimodality, which may lead to erroneous generation, posing potential risks to society. Choosing the appropriate modality alignment method is crucial, as improper methods might require more parameters with limited performance improvement. This paper aims to explore modality alignment methods for LLMs and their existing capabilities. Implementing modality alignment allows LLMs to address environmental issues and enhance accessibility. The study surveys existing modal alignment methods in MLLMs into four groups: (1) Multimodal Converters that change data into something LLMs can understand; (2) Multimodal Perceivers to improve how LLMs perceive different types of data; (3) Tools Assistance for changing data into one common format, usually text; and (4) Data-Driven methods that teach LLMs to understand specific types of data in a dataset. This field is still in a phase of exploration and experimentation, and we will organize and update various existing research methods for multimodal information alignment.","creator":"Shezheng Song, Xiaopeng Li, Shasha Li"},{"id":"2311.07595","slug":"a-decision-support-system-for-liver-diseases-prediction-integrating-batch-processing-rule-based-event-detection-and-sparql-query-arxiv-2311-07595v1-cs-ai","title":"A Decision Support System for Liver Diseases Prediction: Integrating Batch Processing, Rule-Based Event Detection and SPARQL Query.","link":"http://arxiv.org/abs/2311.07595","abstract":"Liver diseases pose a significant global health burden, impacting a substantial number of individuals and exerting substantial economic and social consequences. Rising liver problems are considered a fatal disease in many countries, such as Egypt, Molda, etc. The objective of this study is to construct a predictive model for liver illness using Basic Formal Ontology (BFO) and detection rules derived from a decision tree algorithm. Based on these rules, events are detected through batch processing using the Apache Jena framework. Based on the event detected, queries can be directly processed using SPARQL. To make the ontology operational, these Decision Tree (DT) rules are converted into Semantic Web Rule Language (SWRL). Using this SWRL in the ontology for predicting different types of liver disease with the help of the Pellet and Drool inference engines in Protege Tools, a total of 615 records are taken from different liver diseases. After inferring the rules, the result can be generated for the patient according to the DT rules, and other patient-related details along with different precautionary suggestions can be obtained based on these results. Combining query results of batch processing and ontology-generated results can give more accurate suggestions for disease prevention and detection. This work aims to provide a comprehensive approach that is applicable for liver disease prediction, rich knowledge graph representation, and smart querying capabilities. The results show that combining RDF data, SWRL rules, and SPARQL queries for analysing and predicting liver disease can help medical professionals to learn more about liver diseases and make a Decision Support System (DSS) for health care.","creator":"Ritesh Chandra, Sadhana Tiwari, Satyam Rastogi, Sonali Agarwal"},{"id":"2311.07597","slug":"enhancing-actuarial-non-life-pricing-models-via-transformers-arxiv-2311-07597v1-cs-lg","title":"Enhancing Actuarial Non-Life Pricing Models via Transformers.","link":"http://arxiv.org/abs/2311.07597","abstract":"Currently, there is a lot of research in the field of neural networks for non-life insurance pricing. The usual goal is to improve the predictive power via neural networks while building upon the generalized linear model, which is the current industry standard. Our paper contributes to this current journey via novel methods to enhance actuarial non-life models with transformer models for tabular data. We build here upon the foundation laid out by the combined actuarial neural network as well as the localGLMnet and enhance those models via the feature tokenizer transformer. The manuscript demonstrates the performance of the proposed methods on a real-world claim frequency dataset and compares them with several benchmark models such as generalized linear models, feed-forward neural networks, combined actuarial neural networks, LocalGLMnet, and pure feature tokenizer transformer. The paper shows that the new methods can achieve better results than the benchmark models while preserving certain generalized linear model advantages. The paper also discusses the practical implications and challenges of applying transformer models in actuarial settings.","creator":"Alexej Brauer"},{"id":"2311.07599","slug":"testing-llms-on-code-generation-with-varying-levels-of-prompt-specificity-arxiv-2311-07599v1-cs-se","title":"Testing LLMs on Code Generation with Varying Levels of Prompt Specificity.","link":"http://arxiv.org/abs/2311.07599","abstract":"Large language models (LLMs) have demonstrated unparalleled prowess in mimicking human-like text generation and processing. Among the myriad of applications that benefit from LLMs, automated code generation is increasingly promising. The potential to transform natural language prompts into executable code promises a major shift in software development practices and paves the way for significant reductions in manual coding efforts and the likelihood of human-induced errors. This paper reports the results of a study that evaluates the performance of various LLMs, such as Bard, ChatGPT-3.5, ChatGPT-4, and Claude-2, in generating Python for coding problems. We focus on how levels of prompt specificity impact the accuracy, time efficiency, and space efficiency of the generated code. A benchmark of 104 coding problems, each with four types of prompts with varying degrees of tests and specificity, was employed to examine these aspects comprehensively. Our results indicate significant variations in performance across different LLMs and prompt types, and its key contribution is to reveal the ideal prompting strategy for creating accurate Python functions. This study lays the groundwork for further research in LLM capabilities and suggests practical implications for utilizing LLMs in automated code generation tasks and test-driven development.","creator":"Lincoln Murr, Morgan Grainger, David Gao"},{"id":"2311.07601","slug":"online-advertisements-with-llms-opportunities-and-challenges-arxiv-2311-07601v1-cs-cy","title":"Online Advertisements with LLMs: Opportunities and Challenges.","link":"http://arxiv.org/abs/2311.07601","abstract":"This paper explores the potential for leveraging Large Language Models (LLM) in the realm of online advertising systems. We delve into essential requirements including privacy, latency, reliability, users and advertisers' satisfaction, which such a system must fulfill. We further introduce a general framework for LLM advertisement, consisting of modification, bidding, prediction, and auction modules. Different design considerations for each module is presented, with an in-depth examination of their practicality and the technical challenges inherent to their implementation.","creator":"Soheil Feizi, MohammadTaghi Hajiaghayi, Keivan Rezaei, Suho Shin"},{"id":"2311.07604","slug":"finetuning-text-to-image-diffusion-models-for-fairness-arxiv-2311-07604v1-cs-lg","title":"Finetuning Text-to-Image Diffusion Models for Fairness.","link":"http://arxiv.org/abs/2311.07604","abstract":"The rapid adoption of text-to-image diffusion models in society underscores an urgent need to address their biases. Without interventions, these biases could propagate a distorted worldview and limit opportunities for minority groups. In this work, we frame fairness as a distributional alignment problem. Our solution consists of two main technical contributions: (1) a distributional alignment loss that steers specific characteristics of the generated images towards a user-defined target distribution, and (2) biased direct finetuning of diffusion model's sampling process, which leverages a biased gradient to more effectively optimize losses defined on the generated images. Empirically, our method markedly reduces gender, racial, and their intersectional biases for occupational prompts. Gender bias is significantly reduced even when finetuning just five soft tokens. Crucially, our method supports diverse perspectives of fairness beyond absolute equality, which is demonstrated by controlling age to a $75\\%$ young and $25\\%$ old distribution while simultaneously debiasing gender and race. Finally, our method is scalable: it can debias multiple concepts at once by simply including these prompts in the finetuning data. We hope our work facilitates the social alignment of T2I generative AI. We will share code and various debiased diffusion model adaptors.","creator":"Xudong Shen, Chao Du, Tianyu Pang, Min Lin, Yongkang Wong, Mohan Kankanhalli"},{"id":"2311.07605","slug":"conceptual-model-interpreter-for-large-language-models-arxiv-2311-07605v1-cs-se","title":"Conceptual Model Interpreter for Large Language Models.","link":"http://arxiv.org/abs/2311.07605","abstract":"Large Language Models (LLMs) recently demonstrated capabilities for generating source code in common programming languages. Additionally, commercial products such as ChatGPT 4 started to provide code interpreters, allowing for the automatic execution of generated code fragments, instant feedback, and the possibility to develop and refine in a conversational fashion. With an exploratory research approach, this paper applies code generation and interpretation to conceptual models. The concept and prototype of a conceptual model interpreter is explored, capable of rendering visual models generated in textual syntax by state-of-the-art LLMs such as Llama~2 and ChatGPT 4. In particular, these LLMs can generate textual syntax for the PlantUML and Graphviz modeling software that is automatically rendered within a conversational user interface. The first result is an architecture describing the components necessary to interact with interpreters and LLMs through APIs or locally, providing support for many commercial and open source LLMs and interpreters. Secondly, experimental results for models generated with ChatGPT 4 and Llama 2 are discussed in two cases covering UML and, on an instance level, graphs created from custom data. The results indicate the possibility of modeling iteratively in a conversational fashion.","creator":"Felix H&#xe4;rer"},{"id":"2311.07607","slug":"modeling-choice-via-self-attention-arxiv-2311-07607v1-cs-ai","title":"Modeling Choice via Self-Attention.","link":"http://arxiv.org/abs/2311.07607","abstract":"Models of choice are a fundamental input to many now-canonical optimization problems in the field of Operations Management, including assortment, inventory, and price optimization. Naturally, accurate estimation of these models from data is a critical step in the application of these optimization problems in practice, and so it is perhaps surprising that such choice estimation has to now been accomplished almost exclusively, both in theory and in practice, (a) without the use of deep learning in any meaningful way, and (b) via evaluation on limited data with constantly-changing metrics. This is in stark contrast to the vast majority of similar learning applications, for which the practice of machine learning suggests that (a) neural network-based models are typically state-of-the-art, and (b) strict standardization on evaluation procedures (datasets, metrics, etc.) is crucial. Thus motivated, we first propose a choice model that is the first to successfully (both theoretically and practically) leverage a modern neural network architectural concept (self-attention). Theoretically, we show that our attention-based choice model is a low-rank generalization of the Halo Multinomial Logit model, a recent model that parsimoniously captures irrational choice effects and has seen empirical success. We prove that whereas the Halo-MNL requires $\\Omega(m^2)$ data samples to estimate, where $m$ is the number of products, our model supports a natural nonconvex estimator (in particular, that which a standard neural network implementation would apply) which admits a near-optimal stationary point with $O(m)$ samples. We then establish the first realistic-scale benchmark for choice estimation on real data and use this benchmark to run the largest evaluation of existing choice models to date. We find that the model we propose is dominant over both short-term and long-term data periods.","creator":"Joohwan Ko, Andrew A. Li"},{"id":"2311.07608","slug":"must-multimodal-spatiotemporal-graph-transformer-for-hospital-readmission-prediction-arxiv-2311-07608v1-cs-lg","title":"MuST: Multimodal Spatiotemporal Graph-Transformer for Hospital Readmission Prediction.","link":"http://arxiv.org/abs/2311.07608","abstract":"Hospital readmission prediction is considered an essential approach to decreasing readmission rates, which is a key factor in assessing the quality and efficacy of a healthcare system. Previous studies have extensively utilized three primary modalities, namely electronic health records (EHR), medical images, and clinical notes, to predict hospital readmissions. However, the majority of these studies did not integrate information from all three modalities or utilize the spatiotemporal relationships present in the dataset. This study introduces a novel model called the Multimodal Spatiotemporal Graph-Transformer (MuST) for predicting hospital readmissions. By employing Graph Convolution Networks and temporal transformers, we can effectively capture spatial and temporal dependencies in EHR and chest radiographs. We then propose a fusion transformer to combine the spatiotemporal features from the two modalities mentioned above with the features from clinical notes extracted by a pre-trained, domain-specific transformer. We assess the effectiveness of our methods using the latest publicly available dataset, MIMIC-IV. The experimental results indicate that the inclusion of multimodal features in MuST improves its performance in comparison to unimodal methods. Furthermore, our proposed pipeline outperforms the current leading methods in the prediction of hospital readmissions.","creator":"Yan Miao, Lequan Yu"},{"id":"2311.07616","slug":"reidtracker-sea-the-technical-report-of-boatrack-and-seadronessee-mot-challenge-at-macvi-of-wacv24-arxiv-2311-07616v1-cs-cv","title":"ReIDTracker Sea: the technical report of BoaTrack and SeaDronesSee-MOT challenge at MaCVi of WACV24.","link":"http://arxiv.org/abs/2311.07616","abstract":"Multi-Object Tracking is one of the most important technologies in maritime computer vision. Our solution tries to explore Multi-Object Tracking in maritime Unmanned Aerial vehicles (UAVs) and Unmanned Surface Vehicles (USVs) usage scenarios. Most of the current Multi-Object Tracking algorithms require complex association strategies and association information (2D location and motion, 3D motion, 3D depth, 2D appearance) to achieve better performance, which makes the entire tracking system extremely complex and heavy. At the same time, most of the current Multi-Object Tracking algorithms still require video annotation data which is costly to obtain for training. Our solution tries to explore Multi-Object Tracking in a completely unsupervised way. The scheme accomplishes instance representation learning by using self-supervision on ImageNet. Then, by cooperating with high-quality detectors, the multi-target tracking task can be completed simply and efficiently. The scheme achieved top 3 performance on both UAV-based Multi-Object Tracking with Reidentification and USV-based Multi-Object Tracking benchmarks and the solution won the championship in many multiple Multi-Object Tracking competitions. such as BDD100K MOT,MOTS, Waymo 2D MOT","creator":"Kaer Huang, Weitu Chong"},{"id":"2311.07618","slug":"large-language-models-understanding-of-math-source-criticism-and-extrapolation-arxiv-2311-07618v1-cs-lg","title":"Large Language Models' Understanding of Math: Source Criticism and Extrapolation.","link":"http://arxiv.org/abs/2311.07618","abstract":"It has been suggested that large language models such as GPT-4 have acquired some form of understanding beyond the correlations among the words in text including some understanding of mathematics as well. Here, we perform a critical inquiry into this claim by evaluating the mathematical understanding of the GPT-4 model. Considering that GPT-4's training set is a secret, it is not straightforward to evaluate whether the model's correct answers are based on a mathematical understanding or based on replication of proofs that the model has seen before. We specifically craft mathematical questions which their formal proofs are not readily available on the web, proofs that are more likely not seen by the GPT-4. We see that GPT-4 is unable to solve those problems despite their simplicity. It is hard to find scientific evidence suggesting that GPT-4 has acquired an understanding of even basic mathematical concepts. A straightforward way to find failure modes of GPT-4 in theorem proving is to craft questions where their formal proofs are not available on the web. Our finding suggests that GPT-4's ability is to reproduce, rephrase, and polish the mathematical proofs that it has seen before, and not in grasping mathematical concepts. We also see that GPT-4's ability to prove mathematical theorems is continuously expanding over time despite the claim that it is a fixed model. We suggest that the task of proving mathematical theorems in formal language is comparable to the methods used in search engines such as Google while predicting the next word in a sentence may be a misguided approach, a recipe that often leads to excessive extrapolation and eventual failures. Prompting the GPT-4 over and over may benefit the GPT-4 and the OpenAI, but we question whether it is valuable for machine learning or for theorem proving.","creator":"Roozbeh Yousefzadeh, Xuenan Cao"},{"id":"2311.07619","slug":"modeling-user-viewing-flow-using-large-language-models-for-article-recommendation-arxiv-2311-07619v1-cs-ir","title":"Modeling User Viewing Flow using Large Language Models for Article Recommendation.","link":"http://arxiv.org/abs/2311.07619","abstract":"This paper proposes the User Viewing Flow Modeling (SINGLE) method for the article recommendation task, which models the user constant preference and instant interest from user-clicked articles. Specifically, we employ a user constant viewing flow modeling method to summarize the user's general interest to recommend articles. We utilize Large Language Models (LLMs) to capture constant user preferences from previously clicked articles, such as skills and positions. Then we design the user instant viewing flow modeling method to build interactions between user-clicked article history and candidate articles. It attentively reads the representations of user-clicked articles and aims to learn the user's different interest views to match the candidate article. Our experimental results on the Alibaba Technology Association (ATA) website show the advantage of SINGLE, which achieves 2.4% improvements over previous baseline models in the online A/B test. Our further analyses illustrate that SINGLE has the ability to build a more tailored recommendation system by mimicking different article viewing behaviors of users and recommending more appropriate and diverse articles to match user interests.","creator":"Zhenghao Liu, Zulong Chen, Moufeng Zhang, Shaoyang Duan, Hong Wen, Liangyue Li, Nan Li, Yu Gu, Ge Yu"},{"id":"2311.07632","slug":"resmgcn-residual-message-graph-convolution-network-for-fast-biomedical-interactions-discovering-arxiv-2311-07632v1-cs-lg","title":"ResMGCN: Residual Message Graph Convolution Network for Fast Biomedical Interactions Discovering.","link":"http://arxiv.org/abs/2311.07632","abstract":"Biomedical information graphs are crucial for interaction discovering of biomedical information in modern age, such as identification of multifarious molecular interactions and drug discovery, which attracts increasing interests in biomedicine, bioinformatics, and human healthcare communities. Nowadays, more and more graph neural networks have been proposed to learn the entities of biomedical information and precisely reveal biomedical molecule interactions with state-of-the-art results. These methods remedy the fading of features from a far distance but suffer from remedying such problem at the expensive cost of redundant memory and time. In our paper, we propose a novel Residual Message Graph Convolution Network (ResMGCN) for fast and precise biomedical interaction prediction in a different idea. Specifically, instead of enhancing the message from far nodes, ResMGCN aggregates lower-order information with the next round higher information to guide the node update to obtain a more meaningful node representation. ResMGCN is able to perceive and preserve various messages from the previous layer and high-order information in the current layer with least memory and time cost to obtain informative representations of biomedical entities. We conduct experiments on four biomedical interaction network datasets, including protein-protein, drug-drug, drug-target, and gene-disease interactions, which demonstrates that ResMGCN outperforms previous state-of-the-art models while achieving superb effectiveness on both storage and time.","creator":"Zecheng Yin"},{"id":"2311.07633","slug":"rethinking-and-benchmarking-predict-then-optimize-paradigm-for-combinatorial-optimization-problems-arxiv-2311-07633v1-cs-lg","title":"Rethinking and Benchmarking Predict-then-Optimize Paradigm for Combinatorial Optimization Problems.","link":"http://arxiv.org/abs/2311.07633","abstract":"Numerous web applications rely on solving combinatorial optimization problems, such as energy cost-aware scheduling, budget allocation on web advertising, and graph matching on social networks. However, many optimization problems involve unknown coefficients, and improper predictions of these factors may lead to inferior decisions which may cause energy wastage, inefficient resource allocation, inappropriate matching in social networks, etc. Such a research topic is referred to as \"Predict-Then-Optimize (PTO)\" which considers the performance of prediction and decision-making in a unified system. A noteworthy recent development is the end-to-end methods by directly optimizing the ultimate decision quality which claims to yield better results in contrast to the traditional two-stage approach. However, the evaluation benchmarks in this field are fragmented and the effectiveness of various models in different scenarios remains unclear, hindering the comprehensive assessment and fast deployment of these methods. To address these issues, we provide a comprehensive categorization of current approaches and integrate existing experimental scenarios to establish a unified benchmark, elucidating the circumstances under which end-to-end training yields improvements, as well as the contexts in which it performs ineffectively. We also introduce a new dataset for the industrial combinatorial advertising problem for inclusive finance to open-source. We hope the rethinking and benchmarking of PTO could facilitate more convenient evaluation and deployment, and inspire further improvements both in the academy and industry within this field.","creator":"Haoyu Geng, Han Ruan, Runzhong Wang, Yang Li, Yang Wang, Lei Chen, Junchi Yan"},{"id":"2311.07635","slug":"past-as-a-guide-leveraging-retrospective-learning-for-python-code-completion-arxiv-2311-07635v1-cs-se","title":"Past as a Guide: Leveraging Retrospective Learning for Python Code Completion.","link":"http://arxiv.org/abs/2311.07635","abstract":"This work presents Past as a Guide (PaG), a simple approach for Large Language Models (LLMs) to improve the coding capabilities by integrating the past history with interactive and iterative code refinements. To be specific, inspired by human cognitive processes, the proposed method enables LLMs to utilize previous programming and debugging experiences to enhance the Python code completion tasks. The framework facilitates LLMs to iteratively refine the Python code based on previous execution and debugging results and optimize learning and reasoning capabilities. The proposed methodology achieved a 92\\% pass@1 on HumanEval, demonstrating the potential to advance the field by leveraging retrospection from past experiences and interactive and iterative refinement processes without external correctness indicators.","creator":"Seunggyoon Shin, Seunggyu Chang, Sungjoon Choi"},{"id":"2311.07682","slug":"fuse-to-forget-bias-reduction-and-selective-memorization-through-model-fusion-arxiv-2311-07682v1-cs-cl","title":"Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion.","link":"http://arxiv.org/abs/2311.07682","abstract":"Model fusion research aims to aggregate the knowledge of multiple models to enhance performance by combining their weights. In this work, we study the inverse, investigating whether and how can model fusion interfere and reduce unwanted knowledge. We delve into the effects of model fusion on the evolution of learned shortcuts, social biases, and memorization capabilities in fine-tuned language models. Through several experiments covering text classification and generation tasks, our analysis highlights that shared knowledge among models is usually enhanced during model fusion, while unshared knowledge is usually lost or forgotten. Based on this observation, we demonstrate the potential of model fusion as a debiasing tool and showcase its efficacy in addressing privacy concerns associated with language models.","creator":"Kerem Zaman, Leshem Choshen, Shashank Srivastava"},{"id":"2311.07687","slug":"language-model-in-the-loop-data-optimal-approach-to-learn-to-recommend-actions-in-text-games-arxiv-2311-07687v1-cs-cl","title":"Language Model-In-The-Loop: Data Optimal Approach to Learn-To-Recommend Actions in Text Games.","link":"http://arxiv.org/abs/2311.07687","abstract":"Large Language Models (LLMs) have demonstrated superior performance in language understanding benchmarks. CALM, a popular approach, leverages linguistic priors of LLMs -- GPT-2 -- for action candidate recommendations to improve the performance in text games in Jericho without environment-provided actions. However, CALM adapts GPT-2 with annotated human gameplays and keeps the LLM fixed during the learning of the text based games. In this work, we explore and evaluate updating LLM used for candidate recommendation during the learning of the text based game as well to mitigate the reliance on the human annotated gameplays, which are costly to acquire. We observe that by updating the LLM during learning using carefully selected in-game transitions, we can reduce the dependency on using human annotated game plays for fine-tuning the LLMs. We conducted further analysis to study the transferability of the updated LLMs and observed that transferring in-game trained models to other games did not result in a consistent transfer.","creator":"Arjun Vaithilingam Sudhakar, Prasanna Parthasarathi, Janarthanan Rajendran, Sarath Chandar"},{"id":"2311.07692","slug":"on-the-truthfulness-of-surprisingly-likely-responses-of-large-language-models-arxiv-2311-07692v1-cs-lg","title":"On The Truthfulness of 'Surprisingly Likely' Responses of Large Language Models.","link":"http://arxiv.org/abs/2311.07692","abstract":"The surprisingly likely criterion in the seminal work of Prelec (the Bayesian Truth Serum) guarantees truthfulness in a game-theoretic multi-agent setting, by rewarding rational agents to maximise the expected information gain with their answers w.r.t. their probabilistic beliefs. We investigate the relevance of a similar criterion for responses of LLMs. We hypothesize that if the surprisingly likely criterion works in LLMs, under certain conditions, the responses that maximize the reward under this criterion should be more accurate than the responses that only maximize the posterior probability. Using benchmarks including the TruthfulQA benchmark and using openly available LLMs: GPT-2 and LLaMA-2, we show that the method indeed improves the accuracy significantly (for example, upto 24 percentage points aggregate improvement on TruthfulQA and upto 70 percentage points improvement on individual categories of questions).","creator":"Naman Goel"},{"id":"2311.07700","slug":"authentigpt-detecting-machine-generated-text-via-black-box-language-models-denoising-arxiv-2311-07700v1-cs-cl","title":"AuthentiGPT: Detecting Machine-Generated Text via Black-Box Language Models Denoising.","link":"http://arxiv.org/abs/2311.07700","abstract":"Large language models (LLMs) have opened up enormous opportunities while simultaneously posing ethical dilemmas. One of the major concerns is their ability to create text that closely mimics human writing, which can lead to potential misuse, such as academic misconduct, disinformation, and fraud. To address this problem, we present AuthentiGPT, an efficient classifier that distinguishes between machine-generated and human-written texts. Under the assumption that human-written text resides outside the distribution of machine-generated text, AuthentiGPT leverages a black-box LLM to denoise input text with artificially added noise, and then semantically compares the denoised text with the original to determine if the content is machine-generated. With only one trainable parameter, AuthentiGPT eliminates the need for a large training dataset, watermarking the LLM's output, or computing the log-likelihood. Importantly, the detection capability of AuthentiGPT can be easily adapted to any generative language model. With a 0.918 AUROC score on a domain-specific dataset, AuthentiGPT demonstrates its effectiveness over other commercial algorithms, highlighting its potential for detecting machine-generated text in academic settings.","creator":"Zhen Guo, Shangdi Yu"},{"id":"2311.07705","slug":"robust-and-scalable-hyperdimensional-computing-with-brain-like-neural-adaptations-arxiv-2311-07705v1-cs-lg","title":"Robust and Scalable Hyperdimensional Computing With Brain-Like Neural Adaptations.","link":"http://arxiv.org/abs/2311.07705","abstract":"The Internet of Things (IoT) has facilitated many applications utilizing edge-based machine learning (ML) methods to analyze locally collected data. Unfortunately, popular ML algorithms often require intensive computations beyond the capabilities of today's IoT devices. Brain-inspired hyperdimensional computing (HDC) has been introduced to address this issue. However, existing HDCs use static encoders, requiring extremely high dimensionality and hundreds of training iterations to achieve reasonable accuracy. This results in a huge efficiency loss, severely impeding the application of HDCs in IoT systems. We observed that a main cause is that the encoding module of existing HDCs lacks the capability to utilize and adapt to information learned during training. In contrast, neurons in human brains dynamically regenerate all the time and provide more useful functionalities when learning new information. While the goal of HDC is to exploit the high-dimensionality of randomly generated base hypervectors to represent the information as a pattern of neural activity, it remains challenging for existing HDCs to support a similar behavior as brain neural regeneration. In this work, we present dynamic HDC learning frameworks that identify and regenerate undesired dimensions to provide adequate accuracy with significantly lowered dimensionalities, thereby accelerating both the training and inference.","creator":"Junyao Wang, Mohammad Abdullah Al Faruque"},{"id":"2311.07708","slug":"reinforcement-learning-for-solving-stochastic-vehicle-routing-problem-arxiv-2311-07708v1-cs-ai","title":"Reinforcement Learning for Solving Stochastic Vehicle Routing Problem.","link":"http://arxiv.org/abs/2311.07708","abstract":"This study addresses a gap in the utilization of Reinforcement Learning (RL) and Machine Learning (ML) techniques in solving the Stochastic Vehicle Routing Problem (SVRP) that involves the challenging task of optimizing vehicle routes under uncertain conditions. We propose a novel end-to-end framework that comprehensively addresses the key sources of stochasticity in SVRP and utilizes an RL agent with a simple yet effective architecture and a tailored training method. Through comparative analysis, our proposed model demonstrates superior performance compared to a widely adopted state-of-the-art metaheuristic, achieving a significant 3.43% reduction in travel costs. Furthermore, the model exhibits robustness across diverse SVRP settings, highlighting its adaptability and ability to learn optimal routing strategies in varying environments. The publicly available implementation of our framework serves as a valuable resource for future research endeavors aimed at advancing RL-based solutions for SVRP.","creator":"Zangir Iklassov, Ikboljon Sobirov, Ruben Solozabal, Martin Takac"},{"id":"2311.07711","slug":"histopathologic-cancer-detection-arxiv-2311-07711v1-cs-cv","title":"Histopathologic Cancer Detection.","link":"http://arxiv.org/abs/2311.07711","abstract":"Early diagnosis of the cancer cells is necessary for making an effective treatment plan and for the health and safety of a patient. Nowadays, doctors usually use a histological grade that pathologists determine by performing a semi-quantitative analysis of the histopathological and cytological features of hematoxylin-eosin (HE) stained histopathological images. This research contributes a potential classification model for cancer prognosis to efficiently utilize the valuable information underlying the HE-stained histopathological images. This work uses the PatchCamelyon benchmark datasets and trains them in a multi-layer perceptron and convolution model to observe the model's performance in terms of precision, Recall, F1 Score, Accuracy, and AUC Score. The evaluation result shows that the baseline convolution model outperforms the baseline MLP model. Also, this paper introduced ResNet50 and InceptionNet models with data augmentation, where ResNet50 is able to beat the state-of-the-art model. Furthermore, the majority vote and concatenation ensemble were evaluated and provided the future direction of using transfer learning and segmentation to understand the specific features.","creator":"Varan Singh Rohila, Neeraj Lalwani, Lochan Basyal"},{"id":"2311.07715","slug":"polyie-a-dataset-of-information-extraction-from-polymer-material-scientific-literature-arxiv-2311-07715v1-cs-cl","title":"PolyIE: A Dataset of Information Extraction from Polymer Material Scientific Literature.","link":"http://arxiv.org/abs/2311.07715","abstract":"Scientific information extraction (SciIE), which aims to automatically extract information from scientific literature, is becoming more important than ever. However, there are no existing SciIE datasets for polymer materials, which is an important class of materials used ubiquitously in our daily lives. To bridge this gap, we introduce POLYIE, a new SciIE dataset for polymer materials. POLYIE is curated from 146 full-length polymer scholarly articles, which are annotated with different named entities (i.e., materials, properties, values, conditions) as well as their N-ary relations by domain experts. POLYIE presents several unique challenges due to diverse lexical formats of entities, ambiguity between entities, and variable-length relations. We evaluate state-of-the-art named entity extraction and relation extraction models on POLYIE, analyze their strengths and weaknesses, and highlight some difficult cases for these models. To the best of our knowledge, POLYIE is the first SciIE benchmark for polymer materials, and we hope it will lead to more research efforts from the community on this challenging task. Our code and data are available on: https://github.com/jerry3027/PolyIE.","creator":"Jerry Junyang Cheung, Yuchen Zhuang, Yinghao Li, Pranav Shetty, Wantian Zhao, Sanjeev Grampurohit, Rampi Ramprasad, Chao Zhang"},{"id":"2311.07723","slug":"generalization-analogies-genies-a-testbed-for-generalizing-ai-oversight-to-hard-to-measure-domains-arxiv-2311-07723v1-cs-ai","title":"Generalization Analogies (GENIES): A Testbed for Generalizing AI Oversight to Hard-To-Measure Domains.","link":"http://arxiv.org/abs/2311.07723","abstract":"As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable. To better understand how reward models generalize, we craft 69 distribution shifts spanning 8 categories. We find that reward models do not learn to evaluate `instruction-following' by default and instead favor personas that resemble internet text. Techniques for interpreting reward models' internal representations achieve better generalization than standard fine-tuning, but still frequently fail to distinguish instruction-following from conflated behaviors. We consolidate the 15 most challenging distribution shifts into the GENaralization analogIES (GENIES) benchmark, which we hope will enable progress toward controlling reward model generalization.","creator":"Joshua Clymer, Garrett Baker, Rohan Subramani, Sam Wang"},{"id":"2311.07745","slug":"simplifying-complex-observation-models-in-continuous-pomdp-planning-with-probabilistic-guarantees-and-practice-arxiv-2311-07745v1-cs-ai","title":"Simplifying Complex Observation Models in Continuous POMDP Planning with Probabilistic Guarantees and Practice.","link":"http://arxiv.org/abs/2311.07745","abstract":"Solving partially observable Markov decision processes (POMDPs) with high dimensional and continuous observations, such as camera images, is required for many real life robotics and planning problems. Recent researches suggested machine learned probabilistic models as observation models, but their use is currently too computationally expensive for online deployment. We deal with the question of what would be the implication of using simplified observation models for planning, while retaining formal guarantees on the quality of the solution. Our main contribution is a novel probabilistic bound based on a statistical total variation distance of the simplified model. We show that it bounds the theoretical POMDP value w.r.t. original model, from the empirical planned value with the simplified model, by generalizing recent results of particle-belief MDP concentration bounds. Our calculations can be separated into offline and online parts, and we arrive at formal guarantees without having to access the costly model at all during planning, which is also a novel result. Finally, we demonstrate in simulation how to integrate the bound into the routine of an existing continuous online POMDP solver.","creator":"Idan Lev-Yehudi, Moran Barenboim, Vadim Indelman"},{"id":"2311.07750","slug":"synthensemble-a-fusion-of-cnn-vision-transformer-and-hybrid-models-for-multi-label-chest-x-ray-classification-arxiv-2311-07750v1-cs-cv","title":"SynthEnsemble: A Fusion of CNN, Vision Transformer, and Hybrid Models for Multi-Label Chest X-Ray Classification.","link":"http://arxiv.org/abs/2311.07750","abstract":"Chest X-rays are widely used to diagnose thoracic diseases, but the lack of detailed information about these abnormalities makes it challenging to develop accurate automated diagnosis systems, which is crucial for early detection and effective treatment. To address this challenge, we employed deep learning techniques to identify patterns in chest X-rays that correspond to different diseases. We conducted experiments on the \"ChestX-ray14\" dataset using various pre-trained CNNs, transformers, hybrid(CNN+Transformer) models and classical models. The best individual model was the CoAtNet, which achieved an area under the receiver operating characteristic curve (AUROC) of 84.2%. By combining the predictions of all trained models using a weighted average ensemble where the weight of each model was determined using differential evolution, we further improved the AUROC to 85.4%, outperforming other state-of-the-art methods in this field. Our findings demonstrate the potential of deep learning techniques, particularly ensemble deep learning, for improving the accuracy of automatic diagnosis of thoracic diseases from chest X-rays.","creator":"S.M. Nabil Ashraf, Md. Adyelullahil Mamun, Hasnat Md. Abdullah, Md. Golam Rabiul Alam"},{"id":"2311.07759","slug":"enabling-high-level-machine-reasoning-with-cognitive-neuro-symbolic-systems-arxiv-2311-07759v1-cs-ai","title":"Enabling High-Level Machine Reasoning with Cognitive Neuro-Symbolic Systems.","link":"http://arxiv.org/abs/2311.07759","abstract":"High-level reasoning can be defined as the capability to generalize over knowledge acquired via experience, and to exhibit robust behavior in novel situations. Such form of reasoning is a basic skill in humans, who seamlessly use it in a broad spectrum of tasks, from language communication to decision making in complex situations. When it manifests itself in understanding and manipulating the everyday world of objects and their interactions, we talk about common sense or commonsense reasoning. State-of-the-art AI systems don't possess such capability: for instance, Large Language Models have recently become popular by demonstrating remarkable fluency in conversing with humans, but they still make trivial mistakes when probed for commonsense competence; on a different level, performance degradation outside training data prevents self-driving vehicles to safely adapt to unseen scenarios, a serious and unsolved problem that limits the adoption of such technology. In this paper we propose to enable high-level reasoning in AI systems by integrating cognitive architectures with external neuro-symbolic components. We illustrate a hybrid framework centered on ACT-R and we discuss the role of generative models in recent and future applications.","creator":"Alessandro Oltramari"},{"id":"2311.07761","slug":"amodal-optical-flow-arxiv-2311-07761v1-cs-cv","title":"Amodal Optical Flow.","link":"http://arxiv.org/abs/2311.07761","abstract":"Optical flow estimation is very challenging in situations with transparent or occluded objects. In this work, we address these challenges at the task level by introducing Amodal Optical Flow, which integrates optical flow with amodal perception. Instead of only representing the visible regions, we define amodal optical flow as a multi-layered pixel-level motion field that encompasses both visible and occluded regions of the scene. To facilitate research on this new task, we extend the AmodalSynthDrive dataset to include pixel-level labels for amodal optical flow estimation. We present several strong baselines, along with the Amodal Flow Quality metric to quantify the performance in an interpretable manner. Furthermore, we propose the novel AmodalFlowNet as an initial step toward addressing this task. AmodalFlowNet consists of a transformer-based cost-volume encoder paired with a recurrent transformer decoder which facilitates recurrent hierarchical feature propagation and amodal semantic grounding. We demonstrate the tractability of amodal optical flow in extensive experiments and show its utility for downstream tasks such as panoptic tracking. We make the dataset, code, and trained models publicly available at this http URL","creator":"Maximilian Luz, Rohit Mohan, Ahmed Rida Sekkat, Oliver Sawade, Elmar Matthes, Thomas Brox, Abhinav Valada"},{"id":"2311.07763","slug":"the-disagreement-problem-in-faithfulness-metrics-arxiv-2311-07763v1-cs-lg","title":"The Disagreement Problem in Faithfulness Metrics.","link":"http://arxiv.org/abs/2311.07763","abstract":"The field of explainable artificial intelligence (XAI) aims to explain how black-box machine learning models work. Much of the work centers around the holy grail of providing post-hoc feature attributions to any model architecture. While the pace of innovation around novel methods has slowed down, the question remains of how to choose a method, and how to make it fit for purpose. Recently, efforts around benchmarking XAI methods have suggested metrics for that purpose -- but there are many choices. That bounty of choice still leaves an end user unclear on how to proceed. This paper focuses on comparing metrics with the aim of measuring faithfulness of local explanations on tabular classification problems -- and shows that the current metrics don't agree; leaving users unsure how to choose the most faithful explanations.","creator":"Brian Barr, Noah Fatsi, Leif Hancox-Li, Peter Richter, Daniel Proano, Caleb Mok"},{"id":"2311.07766","slug":"vision-language-integration-in-multimodal-video-transformers-partially-aligns-with-the-brain-arxiv-2311-07766v1-cs-cv","title":"Vision-Language Integration in Multimodal Video Transformers (Partially) Aligns with the Brain.","link":"http://arxiv.org/abs/2311.07766","abstract":"Integrating information from multiple modalities is arguably one of the essential prerequisites for grounding artificial intelligence systems with an understanding of the real world. Recent advances in video transformers that jointly learn from vision, text, and sound over time have made some progress toward this goal, but the degree to which these models integrate information from modalities still remains unclear. In this work, we present a promising approach for probing a pre-trained multimodal video transformer model by leveraging neuroscientific evidence of multimodal information processing in the brain. Using brain recordings of participants watching a popular TV show, we analyze the effects of multi-modal connections and interactions in a pre-trained multi-modal video transformer on the alignment with uni- and multi-modal brain regions. We find evidence that vision enhances masked prediction performance during language processing, providing support that cross-modal representations in models can benefit individual modalities. However, we don't find evidence of brain-relevant information captured by the joint multi-modal transformer representations beyond that captured by all of the individual modalities. We finally show that the brain alignment of the pre-trained joint representation can be improved by fine-tuning using a task that requires vision-language inferences. Overall, our results paint an optimistic picture of the ability of multi-modal transformers to integrate vision and language in partially brain-relevant ways but also show that improving the brain alignment of these models may require new approaches.","creator":"Dota Tianai Dong, Mariya Toneva"},{"id":"2311.07767","slug":"greekt5-a-series-of-greek-sequence-to-sequence-models-for-news-summarization-arxiv-2311-07767v1-cs-cl","title":"GreekT5: A Series of Greek Sequence-to-Sequence Models for News Summarization.","link":"http://arxiv.org/abs/2311.07767","abstract":"Text summarization (TS) is a natural language processing (NLP) subtask pertaining to the automatic formulation of a concise and coherent summary that covers the major concepts and topics from one or multiple documents. Recent advancements in deep learning have led to the development of abstractive summarization transformer-based models, which outperform classical approaches. In any case, research in this field focuses on high resource languages such as English, while the corresponding work for low resource languages is still underdeveloped. Taking the above into account, this paper proposes a series of novel TS models for Greek news articles. The proposed models were thoroughly evaluated on the same dataset against GreekBART, which is the state-of-the-art model in Greek abstractive news summarization. Our evaluation results reveal that most of the proposed models significantly outperform GreekBART on various evaluation metrics. We make our evaluation code public, aiming to increase the reproducibility of this work and facilitate future research in the field.","creator":"Nikolaos Giarelis, Charalampos Mastrokostas, Nikos Karacapilidis"},{"id":"2311.07780","slug":"parrot-trained-adversarial-examples-pushing-the-practicality-of-black-box-audio-attacks-against-speaker-recognition-models-arxiv-2311-07780v1-cs-sd","title":"Parrot-Trained Adversarial Examples: Pushing the Practicality of Black-Box Audio Attacks against Speaker Recognition Models.","link":"http://arxiv.org/abs/2311.07780","abstract":"Audio adversarial examples (AEs) have posed significant security challenges to real-world speaker recognition systems. Most black-box attacks still require certain information from the speaker recognition model to be effective (e.g., keeping probing and requiring the knowledge of similarity scores). This work aims to push the practicality of the black-box attacks by minimizing the attacker's knowledge about a target speaker recognition model. Although it is not feasible for an attacker to succeed with completely zero knowledge, we assume that the attacker only knows a short (or a few seconds) speech sample of a target speaker. Without any probing to gain further knowledge about the target model, we propose a new mechanism, called parrot training, to generate AEs against the target model. Motivated by recent advancements in voice conversion (VC), we propose to use the one short sentence knowledge to generate more synthetic speech samples that sound like the target speaker, called parrot speech. Then, we use these parrot speech samples to train a parrot-trained(PT) surrogate model for the attacker. Under a joint transferability and perception framework, we investigate different ways to generate AEs on the PT model (called PT-AEs) to ensure the PT-AEs can be generated with high transferability to a black-box target model with good human perceptual quality. Real-world experiments show that the resultant PT-AEs achieve the attack success rates of 45.8% - 80.8% against the open-source models in the digital-line scenario and 47.9% - 58.3% against smart devices, including Apple HomePod (Siri), Amazon Echo, and Google Home, in the over-the-air scenario.","creator":"Rui Duan, Zhe Qu, Leah Ding, Yao Liu, Zhuo Lu"},{"id":"2311.07815","slug":"cooperative-ai-via-decentralized-commitment-devices-arxiv-2311-07815v1-cs-ai","title":"Cooperative AI via Decentralized Commitment Devices.","link":"http://arxiv.org/abs/2311.07815","abstract":"Credible commitment devices have been a popular approach for robust multi-agent coordination. However, existing commitment mechanisms face limitations like privacy, integrity, and susceptibility to mediator or user strategic behavior. It is unclear if the cooperative AI techniques we study are robust to real-world incentives and attack vectors. However, decentralized commitment devices that utilize cryptography have been deployed in the wild, and numerous studies have shown their ability to coordinate algorithmic agents facing adversarial opponents with significant economic incentives, currently in the order of several million to billions of dollars. In this paper, we use examples in the decentralization and, in particular, Maximal Extractable Value (MEV) (arXiv:1904.05234) literature to illustrate the potential security issues in cooperative AI. We call for expanded research into decentralized commitments to advance cooperative AI capabilities for secure coordination in open environments and empirical testing frameworks to evaluate multi-agent coordination ability given real-world commitment constraints.","creator":"Xinyuan Sun, Davide Crapis, Matt Stephenson, Barnab&#xe9; Monnot, Thomas Thiery, Jonathan Passerat-Palmbach"},{"id":"2311.07816","slug":"leveraging-large-language-models-to-detect-influence-campaigns-in-social-media-arxiv-2311-07816v1-cs-si","title":"Leveraging Large Language Models to Detect Influence Campaigns in Social Media.","link":"http://arxiv.org/abs/2311.07816","abstract":"Social media influence campaigns pose significant challenges to public discourse and democracy. Traditional detection methods fall short due to the complexity and dynamic nature of social media. Addressing this, we propose a novel detection method using Large Language Models (LLMs) that incorporates both user metadata and network structures. By converting these elements into a text format, our approach effectively processes multilingual content and adapts to the shifting tactics of malicious campaign actors. We validate our model through rigorous testing on multiple datasets, showcasing its superior performance in identifying influence efforts. This research not only offers a powerful tool for detecting campaigns, but also sets the stage for future enhancements to keep up with the fast-paced evolution of social media-based influence tactics.","creator":"Luca Luceri, Eric Boniardi, Emilio Ferrara"},{"id":"2311.07822","slug":"a-neuro-inspired-hierarchical-reinforcement-learning-for-motor-control-arxiv-2311-07822v1-cs-ro","title":"A Neuro-Inspired Hierarchical Reinforcement Learning for Motor Control.","link":"http://arxiv.org/abs/2311.07822","abstract":"Designing controllers to achieve natural motion capabilities for multi-joint robots is a significant challenge. However, animals in nature are naturally with basic motor abilities and can master various complex motor skills through acquired learning. On the basis of analyzing the mechanism of the central motor system in mammals, we propose a neuro-inspired hierarchical reinforcement learning algorithm that enables robots to learn rich motor skills and apply them to complex task environments without relying on external data. We first design a skills network similar to the cerebellum by utilizing the selection mechanism of voluntary movements in the basal ganglia and the regulatory ability of the cerebellum to regulate movement. Subsequently, by imitating the structure of advanced centers in the motion system, we propose a high-level policy to generate different skill combinations, thereby enabling the robot to acquire natural motor abilities. We conduct experiments on 4 types of robots and 22 task environments, and the results show that the proposed method can enable different types of robots to achieve flexible motion skills. Overall, our research provides a promising framework for the design of robotic neural motor controllers.","creator":"Pei Zhang, Zhaobo Hua, Jinliang Ding"},{"id":"2311.07838","slug":"llatrieval-llm-verified-retrieval-for-verifiable-generation-arxiv-2311-07838v1-cs-cl","title":"LLatrieval: LLM-Verified Retrieval for Verifiable Generation.","link":"http://arxiv.org/abs/2311.07838","abstract":"Verifiable generation aims to let the large language model (LLM) generate text with corresponding supporting documents, which enables the user to flexibly verify the answer and makes it more trustworthy. Its evaluation not only measures the correctness of the answer, but also the answer's verifiability, i.e., how well the answer is supported by the corresponding documents. In typical, verifiable generation adopts the retrieval-read pipeline, which is divided into two stages: 1) retrieve relevant documents of the question. 2) according to the documents, generate the corresponding answer. Since the retrieved documents can supplement knowledge for the LLM to generate the answer and serve as evidence, the retrieval stage is essential for the correctness and verifiability of the answer. However, the widely used retrievers become the bottleneck of the entire pipeline and limit the overall performance. They often have fewer parameters than the large language model and have not been proven to scale well to the size of LLMs. Since the LLM passively receives the retrieval result, if the retriever does not correctly find the supporting documents, the LLM can not generate the correct and verifiable answer, which overshadows the LLM's remarkable abilities. In this paper, we propose LLatrieval (Large Language Model Verified Retrieval), where the LLM updates the retrieval result until it verifies that the retrieved documents can support answering the question. Thus, the LLM can iteratively provide feedback to retrieval and facilitate the retrieval result to sufficiently support verifiable generation. Experimental results show that our method significantly outperforms extensive baselines and achieves new state-of-the-art results.","creator":"Xiaonan Li, Changtai Zhu, Linyang Li, Zhangyue Yin, Tianxiang Sun, Xipeng Qiu"},{"id":"2311.07840","slug":"enabling-decision-support-systems-through-automated-cell-tower-detection-arxiv-2311-07840v1-cs-cv","title":"Enabling Decision-Support Systems through Automated Cell Tower Detection.","link":"http://arxiv.org/abs/2311.07840","abstract":"Cell phone coverage and high-speed service gaps persist in rural areas in sub-Saharan Africa, impacting public access to mobile-based financial, educational, and humanitarian services. Improving maps of telecommunications infrastructure can help inform strategies to eliminate gaps in mobile coverage. Deep neural networks, paired with remote sensing images, can be used for object detection of cell towers and eliminate the need for inefficient and burdensome manual mapping to find objects over large geographic regions. In this study, we demonstrate a partially automated workflow to train an object detection model to locate cell towers using OpenStreetMap (OSM) features and high-resolution Maxar imagery. For model fine-tuning and evaluation, we curated a diverse dataset of over 6,000 unique images of cell towers in 26 countries in eastern, southern, and central Africa using automatically generated annotations from OSM points. Our model achieves an average precision at 50% Intersection over Union (IoU) (AP@50) of 81.2 with good performance across different geographies and out-of-sample testing. Accurate localization of cell towers can yield more accurate cell coverage maps, in turn enabling improved delivery of digital services for decision-support applications.","creator":"Natasha Krell, Will Gleave, Daniel Nakada, Justin Downes, Amanda Willet, Matthew Baran"},{"id":"2311.07850","slug":"bring-your-own-kg-self-supervised-program-synthesis-for-zero-shot-kgqa-arxiv-2311-07850v1-cs-cl","title":"Bring Your Own KG: Self-Supervised Program Synthesis for Zero-Shot KGQA.","link":"http://arxiv.org/abs/2311.07850","abstract":"We present BYOKG, a universal question-answering (QA) system that can operate on any knowledge graph (KG), requires no human-annotated training data, and can be ready to use within a day -- attributes that are out-of-scope for current KGQA systems. BYOKG draws inspiration from the remarkable ability of humans to comprehend information present in an unseen KG through exploration -- starting at random nodes, inspecting the labels of adjacent nodes and edges, and combining them with their prior world knowledge. In BYOKG, exploration leverages an LLM-backed symbolic agent that generates a diverse set of query-program exemplars, which are then used to ground a retrieval-augmented reasoning procedure to predict programs for arbitrary questions. BYOKG is effective over both small- and large-scale graphs, showing dramatic gains in QA accuracy over a zero-shot baseline of 27.89 and 58.02 F1 on GrailQA and MetaQA, respectively. On GrailQA, we further show that our unsupervised BYOKG outperforms a supervised in-context learning method, demonstrating the effectiveness of exploration. Lastly, we find that performance of BYOKG reliably improves with continued exploration as well as improvements in the base LLM, notably outperforming a state-of-the-art fine-tuned model by 7.08 F1 on a sub-sampled zero-shot split of GrailQA.","creator":"Dhruv Agarwal, Rajarshi Das, Sopan Khosla, Rashmi Gangadharaiah"},{"id":"2311.07861","slug":"overview-of-the-trec-2023-product-product-search-track-arxiv-2311-07861v1-cs-ir","title":"Overview of the TREC 2023 Product Product Search Track.","link":"http://arxiv.org/abs/2311.07861","abstract":"This is the first year of the TREC Product search track. The focus this year was the creation of a reusable collection and evaluation of the impact of the use of metadata and multi-modal data on retrieval accuracy. This year we leverage the new product search corpus, which includes contextual metadata. Our analysis shows that in the product search domain, traditional retrieval systems are highly effective and commonly outperform general-purpose pretrained embedding models. Our analysis also evaluates the impact of using simplified and metadata-enhanced collections, finding no clear trend in the impact of the expanded collection. We also see some surprising outcomes; despite their widespread adoption and competitive performance on other tasks, we find single-stage dense retrieval runs can commonly be noncompetitive or generate low-quality results both in the zero-shot and fine-tuned domain.","creator":"Daniel Campos, Surya Kallumadi, Corby Rosset, Cheng Xiang Zhai, Alessandro Magnani"},{"id":"2311.07868","slug":"multi-signal-reconstruction-using-masked-autoencoder-from-eeg-during-polysomnography-arxiv-2311-07868v1-cs-lg","title":"Multi-Signal Reconstruction Using Masked Autoencoder From EEG During Polysomnography.","link":"http://arxiv.org/abs/2311.07868","abstract":"Polysomnography (PSG) is an indispensable diagnostic tool in sleep medicine, essential for identifying various sleep disorders. By capturing physiological signals, including EEG, EOG, EMG, and cardiorespiratory metrics, PSG presents a patient's sleep architecture. However, its dependency on complex equipment and expertise confines its use to specialized clinical settings. Addressing these limitations, our study aims to perform PSG by developing a system that requires only a single EEG measurement. We propose a novel system capable of reconstructing multi-signal PSG from a single-channel EEG based on a masked autoencoder. The masked autoencoder was trained and evaluated using the Sleep-EDF-20 dataset, with mean squared error as the metric for assessing the similarity between original and reconstructed signals. The model demonstrated proficiency in reconstructing multi-signal data. Our results present promise for the development of more accessible and long-term sleep monitoring systems. This suggests the expansion of PSG's applicability, enabling its use beyond the confines of clinics.","creator":"Young-Seok Kweon, Gi-Hwan Shin, Heon-Gyu Kwak, Ha-Na Jo, Seong-Whan Lee"},{"id":"2311.07870","slug":"automl-for-large-capacity-modeling-of-meta-ranking-systems-arxiv-2311-07870v1-cs-ir","title":"AutoML for Large Capacity Modeling of Meta Ranking Systems.","link":"http://arxiv.org/abs/2311.07870","abstract":"Web-scale ranking systems at Meta serving billions of users is complex. Improving ranking models is essential but engineering heavy. Automated Machine Learning (AutoML) can release engineers from labor intensive work of tuning ranking models; however, it is unknown if AutoML is efficient enough to meet tight production timeline in real-world and, at the same time, bring additional improvements to the strong baselines. Moreover, to achieve higher ranking performance, there is an ever-increasing demand to scale up ranking models to even larger capacity, which imposes more challenges on the efficiency. The large scale of models and tight production schedule requires AutoML to outperform human baselines by only using a small number of model evaluation trials (around 100). We presents a sampling-based AutoML method, focusing on neural architecture search and hyperparameter optimization, addressing these challenges in Meta-scale production when building large capacity models. Our approach efficiently handles large-scale data demands. It leverages a lightweight predictor-based searcher and reinforcement learning to explore vast search spaces, significantly reducing the number of model evaluations. Through experiments in large capacity modeling for CTR and CVR applications, we show that our method achieves outstanding Return on Investment (ROI) versus human tuned baselines, with up to 0.09% Normalized Entropy (NE) loss reduction or $25\\%$ Query per Second (QPS) increase by only sampling one hundred models on average from a curated search space. The proposed AutoML method has already made real-world impact where a discovered Instagram CTR model with up to -0.36% NE gain (over existing production baseline) was selected for large-scale online A/B test and show statistically significant gain. These production results proved AutoML efficacy and accelerated its adoption in ranking systems at Meta.","creator":"Hang Yin, Kuang-Hung Liu, Mengying Sun, Yuxin Chen, Buyun Zhang, Jiang Liu, Vivek Sehgal, Rudresh Rajnikant Panchal, Eugen Hotaj, Xi Liu, Daifeng Guo, Jamey Zhang, Zhou Wang, Shali Jiang, Huayu Li, Zhengxing Chen, Wen-Yen Chen, Jiyan Yang, Wei Wen"},{"id":"2311.07876","slug":"learning-adversarial-low-rank-markov-decision-processes-with-unknown-transition-and-full-information-feedback-arxiv-2311-07876v1-cs-lg","title":"Learning Adversarial Low-rank Markov Decision Processes with Unknown Transition and Full-information Feedback.","link":"http://arxiv.org/abs/2311.07876","abstract":"In this work, we study the low-rank MDPs with adversarially changed losses in the full-information feedback setting. In particular, the unknown transition probability kernel admits a low-rank matrix decomposition \\citep{REPUCB22}, and the loss functions may change adversarially but are revealed to the learner at the end of each episode. We propose a policy optimization-based algorithm POLO, and we prove that it attains the $\\widetilde{O}(K^{\\frac{5}{6}}A^{\\frac{1}{2}}d\\ln(1+M)/(1-\\gamma)^2)$ regret guarantee, where $d$ is rank of the transition kernel (and hence the dimension of the unknown representations), $A$ is the cardinality of the action space, $M$ is the cardinality of the model class, and $\\gamma$ is the discounted factor. Notably, our algorithm is oracle-efficient and has a regret guarantee with no dependence on the size of potentially arbitrarily large state space. Furthermore, we also prove an $\\Omega(\\frac{\\gamma^2}{1-\\gamma} \\sqrt{d A K})$ regret lower bound for this problem, showing that low-rank MDPs are statistically more difficult to learn than linear MDPs in the regret minimization setting. To the best of our knowledge, we present the first algorithm that interleaves representation learning, exploration, and exploitation to achieve the sublinear regret guarantee for RL with nonlinear function approximation and adversarial losses.","creator":"Canzhe Zhao, Ruofeng Yang, Baoxiang Wang, Xuezhou Zhang, Shuai Li"},{"id":"2311.07879","slug":"toxicity-detection-is-not-all-you-need-measuring-the-gaps-to-supporting-volunteer-content-moderators-arxiv-2311-07879v1-cs-cl","title":"Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators.","link":"http://arxiv.org/abs/2311.07879","abstract":"Extensive efforts in automated approaches for content moderation have been focused on developing models to identify toxic, offensive, and hateful content -- with the aim of lightening the load for moderators. Yet, it remains uncertain whether improvements on those tasks truly address the needs that moderators have in accomplishing their work. In this paper, we surface the gaps between past research efforts that have aimed to provide automation for aspects of the content moderation task, and the needs of volunteer content moderators. To do so, we conduct a model review on Hugging Face to reveal the availability of models to cover various moderation rules and guidelines. We further put state-of-the-art LLMs to the test (GPT-4 and Llama-2), evaluating how well these models perform in flagging violations of platform rules. Overall, we observe a non-trivial gap, as missing developed models and LLMs exhibit low recall on a significant portion of the rules.","creator":"Yang Trista Cao, Lovely-Frances Domingo, Sarah Ann Gilbert, Michelle Mazurek, Katie Shilton, Hal Daum&#xe9; III"},{"id":"2311.07880","slug":"vegaedge-edge-ai-confluence-anomaly-detection-for-real-time-highway-iot-applications-arxiv-2311-07880v1-cs-cv","title":"VegaEdge: Edge AI Confluence Anomaly Detection for Real-Time Highway IoT-Applications.","link":"http://arxiv.org/abs/2311.07880","abstract":"Vehicle anomaly detection plays a vital role in highway safety applications such as accident prevention, rapid response, traffic flow optimization, and work zone safety. With the surge of the Internet of Things (IoT) in recent years, there has arisen a pressing demand for Artificial Intelligence (AI) based anomaly detection methods designed to meet the requirements of IoT devices. Catering to this futuristic vision, we introduce a lightweight approach to vehicle anomaly detection by utilizing the power of trajectory prediction. Our proposed design identifies vehicles deviating from expected paths, indicating highway risks from different camera-viewing angles from real-world highway datasets. On top of that, we present VegaEdge - a sophisticated AI confluence designed for real-time security and surveillance applications in modern highway settings through edge-centric IoT-embedded platforms equipped with our anomaly detection approach. Extensive testing across multiple platforms and traffic scenarios showcases the versatility and effectiveness of VegaEdge. This work also presents the Carolinas Anomaly Dataset (CAD), to bridge the existing gap in datasets tailored for highway anomalies. In real-world scenarios, our anomaly detection approach achieves an AUC-ROC of 0.94, and our proposed VegaEdge design, on an embedded IoT platform, processes 738 trajectories per second in a typical highway setting. The dataset is available at https://github.com/TeCSAR-UNCC/Carolinas_Dataset#chd-anomaly-test-set .","creator":"Vinit Katariya, Fatema-E- Jannat, Armin Danesh Pazho, Ghazal Alinezhad Noghre, Hamed Tabkhi"},{"id":"2311.07885","slug":"one-2-3-45-fast-single-image-to-3d-objects-with-consistent-multi-view-generation-and-3d-diffusion-arxiv-2311-07885v1-cs-cv","title":"One-2-3-45++: Fast Single Image to 3D Objects with Consistent Multi-View Generation and 3D Diffusion.","link":"http://arxiv.org/abs/2311.07885","abstract":"Recent advancements in open-world 3D object generation have been remarkable, with image-to-3D methods offering superior fine-grained control over their text-to-3D counterparts. However, most existing models fall short in simultaneously providing rapid generation speeds and high fidelity to input images - two features essential for practical applications. In this paper, we present One-2-3-45++, an innovative method that transforms a single image into a detailed 3D textured mesh in approximately one minute. Our approach aims to fully harness the extensive knowledge embedded in 2D diffusion models and priors from valuable yet limited 3D data. This is achieved by initially finetuning a 2D diffusion model for consistent multi-view image generation, followed by elevating these images to 3D with the aid of multi-view conditioned 3D native diffusion models. Extensive experimental evaluations demonstrate that our method can produce high-quality, diverse 3D assets that closely mirror the original input image. Our project webpage: https://sudo-ai-3d.github.io/One2345plus_page.","creator":"Minghua Liu, Ruoxi Shi, Linghao Chen, Zhuoyang Zhang, Chao Xu, Xinyue Wei, Hansheng Chen, Chong Zeng, Jiayuan Gu, Hao Su"},{"id":"2311.07888","slug":"robosense-at-edge-detecting-slip-crumple-and-shape-of-the-object-in-robotic-hand-for-teleoprations-arxiv-2311-07888v1-cs-ro","title":"RoboSense At Edge: Detecting Slip, Crumple and Shape of the Object in Robotic Hand for Teleoprations.","link":"http://arxiv.org/abs/2311.07888","abstract":"Slip and crumple detection is essential for performing robust manipulation tasks with a robotic hand (RH) like remote surgery. It has been one of the challenging problems in the robotics manipulation community. In this work, we propose a technique based on machine learning (ML) based techniques to detect the slip, and crumple as well as the shape of an object that is currently held in the robotic hand. We proposed ML model will detect the slip, crumple, and shape using the force/torque exerted and the angular positions of the actuators present in the RH. The proposed model would be integrated into the loop of a robotic hand(RH) and haptic glove(HG). This would help us to reduce the latency in case of teleoperation","creator":"Sudev Kumar Padhi, Mohit Kumar, Debanka Giri, Subidh Ali"},{"id":"2311.07911","slug":"instruction-following-evaluation-for-large-language-models-arxiv-2311-07911v1-cs-cl","title":"Instruction-Following Evaluation for Large Language Models.","link":"http://arxiv.org/abs/2311.07911","abstract":"One core capability of Large Language Models (LLMs) is to follow natural language instructions. However, the evaluation of such abilities is not standardized: Human evaluations are expensive, slow, and not objectively reproducible, while LLM-based auto-evaluation is potentially biased or limited by the ability of the evaluator LLM. To overcome these issues, we introduce Instruction-Following Eval (IFEval) for large language models. IFEval is a straightforward and easy-to-reproduce evaluation benchmark. It focuses on a set of \"verifiable instructions\" such as \"write in more than 400 words\" and \"mention the keyword of AI at least 3 times\". We identified 25 types of those verifiable instructions and constructed around 500 prompts, with each prompt containing one or more verifiable instructions. We show evaluation results of two widely available LLMs on the market. Our code and data can be found at https://github.com/google-research/google-research/tree/master/instruction_following_eval","creator":"Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu, Yi Luan, Denny Zhou, Le Hou"},{"id":"2311.07925","slug":"brain-driven-representation-learning-based-on-diffusion-model-arxiv-2311-07925v1-cs-cl","title":"Brain-Driven Representation Learning Based on Diffusion Model.","link":"http://arxiv.org/abs/2311.07925","abstract":"Interpreting EEG signals linked to spoken language presents a complex challenge, given the data's intricate temporal and spatial attributes, as well as the various noise factors. Denoising diffusion probabilistic models (DDPMs), which have recently gained prominence in diverse areas for their capabilities in representation learning, are explored in our research as a means to address this issue. Using DDPMs in conjunction with a conditional autoencoder, our new approach considerably outperforms traditional machine learning algorithms and established baseline models in accuracy. Our results highlight the potential of DDPMs as a sophisticated computational method for the analysis of speech-related EEG signals. This could lead to significant advances in brain-computer interfaces tailored for spoken communication.","creator":"Soowon Kim, Seo-Hyun Lee, Young-Eun Lee, Ji-Won Lee, Ji-Ha Park, Seong-Whan Lee"},{"id":"2311.07928","slug":"towards-improving-robustness-against-common-corruptions-in-object-detectors-using-adversarial-contrastive-learning-arxiv-2311-07928v1-cs-cv","title":"Towards Improving Robustness Against Common Corruptions in Object Detectors Using Adversarial Contrastive Learning.","link":"http://arxiv.org/abs/2311.07928","abstract":"Neural networks have revolutionized various domains, exhibiting remarkable accuracy in tasks like natural language processing and computer vision. However, their vulnerability to slight alterations in input samples poses challenges, particularly in safety-critical applications like autonomous driving. Current approaches, such as introducing distortions during training, fall short in addressing unforeseen corruptions. This paper proposes an innovative adversarial contrastive learning framework to enhance neural network robustness simultaneously against adversarial attacks and common corruptions. By generating instance-wise adversarial examples and optimizing contrastive loss, our method fosters representations that resist adversarial perturbations and remain robust in real-world scenarios. Subsequent contrastive learning then strengthens the similarity between clean samples and their adversarial counterparts, fostering representations resistant to both adversarial attacks and common distortions. By focusing on improving performance under adversarial and real-world conditions, our approach aims to bolster the robustness of neural networks in safety-critical applications, such as autonomous vehicles navigating unpredictable weather conditions. We anticipate that this framework will contribute to advancing the reliability of neural networks in challenging environments, facilitating their widespread adoption in mission-critical scenarios.","creator":"Shashank Kotyan, Danilo Vasconcellos Vargas"},{"id":"2311.07941","slug":"non-autoregressive-machine-translation-with-probabilistic-context-free-grammar-arxiv-2311-07941v1-cs-cl","title":"Non-autoregressive Machine Translation with Probabilistic Context-free Grammar.","link":"http://arxiv.org/abs/2311.07941","abstract":"Non-autoregressive Transformer(NAT) significantly accelerates the inference of neural machine translation. However, conventional NAT models suffer from limited expression power and performance degradation compared to autoregressive (AT) models due to the assumption of conditional independence among target tokens. To address these limitations, we propose a novel approach called PCFG-NAT, which leverages a specially designed Probabilistic Context-Free Grammar (PCFG) to enhance the ability of NAT models to capture complex dependencies among output tokens. Experimental results on major machine translation benchmarks demonstrate that PCFG-NAT further narrows the gap in translation quality between NAT and AT models. Moreover, PCFG-NAT facilitates a deeper understanding of the generated sentences, addressing the lack of satisfactory explainability in neural machine translation.Code is publicly available at https://github.com/ictnlp/PCFG-NAT.","creator":"Shangtong Gui, Chenze Shao, Zhengrui Ma, Xishan Zhang, Yunji Chen, Yang Feng"},{"id":"2311.07946","slug":"the-impact-of-adversarial-node-placement-in-decentralized-federated-learning-networks-arxiv-2311-07946v1-cs-cr","title":"The Impact of Adversarial Node Placement in Decentralized Federated Learning Networks.","link":"http://arxiv.org/abs/2311.07946","abstract":"As Federated Learning (FL) grows in popularity, new decentralized frameworks are becoming widespread. These frameworks leverage the benefits of decentralized environments to enable fast and energy-efficient inter-device communication. However, this growing popularity also intensifies the need for robust security measures. While existing research has explored various aspects of FL security, the role of adversarial node placement in decentralized networks remains largely unexplored. This paper addresses this gap by analyzing the performance of decentralized FL for various adversarial placement strategies when adversaries can jointly coordinate their placement within a network. We establish two baseline strategies for placing adversarial node: random placement and network centrality-based placement. Building on this foundation, we propose a novel attack algorithm that prioritizes adversarial spread over adversarial centrality by maximizing the average network distance between adversaries. We show that the new attack algorithm significantly impacts key performance metrics such as testing accuracy, outperforming the baseline frameworks by between 9% and 66.5% for the considered setups. Our findings provide valuable insights into the vulnerabilities of decentralized FL systems, setting the stage for future research aimed at developing more secure and robust decentralized FL frameworks.","creator":"Adam Piaseczny, Eric Ruzomberka, Rohit Parasnis, Christopher G. Brinton"},{"id":"2311.07954","slug":"a-closer-look-at-the-self-verification-abilities-of-large-language-models-in-logical-reasoning-arxiv-2311-07954v1-cs-ai","title":"A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning.","link":"http://arxiv.org/abs/2311.07954","abstract":"Logical reasoning has been an ongoing pursuit in the field of AI. Despite significant advancements made by large language models (LLMs), they still struggle with complex logical reasoning problems. To enhance reasoning performance, one promising direction is scalable oversight, which requires LLMs to identify their own errors and then improve by themselves. Various self-verification methods have been proposed in pursuit of this goal. Nevertheless, whether existing models understand their own errors well is still under investigation. In this paper, we take a closer look at the self-verification abilities of LLMs in the context of logical reasoning, focusing on their ability to identify logical fallacies accurately. We introduce a dataset, FALLACIES, containing 232 types of reasoning fallacies categorized in a hierarchical taxonomy. By conducting exhaustive experiments on FALLACIES, we obtain comprehensive and detailed analyses of a series of models on their verification abilities. Our main findings suggest that existing LLMs could struggle to identify fallacious reasoning steps accurately and may fall short of guaranteeing the validity of self-verification methods. Drawing from these observations, we offer suggestions for future research and practical applications of self-verification methods.","creator":"Ruixin Hong, Hongming Zhang, Xinyu Pang, Dong Yu, Changshui Zhang"},{"id":"2311.07955","slug":"deep-learning-based-object-detection-in-maritime-unmanned-aerial-vehicle-imagery-review-and-experimental-comparisons-arxiv-2311-07955v1-cs-cv","title":"Deep Learning-Based Object Detection in Maritime Unmanned Aerial Vehicle Imagery: Review and Experimental Comparisons.","link":"http://arxiv.org/abs/2311.07955","abstract":"With the advancement of maritime unmanned aerial vehicles (UAVs) and deep learning technologies, the application of UAV-based object detection has become increasingly significant in the fields of maritime industry and ocean engineering. Endowed with intelligent sensing capabilities, the maritime UAVs enable effective and efficient maritime surveillance. To further promote the development of maritime UAV-based object detection, this paper provides a comprehensive review of challenges, relative methods, and UAV aerial datasets. Specifically, in this work, we first briefly summarize four challenges for object detection on maritime UAVs, i.e., object feature diversity, device limitation, maritime environment variability, and dataset scarcity. We then focus on computational methods to improve maritime UAV-based object detection performance in terms of scale-aware, small object detection, view-aware, rotated object detection, lightweight methods, and others. Next, we review the UAV aerial image/video datasets and propose a maritime UAV aerial dataset named MS2ship for ship detection. Furthermore, we conduct a series of experiments to present the performance evaluation and robustness analysis of object detection methods on maritime datasets. Eventually, we give the discussion and outlook on future works for maritime UAV-based object detection. The MS2ship dataset is available at \\href{https://github.com/zcj234/MS2ship}{https://github.com/zcj234/MS2ship}.","creator":"Chenjie Zhao, Ryan Wen Liu, Jingxiang Qu, Ruobin Gao"},{"id":"2311.07978","slug":"how-good-are-large-language-models-on-african-languages-arxiv-2311-07978v1-cs-cl","title":"How good are Large Language Models on African Languages?.","link":"http://arxiv.org/abs/2311.07978","abstract":"Recent advancements in natural language processing have led to the proliferation of large language models (LLMs). These models have been shown to yield good performance, using in-context learning, even on unseen tasks and languages. Additionally, they have been widely adopted as language-model-as-a-service commercial APIs like GPT-4 API. However, their performance on African languages is largely unknown. We present an analysis of three popular large language models (mT0, LLaMa 2, and GPT-4) on five tasks (news topic classification, sentiment classification, machine translation, question answering, and named entity recognition) across 30 African languages, spanning different language families and geographical regions. Our results suggest that all LLMs produce below-par performance on African languages, and there is a large gap in performance compared to high-resource languages like English most tasks. We find that GPT-4 has an average or impressive performance on classification tasks but very poor results on generative tasks like machine translation. Surprisingly, we find that mT0 had the best overall on cross-lingual QA, better than the state-of-the-art supervised model (i.e. fine-tuned mT5) and GPT-4 on African languages. Overall, LLaMa 2 records the worst performance due to its limited multilingual capabilities and English-centric pre-training corpus. In general, our findings present a call-to-action to ensure African languages are well represented in large language models, given their growing popularity.","creator":"Jessica Ojo, Kelechi Ogueji, Pontus Stenetorp, David I. Adelani"},{"id":"2311.07989","slug":"a-survey-on-language-models-for-code-arxiv-2311-07989v1-cs-cl","title":"A Survey on Language Models for Code.","link":"http://arxiv.org/abs/2311.07989","abstract":"In this work we systematically review the recent advancements in code processing with language models, covering 50+ models, 30+ evaluation tasks, and 500 related works. We break down code processing models into general language models represented by the GPT family and specialized models that are specifically pretrained on code, often with tailored objectives. We discuss the relations and differences between these models, and highlight the historical transition of code modeling from statistical models and RNNs to pretrained Transformers and LLMs, which is exactly the same course that had been taken by NLP. We also discuss code-specific features such as AST, CFG, and unit tests, along with their application in training code language models, and identify key challenges and potential future directions in this domain. We keep the survey open and updated on github repository at https://github.com/codefuse-ai/Awesome-Code-LLM.","creator":"Ziyin Zhang, Chaoyu Chen, Bingchang Liu, Cong Liao, Zi Gong, Hang Yu, Jianguo Li, Rui Wang"},{"id":"2311.07992","slug":"probable-object-location-polo-score-estimation-for-efficient-object-goal-navigation-arxiv-2311-07992v1-cs-ro","title":"Probable Object Location (POLo) Score Estimation for Efficient Object Goal Navigation.","link":"http://arxiv.org/abs/2311.07992","abstract":"To advance the field of autonomous robotics, particularly in object search tasks within unexplored environments, we introduce a novel framework centered around the Probable Object Location (POLo) score. Utilizing a 3D object probability map, the POLo score allows the agent to make data-driven decisions for efficient object search. We further enhance the framework's practicality by introducing POLoNet, a neural network trained to approximate the computationally intensive POLo score. Our approach addresses critical limitations of both end-to-end reinforcement learning methods, which suffer from memory decay over long-horizon tasks, and traditional map-based methods that neglect visibility constraints. Our experiments, involving the first phase of the OVMM 2023 challenge, demonstrate that an agent equipped with POLoNet significantly outperforms a range of baseline methods, including end-to-end RL techniques and prior map-based strategies. To provide a comprehensive evaluation, we introduce new performance metrics that offer insights into the efficiency and effectiveness of various agents in object goal navigation.","creator":"Jiaming Wang, Harold Soh"},{"id":"2311.08000","slug":"lipar-a-lightweight-parallel-learning-model-for-practical-in-vehicle-network-intrusion-detection-arxiv-2311-08000v1-cs-cr","title":"LiPar: A Lightweight Parallel Learning Model for Practical In-Vehicle Network Intrusion Detection.","link":"http://arxiv.org/abs/2311.08000","abstract":"With the development of intelligent transportation systems, vehicles are exposed to a complex network environment. As the main network of in-vehicle networks, the controller area network (CAN) has many potential security hazards, resulting in higher requirements for intrusion detection systems to ensure safety. Among intrusion detection technologies, methods based on deep learning work best without prior expert knowledge. However, they all have a large model size and rely on cloud computing, and are therefore not suitable to be installed on the in-vehicle network. Therefore, we propose a lightweight parallel neural network structure, LiPar, to allocate task loads to multiple electronic control units (ECU). The LiPar model consists of multi-dimensional branch convolution networks, spatial and temporal feature fusion learning, and a resource adaptation algorithm. Through experiments, we prove that LiPar has great detection performance, running efficiency, and lightweight model size, which can be well adapted to the in-vehicle environment practically and protect the in-vehicle CAN bus security.","creator":"Aiheng Zhang, Kai Wang, Bailing Wang, Yulei Wu"},{"id":"2311.08002","slug":"temptabqa-temporal-question-answering-for-semi-structured-tables-arxiv-2311-08002v1-cs-cl","title":"TempTabQA: Temporal Question Answering for Semi-Structured Tables.","link":"http://arxiv.org/abs/2311.08002","abstract":"Semi-structured data, such as Infobox tables, often include temporal information about entities, either implicitly or explicitly. Can current NLP systems reason about such information in semi-structured tables? To tackle this question, we introduce the task of temporal question answering on semi-structured tables. We present a dataset, TempTabQA, which comprises 11,454 question-answer pairs extracted from 1,208 Wikipedia Infobox tables spanning more than 90 distinct domains. Using this dataset, we evaluate several state-of-the-art models for temporal reasoning. We observe that even the top-performing LLMs lag behind human performance by more than 13.5 F1 points. Given these results, our dataset has the potential to serve as a challenging benchmark to improve the temporal reasoning capabilities of NLP models.","creator":"Vivek Gupta, Pranshu Kandoi, Mahek Bhavesh Vora, Shuo Zhang, Yujie He, Ridho Reinanda, Vivek Srikumar"},{"id":"2311.08005","slug":"iterative-missing-value-imputation-based-on-feature-importance-arxiv-2311-08005v1-cs-lg","title":"Iterative missing value imputation based on feature importance.","link":"http://arxiv.org/abs/2311.08005","abstract":"Many datasets suffer from missing values due to various reasons,which not only increases the processing difficulty of related tasks but also reduces the accuracy of classification. To address this problem, the mainstream approach is to use missing value imputation to complete the dataset. Existing imputation methods estimate the missing parts based on the observed values in the original feature space, and they treat all features as equally important during data completion, while in fact different features have different importance. Therefore, we have designed an imputation method that considers feature importance. This algorithm iteratively performs matrix completion and feature importance learning, and specifically, matrix completion is based on a filling loss that incorporates feature importance. Our experimental analysis involves three types of datasets: synthetic datasets with different noisy features and missing values, real-world datasets with artificially generated missing values, and real-world datasets originally containing missing values. The results on these datasets consistently show that the proposed method outperforms the existing five imputation algorithms.To the best of our knowledge, this is the first work that considers feature importance in the imputation model.","creator":"Cong Guo, Chun Liu, Wei Yang"},{"id":"2311.08010","slug":"distantly-supervised-named-entity-recognition-with-uncertainty-aware-teacher-learning-and-student-student-collaborative-learning-arxiv-2311-08010v1-cs-cl","title":"Distantly-Supervised Named Entity Recognition with Uncertainty-aware Teacher Learning and Student-student Collaborative Learning.","link":"http://arxiv.org/abs/2311.08010","abstract":"Distantly-Supervised Named Entity Recognition (DS-NER) effectively alleviates the burden of annotation, but meanwhile suffers from the label noise. Recent works attempt to adopt the teacher-student framework to gradually refine the training labels and improve the overall robustness. However, we argue that these teacher-student methods achieve limited performance because poor network calibration produces incorrectly pseudo-labeled samples, leading to error propagation. Therefore, we attempt to mitigate this issue by proposing: (1) Uncertainty-aware Teacher Learning that leverages the prediction uncertainty to guide the selection of pseudo-labels, avoiding the number of incorrect pseudo-labels in the self-training stage. (2) Student-student Collaborative Learning that allows the transfer of reliable labels between two student networks instead of completely relying on all pseudo-labels from its teacher. Meanwhile, this approach allows a full exploration of mislabeled samples rather than simply filtering unreliable pseudo-labeled samples. Extensive experimental results on five DS-NER datasets demonstrate that our method is superior to state-of-the-art teacher-student methods.","creator":"Helan Hu, Shuzheng Si, Haozhe Zhao, Shuang Zeng, Kaikai An, Zefan Cai, Baobao Chang"},{"id":"2311.08022","slug":"two-stage-predict-optimize-for-mixed-integer-linear-programs-with-unknown-parameters-in-constraints-arxiv-2311-08022v1-cs-ai","title":"Two-Stage Predict+Optimize for Mixed Integer Linear Programs with Unknown Parameters in Constraints.","link":"http://arxiv.org/abs/2311.08022","abstract":"Consider the setting of constrained optimization, with some parameters unknown at solving time and requiring prediction from relevant features. Predict+Optimize is a recent framework for end-to-end training supervised learning models for such predictions, incorporating information about the optimization problem in the training process in order to yield better predictions in terms of the quality of the predicted solution under the true parameters. Almost all prior works have focused on the special case where the unknowns appear only in the optimization objective and not the constraints. Hu et al.~proposed the first adaptation of Predict+Optimize to handle unknowns appearing in constraints, but the framework has somewhat ad-hoc elements, and they provided a training algorithm only for covering and packing linear programs. In this work, we give a new \\emph{simpler} and \\emph{more powerful} framework called \\emph{Two-Stage Predict+Optimize}, which we believe should be the canonical framework for the Predict+Optimize setting. We also give a training algorithm usable for all mixed integer linear programs, vastly generalizing the applicability of the framework. Experimental results demonstrate the superior prediction performance of our training framework over all classical and state-of-the-art methods.","creator":"Xinyi Hu, Jasper C.H. Lee, Jimmy H.M. Lee"},{"id":"2311.08035","slug":"data-driven-building-energy-efficiency-prediction-based-on-envelope-heat-losses-using-physics-informed-neural-networks-arxiv-2311-08035v1-cs-lg","title":"Data-driven building energy efficiency prediction based on envelope heat losses using physics-informed neural networks.","link":"http://arxiv.org/abs/2311.08035","abstract":"The analytical prediction of building energy performance in residential buildings based on the heat losses of its individual envelope components is a challenging task. It is worth noting that this field is still in its infancy, with relatively limited research conducted in this specific area to date, especially when it comes for data-driven approaches. In this paper we introduce a novel physics-informed neural network model for addressing this problem. Through the employment of unexposed datasets that encompass general building information, audited characteristics, and heating energy consumption, we feed the deep learning model with general building information, while the model's output consists of the structural components and several thermal properties that are in fact the basic elements of an energy performance certificate (EPC). On top of this neural network, a function, based on physics equations, calculates the energy consumption of the building based on heat losses and enhances the loss function of the deep learning model. This methodology is tested on a real case study for 256 buildings located in Riga, Latvia. Our investigation comes up with promising results in terms of prediction accuracy, paving the way for automated, and data-driven energy efficiency performance prediction based on basic properties of the building, contrary to exhaustive energy efficiency audits led by humans, which are the current status quo.","creator":"Vasilis Michalakopoulos, Sotiris Pelekis, Giorgos Kormpakis, Vagelis Karakolis, Spiros Mouzakitis, Dimitris Askounis"},{"id":"2311.08045","slug":"adversarial-preference-optimization-arxiv-2311-08045v1-cs-cl","title":"Adversarial Preference Optimization.","link":"http://arxiv.org/abs/2311.08045","abstract":"Human preference alignment is a crucial training step to improve the interaction quality of large language models (LLMs). Existing aligning methods depend on manually annotated preference data to guide the LLM optimization directions. However, in practice, continuously updating LLMs raises a distribution gap between model-generated samples and human-preferred responses, which hinders model fine-tuning efficiency. To mitigate this issue, previous methods require additional preference annotation on generated samples to adapt the shifted distribution, which consumes a large amount of annotation resources. Targeting more efficient human preference optimization, we propose an adversarial preference optimization (APO) framework, where the LLM agent and the preference model update alternatively via a min-max game. Without additional annotation, our APO method can make a self-adaption to the generation distribution gap through the adversarial learning process. In experiments, we empirically verify the effectiveness of APO in improving LLM's helpfulness and harmlessness compared with rejection sampling baselines.","creator":"Pengyu Cheng, Yifan Yang, Jian Li, Yong Dai, Nan Du"},{"id":"2311.08077","slug":"zero-shot-segmentation-of-eye-features-using-the-segment-anything-model-sam-arxiv-2311-08077v1-cs-cv","title":"Zero-Shot Segmentation of Eye Features Using the Segment Anything Model (SAM).","link":"http://arxiv.org/abs/2311.08077","abstract":"The advent of foundation models signals a new era in artificial intelligence. The Segment Anything Model (SAM) is the first foundation model for image segmentation. In this study, we evaluate SAM's ability to segment features from eye images recorded in virtual reality setups. The increasing requirement for annotated eye-image datasets presents a significant opportunity for SAM to redefine the landscape of data annotation in gaze estimation. Our investigation centers on SAM's zero-shot learning abilities and the effectiveness of prompts like bounding boxes or point clicks. Our results are consistent with studies in other domains, demonstrating that SAM's segmentation effectiveness can be on-par with specialized models depending on the feature, with prompts improving its performance, evidenced by an IoU of 93.34% for pupil segmentation in one dataset. Foundation models like SAM could revolutionize gaze estimation by enabling quick and easy image segmentation, reducing reliance on specialized models and extensive manual annotation.","creator":"Virmarie Maquiling, Sean Anthony Byrne, Diederick C. Niehorster, Marcus Nystr&#xf6;m, Enkelejda Kasneci"},{"id":"2311.08083","slug":"solving-arc-visual-analogies-with-neural-embeddings-and-vector-arithmetic-a-generalized-method-arxiv-2311-08083v1-cs-ai","title":"Solving ARC visual analogies with neural embeddings and vector arithmetic: A generalized method.","link":"http://arxiv.org/abs/2311.08083","abstract":"Analogical reasoning derives information from known relations and generalizes this information to similar yet unfamiliar situations. One of the first generalized ways in which deep learning models were able to solve verbal analogies was through vector arithmetic of word embeddings, essentially relating words that were mapped to a vector space (e.g., king - man + woman = __?). In comparison, most attempts to solve visual analogies are still predominantly task-specific and less generalizable. This project focuses on visual analogical reasoning and applies the initial generalized mechanism used to solve verbal analogies to the visual realm. Taking the Abstraction and Reasoning Corpus (ARC) as an example to investigate visual analogy solving, we use a variational autoencoder (VAE) to transform ARC items into low-dimensional latent vectors, analogous to the word embeddings used in the verbal approaches. Through simple vector arithmetic, underlying rules of ARC items are discovered and used to solve them. Results indicate that the approach works well on simple items with fewer dimensions (i.e., few colors used, uniform shapes), similar input-to-output examples, and high reconstruction accuracy on the VAE. Predictions on more complex items showed stronger deviations from expected outputs, although, predictions still often approximated parts of the item's rule set. Error patterns indicated that the model works as intended. On the official ARC paradigm, the model achieved a score of 2% (cf. current world record is 21%) and on ConceptARC it scored 8.8%. Although the methodology proposed involves basic dimensionality reduction techniques and standard vector arithmetic, this approach demonstrates promising outcomes on ARC and can easily be generalized to other abstract visual reasoning tasks.","creator":"Luca H. Thoms, Karel A. Veldkamp, Hannes Rosenbusch, Claire E. Stevenson"},{"id":"2311.08086","slug":"cpsor-gcn-a-vehicle-trajectory-prediction-method-powered-by-emotion-and-cognitive-theory-arxiv-2311-08086v1-cs-ai","title":"CPSOR-GCN: A Vehicle Trajectory Prediction Method Powered by Emotion and Cognitive Theory.","link":"http://arxiv.org/abs/2311.08086","abstract":"Active safety systems on vehicles often face problems with false alarms. Most active safety systems predict the driver's trajectory with the assumption that the driver is always in a normal emotion, and then infer risks. However, the driver's trajectory uncertainty increases under abnormal emotions. This paper proposes a new trajectory prediction model: CPSOR-GCN, which predicts vehicle trajectories under abnormal emotions. At the physical level, the interaction features between vehicles are extracted by the physical GCN module. At the cognitive level, SOR cognitive theory is used as prior knowledge to build a Dynamic Bayesian Network (DBN) structure. The conditional probability and state transition probability of nodes from the calibrated SOR-DBN quantify the causal relationship between cognitive factors, which is embedded into the cognitive GCN module to extract the characteristics of the influence mechanism of emotions on driving behavior. The CARLA-SUMO joint driving simulation platform was built to develop dangerous pre-crash scenarios. Methods of recreating traffic scenes were used to naturally induce abnormal emotions. The experiment collected data from 26 participants to verify the proposed model. Compared with the model that only considers physical motion features, the prediction accuracy of the proposed model is increased by 68.70%. Furthermore,considering the SOR-DBN reduces the prediction error of the trajectory by 15.93%. Compared with other advanced trajectory prediction models, the results of CPSOR-GCN also have lower errors. This model can be integrated into active safety systems to better adapt to the driver's emotions, which could effectively reduce false alarms.","creator":"L. Tang, Y. Li, J. Yuan, A. Fu, J. Sun"},{"id":"2311.08093","slug":"spot-a-natural-language-interface-for-geospatial-searches-in-osm-arxiv-2311-08093v1-cs-cl","title":"Spot: A Natural Language Interface for Geospatial Searches in OSM.","link":"http://arxiv.org/abs/2311.08093","abstract":"Investigative journalists and fact-checkers have found OpenStreetMap (OSM) to be an invaluable resource for their work due to its extensive coverage and intricate details of various locations, which play a crucial role in investigating news scenes. Despite its value, OSM's complexity presents considerable accessibility and usability challenges, especially for those without a technical background. To address this, we introduce 'Spot', a user-friendly natural language interface for querying OSM data. Spot utilizes a semantic mapping from natural language to OSM tags, leveraging artificially generated sentence queries and a T5 transformer. This approach enables Spot to extract relevant information from user-input sentences and display candidate locations matching the descriptions on a map. To foster collaboration and future advancement, all code and generated data is available as an open-source repository.","creator":"Lynn Khellaf, Ipek Baris Schlicht, Julia Bayer, Ruben Bouwmeester, Tilman Mira&#xdf;, Tilman Wagner"},{"id":"2311.08094","slug":"act-vit-a-representationally-robust-attention-architecture-for-skeleton-based-action-recognition-using-vision-transformer-arxiv-2311-08094v1-cs-cv","title":"Act-VIT: A Representationally Robust Attention Architecture for Skeleton Based Action Recognition Using Vision Transformer.","link":"http://arxiv.org/abs/2311.08094","abstract":"Skeleton-based action recognition receives the attention of many researchers as it is robust to viewpoint and illumination changes, and its processing is much more efficient than video frames. With the emergence of deep learning models, it has become very popular to represent the skeleton data in pseudo-image form and apply Convolutional Neural Networks for action recognition. Thereafter, studies concentrated on finding effective methods for forming pseudo-images. Recently, attention networks, more specifically transformers have provided promising results in various vision problems. In this study, the effectiveness of vision transformers for skeleton-based action recognition is examined and its robustness on the pseudo-image representation scheme is investigated. To this end, a three-level architecture, Act-VIT is proposed, which forms a set of pseudo images apply a classifier on each of the representation and combine their results to find the final action class. The classifiers of Act-VIT are first realized by CNNs and then by VITs and their performances are compared. Experimental studies reveal that the vision transformer is less sensitive to the initial pseudo-image representation compared to CNN. Nevertheless, even with the vision transformer, the recognition performance can be further improved by consensus of classifiers.","creator":"Ozge Oztimur Karadag"},{"id":"2311.08097","slug":"empowering-multi-step-reasoning-across-languages-via-tree-of-thoughts-arxiv-2311-08097v1-cs-cl","title":"Empowering Multi-step Reasoning across Languages via Tree-of-Thoughts.","link":"http://arxiv.org/abs/2311.08097","abstract":"Chain-of-Thought (CoT) prompting empowers the reasoning abilities of Large Language Models (LLMs), eliciting them to solve complex reasoning tasks step-by-step. However, with the success of CoT methods, the ability to deliver multi-step reasoning remains limited to English due to the imbalance in the distribution of the pre-training data, making the other languages a barrier.  In this work, we propose a Cross-lingual multi-step reasoning approach, aiming to align reasoning processes across different languages. In particular, our method, through a Self-consistent Cross-lingual prompting mechanism inspired by the Tree-of-Thoughts approach, delivers multi-step reasoning paths in different languages that, during the steps, lead to the final solution. Our experimental evaluations show that our method significantly outperforms existing prompting methods, reducing the number of interactions and achieving state-of-the-art performance.","creator":"Leonardo Ranaldi, Fabio Massimo Zanzotto"},{"id":"2311.08103","slug":"exploring-semi-supervised-hierarchical-stacked-encoder-for-legal-judgement-prediction-arxiv-2311-08103v1-cs-cl","title":"Exploring Semi-supervised Hierarchical Stacked Encoder for Legal Judgement Prediction.","link":"http://arxiv.org/abs/2311.08103","abstract":"Predicting the judgment of a legal case from its unannotated case facts is a challenging task. The lengthy and non-uniform document structure poses an even greater challenge in extracting information for decision prediction. In this work, we explore and propose a two-level classification mechanism; both supervised and unsupervised; by using domain-specific pre-trained BERT to extract information from long documents in terms of sentence embeddings further processing with transformer encoder layer and use unsupervised clustering to extract hidden labels from these embeddings to better predict a judgment of a legal case. We conduct several experiments with this mechanism and see higher performance gains than the previously proposed methods on the ILDC dataset. Our experimental results also show the importance of domain-specific pre-training of Transformer Encoders in legal information processing.","creator":"Nishchal Prasad, Mohand Boughanem, Taoufiq Dkaki"},{"id":"2311.08104","slug":"reimagining-speech-a-scoping-review-of-deep-learning-powered-voice-conversion-arxiv-2311-08104v1-cs-sd","title":"Reimagining Speech: A Scoping Review of Deep Learning-Powered Voice Conversion.","link":"http://arxiv.org/abs/2311.08104","abstract":"Research on deep learning-powered voice conversion (VC) in speech-to-speech scenarios is getting increasingly popular. Although many of the works in the field of voice conversion share a common global pipeline, there is a considerable diversity in the underlying structures, methods, and neural sub-blocks used across research efforts. Thus, obtaining a comprehensive understanding of the reasons behind the choice of the different methods in the voice conversion pipeline can be challenging, and the actual hurdles in the proposed solutions are often unclear. To shed light on these aspects, this paper presents a scoping review that explores the use of deep learning in speech analysis, synthesis, and disentangled speech representation learning within modern voice conversion systems. We screened 621 publications from more than 38 different venues between the years 2017 and 2023, followed by an in-depth review of a final database consisting of 123 eligible studies. Based on the review, we summarise the most frequently used approaches to voice conversion based on deep learning and highlight common pitfalls within the community. Lastly, we condense the knowledge gathered, identify main challenges and provide recommendations for future research directions.","creator":"Anders R. Bargum, Stefania Serafin, Cumhur Erkut"},{"id":"2311.08118","slug":"evaluating-neighbor-explainability-for-graph-neural-networks-arxiv-2311-08118v1-cs-lg","title":"Evaluating Neighbor Explainability for Graph Neural Networks.","link":"http://arxiv.org/abs/2311.08118","abstract":"Explainability in Graph Neural Networks (GNNs) is a new field growing in the last few years. In this publication we address the problem of determining how important is each neighbor for the GNN when classifying a node and how to measure the performance for this specific task. To do this, various known explainability methods are reformulated to get the neighbor importance and four new metrics are presented. Our results show that there is almost no difference between the explanations provided by gradient-based techniques in the GNN domain. In addition, many explainability techniques failed to identify important neighbors when GNNs without self-loops are used.","creator":"Oscar Llorente, P&#xe9;ter Vaderna, S&#xe1;ndor Laki, Roland Kotrocz&#xf3;, Rita Csoma, J&#xe1;nos M&#xe1;rk Szalai-Gindl"},{"id":"2311.08120","slug":"caring-trouble-and-musical-ai-considerations-towards-a-feminist-musical-ai-arxiv-2311-08120v1-cs-hc","title":"Caring Trouble and Musical AI: Considerations towards a Feminist Musical AI.","link":"http://arxiv.org/abs/2311.08120","abstract":"The ethics of AI as both material and medium for interaction remains in murky waters within the context of musical and artistic practice. The interdisciplinarity of the field is revealing matters of concern and care, which necessitate interdisciplinary methodologies for evaluation to trouble and critique the inheritance of \"residue-laden\" AI-tools in musical applications. Seeking to unsettle these murky waters, this paper critically examines the example of Holly+, a deep neural network that generates raw audio in the likeness of its creator Holly Herndon. Drawing from theoretical concerns and considerations from speculative feminism and care ethics, we care-fully trouble the structures, frameworks and assumptions that oscillate within and around Holly+. We contribute with several considerations and contemplate future directions for integrating speculative feminism and care into musical-AI agent and system design, derived from our critical feminist examination.","creator":"Kelsey Cotton, K&#x131;van&#xe7; Tatar"},{"id":"2311.08147","slug":"recall-a-benchmark-for-llms-robustness-against-external-counterfactual-knowledge-arxiv-2311-08147v1-cs-cl","title":"RECALL: A Benchmark for LLMs Robustness against External Counterfactual Knowledge.","link":"http://arxiv.org/abs/2311.08147","abstract":"LLMs and AI chatbots have improved people's efficiency in various fields. However, the necessary knowledge for answering the question may be beyond the models' knowledge boundaries. To mitigate this issue, many researchers try to introduce external knowledge, such as knowledge graphs and Internet contents, into LLMs for up-to-date information. However, the external information from the Internet may include counterfactual information that will confuse the model and lead to an incorrect response. Thus there is a pressing need for LLMs to possess the ability to distinguish reliable information from external knowledge. Therefore, to evaluate the ability of LLMs to discern the reliability of external knowledge, we create a benchmark from existing knowledge bases. Our benchmark consists of two tasks, Question Answering and Text Generation, and for each task, we provide models with a context containing counterfactual information. Evaluation results show that existing LLMs are susceptible to interference from unreliable external knowledge with counterfactual information, and simple intervention methods make limited contributions to the alleviation of this issue.","creator":"Yi Liu, Lianzhe Huang, Shicheng Li, Sishuo Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun"},{"id":"2311.08148","slug":"cattle-identification-using-muzzle-images-and-deep-learning-techniques-arxiv-2311-08148v1-cs-cv","title":"Cattle Identification Using Muzzle Images and Deep Learning Techniques.","link":"http://arxiv.org/abs/2311.08148","abstract":"Traditional animal identification methods such as ear-tagging, ear notching, and branding have been effective but pose risks to the animal and have scalability issues. Electrical methods offer better tracking and monitoring but require specialized equipment and are susceptible to attacks. Biometric identification using time-immutable dermatoglyphic features such as muzzle prints and iris patterns is a promising solution. This project explores cattle identification using 4923 muzzle images collected from 268 beef cattle. Two deep learning classification models are implemented - wide ResNet50 and VGG16\\_BN and image compression is done to lower the image quality and adapt the models to work for the African context. From the experiments run, a maximum accuracy of 99.5\\% is achieved while using the wide ResNet50 model with a compression retaining 25\\% of the original image. From the study, it is noted that the time required by the models to train and converge as well as recognition time are dependent on the machine used to run the model.","creator":"G. N. Kimani, P. Oluwadara, P. Fashingabo, M. Busogi, E. Luhanga, K. Sowon, L. Chacha ((1) CyLab-Africa / Upanzi Network, (2) Carnegie Mellon University Africa and (3) Carnegie Mellon University Pittsburgh)"},{"id":"2311.08150","slug":"the-hyperdimensional-transform-for-distributional-modelling-regression-and-classification-arxiv-2311-08150v1-cs-lg","title":"The Hyperdimensional Transform for Distributional Modelling, Regression and Classification.","link":"http://arxiv.org/abs/2311.08150","abstract":"Hyperdimensional computing (HDC) is an increasingly popular computing paradigm with immense potential for future intelligent applications. Although the main ideas already took form in the 1990s, HDC recently gained significant attention, especially in the field of machine learning and data science. Next to efficiency, interoperability and explainability, HDC offers attractive properties for generalization as it can be seen as an attempt to combine connectionist ideas from neural networks with symbolic aspects. In recent work, we introduced the hyperdimensional transform, revealing deep theoretical foundations for representing functions and distributions as high-dimensional holographic vectors. Here, we present the power of the hyperdimensional transform to a broad data science audience. We use the hyperdimensional transform as a theoretical basis and provide insight into state-of-the-art HDC approaches for machine learning. We show how existing algorithms can be modified and how this transform can lead to a novel, well-founded toolbox. Next to the standard regression and classification tasks of machine learning, our discussion includes various aspects of statistical modelling, such as representation, learning and deconvolving distributions, sampling, Bayesian inference, and uncertainty estimation.","creator":"Pieter Dewulf, Bernard De Baets, Michiel Stock"},{"id":"2311.08153","slug":"when-mining-electric-locomotives-meet-reinforcement-learning-arxiv-2311-08153v1-eess-sy","title":"When Mining Electric Locomotives Meet Reinforcement Learning.","link":"http://arxiv.org/abs/2311.08153","abstract":"As the most important auxiliary transportation equipment in coal mines, mining electric locomotives are mostly operated manually at present. However, due to the complex and ever-changing coal mine environment, electric locomotive safety accidents occur frequently these years. A mining electric locomotive control method that can adapt to different complex mining environments is needed. Reinforcement Learning (RL) is concerned with how artificial agents ought to take actions in an environment so as to maximize reward, which can help achieve automatic control of mining electric locomotive. In this paper, we present how to apply RL to the autonomous control of mining electric locomotives. To achieve more precise control, we further propose an improved epsilon-greedy (IEG) algorithm which can better balance the exploration and exploitation. To verify the effectiveness of this method, a co-simulation platform for autonomous control of mining electric locomotives is built which can complete closed-loop simulation of the vehicles. The simulation results show that this method ensures the locomotives following the front vehicle safely and responding promptly in the event of sudden obstacles on the road when the vehicle in complex and uncertain coal mine environments.","creator":"Ying Li, Zhencai Zhu, Xiaoqiang Li, Chunyu Yang, Hao Lu"},{"id":"2311.08154","slug":"ask-one-more-time-self-agreement-improves-reasoning-of-language-models-in-almost-all-scenarios-arxiv-2311-08154v1-cs-cl","title":"Ask One More Time: Self-Agreement Improves Reasoning of Language Models in (Almost) All Scenarios.","link":"http://arxiv.org/abs/2311.08154","abstract":"Although chain-of-thought (CoT) prompting combined with language models has achieved encouraging results on complex reasoning tasks, the naive greedy decoding used in CoT prompting usually causes the repetitiveness and local optimality. To address this shortcoming, ensemble-optimization tries to obtain multiple reasoning paths to get the final answer assembly. However, current ensemble-optimization methods either simply employ rule-based post-processing such as \\textit{self-consistency}, or train an additional model based on several task-related human annotations to select the best one among multiple reasoning paths, yet fail to generalize to realistic settings where the type of input questions is unknown or the answer format of reasoning paths is unknown. To avoid their limitations, we propose \\textbf{self-agreement}, a generalizable ensemble-optimization method applying in almost all scenarios where the type of input questions and the answer format of reasoning paths may be known or unknown. Self-agreement firstly samples from language model's decoder to generate a \\textit{diverse} set of reasoning paths, and subsequently prompts the language model \\textit{one more time} to determine the optimal answer by selecting the most \\textit{agreed} answer among the sampled reasoning paths. Self-agreement simultaneously achieves remarkable performance on six public reasoning benchmarks and superior generalization capabilities.","creator":"Lei Lin, Jiayi Fu, Pengli Liu, Junchen Wan, Fuzheng Zhang, Zhongyuan Wang, Di Zhang, Kun Gai"},{"id":"2311.08157","slug":"transformcode-a-contrastive-learning-framework-for-code-embedding-via-subtree-transformation-arxiv-2311-08157v1-cs-se","title":"TransformCode: A Contrastive Learning Framework for Code Embedding via Subtree transformation.","link":"http://arxiv.org/abs/2311.08157","abstract":"Large-scale language models have made great progress in the field of software engineering in recent years. They can be used for many code-related tasks such as code clone detection, code-to-code search, and method name prediction. However, these large-scale language models based on each code token have several drawbacks: They are usually large in scale, heavily dependent on labels, and require a lot of computing power and time to fine-tune new datasets.Furthermore, code embedding should be performed on the entire code snippet rather than encoding each code token. The main reason for this is that encoding each code token would cause model parameter inflation, resulting in a lot of parameters storing information that we are not very concerned about. In this paper, we propose a novel framework, called TransformCode, that learns about code embeddings in a contrastive learning manner. The framework uses the Transformer encoder as an integral part of the model. We also introduce a novel data augmentation technique called abstract syntax tree transformation: This technique applies syntactic and semantic transformations to the original code snippets to generate more diverse and robust anchor samples. Our proposed framework is both flexible and adaptable: It can be easily extended to other downstream tasks that require code representation such as code clone detection and classification. The framework is also very efficient and scalable: It does not require a large model or a large amount of training data, and can support any programming language.Finally, our framework is not limited to unsupervised learning, but can also be applied to some supervised learning tasks by incorporating task-specific labels or objectives. To explore the effectiveness of our framework, we conducted extensive experiments on different software engineering tasks using different programming languages and multiple datasets.","creator":"Zixiang Xian, Rubing Huang, Dave Towey, Chunrong Fang, Zhenyu Chen"},{"id":"2311.08166","slug":"mechagents-large-language-model-multi-agent-collaborations-can-solve-mechanics-problems-generate-new-data-and-integrate-knowledge-arxiv-2311-08166v1-cs-ai","title":"MechAgents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge.","link":"http://arxiv.org/abs/2311.08166","abstract":"Solving mechanics problems using numerical methods requires comprehensive intelligent capability of retrieving relevant knowledge and theory, constructing and executing codes, analyzing the results, a task that has thus far mainly been reserved for humans. While emerging AI methods can provide effective approaches to solve end-to-end problems, for instance via the use of deep surrogate models or various data analytics strategies, they often lack physical intuition since knowledge is baked into the parametric complement through training, offering less flexibility when it comes to incorporating mathematical or physical insights. By leveraging diverse capabilities of multiple dynamically interacting large language models (LLMs), we can overcome the limitations of conventional approaches and develop a new class of physics-inspired generative machine learning platform, here referred to as MechAgents. A set of AI agents can solve mechanics tasks, here demonstrated for elasticity problems, via autonomous collaborations. A two-agent team can effectively write, execute and self-correct code, in order to apply finite element methods to solve classical elasticity problems in various flavors (different boundary conditions, domain geometries, meshes, small/finite deformation and linear/hyper-elastic constitutive laws, and others). For more complex tasks, we construct a larger group of agents with enhanced division of labor among planning, formulating, coding, executing and criticizing the process and results. The agents mutually correct each other to improve the overall team-work performance in understanding, formulating and validating the solution. Our framework shows the potential of synergizing the intelligence of language models, the reliability of physics-based modeling, and the dynamic collaborations among diverse agents, opening novel avenues for automation of solving engineering problems.","creator":"Bo Ni, Markus J. Buehler"},{"id":"2311.08170","slug":"neural-lattice-reduction-a-self-supervised-geometric-deep-learning-approach-arxiv-2311-08170v1-cs-lg","title":"Neural Lattice Reduction: A Self-Supervised Geometric Deep Learning Approach.","link":"http://arxiv.org/abs/2311.08170","abstract":"Lattice reduction is a combinatorial optimization problem aimed at finding the most orthogonal basis in a given lattice. In this work, we address lattice reduction via deep learning methods. We design a deep neural model outputting factorized unimodular matrices and train it in a self-supervised manner by penalizing non-orthogonal lattice bases. We incorporate the symmetries of lattice reduction into the model by making it invariant and equivariant with respect to appropriate continuous and discrete groups.","creator":"Giovanni Luca Marchetti, Gabriele Cesa, Kumar Pratik, Arash Behboodi"},{"id":"2311.08179","slug":"semi-supervised-learning-via-swapped-prediction-for-communication-signal-recognition-arxiv-2311-08179v1-eess-sp","title":"Semi-Supervised Learning via Swapped Prediction for Communication Signal Recognition.","link":"http://arxiv.org/abs/2311.08179","abstract":"Deep neural networks have been widely used in communication signal recognition and achieved remarkable performance, but this superiority typically depends on using massive examples for supervised learning, whereas training a deep neural network on small datasets with few labels generally falls into overfitting, resulting in degenerated performance. To this end, we develop a semi-supervised learning (SSL) method that effectively utilizes a large collection of more readily available unlabeled signal data to improve generalization. The proposed method relies largely on a novel implementation of consistency-based regularization, termed Swapped Prediction, which leverages strong data augmentation to perturb an unlabeled sample and then encourage its corresponding model prediction to be close to its original, optimized with a scaled cross-entropy loss with swapped symmetry. Extensive experiments indicate that our proposed method can achieve a promising result for deep SSL of communication signal recognition.","creator":"Weidong Wang, Hongshu Liao, Lu Gan"},{"id":"2311.08195","slug":"automated-fact-checking-in-dialogue-are-specialized-models-needed-arxiv-2311-08195v1-cs-cl","title":"Automated Fact-Checking in Dialogue: Are Specialized Models Needed?.","link":"http://arxiv.org/abs/2311.08195","abstract":"Prior research has shown that typical fact-checking models for stand-alone claims struggle with claims made in dialogues. As a solution, fine-tuning these models on labelled dialogue data has been proposed. However, creating separate models for each use case is impractical, and we show that fine-tuning models for dialogue results in poor performance on typical fact-checking. To overcome this challenge, we present techniques that allow us to use the same models for both dialogue and typical fact-checking. These mainly focus on retrieval adaptation and transforming conversational inputs so that they can be accurately predicted by models trained on stand-alone claims. We demonstrate that a typical fact-checking model incorporating these techniques is competitive with state-of-the-art models fine-tuned for dialogue, while maintaining its accuracy on stand-alone claims.","creator":"Eric Chamoun, Marzieh Saeidi, Andreas Vlachos"},{"id":"2311.08206","slug":"human-centric-autonomous-systems-with-llms-for-user-command-reasoning-arxiv-2311-08206v1-cs-cl","title":"Human-Centric Autonomous Systems With LLMs for User Command Reasoning.","link":"http://arxiv.org/abs/2311.08206","abstract":"The evolution of autonomous driving has made remarkable advancements in recent years, evolving into a tangible reality. However, a human-centric large-scale adoption hinges on meeting a variety of multifaceted requirements. To ensure that the autonomous system meets the user's intent, it is essential to accurately discern and interpret user commands, especially in complex or emergency situations. To this end, we propose to leverage the reasoning capabilities of Large Language Models (LLMs) to infer system requirements from in-cabin users' commands. Through a series of experiments that include different LLM models and prompt designs, we explore the few-shot multivariate binary classification accuracy of system requirements from natural language textual commands. We confirm the general ability of LLMs to understand and reason about prompts but underline that their effectiveness is conditioned on the quality of both the LLM model and the design of appropriate sequential prompts. Code and models are public with the link \\url{https://github.com/KTH-RPL/DriveCmd_LLM}.","creator":"Yi Yang, Qingwen Zhang, Ci Li, Daniel Sim&#xf5;es Marta, Nazre Batool, John Folkesson"},{"id":"2311.08219","slug":"eval-gcsc-a-new-metric-for-evaluating-chatgpt-s-performance-in-chinese-spelling-correction-arxiv-2311-08219v1-cs-cl","title":"Eval-GCSC: A New Metric for Evaluating ChatGPT's Performance in Chinese Spelling Correction.","link":"http://arxiv.org/abs/2311.08219","abstract":"ChatGPT has demonstrated impressive performance in various downstream tasks. However, in the Chinese Spelling Correction (CSC) task, we observe a discrepancy: while ChatGPT performs well under human evaluation, it scores poorly according to traditional metrics. We believe this inconsistency arises because the traditional metrics are not well-suited for evaluating generative models. Their overly strict length and phonics constraints may lead to underestimating ChatGPT's correction capabilities. To better evaluate generative models in the CSC task, this paper proposes a new evaluation metric: Eval-GCSC. By incorporating word-level and semantic similarity judgments, it relaxes the stringent length and phonics constraints. Experimental results show that Eval-GCSC closely aligns with human evaluations. Under this metric, ChatGPT's performance is comparable to traditional token-level classification models (TCM), demonstrating its potential as a CSC tool. The source code and scripts can be accessed at https://github.com/ktlKTL/Eval-GCSC.","creator":"Kunting Li, Yong Hu, Shaolei Wang, Hanhan Ma, Liang He, Fandong Meng, Jie Zhou"},{"id":"2311.08239","slug":"learning-physics-inspired-regularization-for-medical-image-registration-with-hypernetworks-arxiv-2311-08239v1-eess-iv","title":"Learning Physics-Inspired Regularization for Medical Image Registration with Hypernetworks.","link":"http://arxiv.org/abs/2311.08239","abstract":"Medical image registration aims at identifying the spatial deformation between images of the same anatomical region and is fundamental to image-based diagnostics and therapy. To date, the majority of the deep learning-based registration methods employ regularizers that enforce global spatial smoothness, e.g., the diffusion regularizer. However, such regularizers are not tailored to the data and might not be capable of reflecting the complex underlying deformation. In contrast, physics-inspired regularizers promote physically plausible deformations. One such regularizer is the linear elastic regularizer which models the deformation of elastic material. These regularizers are driven by parameters that define the material's physical properties. For biological tissue, a wide range of estimations of such parameters can be found in the literature and it remains an open challenge to identify suitable parameter values for successful registration. To overcome this problem and to incorporate physical properties into learning-based registration, we propose to use a hypernetwork that learns the effect of the physical parameters of a physics-inspired regularizer on the resulting spatial deformation field. In particular, we adapt the HyperMorph framework to learn the effect of the two elasticity parameters of the linear elastic regularizer. Our approach enables the efficient discovery of suitable, data-specific physical parameters at test time.","creator":"Anna Reithmeir, Julia A. Schnabel, Veronika A. Zimmer"},{"id":"2311.08240","slug":"investigating-the-encoding-of-words-in-bert-s-neurons-using-feature-textualization-arxiv-2311-08240v1-cs-cl","title":"Investigating the Encoding of Words in BERT's Neurons using Feature Textualization.","link":"http://arxiv.org/abs/2311.08240","abstract":"Pretrained language models (PLMs) form the basis of most state-of-the-art NLP technologies. Nevertheless, they are essentially black boxes: Humans do not have a clear understanding of what knowledge is encoded in different parts of the models, especially in individual neurons. The situation is different in computer vision, where feature visualization provides a decompositional interpretability technique for neurons of vision models. Activation maximization is used to synthesize inherently interpretable visual representations of the information encoded in individual neurons. Our work is inspired by this but presents a cautionary tale on the interpretability of single neurons, based on the first large-scale attempt to adapt activation maximization to NLP, and, more specifically, large PLMs. We propose feature textualization, a technique to produce dense representations of neurons in the PLM word embedding space. We apply feature textualization to the BERT model (Devlin et al., 2019) to investigate whether the knowledge encoded in individual neurons can be interpreted and symbolized. We find that the produced representations can provide insights about the knowledge encoded in individual neurons, but that individual neurons do not represent clearcut symbolic units of language such as words. Additionally, we use feature textualization to investigate how many neurons are needed to encode words in BERT.","creator":"Tanja Baeumel, Soniya Vijayakumar, Josef van Genabith, Guenter Neumann, Simon Ostermann"},{"id":"2311.08252","slug":"rest-retrieval-based-speculative-decoding-arxiv-2311-08252v1-cs-cl","title":"REST: Retrieval-Based Speculative Decoding.","link":"http://arxiv.org/abs/2311.08252","abstract":"We introduce Retrieval-Based Speculative Decoding (REST), a novel algorithm designed to speed up language model generation. The key insight driving the development of REST is the observation that the process of text generation often includes certain common phases and patterns. Unlike previous methods that rely on a draft language model for speculative decoding, REST harnesses the power of retrieval to generate draft tokens. This method draws from the reservoir of existing knowledge, retrieving and employing relevant tokens based on the current context. Its plug-and-play nature allows for seamless integration and acceleration of any language models, all without necessitating additional training. When benchmarked on 7B and 13B language models in a single-batch setting, REST achieves a significant speedup of 1.62X to 2.36X on code or text generation. The code of REST is available at https://github.com/FasterDecoding/REST.","creator":"Zhenyu He, Zexuan Zhong, Tianle Cai, Jason D Lee, Di He"},{"id":"2311.08265","slug":"on-the-relationship-between-universal-adversarial-attacks-and-sparse-representations-arxiv-2311-08265v1-cs-cv","title":"On The Relationship Between Universal Adversarial Attacks And Sparse Representations.","link":"http://arxiv.org/abs/2311.08265","abstract":"The prominent success of neural networks, mainly in computer vision tasks, is increasingly shadowed by their sensitivity to small, barely perceivable adversarial perturbations in image input.  In this work, we aim at explaining this vulnerability through the framework of sparsity.  We show the connection between adversarial attacks and sparse representations, with a focus on explaining the universality and transferability of adversarial examples in neural networks.  To this end, we show that sparse coding algorithms, and the neural network-based learned iterative shrinkage thresholding algorithm (LISTA) among them, suffer from this sensitivity, and that common attacks on neural networks can be expressed as attacks on the sparse representation of the input image. The phenomenon that we observe holds true also when the network is agnostic to the sparse representation and dictionary, and thus can provide a possible explanation for the universality and transferability of adversarial attacks.  The code is available at https://github.com/danawr/adversarial_attacks_and_sparse_representations.","creator":"Dana Weitzner, Raja Giryes"},{"id":"2106.06854","slug":"a-deep-reinforcement-learning-approach-to-marginalized-importance-sampling-with-the-successor-representation-arxiv-2106-06854v2-cs-lg-updated","title":"A Deep Reinforcement Learning Approach to Marginalized Importance Sampling with the Successor Representation.","link":"http://arxiv.org/abs/2106.06854","abstract":"Marginalized importance sampling (MIS), which measures the density ratio between the state-action occupancy of a target policy and that of a sampling distribution, is a promising approach for off-policy evaluation. However, current state-of-the-art MIS methods rely on complex optimization tricks and succeed mostly on simple toy problems. We bridge the gap between MIS and deep reinforcement learning by observing that the density ratio can be computed from the successor representation of the target policy. The successor representation can be trained through deep reinforcement learning methodology and decouples the reward optimization from the dynamics of the environment, making the resulting algorithm stable and applicable to high-dimensional domains. We evaluate the empirical performance of our approach on a variety of challenging Atari and MuJoCo environments.","creator":"Scott Fujimoto, David Meger, Doina Precup"},{"id":"2201.10859","slug":"visualizing-the-diversity-of-representations-learned-by-bayesian-neural-networks-arxiv-2201-10859v2-cs-lg-updated","title":"Visualizing the Diversity of Representations Learned by Bayesian Neural Networks.","link":"http://arxiv.org/abs/2201.10859","abstract":"Explainable Artificial Intelligence (XAI) aims to make learning machines less opaque, and offers researchers and practitioners various tools to reveal the decision-making strategies of neural networks. In this work, we investigate how XAI methods can be used for exploring and visualizing the diversity of feature representations learned by Bayesian Neural Networks (BNNs). Our goal is to provide a global understanding of BNNs by making their decision-making strategies a) visible and tangible through feature visualizations and b) quantitatively measurable with a distance measure learned by contrastive learning. Our work provides new insights into the \\emph{posterior} distribution in terms of human-understandable feature information with regard to the underlying decision making strategies. The main findings of our work are the following: 1) global XAI methods can be applied to explain the diversity of decision-making strategies of BNN instances, 2) Monte Carlo dropout with commonly used Dropout rates exhibit increased diversity in feature representations compared to the multimodal posterior approximation of MultiSWAG, 3) the diversity of learned feature representations highly correlates with the uncertainty estimate for the output and 4) the inter-mode diversity of the multimodal posterior decreases as the network width increases, while the intra mode diversity increases. These findings are consistent with the recent Deep Neural Networks theory, providing additional intuitions about what the theory implies in terms of humanly understandable concepts.","creator":"Dennis Grinwald, Kirill Bykov, Shinichi Nakajima, Marina M.-C. H&#xf6;hne"},{"id":"2201.11239","slug":"diagnosing-ai-explanation-methods-with-folk-concepts-of-behavior-arxiv-2201-11239v5-cs-ai-updated","title":"Diagnosing AI Explanation Methods with Folk Concepts of Behavior.","link":"http://arxiv.org/abs/2201.11239","abstract":"We investigate a formalism for the conditions of a successful explanation of AI. We consider \"success\" to depend not only on what information the explanation contains, but also on what information the human explainee understands from it. Theory of mind literature discusses the folk concepts that humans use to understand and generalize behavior. We posit that folk concepts of behavior provide us with a \"language\" that humans understand behavior with. We use these folk concepts as a framework of social attribution by the human explainee - the information constructs that humans are likely to comprehend from explanations - by introducing a blueprint for an explanatory narrative (Figure 1) that explains AI behavior with these constructs. We then demonstrate that many XAI methods today can be mapped to folk concepts of behavior in a qualitative evaluation. This allows us to uncover their failure modes that prevent current methods from explaining successfully - i.e., the information constructs that are missing for any given XAI method, and whose inclusion can decrease the likelihood of misunderstanding AI behavior.","creator":"Alon Jacovi, Jasmijn Bastings, Sebastian Gehrmann, Yoav Goldberg, Katja Filippova"},{"id":"2210.03461","slug":"fastclipstyler-optimisation-free-text-based-image-style-transfer-using-style-representations-arxiv-2210-03461v4-cs-cv-updated","title":"FastCLIPstyler: Optimisation-free Text-based Image Style Transfer Using Style Representations.","link":"http://arxiv.org/abs/2210.03461","abstract":"In recent years, language-driven artistic style transfer has emerged as a new type of style transfer technique, eliminating the need for a reference style image by using natural language descriptions of the style. The first model to achieve this, called CLIPstyler, has demonstrated impressive stylisation results. However, its lengthy optimisation procedure at runtime for each query limits its suitability for many practical applications. In this work, we present FastCLIPstyler, a generalised text-based image style transfer model capable of stylising images in a single forward pass for arbitrary text inputs. Furthermore, we introduce EdgeCLIPstyler, a lightweight model designed for compatibility with resource-constrained devices. Through quantitative and qualitative comparisons with state-of-the-art approaches, we demonstrate that our models achieve superior stylisation quality based on measurable metrics while offering significantly improved runtime efficiency, particularly on edge devices.","creator":"Ananda Padhmanabhan Suresh, Sanjana Jain, Pavit Noinongyao, Ankush Ganguly, Ukrit Watchareeruetai, Aubin Samacoits"},{"id":"2210.03475","slug":"winner-takes-it-all-training-performant-rl-populations-for-combinatorial-optimization-arxiv-2210-03475v2-cs-ai-updated","title":"Winner Takes It All: Training Performant RL Populations for Combinatorial Optimization.","link":"http://arxiv.org/abs/2210.03475","abstract":"Applying reinforcement learning (RL) to combinatorial optimization problems is attractive as it removes the need for expert knowledge or pre-solved instances. However, it is unrealistic to expect an agent to solve these (often NP-)hard problems in a single shot at inference due to their inherent complexity. Thus, leading approaches often implement additional search strategies, from stochastic sampling and beam search to explicit fine-tuning. In this paper, we argue for the benefits of learning a population of complementary policies, which can be simultaneously rolled out at inference. To this end, we introduce Poppy, a simple training procedure for populations. Instead of relying on a predefined or hand-crafted notion of diversity, Poppy induces an unsupervised specialization targeted solely at maximizing the performance of the population. We show that Poppy produces a set of complementary policies, and obtains state-of-the-art RL results on four popular NP-hard problems: traveling salesman, capacitated vehicle routing, 0-1 knapsack, and job-shop scheduling.","creator":"Nathan Grinsztajn, Daniel Furelos-Blanco, Shikha Surana, Cl&#xe9;ment Bonnet, Thomas D. Barrett"},{"id":"2210.07410","slug":"identification-of-quantum-entanglement-with-siamese-convolutional-neural-networks-and-semi-supervised-learning-arxiv-2210-07410v3-quant-ph-updated","title":"Identification of quantum entanglement with Siamese convolutional neural networks and semi-supervised learning.","link":"http://arxiv.org/abs/2210.07410","abstract":"Quantum entanglement is a fundamental property commonly used in various quantum information protocols and algorithms. Nonetheless, the problem of identifying entanglement has still not reached a general solution for systems larger than two qubits. In this study, we use deep convolutional neural networks, a type of supervised machine learning, to identify quantum entanglement for any bipartition in a 3-qubit system. We demonstrate that training the model on synthetically generated datasets of random density matrices excluding challenging positive-under-partial-transposition entangled states (PPTES), which cannot be identified (and correctly labeled) in general, leads to good model accuracy even for PPTES states, that were outside the training data. Our aim is to enhance the model's generalization on PPTES. By applying entanglement-preserving symmetry operations through a triple Siamese network trained in a semi-supervised manner, we improve the model's accuracy and ability to recognize PPTES. Moreover, by constructing an ensemble of Siamese models, even better generalization is observed, in analogy with the idea of finding separate types of entanglement witnesses for different classes of states. The neural models' code and training schemes, as well as data generation procedures, are available at github.com/Maticraft/quantum_correlations.","creator":"Jaros&#x142;aw Paw&#x142;owski, Mateusz Krawczyk"},{"id":"2211.08253","slug":"hmoe-hypernetwork-based-mixture-of-experts-for-domain-generalization-arxiv-2211-08253v3-cs-lg-updated","title":"HMOE: Hypernetwork-based Mixture of Experts for Domain Generalization.","link":"http://arxiv.org/abs/2211.08253","abstract":"Due to domain shifts, machine learning systems typically struggle to generalize well to new domains that differ from those of training data, which is what domain generalization (DG) aims to address. Although a variety of DG methods have been proposed, most of them fall short in interpretability and require domain labels, which are not available in many real-world scenarios. This paper presents a novel DG method, called HMOE: Hypernetwork-based Mixture of Experts (MoE), which does not rely on domain labels and is more interpretable. MoE proves effective in identifying heterogeneous patterns in data. For the DG problem, heterogeneity arises exactly from domain shifts. HMOE employs hypernetworks taking vectors as input to generate the weights of experts, which promotes knowledge sharing among experts and enables the exploration of their similarities in a low-dimensional vector space. We benchmark HMOE against other DG methods under a fair evaluation framework -- DomainBed. Our extensive experiments show that HMOE can effectively separate mixed-domain data into distinct clusters that are surprisingly more consistent with human intuition than original domain labels. Using self-learned domain information, HMOE achieves state-of-the-art results on most datasets and significantly surpasses other DG methods in average accuracy across all datasets.","creator":"Jingang Qu, Thibault Faney, Ze Wang, Patrick Gallinari, Soleiman Yousef, Jean-Charles de Hemptinne"},{"id":"2211.10627","slug":"egrc-net-embedding-induced-graph-refinement-clustering-network-arxiv-2211-10627v2-cs-lg-updated","title":"EGRC-Net: Embedding-induced Graph Refinement Clustering Network.","link":"http://arxiv.org/abs/2211.10627","abstract":"Existing graph clustering networks heavily rely on a predefined yet fixed graph, which can lead to failures when the initial graph fails to accurately capture the data topology structure of the embedding space. In order to address this issue, we propose a novel clustering network called Embedding-Induced Graph Refinement Clustering Network (EGRC-Net), which effectively utilizes the learned embedding to adaptively refine the initial graph and enhance the clustering performance. To begin, we leverage both semantic and topological information by employing a vanilla auto-encoder and a graph convolution network, respectively, to learn a latent feature representation. Subsequently, we utilize the local geometric structure within the feature embedding space to construct an adjacency matrix for the graph. This adjacency matrix is dynamically fused with the initial one using our proposed fusion architecture. To train the network in an unsupervised manner, we minimize the Jeffreys divergence between multiple derived distributions. Additionally, we introduce an improved approximate personalized propagation of neural predictions to replace the standard graph convolution network, enabling EGRC-Net to scale effectively. Through extensive experiments conducted on nine widely-used benchmark datasets, we demonstrate that our proposed methods consistently outperform several state-of-the-art approaches. Notably, EGRC-Net achieves an improvement of more than 11.99\\% in Adjusted Rand Index (ARI) over the best baseline on the DBLP dataset. Furthermore, our scalable approach exhibits a 10.73% gain in ARI while reducing memory usage by 33.73% and decreasing running time by 19.71%. The code for EGRC-Net will be made publicly available at \\url{https://github.com/ZhihaoPENG-CityU/EGRC-Net}.","creator":"Zhihao Peng, Hui Liu, Yuheng Jia, Junhui Hou"},{"id":"2211.13854","slug":"comclip-training-free-compositional-image-and-text-matching-arxiv-2211-13854v3-cs-cv-updated","title":"ComCLIP: Training-Free Compositional Image and Text Matching.","link":"http://arxiv.org/abs/2211.13854","abstract":"Contrastive Language-Image Pretraining (CLIP) has demonstrated great zero-shot performance for matching images and text. However, it is still challenging to adapt vision-lanaguage pretrained models like CLIP to compositional image and text matching -- a more challenging image and text matching task requiring the model understanding of compositional word concepts and visual components. Towards better compositional generalization in zero-shot image and text matching, in this paper, we study the problem from a causal perspective: the erroneous semantics of individual entities are essentially confounders that cause the matching failure. Therefore, we propose a novel \\textbf{\\textit{training-free}} compositional CLIP model (ComCLIP). ComCLIP disentangles input images into subjects, objects, and action sub-images and composes CLIP's vision encoder and text encoder to perform evolving matching over compositional text embedding and sub-image embeddings. In this way, ComCLIP can mitigate spurious correlations introduced by the pretrained CLIP models and dynamically evaluate the importance of each component. Experiments on four compositional image-text matching datasets: SVO, ComVG, Winoground, and VL-checklist, and two general image-text retrieval datasets: Flick30K, and MSCOCO demonstrate the effectiveness of our plug-and-play method, which boosts the \\textbf{\\textit{zero-shot}} inference ability of CLIP, SLIP, and BLIP2 even without further training or fine-tuning. Our codes can be found at https://github.com/eric-ai-lab/ComCLIP.","creator":"Kenan Jiang, Xuehai He, Ruize Xu, Xin Eric Wang"},{"id":"2212.02712","slug":"improved-beam-search-for-hallucination-mitigation-in-abstractive-summarization-arxiv-2212-02712v2-cs-cl-updated","title":"Improved Beam Search for Hallucination Mitigation in Abstractive Summarization.","link":"http://arxiv.org/abs/2212.02712","abstract":"Advancement in large pretrained language models has significantly improved their performance for conditional language generation tasks including summarization albeit with hallucinations. To reduce hallucinations, conventional methods proposed improving beam search or using a fact checker as a postprocessing step. In this paper, we investigate the use of the Natural Language Inference (NLI) entailment metric to detect and prevent hallucinations in summary generation. We propose an NLI-assisted beam re-ranking mechanism by computing entailment probability scores between the input context and summarization model-generated beams during saliency-enhanced greedy decoding. Moreover, a diversity metric is introduced to compare its effectiveness against vanilla beam search. Our proposed algorithm significantly outperforms vanilla beam decoding on XSum and CNN/DM datasets.","creator":"Arvind Krishna Sridhar, Erik Visser"},{"id":"2212.04972","slug":"moprd-a-multidisciplinary-open-peer-review-dataset-arxiv-2212-04972v2-cs-dl-updated","title":"MOPRD: A multidisciplinary open peer review dataset.","link":"http://arxiv.org/abs/2212.04972","abstract":"Open peer review is a growing trend in academic publications. Public access to peer review data can benefit both the academic and publishing communities. It also serves as a great support to studies on review comment generation and further to the realization of automated scholarly paper review. However, most of the existing peer review datasets do not provide data that cover the whole peer review process. Apart from this, their data are not diversified enough as the data are mainly collected from the field of computer science. These two drawbacks of the currently available peer review datasets need to be addressed to unlock more opportunities for related studies. In response, we construct MOPRD, a multidisciplinary open peer review dataset. This dataset consists of paper metadata, multiple version manuscripts, review comments, meta-reviews, author's rebuttal letters, and editorial decisions. Moreover, we propose a modular guided review comment generation method based on MOPRD. Experiments show that our method delivers better performance as indicated by both automatic metrics and human evaluation. We also explore other potential applications of MOPRD, including meta-review generation, editorial decision prediction, author rebuttal generation, and scientometric analysis. MOPRD is a strong endorsement for further studies in peer review-related research and other applications.","creator":"Jialiang Lin, Jiaxin Song, Zhangping Zhou, Yidong Chen, Xiaodong Shi"},{"id":"2301.05525","slug":"understanding-concept-identification-as-consistent-data-clustering-across-multiple-feature-spaces-arxiv-2301-05525v2-cs-lg-updated","title":"Understanding Concept Identification as Consistent Data Clustering Across Multiple Feature Spaces.","link":"http://arxiv.org/abs/2301.05525","abstract":"Identifying meaningful concepts in large data sets can provide valuable insights into engineering design problems. Concept identification aims at identifying non-overlapping groups of design instances that are similar in a joint space of all features, but which are also similar when considering only subsets of features. These subsets usually comprise features that characterize a design with respect to one specific context, for example, constructive design parameters, performance values, or operation modes. It is desirable to evaluate the quality of design concepts by considering several of these feature subsets in isolation. In particular, meaningful concepts should not only identify dense, well separated groups of data instances, but also provide non-overlapping groups of data that persist when considering pre-defined feature subsets separately. In this work, we propose to view concept identification as a special form of clustering algorithm with a broad range of potential applications beyond engineering design. To illustrate the differences between concept identification and classical clustering algorithms, we apply a recently proposed concept identification algorithm to two synthetic data sets and show the differences in identified solutions. In addition, we introduce the mutual information measure as a metric to evaluate whether solutions return consistent clusters across relevant subsets. To support the novel understanding of concept identification, we consider a simulated data set from a decision-making problem in the energy management domain and show that the identified clusters are more interpretable with respect to relevant feature subsets than clusters found by common clustering algorithms and are thus more suitable to support a decision maker.","creator":"Felix Lanfermann, Sebastian Schmitt, Patricia Wollstadt"},{"id":"2302.08942","slug":"pac-bayesian-generalization-bounds-for-adversarial-generative-models-arxiv-2302-08942v4-cs-lg-updated","title":"PAC-Bayesian Generalization Bounds for Adversarial Generative Models.","link":"http://arxiv.org/abs/2302.08942","abstract":"We extend PAC-Bayesian theory to generative models and develop generalization bounds for models based on the Wasserstein distance and the total variation distance. Our first result on the Wasserstein distance assumes the instance space is bounded, while our second result takes advantage of dimensionality reduction. Our results naturally apply to Wasserstein GANs and Energy-Based GANs, and our bounds provide new training objectives for these two. Although our work is mainly theoretical, we perform numerical experiments showing non-vacuous generalization bounds for Wasserstein GANs on synthetic datasets.","creator":"Sokhna Diarra Mbacke, Florence Clerc, Pascal Germain"},{"id":"2303.06273","slug":"consistency-analysis-of-chatgpt-arxiv-2303-06273v3-cs-cl-updated","title":"Consistency Analysis of ChatGPT.","link":"http://arxiv.org/abs/2303.06273","abstract":"ChatGPT has gained a huge popularity since its introduction. Its positive aspects have been reported through many media platforms, and some analyses even showed that ChatGPT achieved a decent grade in professional exams, adding extra support to the claim that AI can now assist and even replace humans in industrial fields. Others, however, doubt its reliability and trustworthiness. This paper investigates the trustworthiness of ChatGPT and GPT-4 regarding logically consistent behaviour, focusing specifically on semantic consistency and the properties of negation, symmetric, and transitive consistency. Our findings suggest that while both models appear to show an enhanced language understanding and reasoning ability, they still frequently fall short of generating logically consistent predictions. We also ascertain via experiments that prompt designing, few-shot learning and employing larger large language models (LLMs) are unlikely to be the ultimate solution to resolve the inconsistency issue of LLMs.","creator":"Myeongjun Erik Jang, Thomas Lukasiewicz"},{"id":"2304.02192","slug":"a-diffusion-based-method-for-multi-turn-compositional-image-generation-arxiv-2304-02192v2-cs-cv-updated","title":"A Diffusion-based Method for Multi-turn Compositional Image Generation.","link":"http://arxiv.org/abs/2304.02192","abstract":"Multi-turn compositional image generation (M-CIG) is a challenging task that aims to iteratively manipulate a reference image given a modification text. While most of the existing methods for M-CIG are based on generative adversarial networks (GANs), recent advances in image generation have demonstrated the superiority of diffusion models over GANs. In this paper, we propose a diffusion-based method for M-CIG named conditional denoising diffusion with image compositional matching (CDD-ICM). We leverage CLIP as the backbone of image and text encoders, and incorporate a gated fusion mechanism, originally proposed for question answering, to compositionally fuse the reference image and the modification text at each turn of M-CIG. We introduce a conditioning scheme to generate the target image based on the fusion results. To prioritize the semantic quality of the generated target image, we learn an auxiliary image compositional match (ICM) objective, along with the conditional denoising diffusion (CDD) objective in a multi-task learning framework. Additionally, we also perform ICM guidance and classifier-free guidance to improve performance. Experimental results show that CDD-ICM achieves state-of-the-art results on two benchmark datasets for M-CIG, i.e., CoDraw and i-CLEVR.","creator":"Chao Wang"},{"id":"2304.13765","slug":"towards-ethical-multimodal-systems-arxiv-2304-13765v2-cs-ai-updated","title":"Towards ethical multimodal systems.","link":"http://arxiv.org/abs/2304.13765","abstract":"Generative AI systems (ChatGPT, DALL-E, etc) are expanding into multiple areas of our lives, from art Rombach et al. [2021] to mental health Rob Morris and Kareem Kouddous [2022]; their rapidly growing societal impact opens new opportunities, but also raises ethical concerns. The emerging field of AI alignment aims to make AI systems reflect human values. This paper focuses on evaluating the ethics of multimodal AI systems involving both text and images - a relatively under-explored area, as most alignment work is currently focused on language models. We first create a multimodal ethical database from human feedback on ethicality. Then, using this database, we develop algorithms, including a RoBERTa-large classifier and a multilayer perceptron, to automatically assess the ethicality of system responses.","creator":"Alexis Roger, Esma A&#xef;meur, Irina Rish"},{"id":"2305.03520","slug":"context-aware-semantic-similarity-measurement-for-unsupervised-word-sense-disambiguation-arxiv-2305-03520v2-cs-cl-updated","title":"Context-Aware Semantic Similarity Measurement for Unsupervised Word Sense Disambiguation.","link":"http://arxiv.org/abs/2305.03520","abstract":"The issue of word sense ambiguity poses a significant challenge in natural language processing due to the scarcity of annotated data to feed machine learning models to face the challenge. Therefore, unsupervised word sense disambiguation methods have been developed to overcome that challenge without relying on annotated data. This research proposes a new context-aware approach to unsupervised word sense disambiguation, which provides a flexible mechanism for incorporating contextual information into the similarity measurement process. We experiment with a popular benchmark dataset to evaluate the proposed strategy and compare its performance with state-of-the-art unsupervised word sense disambiguation techniques. The experimental results indicate that our approach substantially enhances disambiguation accuracy and surpasses the performance of several existing techniques. Our findings underscore the significance of integrating contextual information in semantic similarity measurements to manage word sense ambiguity in unsupervised scenarios effectively.","creator":"Jorge Martinez-Gil"},{"id":"2306.00183","slug":"diffused-redundancy-in-pre-trained-representations-arxiv-2306-00183v3-cs-lg-updated","title":"Diffused Redundancy in Pre-trained Representations.","link":"http://arxiv.org/abs/2306.00183","abstract":"Representations learned by pre-training a neural network on a large dataset are increasingly used successfully to perform a variety of downstream tasks. In this work, we take a closer look at how features are encoded in such pre-trained representations. We find that learned representations in a given layer exhibit a degree of diffuse redundancy, ie, any randomly chosen subset of neurons in the layer that is larger than a threshold size shares a large degree of similarity with the full layer and is able to perform similarly as the whole layer on a variety of downstream tasks. For example, a linear probe trained on $20\\%$ of randomly picked neurons from the penultimate layer of a ResNet50 pre-trained on ImageNet1k achieves an accuracy within $5\\%$ of a linear probe trained on the full layer of neurons for downstream CIFAR10 classification. We conduct experiments on different neural architectures (including CNNs and Transformers) pre-trained on both ImageNet1k and ImageNet21k and evaluate a variety of downstream tasks taken from the VTAB benchmark. We find that the loss and dataset used during pre-training largely govern the degree of diffuse redundancy and the \"critical mass\" of neurons needed often depends on the downstream task, suggesting that there is a task-inherent redundancy-performance Pareto frontier. Our findings shed light on the nature of representations learned by pre-trained deep neural networks and suggest that entire layers might not be necessary to perform many downstream tasks. We investigate the potential for exploiting this redundancy to achieve efficient generalization for downstream tasks and also draw caution to certain possible unintended consequences. Our code is available at \\url{https://github.com/nvedant07/diffused-redundancy}.","creator":"Vedant Nanda, Till Speicher, John P. Dickerson, Soheil Feizi, Krishna P. Gummadi, Adrian Weller"},{"id":"2306.09299","slug":"can-language-models-teach-weaker-agents-teacher-explanations-improve-students-via-personalization-arxiv-2306-09299v2-cs-cl-updated","title":"Can Language Models Teach Weaker Agents? Teacher Explanations Improve Students via Personalization.","link":"http://arxiv.org/abs/2306.09299","abstract":"A hallmark property of explainable AI models is the ability to teach other agents, communicating knowledge of how to perform a task. While Large Language Models perform complex reasoning by generating explanations for their predictions, it is unclear whether they also make good teachers for weaker agents. To address this, we consider a student-teacher framework between two LLM agents and study if, when, and how the teacher should intervene with natural language explanations to improve the student's performance. Since communication is expensive, we define a budget such that the teacher only communicates explanations for a fraction of the data, after which the student should perform well on its own. We decompose the teaching problem along four axes: (1) if teacher's test time intervention improve student predictions, (2) when it is worth explaining a data point, (3) how the teacher should personalize explanations to better teach the student, and (4) if teacher explanations also improve students on future unexplained data. We first show that teacher LLMs can indeed intervene on student reasoning to improve their performance. Next, inspired by the Theory of Mind abilities of effective teachers, we propose building two few-shot mental models of the student. The first model defines an Intervention Function that simulates the utility of an intervention, allowing the teacher to intervene when this utility is the highest and improving student performance at lower budgets. The second model enables the teacher to personalize explanations for a particular student and outperform unpersonalized teachers. We also demonstrate that in multi-turn interactions, teacher explanations generalize and learning from explained data improves student performance on future unexplained data. Finally, we verify that misaligned teachers can lower student performance to random chance by intentionally misleading them.","creator":"Swarnadeep Saha, Peter Hase, Mohit Bansal"},{"id":"2306.13258","slug":"fast-maximum-k-plex-algorithms-parameterized-by-small-degeneracy-gaps-arxiv-2306-13258v3-cs-ds-updated","title":"Fast Maximum $k$-Plex Algorithms Parameterized by Small Degeneracy Gaps.","link":"http://arxiv.org/abs/2306.13258","abstract":"Given a graph, a $k$-plex is a set of vertices in which each vertex is not adjacent to at most $k-1$ other vertices in the set. The maximum $k$-plex problem, which asks for the largest $k$-plex from the given graph, is an important but computationally challenging problem in applications such as graph mining and community detection. So far, there are many practical algorithms, but without providing theoretical explanations on their efficiency. We define a novel parameter of the input instance, $g_k(G)$, the gap between the degeneracy bound and the size of the maximum $k$-plex in the given graph, and present an exact algorithm parameterized by this $g_k(G)$, which has a worst-case running time polynomial in the size of the input graph and exponential in $g_k(G)$. In real-world inputs, $g_k(G)$ is very small, usually bounded by $O(\\log{(|V|)})$, indicating that the algorithm runs in polynomial time. We further extend our discussion to an even smaller parameter $cg_k(G)$, the gap between the community-degeneracy bound and the size of the maximum $k$-plex, and show that without much modification, our algorithm can also be parameterized by $cg_k(G)$. To verify the empirical performance of these algorithms, we carry out extensive experiments to show that these algorithms are competitive with the state-of-the-art algorithms. In particular, for large $k$ values such as $15$ and $20$, our algorithms dominate the existing algorithms. Finally, empirical analysis is performed to illustrate the effectiveness of the parameters and other key components in the implementation.","creator":"Zhengren Wang, Yi Zhou, Chunyu Luo, Mingyu Xiao, Jin-Kao Hao"},{"id":"2307.00754","slug":"imdiffusion-imputed-diffusion-models-for-multivariate-time-series-anomaly-detection-arxiv-2307-00754v2-cs-lg-updated","title":"ImDiffusion: Imputed Diffusion Models for Multivariate Time Series Anomaly Detection.","link":"http://arxiv.org/abs/2307.00754","abstract":"Anomaly detection in multivariate time series data is of paramount importance for ensuring the efficient operation of large-scale systems across diverse domains. However, accurately detecting anomalies in such data poses significant challenges. Existing approaches, including forecasting and reconstruction-based methods, struggle to address these challenges effectively. To overcome these limitations, we propose a novel anomaly detection framework named ImDiffusion, which combines time series imputation and diffusion models to achieve accurate and robust anomaly detection. The imputation-based approach employed by ImDiffusion leverages the information from neighboring values in the time series, enabling precise modeling of temporal and inter-correlated dependencies, reducing uncertainty in the data, thereby enhancing the robustness of the anomaly detection process. ImDiffusion further leverages diffusion models as time series imputers to accurately capturing complex dependencies. We leverage the step-by-step denoised outputs generated during the inference process to serve as valuable signals for anomaly prediction, resulting in improved accuracy and robustness of the detection process.  We evaluate the performance of ImDiffusion via extensive experiments on benchmark datasets. The results demonstrate that our proposed framework significantly outperforms state-of-the-art approaches in terms of detection accuracy and timeliness. ImDiffusion is further integrated into the real production system in Microsoft and observe a remarkable 11.4% increase in detection F1 score compared to the legacy approach. To the best of our knowledge, ImDiffusion represents a pioneering approach that combines imputation-based techniques with time series anomaly detection, while introducing the novel use of diffusion models to the field.","creator":"Yuhang Chen, Chaoyun Zhang, Minghua Ma, Yudong Liu, Ruomeng Ding, Bowen Li, Shilin He, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang"},{"id":"2307.02933","slug":"in-time-and-space-towards-usable-adaptive-control-for-assistive-robotic-arms-arxiv-2307-02933v2-cs-hc-updated","title":"In Time and Space: Towards Usable Adaptive Control for Assistive Robotic Arms.","link":"http://arxiv.org/abs/2307.02933","abstract":"Robotic solutions, in particular robotic arms, are becoming more frequently deployed for close collaboration with humans, for example in manufacturing or domestic care environments. These robotic arms require the user to control several Degrees-of-Freedom (DoFs) to perform tasks, primarily involving grasping and manipulating objects. Standard input devices predominantly have two DoFs, requiring time-consuming and cognitively demanding mode switches to select individual DoFs. Contemporary Adaptive DoF Mapping Controls (ADMCs) have shown to decrease the necessary number of mode switches but were up to now not able to significantly reduce the perceived workload. Users still bear the mental workload of incorporating abstract mode switching into their workflow. We address this by providing feed-forward multimodal feedback using updated recommendations of ADMC, allowing users to visually compare the current and the suggested mapping in real-time. We contrast the effectiveness of two new approaches that a) continuously recommend updated DoF combinations or b) use discrete thresholds between current robot movements and new recommendations. Both are compared in a Virtual Reality (VR) in-person study against a classic control method. Significant results for lowered task completion time, fewer mode switches, and reduced perceived workload conclusively establish that in combination with feedforward, ADMC methods can indeed outperform classic mode switching. A lack of apparent quantitative differences between Continuous and Threshold reveals the importance of user-centered customization options. Including these implications in the development process will improve usability, which is essential for successfully implementing robotic technologies with high user acceptance.","creator":"Max Pascher, Kirill Kronhardt, Felix Ferdinand Goldau, Udo Frese, Jens Gerken"},{"id":"2307.06440","slug":"no-train-no-gain-revisiting-efficient-training-algorithms-for-transformer-based-language-models-arxiv-2307-06440v4-cs-lg-updated","title":"No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models.","link":"http://arxiv.org/abs/2307.06440","abstract":"The computation necessary for training Transformer-based language models has skyrocketed in recent years. This trend has motivated research on efficient training algorithms designed to improve training, validation, and downstream performance faster than standard training. In this work, we revisit three categories of such algorithms: dynamic architectures (layer stacking, layer dropping), batch selection (selective backprop, RHO loss), and efficient optimizers (Lion, Sophia). When pre-training BERT and T5 with a fixed computation budget using such methods, we find that their training, validation, and downstream gains vanish compared to a baseline with a fully-decayed learning rate. We define an evaluation protocol that enables computation to be done on arbitrary machines by mapping all computation time to a reference machine which we call reference system time. We discuss the limitations of our proposed protocol and release our code to encourage rigorous research in efficient training procedures: https://github.com/JeanKaddour/NoTrainNoGain.","creator":"Jean Kaddour, Oscar Key, Piotr Nawrot, Pasquale Minervini, Matt J. Kusner"},{"id":"2307.12540","slug":"uniformaly-towards-task-agnostic-unified-framework-for-visual-anomaly-detection-arxiv-2307-12540v2-cs-cv-updated","title":"UniFormaly: Towards Task-Agnostic Unified Framework for Visual Anomaly Detection.","link":"http://arxiv.org/abs/2307.12540","abstract":"Visual anomaly detection aims to learn normality from normal images, but existing approaches are fragmented across various tasks: defect detection, semantic anomaly detection, multi-class anomaly detection, and anomaly clustering. This one-task-one-model approach is resource-intensive and incurs high maintenance costs as the number of tasks increases. We present UniFormaly, a universal and powerful anomaly detection framework. We emphasize the necessity of our off-the-shelf approach by pointing out a suboptimal issue in online encoder-based methods. We introduce Back Patch Masking (BPM) and top k-ratio feature matching to achieve unified anomaly detection. BPM eliminates irrelevant background regions using a self-attention map from self-supervised ViTs. This operates in a task-agnostic manner and alleviates memory storage consumption, scaling to tasks with large-scale datasets. Top k-ratio feature matching unifies anomaly levels and tasks by casting anomaly scoring into multiple instance learning. Finally, UniFormaly achieves outstanding results on various tasks and datasets. Codes are available at https://github.com/YoojLee/Uniformaly.","creator":"Yujin Lee, Harin Lim, Seoyoon Jang, Hyunsoo Yoon"},{"id":"2308.07336","slug":"learning-deductive-reasoning-from-synthetic-corpus-based-on-formal-logic-arxiv-2308-07336v3-cs-ai-updated","title":"Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic.","link":"http://arxiv.org/abs/2308.07336","abstract":"We study a synthetic corpus based approach for language models (LMs) to acquire logical deductive reasoning ability. The previous studies generated deduction examples using specific sets of deduction rules. However, these rules were limited or otherwise arbitrary, limiting the generalizability of acquired reasoning ability. We rethink this and adopt a well-grounded set of deduction rules based on formal logic theory, which can derive any other deduction rules when combined in a multistep way. Then, using the proposed corpora, which we name FLD (Formal Logic Deduction), we first evaluate and analyze the logical reasoning ability of the latest LLMs. Even GPT-4 can solve only half of the problems, suggesting that pure logical reasoning isolated from knowledge is still challenging for the LLMs, and additional training specialized in logical reasoning is indeed essential. We next empirically verify that LMs trained on FLD corpora acquire more generalizable reasoning ability. Furthermore, we identify the aspects of reasoning ability on which deduction corpora can enhance LMs and those on which they cannot, and discuss future directions on each aspect. The released corpora serve both as learning resources and as challenging benchmarks.","creator":"Terufumi Morishita, Gaku Morio, Atsuki Yamaguchi, Yasuhiro Sogawa"},{"id":"2308.10874","slug":"analyzing-transformer-dynamics-as-movement-through-embedding-space-arxiv-2308-10874v2-cs-lg-updated","title":"Analyzing Transformer Dynamics as Movement through Embedding Space.","link":"http://arxiv.org/abs/2308.10874","abstract":"Transformer based language models exhibit intelligent behaviors such as understanding natural language, recognizing patterns, acquiring knowledge, reasoning, planning, reflecting and using tools. This paper explores how their underlying mechanics give rise to intelligent behaviors. Towards that end, we propose framing Transformer dynamics as movement through embedding space. Examining Transformers through this perspective reveals key insights, establishing a Theory of Transformers: 1) Intelligent behaviours map to paths in Embedding Space which, the Transformer random-walks through during inferencing. 2) LM training learns a probability distribution over all possible paths. `Intelligence' is learnt by assigning higher probabilities to paths representing intelligent behaviors. No learning can take place in-context; context only narrows the subset of paths sampled during decoding. 5) The Transformer is a self-mapping composition function, folding a context sequence into a context-vector such that it's proximity to a token-vector reflects its co-occurrence and conditioned probability. Thus, the physical arrangement of vectors in Embedding Space determines path probabilities. 6) Context vectors are composed by aggregating features of the sequence's tokens via a process we call the encoding walk. Attention contributes a - potentially redundant - association-bias to this process. 7) This process is comprised of two principal operation types: filtering (data independent) and aggregation (data dependent). This generalization unifies Transformers with other sequence models. Building upon this foundation, we formalize a popular semantic interpretation of embeddings into a ``concept-space theory'' and find some evidence of it's validity.","creator":"Sumeet S. Singh"},{"id":"2308.13816","slug":"homological-convolutional-neural-networks-arxiv-2308-13816v2-cs-lg-updated","title":"Homological Convolutional Neural Networks.","link":"http://arxiv.org/abs/2308.13816","abstract":"Deep learning methods have demonstrated outstanding performances on classification and regression tasks on homogeneous data types (e.g., image, audio, and text data). However, tabular data still pose a challenge, with classic machine learning approaches being often computationally cheaper and equally effective than increasingly complex deep learning architectures. The challenge arises from the fact that, in tabular data, the correlation among features is weaker than the one from spatial or semantic relationships in images or natural language, and the dependency structures need to be modeled without any prior information. In this work, we propose a novel deep learning architecture that exploits the data structural organization through topologically constrained network representations to gain relational information from sparse tabular inputs. The resulting model leverages the power of convolution and is centered on a limited number of concepts from network topology to guarantee: (i) a data-centric and deterministic building pipeline; (ii) a high level of interpretability over the inference process; and (iii) an adequate room for scalability. We test our model on 18 benchmark datasets against 5 classic machine learning and 3 deep learning models, demonstrating that our approach reaches state-of-the-art performances on these challenging datasets. The code to reproduce all our experiments is provided at https://github.com/FinancialComputingUCL/HomologicalCNN.","creator":"Antonio Briola, Yuanrong Wang, Silvia Bartolucci, Tomaso Aste"},{"id":"2309.08918","slug":"exploration-of-tpus-for-ai-applications-arxiv-2309-08918v2-cs-ar-updated","title":"Exploration of TPUs for AI Applications.","link":"http://arxiv.org/abs/2309.08918","abstract":"Tensor Processing Units (TPUs) are specialized hardware accelerators for deep learning developed by Google. This paper aims to explore TPUs in cloud and edge computing focusing on its applications in AI. We provide an overview of TPUs, their general architecture, specifically their design in relation to neural networks, compilation techniques and supporting frameworks. Furthermore, we provide a comparative analysis of Cloud and Edge TPU performance against other counterpart chip architectures. Our results show that TPUs can provide significant performance improvements in both cloud and edge computing. Additionally, this paper underscores the imperative need for further research in optimization techniques for efficient deployment of AI architectures on the Edge TPU and benchmarking standards for a more robust comparative analysis in edge computing scenarios. The primary motivation behind this push for research is that efficient AI acceleration, facilitated by TPUs, can lead to substantial savings in terms of time, money, and environmental resources.","creator":"Diego Sanmart&#xed;n Carri&#xf3;n, Vera Prohaska"},{"id":"2309.14610","slug":"unsupervised-graph-deep-learning-reveals-emergent-flood-risk-profile-of-urban-areas-arxiv-2309-14610v3-cs-lg-updated","title":"Unsupervised Graph Deep Learning Reveals Emergent Flood Risk Profile of Urban Areas.","link":"http://arxiv.org/abs/2309.14610","abstract":"Urban flood risk emerges from complex and nonlinear interactions among multiple features related to flood hazard, flood exposure, and social and physical vulnerabilities, along with the complex spatial flood dependence relationships. Existing approaches for characterizing urban flood risk, however, are primarily based on flood plain maps, focusing on a limited number of features, primarily hazard and exposure features, without consideration of feature interactions or the dependence relationships among spatial areas. To address this gap, this study presents an integrated urban flood-risk rating model based on a novel unsupervised graph deep learning model (called FloodRisk-Net). FloodRisk-Net is capable of capturing spatial dependence among areas and complex and nonlinear interactions among flood hazards and urban features for specifying emergent flood risk. Using data from multiple metropolitan statistical areas (MSAs) in the United States, the model characterizes their flood risk into six distinct city-specific levels. The model is interpretable and enables feature analysis of areas within each flood-risk level, allowing for the identification of the three archetypes shaping the highest flood risk within each MSA. Flood risk is found to be spatially distributed in a hierarchical structure within each MSA, where the core city disproportionately bears the highest flood risk. Multiple cities are found to have high overall flood-risk levels and low spatial inequality, indicating limited options for balancing urban development and flood-risk reduction. Relevant flood-risk reduction strategies are discussed considering ways that the highest flood risk and uneven spatial distribution of flood risk are formed.","creator":"Kai Yin, Ali Mostafavi"},{"id":"2310.00566","slug":"empowering-many-biasing-a-few-generalist-credit-scoring-through-large-language-models-arxiv-2310-00566v2-cs-lg-updated","title":"Empowering Many, Biasing a Few: Generalist Credit Scoring through Large Language Models.","link":"http://arxiv.org/abs/2310.00566","abstract":"In the financial industry, credit scoring is a fundamental element, shaping access to credit and determining the terms of loans for individuals and businesses alike. Traditional credit scoring methods, however, often grapple with challenges such as narrow knowledge scope and isolated evaluation of credit tasks. Our work posits that Large Language Models (LLMs) have great potential for credit scoring tasks, with strong generalization ability across multiple tasks. To systematically explore LLMs for credit scoring, we propose the first open-source comprehensive framework. We curate a novel benchmark covering 9 datasets with 14K samples, tailored for credit assessment and a critical examination of potential biases within LLMs, and the novel instruction tuning data with over 45k samples. We then propose the first Credit and Risk Assessment Large Language Model (CALM) by instruction tuning, tailored to the nuanced demands of various financial risk assessment tasks. We evaluate CALM, and existing state-of-art (SOTA) open source and close source LLMs on the build benchmark. Our empirical results illuminate the capability of LLMs to not only match but surpass conventional models, pointing towards a future where credit scoring can be more inclusive, comprehensive, and unbiased. We contribute to the industry's transformation by sharing our pioneering instruction-tuning datasets, credit and risk assessment LLM, and benchmarks with the research community and the financial industry.","creator":"Duanyu Feng, Yongfu Dai, Jimin Huang, Yifang Zhang, Qianqian Xie, Weiguang Han, Alejandro Lopez-Lira, Hao Wang"},{"id":"2310.01331","slug":"choicemates-supporting-unfamiliar-online-decision-making-with-multi-agent-conversational-interactions-arxiv-2310-01331v2-cs-hc-updated","title":"ChoiceMates: Supporting Unfamiliar Online Decision-Making with Multi-Agent Conversational Interactions.","link":"http://arxiv.org/abs/2310.01331","abstract":"Unfamiliar decisions -- decisions where people lack adequate domain knowledge or expertise -- specifically increase the complexity and uncertainty of the process of searching for, understanding, and making decisions with online information. Through our formative study (n=14), we observed users' challenges in accessing diverse perspectives, identifying relevant information, and deciding the right moment to make the final decision. We present ChoiceMates, a system that enables conversations with a dynamic set of LLM-powered agents for a holistic domain understanding and efficient discovery and management of information to make decisions. Agents, as opinionated personas, flexibly join the conversation, not only providing responses but also conversing among themselves to elicit each agent's preferences. Our between-subjects study (n=36) comparing ChoiceMates to conventional web search and single-agent showed that ChoiceMates was more helpful in discovering, diving deeper, and managing information compared to Web with higher confidence. We also describe how participants utilized multi-agent conversations in their decision-making process.","creator":"Jeongeon Park, Bryan Min, Xiaojuan Ma, Juho Kim"},{"id":"2310.01420","slug":"ruffle-riley-towards-the-automated-induction-of-conversational-tutoring-systems-arxiv-2310-01420v2-cs-cl-updated","title":"Ruffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems.","link":"http://arxiv.org/abs/2310.01420","abstract":"Conversational tutoring systems (CTSs) offer learning experiences driven by natural language interaction. They are known to promote high levels of cognitive engagement and benefit learning outcomes, particularly in reasoning tasks. Nonetheless, the time and cost required to author CTS content is a major obstacle to widespread adoption. In this paper, we introduce a novel type of CTS that leverages the recent advances in large language models (LLMs) in two ways: First, the system induces a tutoring script automatically from a lesson text. Second, the system automates the script orchestration via two LLM-based agents (Ruffle&amp;Riley) with the roles of a student and a professor in a learning-by-teaching format. The system allows a free-form conversation that follows the ITS-typical inner and outer loop structure. In an initial between-subject online user study (N = 100) comparing Ruffle&amp;Riley to simpler QA chatbots and reading activity, we found no significant differences in post-test scores. Nonetheless, in the learning experience survey, Ruffle&amp;Riley users expressed higher ratings of understanding and remembering and further perceived the offered support as more helpful and the conversation as coherent. Our study provides insights for a new generation of scalable CTS technologies.","creator":"Robin Schmucker, Meng Xia, Amos Azaria, Tom Mitchell"},{"id":"2310.07793","slug":"gentkg-generative-forecasting-on-temporal-knowledge-graph-arxiv-2310-07793v2-cs-cl-updated","title":"GenTKG: Generative Forecasting on Temporal Knowledge Graph.","link":"http://arxiv.org/abs/2310.07793","abstract":"The rapid advancements in large language models (LLMs) have ignited interest in the temporal knowledge graph (tKG) domain, where conventional carefully designed embedding-based and rule-based models dominate. The question remains open of whether pre-trained LLMs can understand structured temporal relational data and replace them as the foundation model for temporal relational forecasting. Therefore, we bring temporal knowledge forecasting into the generative setting. However, challenges occur in the huge chasms between complex temporal graph data structure and sequential natural expressions LLMs can handle, and between the enormous data sizes of tKGs and heavy computation costs of finetuning LLMs. To address these challenges, we propose a novel retrieval augmented generation framework that performs generative forecasting on tKGs named GenTKG, which combines a temporal logical rule-based retrieval strategy and lightweight parameter-efficient instruction tuning. Extensive experiments have shown that GenTKG outperforms conventional methods of temporal relational forecasting under low computation resources. GenTKG also highlights remarkable transferability with exceeding performance on unseen datasets without re-training. Our work reveals the huge potential of LLMs in the tKG domain and opens a new frontier for generative forecasting on tKGs.","creator":"Ruotong Liao, Xu Jia, Yunpu Ma, Volker Tresp"},{"id":"2310.07838","slug":"towards-the-fundamental-limits-of-knowledge-transfer-over-finite-domains-arxiv-2310-07838v4-cs-lg-updated","title":"Towards the Fundamental Limits of Knowledge Transfer over Finite Domains.","link":"http://arxiv.org/abs/2310.07838","abstract":"We characterize the statistical efficiency of knowledge transfer through $n$ samples from a teacher to a probabilistic student classifier with input space $\\mathcal S$ over labels $\\mathcal A$. We show that privileged information at three progressive levels accelerates the transfer. At the first level, only samples with hard labels are known, via which the maximum likelihood estimator attains the minimax rate $\\sqrt{{|{\\mathcal S}||{\\mathcal A}|}/{n}}$. The second level has the teacher probabilities of sampled labels available in addition, which turns out to boost the convergence rate lower bound to ${{|{\\mathcal S}||{\\mathcal A}|}/{n}}$. However, under this second data acquisition protocol, minimizing a naive adaptation of the cross-entropy loss results in an asymptotically biased student. We overcome this limitation and achieve the fundamental limit by using a novel empirical variant of the squared error logit loss. The third level further equips the student with the soft labels (complete logits) on ${\\mathcal A}$ given every sampled input, thereby provably enables the student to enjoy a rate ${|{\\mathcal S}|}/{n}$ free of $|{\\mathcal A}|$. We find any Kullback-Leibler divergence minimizer to be optimal in the last case. Numerical simulations distinguish the four learners and corroborate our theory.","creator":"Qingyue Zhao, Banghua Zhu"},{"id":"2310.14421","slug":"on-existence-uniqueness-and-scalability-of-adversarial-robustness-measures-for-ai-classifiers-arxiv-2310-14421v3-stat-ml-updated","title":"On existence, uniqueness and scalability of adversarial robustness measures for AI classifiers.","link":"http://arxiv.org/abs/2310.14421","abstract":"Simply-verifiable mathematical conditions for existence, uniqueness and explicit analytical computation of minimal adversarial paths (MAP) and minimal adversarial distances (MAD) for (locally) uniquely-invertible classifiers, for generalized linear models (GLM), and for entropic AI (EAI) are formulated and proven. Practical computation of MAP and MAD, their comparison and interpretations for various classes of AI tools (for neuronal networks, boosted random forests, GLM and EAI) are demonstrated on the common synthetic benchmarks: on a double Swiss roll spiral and its extensions, as well as on the two biomedical data problems (for the health insurance claim predictions, and for the heart attack lethality classification). On biomedical applications it is demonstrated how MAP provides unique minimal patient-specific risk-mitigating interventions in the predefined subsets of accessible control variables.","creator":"Illia Horenko"},{"id":"2310.16147","slug":"prewome-exploiting-presuppositions-as-working-memory-for-long-form-question-answering-arxiv-2310-16147v2-cs-cl-updated","title":"PreWoMe: Exploiting Presuppositions as Working Memory for Long Form Question Answering.","link":"http://arxiv.org/abs/2310.16147","abstract":"Information-seeking questions in long-form question answering (LFQA) often prove misleading due to ambiguity or false presupposition in the question. While many existing approaches handle misleading questions, they are tailored to limited questions, which are insufficient in a real-world setting with unpredictable input characteristics. In this work, we propose PreWoMe, a unified approach capable of handling any type of information-seeking question. The key idea of PreWoMe involves extracting presuppositions in the question and exploiting them as working memory to generate feedback and action about the question. Our experiment shows that PreWoMe is effective not only in tackling misleading questions but also in handling normal ones, thereby demonstrating the effectiveness of leveraging presuppositions, feedback, and action for real-world QA settings.","creator":"Wookje Han, Jinsol Park, Kyungjae Lee"},{"id":"2310.16600","slug":"balancing-central-and-marginal-rejection-when-combining-independent-significance-tests-arxiv-2310-16600v2-stat-me-updated","title":"Balancing central and marginal rejection when combining independent significance tests.","link":"http://arxiv.org/abs/2310.16600","abstract":"A common approach to evaluating the significance of a collection of $p$-values combines them with a pooling function, in particular when the original data are not available. These pooled $p$-values convert a sample of $p$-values into a single number which behaves like a univariate $p$-value. To clarify discussion of these functions, a telescoping series of alternative hypotheses are introduced that communicate the strength and prevalence of non-null evidence in the $p$-values before general pooling formulae are discussed. A pattern noticed in the UMP pooled $p$-value for a particular alternative motivates the definition and discussion of central and marginal rejection levels at $\\alpha$. It is proven that central rejection is always greater than or equal to marginal rejection, motivating a quotient to measure the balance between the two for pooled $p$-values. A combining function based on the $\\chi^2_{\\kappa}$ quantile transformation is proposed to control this quotient and shown to be robust to mis-specified parameters relative to the UMP. Different powers for different parameter settings motivate a map of plausible alternatives based on where this pooled $p$-value is minimized.","creator":"Chris Salahub, Wayne Oldford"},{"id":"2310.17490","slug":"improving-zero-shot-reader-by-reducing-distractions-from-irrelevant-documents-in-open-domain-question-answering-arxiv-2310-17490v3-cs-cl-updated","title":"Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Question Answering.","link":"http://arxiv.org/abs/2310.17490","abstract":"Large language models (LLMs) enable zero-shot approaches in open-domain question answering (ODQA), yet with limited advancements as the reader is compared to the retriever. This study aims at the feasibility of a zero-shot reader that addresses the challenges of computational cost and the need for labeled data. We find that LLMs are distracted due to irrelevant documents in the retrieved set and the overconfidence of the generated answers when they are exploited as zero-shot readers. To tackle these problems, we mitigate the impact of such documents via Distraction-aware Answer Selection (DAS) with a negation-based instruction and score adjustment for proper answer selection. Experimental results show that our approach successfully handles distraction across diverse scenarios, enhancing the performance of zero-shot readers. Furthermore, unlike supervised readers struggling with unseen data, zero-shot readers demonstrate outstanding transferability without any training.","creator":"Sukmin Cho, Jeongyeon Seo, Soyeong Jeong, Jong C. Park"},{"id":"2310.17784","slug":"data-centric-financial-large-language-models-arxiv-2310-17784v2-cs-cl-updated","title":"Data-Centric Financial Large Language Models.","link":"http://arxiv.org/abs/2310.17784","abstract":"Large language models (LLMs) show promise for natural language tasks but struggle when applied directly to complex domains like finance. LLMs have difficulty reasoning about and integrating all relevant information. We propose a data-centric approach to enable LLMs to better handle financial tasks. Our key insight is that rather than overloading the LLM with everything at once, it is more effective to preprocess and pre-understand the data. We create a financial LLM (FLLM) using multitask prompt-based finetuning to achieve data pre-processing and pre-understanding. However, labeled data is scarce for each task. To overcome manual annotation costs, we employ abductive augmentation reasoning (AAR) to automatically generate training data by modifying the pseudo labels from FLLM's own outputs. Experiments show our data-centric FLLM with AAR substantially outperforms baseline financial LLMs designed for raw text, achieving state-of-the-art on financial analysis and interpretation tasks. We also open source a new benchmark for financial analysis and interpretation. Our methodology provides a promising path to unlock LLMs' potential for complex real-world domains.","creator":"Zhixuan Chu, Huaiyu Guo, Xinyuan Zhou, Yijia Wang, Fei Yu, Hong Chen, Wanqing Xu, Xin Lu, Qing Cui, Longfei Li, Jun Zhou, Sheng Li"},{"id":"2310.17940","slug":"unified-segment-to-segment-framework-for-simultaneous-sequence-generation-arxiv-2310-17940v2-cs-cl-updated","title":"Unified Segment-to-Segment Framework for Simultaneous Sequence Generation.","link":"http://arxiv.org/abs/2310.17940","abstract":"Simultaneous sequence generation is a pivotal task for real-time scenarios, such as streaming speech recognition, simultaneous machine translation and simultaneous speech translation, where the target sequence is generated while receiving the source sequence. The crux of achieving high-quality generation with low latency lies in identifying the optimal moments for generating, accomplished by learning a mapping between the source and target sequences. However, existing methods often rely on task-specific heuristics for different sequence types, limiting the model's capacity to adaptively learn the source-target mapping and hindering the exploration of multi-task learning for various simultaneous tasks. In this paper, we propose a unified segment-to-segment framework (Seg2Seg) for simultaneous sequence generation, which learns the mapping in an adaptive and unified manner. During the process of simultaneous generation, the model alternates between waiting for a source segment and generating a target segment, making the segment serve as the natural bridge between the source and target. To accomplish this, Seg2Seg introduces a latent segment as the pivot between source to target and explores all potential source-target mappings via the proposed expectation training, thereby learning the optimal moments for generating. Experiments on multiple simultaneous generation tasks demonstrate that Seg2Seg achieves state-of-the-art performance and exhibits better generality across various tasks.","creator":"Shaolei Zhang, Yang Feng"},{"id":"2310.19347","slug":"improving-factual-consistency-of-text-summarization-by-adversarially-decoupling-comprehension-and-embellishment-abilities-of-llms-arxiv-2310-19347v3-cs-cl-updated","title":"Improving Factual Consistency of Text Summarization by Adversarially Decoupling Comprehension and Embellishment Abilities of LLMs.","link":"http://arxiv.org/abs/2310.19347","abstract":"Despite the recent progress in text summarization made by large language models (LLMs), they often generate summaries that are factually inconsistent with original articles, known as \"hallucinations\" in text generation. Unlike previous small models (e.g., BART, T5), current LLMs make fewer silly mistakes but more sophisticated ones, such as imposing cause and effect, adding false details, overgeneralizing, etc. These hallucinations are challenging to detect through traditional methods, which poses great challenges for improving the factual consistency of text summarization. In this paper, we propose an adversarially DEcoupling method to disentangle the Comprehension and EmbellishmeNT abilities of LLMs (DECENT). Furthermore, we adopt a probing-based efficient training to cover the shortage of sensitivity for true and false in the training process of LLMs. In this way, LLMs are less confused about embellishing and understanding; thus, they can execute the instructions more accurately and have enhanced abilities to distinguish hallucinations. Experimental results show that DECENT significantly improves the reliability of text summarization based on LLMs.","creator":"Huawen Feng, Yan Fan, Xiong Liu, Ting-En Lin, Zekun Yao, Yuchuan Wu, Fei Huang, Yongbin Li, Qianli Ma"},{"id":"2310.19647","slug":"fast-swap-regret-minimization-and-applications-to-approximate-correlated-equilibria-arxiv-2310-19647v2-cs-gt-updated","title":"Fast swap regret minimization and applications to approximate correlated equilibria.","link":"http://arxiv.org/abs/2310.19647","abstract":"We give a simple and computationally efficient algorithm that, for any constant $\\varepsilon&gt;0$, obtains $\\varepsilon T$-swap regret within only $T = \\mathsf{polylog}(n)$ rounds; this is an exponential improvement compared to the super-linear number of rounds required by the state-of-the-art algorithm, and resolves the main open problem of [Blum and Mansour 2007]. Our algorithm has an exponential dependence on $\\varepsilon$, but we prove a new, matching lower bound.  Our algorithm for swap regret implies faster convergence to $\\varepsilon$-Correlated Equilibrium ($\\varepsilon$-CE) in several regimes: For normal form two-player games with $n$ actions, it implies the first uncoupled dynamics that converges to the set of $\\varepsilon$-CE in polylogarithmic rounds; a $\\mathsf{polylog}(n)$-bit communication protocol for $\\varepsilon$-CE in two-player games (resolving an open problem mentioned by [Babichenko-Rubinstein'2017, Goos-Rubinstein'2018, Ganor-CS'2018]); and an $\\tilde{O}(n)$-query algorithm for $\\varepsilon$-CE (resolving an open problem of [Babichenko'2020] and obtaining the first separation between $\\varepsilon$-CE and $\\varepsilon$-Nash equilibrium in the query complexity model).  For extensive-form games, our algorithm implies a PTAS for $\\mathit{normal}$ $\\mathit{form}$ $\\mathit{correlated}$ $\\mathit{equilibria}$, a solution concept often conjectured to be computationally intractable (e.g. [Stengel-Forges'08, Fujii'23]).","creator":"Binghui Peng, Aviad Rubinstein"},{"id":"2310.20689","slug":"learning-from-mistakes-makes-llm-better-reasoner-arxiv-2310-20689v2-cs-cl-updated","title":"Learning From Mistakes Makes LLM Better Reasoner.","link":"http://arxiv.org/abs/2310.20689","abstract":"Large language models (LLMs) recently exhibited remarkable reasoning capabilities on solving math problems. To further improve this capability, this work proposes Learning from Mistakes (LeMa), akin to human learning processes. Consider a human student who failed to solve a math problem, he will learn from what mistake he has made and how to correct it. Mimicking this error-driven learning process, LeMa fine-tunes LLMs on mistake-correction data pairs generated by GPT-4. Specifically, we first collect inaccurate reasoning paths from various LLMs and then employ GPT-4 as a \"corrector\" to (1) identify the mistake step, (2) explain the reason for the mistake, and (3) correct the mistake and generate the final answer. Experimental results demonstrate the effectiveness of LeMa: across five backbone LLMs and two mathematical reasoning tasks, LeMa consistently improves the performance compared with fine-tuning on CoT data alone. Impressively, LeMa can also benefit specialized LLMs such as WizardMath and MetaMath, achieving 85.4% pass@1 accuracy on GSM8K and 27.1% on MATH. This surpasses the SOTA performance achieved by non-execution open-source models on these challenging tasks. Our code, data and models will be publicly available at https://github.com/microsoft/LEMA.","creator":"Shengnan An, Zexiong Ma, Zeqi Lin, Nanning Zheng, Jian-Guang Lou, Weizhu Chen"},{"id":"2311.01351","slug":"simplicial-models-for-the-epistemic-logic-of-faulty-agents-arxiv-2311-01351v3-cs-lo-updated","title":"Simplicial Models for the Epistemic Logic of Faulty Agents.","link":"http://arxiv.org/abs/2311.01351","abstract":"In recent years, several authors have been investigating simplicial models, a model of epistemic logic based on higher-dimensional structures called simplicial complexes. In the original formulation, simplicial models were always assumed to be pure, meaning that all worlds have the same dimension. This is equivalent to the standard S5n semantics of epistemic logic, based on Kripke models. By removing the assumption that models must be pure, we can go beyond the usual Kripke semantics and study epistemic logics where the number of agents participating in a world can vary. This approach has been developed in a number of papers, with applications in fault-tolerant distributed computing where processes may crash during the execution of a system. A difficulty that arises is that subtle design choices in the definition of impure simplicial models can result in different axioms of the resulting logic. In this paper, we classify those design choices systematically, and axiomatize the corresponding logics. We illustrate them via distributed computing examples of synchronous systems where processes may crash.","creator":"Eric Goubault, Roman Kniazev, Jeremy Ledent, Sergio Rajsbaum"},{"id":"2311.02082","slug":"semantic-modelling-of-organizational-knowledge-as-a-basis-for-enterprise-data-governance-4-0-application-to-a-unified-clinical-data-model-arxiv-2311-02082v2-cs-ai-updated","title":"Semantic Modelling of Organizational Knowledge as a Basis for Enterprise Data Governance 4.0 -- Application to a Unified Clinical Data Model.","link":"http://arxiv.org/abs/2311.02082","abstract":"Individuals and organizations cope with an always-growing data amount, heterogeneous in contents and formats. A prerequisite to get value out this data and minimise inherent risks related to multiple usages is an adequate data management process yielding data quality and control over its lifecycle. Common data governance frameworks relying on people, policies and processes falls short of the overwhelming data complexity. Yet, harnessing this complexity is necessary to achieve high quality standards. The later will condition the outcome of any downstream data usage, including generative artificial intelligence trained on this data. In this paper, we report our concrete experience establishing a simple, cost-efficient framework, that enables metadata-driven, agile and (semi-)automated data governance (i.e. Data Governance 4.0). We explain how we implement and use this framework to integrate 25 years of clinical study data at enterprise scale, in a fully productive environment. The framework encompasses both methodologies and technologies leveraging semantic web principles. We built a knowledge graph describing avatars of data assets in their business context including governance principles. Multiple ontologies articulated by an enterprise upper ontology enable key governance actions such as FAIRification, lifecycle management, definition of roles and responsibilities, lineage across transformations and provenance from source systems. This metadata model is the keystone to data governance 4.0: a semi-automatized data management process, taking in account the business context in an agile manner to adapt governance constraints to each use case and dynamically tune it based on business changes.","creator":"Miguel AP Oliveira, Stephane Manara, Bruno Mol&#xe9;, Thomas Muller, Aur&#xe9;lien Guillouche, Lysann Hesske, Bruce Jordan, Gilles Hubert, Chinmay Kulkarni, Pralipta Jagdev, Cedric R. Berger"},{"id":"2311.04589","slug":"teal-tokenize-and-embed-all-for-multi-modal-large-language-models-arxiv-2311-04589v2-cs-cl-updated","title":"TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models.","link":"http://arxiv.org/abs/2311.04589","abstract":"Despite Multi-modal Large Language Models (MM-LLMs) have made exciting strides recently, they are still struggling to efficiently model the interactions among multi-modal inputs and the generation in non-textual modalities. In this work, we propose TEAL (Tokenize and Embed ALl)}, an approach to treat the input from any modality as a token sequence and learn a joint embedding space for all modalities. Specifically, for the input from any modality, TEAL first discretizes it into a token sequence with the off-the-shelf tokenizer and embeds the token sequence into a joint embedding space with a learnable embedding matrix. MM-LLMs just need to predict the multi-modal tokens autoregressively as the textual LLMs do. Finally, the corresponding de-tokenizer is applied to generate the output in each modality based on the predicted token sequence. With the joint embedding space, TEAL enables the frozen LLMs to perform both understanding and generation tasks involving non-textual modalities, such as image and audio. Thus, the textual LLM can just work as an interface and maintain its high performance in textual understanding and generation. Experiments show that TEAL achieves substantial improvements in multi-modal understanding, and implements a simple scheme for multi-modal generations.","creator":"Zhen Yang, Yingxue Zhang, Fandong Meng, Jie Zhou"},{"id":"2311.05511","slug":"anytime-constrained-reinforcement-learning-arxiv-2311-05511v2-cs-lg-updated","title":"Anytime-Constrained Reinforcement Learning.","link":"http://arxiv.org/abs/2311.05511","abstract":"We introduce and study constrained Markov Decision Processes (cMDPs) with anytime constraints. An anytime constraint requires the agent to never violate its budget at any point in time, almost surely. Although Markovian policies are no longer sufficient, we show that there exist optimal deterministic policies augmented with cumulative costs. In fact, we present a fixed-parameter tractable reduction from anytime-constrained cMDPs to unconstrained MDPs. Our reduction yields planning and learning algorithms that are time and sample-efficient for tabular cMDPs so long as the precision of the costs is logarithmic in the size of the cMDP. However, we also show that computing non-trivial approximately optimal policies is NP-hard in general. To circumvent this bottleneck, we design provable approximation algorithms that efficiently compute or learn an arbitrarily accurate approximately feasible policy with optimal value so long as the maximum supported cost is bounded by a polynomial in the cMDP or the absolute budget. Given our hardness results, our approximation guarantees are the best possible under worst-case analysis.","creator":"Jeremy McMahan, Xiaojin Zhu"},{"id":"2311.05915","slug":"fake-alignment-are-llms-really-aligned-well-arxiv-2311-05915v2-cs-cl-updated","title":"Fake Alignment: Are LLMs Really Aligned Well?.","link":"http://arxiv.org/abs/2311.05915","abstract":"The growing awareness of safety concerns in large language models (LLMs) has sparked considerable interest in the evaluation of safety within current research endeavors. This study investigates an interesting issue pertaining to the evaluation of LLMs, namely the substantial discrepancy in performance between multiple-choice questions and open-ended questions. Inspired by research on jailbreak attack patterns, we argue this is caused by mismatched generalization. That is, the LLM does not have a comprehensive understanding of the complex concept of safety. Instead, it only remembers what to answer for open-ended safety questions, which makes it unable to solve other forms of safety tests. We refer to this phenomenon as fake alignment and construct a comparative benchmark to empirically verify its existence in LLMs. Such fake alignment renders previous evaluation protocols unreliable. To address this, we introduce the Fake alIgNment Evaluation (FINE) framework and two novel metrics--Consistency Score (CS) and Consistent Safety Score (CSS), which jointly assess two complementary forms of evaluation to quantify fake alignment and obtain corrected performance estimates. Applying FINE to 14 widely-used LLMs reveals several models with purported safety are poorly aligned in practice. Our work highlights potential limitations in prevailing alignment methodologies.","creator":"Yixu Wang, Yan Teng, Kexin Huang, Chengqi Lyu, Songyang Zhang, Wenwei Zhang, Xingjun Ma, Yu-Gang Jiang, Yu Qiao, Yingchun Wang"},{"id":"2311.06315","slug":"shipgen-a-diffusion-model-for-parametric-ship-hull-generation-with-multiple-objectives-and-constraints-arxiv-2311-06315v2-cs-lg-updated","title":"ShipGen: A Diffusion Model for Parametric Ship Hull Generation with Multiple Objectives and Constraints.","link":"http://arxiv.org/abs/2311.06315","abstract":"Ship design is a years-long process that requires balancing complex design trade-offs to create a ship that is efficient and effective. Finding new ways to improve the ship design process can lead to significant cost savings for ship building and operation. One promising technology is generative artificial intelligence, which has been shown to reduce design cycle time and create novel, high-performing designs. In literature review, generative artificial intelligence has been shown to generate ship hulls; however, ship design is particularly difficult as the hull of a ship requires the consideration of many objectives. This paper presents a study on the generation of parametric ship hull designs using a parametric diffusion model that considers multiple objectives and constraints for the hulls. This denoising diffusion probabilistic model (DDPM) generates the tabular parametric design vectors of a ship hull for evaluation. In addition to a tabular DDPM, this paper details adding guidance to improve the quality of generated ship hull designs. By leveraging classifier guidance, the DDPM produced feasible parametric ship hulls that maintain the coverage of the initial training dataset of ship hulls with a 99.5% rate, a 149x improvement over random sampling of the design vector parameters across the design space. Parametric ship hulls produced with performance guidance saw an average of 91.4% reduction in wave drag coefficients and an average of a 47.9x relative increase in the total displaced volume of the hulls compared to the mean performance of the hulls in the training dataset. The use of a DDPM to generate parametric ship hulls can reduce design time by generating high-performing hull designs for future analysis. These generated hulls have low drag and high volume, which can reduce the cost of operating a ship and increase its potential to generate revenue.","creator":"Noah J. Bagazinski, Faez Ahmed"},{"id":"2311.06513","slug":"step-by-step-to-fairness-attributing-societal-bias-in-task-oriented-dialogue-systems-arxiv-2311-06513v2-cs-cl-updated","title":"Step by Step to Fairness: Attributing Societal Bias in Task-oriented Dialogue Systems.","link":"http://arxiv.org/abs/2311.06513","abstract":"Recent works have shown considerable improvements in task-oriented dialogue (TOD) systems by utilizing pretrained large language models (LLMs) in an end-to-end manner. However, the biased behavior of each component in a TOD system and the error propagation issue in the end-to-end framework can lead to seriously biased TOD responses. Existing works of fairness only focus on the total bias of a system. In this paper, we propose a diagnosis method to attribute bias to each component of a TOD system. With the proposed attribution method, we can gain a deeper understanding of the sources of bias. Additionally, researchers can mitigate biased model behavior at a more granular level. We conduct experiments to attribute the TOD system's bias toward three demographic axes: gender, age, and race. Experimental results show that the bias of a TOD system usually comes from the response generation model.","creator":"Hsuan Su, Rebecca Qian, Chinnadhurai Sankar, Shahin Shayandeh, Shang-Tse Chen, Hung-yi Lee, Daniel M. Bikel"},{"id":"2311.06703","slug":"enabling-human-centered-ai-a-methodological-perspective-arxiv-2311-06703v2-cs-ai-updated","title":"Enabling Human-Centered AI: A Methodological Perspective.","link":"http://arxiv.org/abs/2311.06703","abstract":"Human-centered AI (HCAI) is a design philosophy that advocates prioritizing humans in designing, developing, and deploying intelligent systems, aiming to maximize the benefits of AI to humans and avoid potential adverse impacts. While HCAI continues to influence, the lack of guidance on methodology in practice makes its adoption challenging. This paper proposes a comprehensive HCAI framework based on our previous work with integrated components, including design goals, design principles, implementation approaches, interdisciplinary teams, HCAI methods, and HCAI processes. This paper also presents a \"three-layer\" approach to facilitate the implementation of the framework. We believe this systematic and executable framework can overcome the weaknesses in current HCAI frameworks and the challenges currently faced in practice, putting it into action to enable HCAI further.","creator":"Wei Xu, Zaifeng Gao"},{"id":"2311.07439","slug":"investigating-multi-pivot-ensembling-with-massively-multilingual-machine-translation-models-arxiv-2311-07439v2-cs-cl-updated","title":"Investigating Multi-Pivot Ensembling with Massively Multilingual Machine Translation Models.","link":"http://arxiv.org/abs/2311.07439","abstract":"Massively multilingual machine translation models allow for the translation of a large number of languages with a single model, but have limited performance on low- and very-low-resource translation directions. Pivoting via high-resource languages remains a strong strategy for low-resource directions, and in this paper we revisit ways of pivoting through multiple languages. Previous work has used a simple averaging of probability distributions from multiple paths, but we find that this performs worse than using a single pivot, and exacerbates the hallucination problem because the same hallucinations can be probable across different paths. As an alternative, we propose MaxEns, a combination strategy that is biased towards the most confident predictions, hypothesising that confident predictions are less prone to be hallucinations. We evaluate different strategies on the FLORES benchmark for 20 low-resource language directions, demonstrating that MaxEns improves translation quality for low-resource languages while reducing hallucination in translations, compared to both direct translation and an averaging approach. On average, multi-pivot strategies still lag behind using English as a single pivot language, raising the question of how to identify the best pivoting strategy for a given translation direction.","creator":"Alireza Mohammadshahi, Jannis Vamvas, Rico Sennrich"},{"id":"2304.01994","slug":"waving-goodbye-to-low-res-a-diffusion-wavelet-approach-for-image-super-resolution-arxiv-2304-01994v2-cs-cv-cross-listed","title":"Waving Goodbye to Low-Res: A Diffusion-Wavelet Approach for Image Super-Resolution.","link":"http://arxiv.org/abs/2304.01994","abstract":"This paper presents a novel Diffusion-Wavelet (DiWa) approach for Single-Image Super-Resolution (SISR). It leverages the strengths of Denoising Diffusion Probabilistic Models (DDPMs) and Discrete Wavelet Transformation (DWT). By enabling DDPMs to operate in the DWT domain, our DDPM models effectively hallucinate high-frequency information for super-resolved images on the wavelet spectrum, resulting in high-quality and detailed reconstructions in image space. Quantitatively, we outperform state-of-the-art diffusion-based SISR methods, namely SR3 and SRDiff, regarding PSNR, SSIM, and LPIPS on both face (8x scaling) and general (4x scaling) SR benchmarks. Meanwhile, using DWT enabled us to use fewer parameters than the compared models: 92M parameters instead of 550M compared to SR3 and 9.3M instead of 12M compared to SRDiff. Additionally, our method outperforms other state-of-the-art generative methods on classical general SR datasets while saving inference time. Finally, our work highlights its potential for various applications.","creator":"Brian Moser, Stanislav Frolov, Federico Raue, Sebastian Palacio, Andreas Dengel"}]},{"name":"Plant Biology","feed":[{"id":"2023.11.12.566746v1","slug":"a-transcriptomic-dataset-for-investigating-the-arabidopsis-unfolded-protein-response-under-chronic-proteotoxic-endoplasmic-reticulum-stress","title":"A transcriptomic dataset for investigating the Arabidopsis Unfolded Protein Response under chronic, proteotoxic endoplasmic reticulum stress","link":"http://biorxiv.org/cgi/content/short/2023.11.12.566746v1?rss=1","abstract":"The Unfolded Protein Response (UPR) is a retrograde, ER-to-nucleus, signalling pathway which is conserved across kingdoms. In plants, it contributes to development, reproduction, immunity and tolerance to abiotic stress. This RNA sequencing dataset was produced from 14-day-old Arabidopsis thaliana seedlings challenged by tunicamycin (Tm), an antibiotic inhibiting Asn-linked glycosylation in the endoplasmic reticulum (ER), causing an ER stress and eventually activating the UPR. Wild-type (WT) and a double mutant deficient for two main actors of the UPR (INOSITOL-REQUIRING ENZYME 1A and INOSITOL-REQUIRING ENZYME 1B) were used as genetic backgrounds in our experimental setup, allowing to distinguish among differentially-expressed genes (DEGs) which ones are dependent on or independent on IRE1s. Also, shoots and roots were harvested separately to determine organ-specific transcriptomic responses to Tm. Library and sequencing were performed using DNBseq technology by the Beijing Genomics Institute. Reads were mapped and quantified against the Arabidopsis genome. Differentially-expressed genes were identified using Rflomics upon filtering and normalization by the Trimmed Mean of M-value (TMM) method. While the genotype effect was weak under mock conditions (with a total of 182 DEGs in shoots and 195 DEGs in roots), the tunicamycin effect on each genotype was characterized by several hundred of DEGs in both shoots and roots. Among these genes, 872 and 563 genes were statistically up- and down-regulated in the shoot tissues of the double mutant when compared to those of WT, respectively. In roots of Tm-challenged seedlings, 425 and 439 genes were significantly up- and down-regulated in mutants with respect to WT. We believe that our dataset could be reused for investigating any biological questions linked to ER homeostasis and its role in plant physiology.","creator":"Ducloy, A., Azzopardi, M., Ivsic, C., Cueff, G., Sourdeval, D., Charif, D., Cacas, J.-L."},{"id":"2023.11.12.566724v1","slug":"photobodies-enable-the-phase-separation-and-counterbalance-of-phytochrome-b-mediated-pif5-degradation-and-stabilization","title":"Photobodies enable the phase-separation and counterbalance of phytochrome B mediated PIF5 degradation and stabilization","link":"http://biorxiv.org/cgi/content/short/2023.11.12.566724v1?rss=1","abstract":"Photoactivation of the plant photoreceptor and thermosensor phytochrome B (PHYB) triggers its condensation into subnuclear photobodies (PBs). However, the function of PBs remains frustratingly elusive. Here, we show that PHYB condensation enables the co-occurrence and competition of two antagonistic phase-separated signaling actions. We found that PHYB recruits PHYTOCHROME-INTERACTING FACTOR5 (PIF5) to PBs and, surprisingly, that PHYB exerts opposing roles in degrading and stabilizing PIF5. Perturbing PB size by overproducing PHYB provoked a biphasic PIF5 response: while a moderate increase in PHYB enhanced PIF5 degradation, further elevating the PHYB level stabilized PIF5 by retaining more of it in enlarged PBs. Our results support a model in which PHYB condensation stabilizes PIF5 in PBs to counteract PIF5 degradation in the surrounding nucleoplasm, thereby enabling an environmentally sensitive counterbalancing mechanism to titrate nucleoplasmic PIF5 and its transcriptional output. This PB-enabled signaling mechanism provides a framework for regulating a plethora of PHYB-interacting signaling molecules in diverse plant environmental responses. We propose that this function of PBs represents a general function of biomolecular condensates to allow distinct variations of a cellular process or signaling pathway to coexist and interact to generate dynamically adjustable integrated outputs within a single subcellular space.","creator":"Kim, R. J. A., Fan, D., He, J., Kim, K., Du, J., Chen, M."},{"id":"2023.11.10.566533v1","slug":"a-multiscale-approach-to-investigate-fluorescence-and-ndvi-imaging-as-proxy-of-photosynthetic-traits-in-wheat","title":"A multiscale approach to investigate fluorescence and NDVI imaging as proxy of photosynthetic traits in wheat","link":"http://biorxiv.org/cgi/content/short/2023.11.10.566533v1?rss=1","abstract":"With the development of the digital phenotyping, repeated measurements of agronomic traits over time are easily accessible, notably for morphological and phenological traits. However high throughput methods for estimating physiological traits such as photosynthesis are lacking. This study demonstrates the links of fluorescence and reflectance imaging with photosynthetic traits. Two wheat cultivars were grown in pots in a controlled environment. Photosynthesis was characterised by gas-exchange and biochemical analysis at five time points, from booting to 21 days post anthesis. On the same days imaging was performed on the same pots, at leaf and plant scale, using indoor and outdoor phenotyping platforms, respectively. Five image variables (Fv/Fm and NDVI at the whole plant level and Fv/Fm, {Phi}(II)532 and {Phi}(NPQ)1077 at the leaf scale) were compared to variables from A-Ci and A-Par curves, biochemical analysis, and fluorescence instruments. The results suggested that the image variables are robust estimators of photosynthetic traits, as long as senescence is driving the variability. Despite contrasting cultivar behaviour, linear regression models which account for the cultivar and the interaction effects, further improved the modelling of photosynthesis indicators. Finally, the results highlight the challenge of discriminating functional to cosmetic stay green genotypes using digital imaging.","creator":"Virlet, N., Pennacchi, J. P., Sadeghi-Tehran, P., Ashfield, T., Orr, D., Carmo-Silva, E., Hawkesford, M."},{"id":"2023.11.14.566975v1","slug":"plant-pathogenic-fungi-hijack-phosphate-starvation-signaling-with-conserved-enzymatic-effectors","title":"Plant pathogenic fungi hijack phosphate starvation signaling with conserved enzymatic effectors","link":"http://biorxiv.org/cgi/content/short/2023.11.14.566975v1?rss=1","abstract":"Phosphate availability modulates plant immune function and regulates interactions with beneficial, phosphate-providing, microbes. Here, we describe the hijacking of plant phosphate sensing by a family of Nudix hydrolase effectors from pathogenic Magnaporthe oryzae and Colletotrichum fungi. Structural and enzymatic analyses of the Nudix effector family demonstrate that they selectively hydrolyze inositol pyrophosphates, a molecule used by plants to monitor phosphate status and regulate starvation responses. In M. oryzae, gene deletion and complementation experiments reveal that the enzymatic activity of a Nudix effector significantly contributes to pathogen virulence. Further, we show that this conserved effector protein family induces phosphate starvation signaling in plants. Our study elucidates a molecular mechanism, utilized by multiple phytopathogenic fungi, that manipulates the highly conserved plant phosphate sensing pathway to exacerbate disease.","creator":"McCombe, C. L., Wegner, A., Zamora, C. S., Casanova, F., Aditya, S., Greenwood, J. R., Wirtz, L., de Paula, S., England, E., Shang, S., Ericsson, D. J., Oliveira-Garcia, E., Williams, S. J., Schaffrath, U."},{"id":"2023.11.14.567017v1","slug":"evidence-that-variation-in-root-anatomy-contributes-to-local-adaptation-in-mexican-native-maize","title":"Evidence that variation in root anatomy contributes to local adaptation in Mexican native maize","link":"http://biorxiv.org/cgi/content/short/2023.11.14.567017v1?rss=1","abstract":"Mexican native maize (Zea mays ssp. mays) is adapted to a wide range of climatic and edaphic conditions. Here, we focus specifically on the potential role of root anatomical variation in this adaptation. In light of the investment required to characterize root anatomy, we present a machine learning approach using environmental descriptors to project trait variation from a relatively small training panel onto a larger panel of genotyped and georeferenced Mexican maize accessions. The resulting models defined potential biologically relevant clines across a complex environment and were used subsequently in genotype-environment association. We found evidence of systematic variation in maize root anatomy across Mexico, notably a prevalence of trait combinations favoring a reduction in axial conductance in cooler, drier highland areas. We discuss our results in the context of previously described water-banking strategies and present candidate genes that are associated with both root anatomical and environmental variation. Our strategy is a refinement of standard environmental genome wide association analysis that is applicable whenever a training set of georeferenced phenotypic data is available.","creator":"McLaughlin, C., Li, M., Perryman, M., Heymans, A., Schneider, H., Lasky, J., Sawers, R."},{"id":"2023.11.14.567013v1","slug":"primary-multistep-phosphorelay-activation-comprises-both-cytokinin-and-abiotic-stress-responses-in-brassicaceae","title":"Primary multistep phosphorelay activation comprises both cytokinin and abiotic stress responses in Brassicaceae","link":"http://biorxiv.org/cgi/content/short/2023.11.14.567013v1?rss=1","abstract":"Multistep phosphorelay (MSP) signaling integrates hormonal and environmental signals to control plant development and adaptive responses. The type-A RESPONSE REGULATORs (RRAs), the downstream members of the MSP cascade and cytokinin primary response genes, are supposed to mediate primarily the negative feedback regulation of (cytokinin-induced) MSP signaling. However, the transcriptional data suggest the involvement of RRAs in stress-related responses as well. By employing evolutionary conservation with the well-characterized Arabidopsis thaliana RRAs, we identified 5 and 38 novel putative RRAs in Brassica oleracea and Brassica napus, respectively. Our phylogenetic analysis suggests the existence of gene-specific selective pressure, maintaining the homologs of ARR3, ARR6, and ARR16 as singletons during the evolution of Brassica oleracea and Brassica rapa. We categorized RRAs based on the kinetics of their cytokinin-mediated upregulation and observed both similarities and specificities in this type of response across Brassicaceae. Using bioinformatic analysis and experimental data demonstrating the cytokinin responsiveness of Arabidopsis-derived TCSv2 reporter, we unveil the mechanistic conservation of cytokinin-mediated upregulation of RRAs in Brassica rapa and Brassica napus. Notably, we identify partial cytokinin dependency of cold stress-induced RRA transcription, thus corroborating the role of cytokinin signaling in the crop adaptive responses.","creator":"Nicolas Mala, K. L., Skalak, J., Zemlyanskaya, E., Dolgikh, V., Jedlickova, V., Robert-Boisivon, H., Havlickova, L., Panzarova, K., Trtilek, M., Bancroft, I., Hejatko, J."},{"id":"2023.11.13.566960v1","slug":"does-stomatal-patterning-in-amphistomatous-leavesminimize-the-co2-diffusion-path-length-withinleaves","title":"Does stomatal patterning in amphistomatous leavesminimize the CO2 diffusion path length withinleaves?","link":"http://biorxiv.org/cgi/content/short/2023.11.13.566960v1?rss=1","abstract":"Photosynthesis is co-limited by multiple factors depending on the plant and its environment. These include biochemical rate limitations, internal and external water potentials, temperature, irradiance, and carbon dioxide (CO2). Amphistomatous leaves have stomata on both abaxial and adaxial leaf surfaces. This feature is considered an adaptation to alleviate CO2 diffusion limitations in productive environments where other factors are not limiting as the diffusion path length from stomate to chloroplast is effectively halved. Plants can also reduce CO2 limitations through other aspects of optimal stomatal anatomy: stomatal density, distribution, patterning, and size. A number of studies have demonstrated that stomata are overdispersed on a single leaf surface; however, much less is known about stomatal anatomy in amphistomatous leaves, especially the coordination between leaf surfaces, despite their prevelance in nature and near ubiquity among crop species. Here we use novel spatial statistics based on simulations and photosynthesis modeling to test hypotheses about how amphistomatous plants may optimize CO2 limitations in the model angiosperm Arabidopsis thaliana grown in different light environments. We find that 1) stomata are overdispersed, but not ideally dispersed, on both leaf surfaces across all light treatments; 2) abaxial and adaxial leaf surface patterning are independent; and 3) the theoretical improvements to photosynthesis from abaxial-adaxial stomatal coordination are miniscule (<< 1%) across the range of feasible parameter space. However, we also find that 4) stomatal size is correlated with the mesophyll volume that it supplies with CO2, suggesting that plants may optimize CO2 diffusion limitations through alternative pathways other than ideal, uniform stomatal spacing. We discuss the developmental, physical, and evolutionary constraits which may prohibit plants from reaching the theoretical adaptive peak of uniform stomatal spacing and inter surface stomatal coordination. These findings contribute to our understanding of variation in the anatomy of amphistomatous leaves.","creator":"Watts, J. L., Dow, G. J., Buckley, T. N., Muir, C. D."},{"id":"2023.11.14.566984v1","slug":"a-tomato-ethylene-insensitive-mutant-displays-altered-growth-and-higher-carotene-levels-in-fruit","title":"A tomato ethylene-insensitive mutant displays altered growth and higher -carotene levels in fruit","link":"http://biorxiv.org/cgi/content/short/2023.11.14.566984v1?rss=1","abstract":"The mutants insensitive to ethylene are helpful in deciphering the role of ethylene in plant development. We isolated an ethylene-insensitive tomato (Solanum lycopersicum) mutant by screening for acetylene-resistant (atr-1) seedlings. The atr-1 mutant displayed resistance to kinetin, suggesting attenuation of the ethylene sensing response. atr-1 also exhibited resistance to ABA- and glucose-mediated inhibition of seed germination. Unlike the Never-ripe (Nr) mutant, atr-1 seedlings were resistant to glucose, indicating ethylene sensing in atr-1 is located in a component distinct from Nr. Metabolically, atr-1 seedlings had lower levels of amino acids but higher levels of several phytohormones, including ABA. atr-1 plants grew faster and produced more flowers, leading to a higher fruit set. However, the atr-1 fruits took a longer duration to reach the red-ripe (RR) stage. The ripened atr-1 fruits had higher {beta}-carotene levels, retained high {beta}-carotene and lycopene levels post-RR stage. The metabolome profiles of post-RR stage atr-1 fruits revealed increased levels of sugars. The atr-1 had a P279L mutation in the GAF domain of the ETR4, a key ethylene receptor regulating tomato ripening. Our study highlights that novel alleles in ethylene receptors may aid in enhancing the nutritional quality of tomato.","creator":"Gupta, S. K., Santisree, P., Gupta, P., Kilambi, H. V., Sreelakshmi, Y., Sharma, R."},{"id":"2023.11.13.566818v1","slug":"transcriptomic-landscape-of-seedstick-in-arabidopsis-thaliana-funiculus-after-fertilisation","title":"Transcriptomic landscape of seedstick in Arabidopsis thaliana funiculus after fertilisation","link":"http://biorxiv.org/cgi/content/short/2023.11.13.566818v1?rss=1","abstract":"In Angiosperms, the continuation of plant species is intricately dependent on the funiculus multifaceted role in nutrient transport, mechanical support, and dehiscence of seeds. SEEDSTICK (STK) is a MADS-box transcription factor involved in seed size and dehiscence, and one of the few genes identified as affecting funiculus growth. Given the importance of the funiculus to a correct seed development, allied with previous phenotypic observations of stk mutants, we performed a transcriptomic analysis of stk funiculi, using RNA-sequencing, to infer on the deregulated networks of genes. The generated dataset of differentially expressed genes was enriched with cell wall biogenesis, cell cycle, sugar metabolism and transport terms, all in accordance with stk phenotype. We selected eight differentially expressed genes involved with abscission, seed development or novel functions in stk funiculus, such as hormones/secondary metabolites transport, for transcriptome validation using qPCR and/or promoter reporter lines. Overall, the analysis performed in this study allowed delving into the STK-network established in Arabidopsis funiculus, fulfilling a literature gap. Simultaneously, our findings reinforced the reliability of the transcriptome, and identified processes and new candidate genes that will enable a better understanding on the role of this sporophytic structure and how seed development may be affected by it.","creator":"Ferreira, M. J., Silva, J., Takeuchi, H., Suzuki, T., Higashiyama, T., Coimbra, S. V. d. A."},{"id":"2023.11.14.567063v1","slug":"comparing-hormone-dynamics-in-cereal-crops-via-transient-expression-of-hormone-sensors","title":"Comparing hormone dynamics in cereal crops via transient expression of hormone sensors","link":"http://biorxiv.org/cgi/content/short/2023.11.14.567063v1?rss=1","abstract":"Plant hormones are small molecules which elicit profound physiological responses. Although plant hormone biosynthesis and response genes have been critical for agricultural improvement, it has been difficult to experimentally compare hormone biology across species because of complex phenotypic outputs. We used transient expression of genetic hormone sensors and transcriptomics to quantify tissue-specific gibberellic acid (GA) and auxin responses across tissues and genotypes in cereal crops. We found that the FRET-based GPS2 biosensor detects exogenous GA treatments in maize, barley, sorghum, and wheat, in both vegetative and floral tissues. Measuring GPS2 output across GA dosages revealed tissue- and genotype-specific differences in GA sensor response. We observed marked differences in maize vs barley leaves and floral tissues and an unexpected drop in GPS2 output in the maize d1 GA biosynthesis mutant after GA treatment, likely reflecting differences in bioactive GA content, GA transport, and mechanisms of GA response. We then used RNAseq to measure transcriptional responses to GA treatment in leaves from maize wildtype, d1, and barley as well as floral tissues from maize and barley for a cross-tissue, cross-genotype, and cross-species GA-response comparison. After orthology prediction and analysis of within- and cross-species GO-term enrichment, we identified core sets of GA-responsive genes in each species as well as maize-barley orthogroups. Our analysis suggests that downregulation of GA-INSENSITIVE DWARF1 (GID1) and upregulation of -Expansin1 (EXPA1) orthologs comprises a universal GA-response mechanism that is independent of GA biosynthesis, and identifies F-Box proteins, hexokinase, and AMPK/SNF1 protein kinase orthologs as unexpected cross-tissue, cross-genotype, and cross-species GA-responsive genes. We then compared the transient expression of the DR5, DR5v2, and DII-mDII auxin reporters in barley and maize and find that although DR5 did not respond to exogenous auxin in barley, DR5v2 responded to auxin treatment with a similar magnitude as in maize. Both species display auxin-mediated DII degradation that requires the 26S proteasome.","creator":"Dao, T. Q., Drapek, C., Jones, A. M., Leiboff, S."},{"id":"2023.11.11.566720v1","slug":"sucrose-or-starch-the-influence-of-tonoplast-sucrose-transporter-perturbation-on-carbon-partitioning-for-growth-defense-and-winter-protection-in-coppiced-poplar","title":"Sucrose or starch? The influence of tonoplast sucrose transporter perturbation on carbon partitioning for growth, defense, and winter protection in coppiced poplar","link":"http://biorxiv.org/cgi/content/short/2023.11.11.566720v1?rss=1","abstract":"Non-structural carbohydrate reserves of stems and roots underpin overall tree fitness as well as productivity under short-rotation management practices such as coppicing for bioenergy. While both sucrose and starch comprise the predominant carbohydrate reserves of Populus, utilization is understood primarily in terms of starch turnover. The tonoplast sucrose transport protein SUT4 modulates sucrose export to distant sinks, but the possibility of its involvement in sink tissue carbohydrate remobilization has not been explored. Here, we used PtaSUT4-knockout mutants of Populus tremula x alba (INRA 717-1B4) in winter and summer glasshouse coppicing experiments to strain carbon demand and test for SUT4 involvement in reserve utilization. We show that epicormic bud emergence was delayed and subsequent growth reduced in sut4 mutants following winter but not summer coppicing. Reserve depletion during post-coppice regrowth was not impaired in the sut4 mutants under winter or summer glasshouse conditions. Interestingly, xylem hexose increased during post-coppice growth exclusively in the winter when osmoprotection is critical, and the increase was attenuated in sut4 mutants. Accrual of abundant defense metabolites, including salicinoids, chlorogenic acids, and flavonoid products was prioritized in the summer, but conspicuously lower in sut4 mutants than controls. Together, our results point to shifting priorities for SUT4 function from support for osmoprotection in winter to chemical defense in summer. Delayed bud release and growth following winter but not summer coppicing in the sut4 mutants demonstrate the importance of SUT4 in modulating trade-offs between growth and the other priorities during reserve utilization in Populus.","creator":"Tuma, T. T., Nyamdari, B., Hsieh, C., Chen, Y.-H., Harding, S. A., Tsai, C.-J."},{"id":"2023.11.11.566685v1","slug":"robust-organ-size-in-arabidopsis-is-primarily-governed-by-cell-growth-rather-than-cell-division-patterns","title":"Robust organ size in Arabidopsis is primarily governed by cell growth rather than cell division patterns","link":"http://biorxiv.org/cgi/content/short/2023.11.11.566685v1?rss=1","abstract":"Organ sizes and shapes are highly reproducible, or robust, within a species and individuals. Arabidopsis thaliana sepals, which are the leaf-like organs that enclose flower buds, have consistent size and shape, which indicates robust development. Counterintuitively, variability in cell growth rate over time and between cells facilitates robust development because cumulative cell growth averages to a uniform rate. Here we investigate how sepal morphogenesis is robust to changes in cell division but not robust to changes in cell growth variability. We live image and quantitatively compare the development of sepals with increased or decreased cell division rate (lgo mutant and LGO overexpression, respectively), a mutant with altered cell growth variability (ftsh4), and double mutants combining these. We find that robustness is preserved when cell division rate changes because there is no change in the spatial pattern of growth. Meanwhile when robustness is lost in ftsh4 mutants, cell growth accumulates unevenly, and cells have disorganized growth directions. Thus, we demonstrate in vivo that both cell growth rate and direction average in robust development, preserving robustness despite changes in cell division.","creator":"Burda, I., Li, C.-B., Clark, F. K., Roeder, A. H."},{"id":"2023.11.09.566501v1","slug":"genetic-factors-acting-prior-to-dormancy-in-sour-cherry-influence-bloom-time-the-following-spring","title":"Genetic factors acting prior to dormancy in sour cherry influence bloom time the following spring","link":"http://biorxiv.org/cgi/content/short/2023.11.09.566501v1?rss=1","abstract":"Bloom time is central to tree fruit production, and for Prunus species floral development leading up to bloom spans four seasons. Understanding this entire process is crucial for developing strategies to manipulate bloom time to prevent crop loss due to climate change. Here, we present a detailed examination of flower development from initiation until bloom for early- and late-blooming sour cherries (Prunus cerasus) from a population segregating for a major bloom time QTL on chromosome 4. Using a new staging system, we identified floral buds from early-blooming trees were persistently more advanced than those from late-blooming siblings. A gDNA coverage analysis revealed the late-blooming haplotype of this QTL, k, is located on a subgenome originating from the late-blooming P. fruticosa progenitor. Transcriptome analyses identified a large number of genes within this QTL as differentially expressed between early- and late-blooming trees during the vegetative-to-floral transition. From these, we identified candidate genes for the late bloom phenotype, including multiple transcription factors homologous to REproductive Meristem (REM) B3 domain-containing proteins. Additionally, we determined the basis of k in sour cherry is likely separate from candidate genes found in sweet cherry-suggesting several major regulators of bloom time are located on Prunus chromosome 4.","creator":"Goeckeritz, C. Z., Grabb, C., Grumet, R., Iezzoni, A. F., Hollender, C. A."},{"id":"2023.11.10.566572v1","slug":"an-arabidopsis-leaf-expression-atlas-across-diurnal-and-developmental-scales","title":"An Arabidopsis leaf expression atlas across diurnal and developmental scales","link":"http://biorxiv.org/cgi/content/short/2023.11.10.566572v1?rss=1","abstract":"Mature plant leaves are a composite of distinct cell types, including epidermal, mesophyll and vascular cells. Notably the proportion of these cells, and the relative transcript concentrations within different cell types may change over time. While gene expression data at a single-cell level can provide cell-type specific expression values, it is often too expensive to perform this on high resolution time series. Although bulk RNA-seq can be performed in a high resolution time series, the RNA-seq in whole leaves measures the average gene expression values across all cell types in each sample. In this study, we combined single cell RNA-seq data with time-series data from whole leaves to infer an atlas of cell type-specific gene expression changes over time for Arabidopsis thaliana. We inferred how relative transcript concentrations of cell types vary across diurnal and developmental time scales. Importantly this analysis revealed three sub-groups of mesophyll cells that have distinct temporal profiles of expression. Finally, we develop tissue-specific gene networks that form a new community resource: An Arabidopsis Leaf Time-Dependent Atlas (AraLeTa), which allows users to extract gene networks that are confirmed by transcription factor binding data and specific to certain cell types, at certain times of day and certain developmental stages, which is available at: https://regulatorynet.shinyapps.io/araleta/.","creator":"Vong, G., McCarthy, K., Claydon, W., Davis, S. J., Redmond, E. J., Ezer, D."},{"id":"2023.11.10.566469v1","slug":"assessing-the-capacity-of-high-resolution-commercial-satellite-imagery-for-grapevine-downy-mildew-detection-and-surveillance-in-new-york-state","title":"Assessing the capacity of high-resolution commercial satellite imagery for grapevine downy mildew detection and surveillance in New York state","link":"http://biorxiv.org/cgi/content/short/2023.11.10.566469v1?rss=1","abstract":"Grapevine downy mildew (GDM), caused by the oomycete Plasmopara viticola, can cause 100% yield loss and vine death under conducive conditions. Growers currently rely on frequent fungicide applications for control, but this practice has led to widespread resistance. Rapid remote detection and surveillance of GDM outbreaks would enable precision pesticide applications to target effective but resistance-prone fungicides where and when most needed, while relying on less resistance-prone protectants elsewhere. High resolution commercial satellite platforms offer the opportunity to track rapidly spreading diseases like GDM over large, heterogeneous fields. Here, we investigate the capacity of PlanetScope (3 m) and SkySat (50 cm) imagery for season-long GDM detection and surveillance. A team of trained scouts rated GDM severity and incidence in two acres of Chardonnay grapevines in Geneva, NY, USA in June-August of 2020, 2021, and 2022. Satellite imagery acquired within 72 hours of scouting was processed to extract single-band reflectance and vegetation indices (VIs). Random forest models trained on spectral bands and VIs derived from both image datasets could classify areas of high and low GDM incidence and severity with maximum accuracies of 0.88 (SkySat) and 0.94 (PlanetScope). However, we do not observe significant differences between VIs of high and low damage classes until late July-early August. We identify cloud cover, image co-registration, and low spectral resolution as key challenges to operationalizing satellite-based GDM surveillance. This work establishes the capacity of spaceborne multispectral sensors to detect late-stage GDM and outlines steps towards incorporating satellite remote sensing in grapevine disease surveillance systems.","creator":"Kanaley, K., Combs, D. B., Paul, A., Jiang, Y., Bates, T., Gold, K. M."},{"id":"2023.11.09.566459v1","slug":"comparative-mutant-analyses-reveal-a-novel-mechanism-of-arf-regulation-in-land-plants","title":"Comparative mutant analyses reveal a novel mechanism of ARF regulation in land plants","link":"http://biorxiv.org/cgi/content/short/2023.11.09.566459v1?rss=1","abstract":"A major challenge in plant biology is to understand how the plant hormone auxin regulates diverse transcriptional responses throughout development, in different environments, and in different species. The answer may lie in the specific complement of auxin signaling components in each cell. The balance between activators (class-A AUXIN RESPONSE FACTORS) and repressors (class-B ARFs) is particularly important. It is unclear how this balance is achieved. Through comparative analysis of novel, dominant mutants in maize and the moss Physcomitrium patens, we have discovered a ~500-million-year-old mechanism of class-B ARF protein level regulation, important in determining cell fate decisions across land plants. Thus, our results add a key piece to the puzzle of how auxin regulates plant development.","creator":"Prigge, M. J., Morffy, N., De Neve, A., Szutu, W., Juarez, M. J. A., Johnson, K., Do, N., Lavy, M., Hake, S., Strader, L., Estelle, M., Richardson, A. E."},{"id":"2023.11.09.566437v1","slug":"systems-analysis-of-long-term-heat-stress-responses-in-the-c4-grass-setaria-viridis","title":"Systems analysis of long-term heat stress responses in the C4 grass Setaria viridis","link":"http://biorxiv.org/cgi/content/short/2023.11.09.566437v1?rss=1","abstract":"A substantial number of C4 plants are utilized as food and fodder crops and often display improved resource use efficiency compared to C3 counterparts. However, their response to future extreme climates such as heatwaves is less understood. Setaria viridis, an emerging C4 model grass closely related to important C4 crops, was grown under high temperature for two weeks (42{degrees}C as compared to 28{degrees}C). High temperature resulted in stunted growth, but surprisingly had little impact on leaf area based photosynthetic rates. Rates of dark respiration significantly increased and there were major alterations in carbon and nitrogen metabolism in the heat-stressed plants, including reduced starch levels, accumulation of soluble sugars and an increase in leaf nitrogen content. Measurements of major phytohormones revealed a dramatic increase in abscisic acid in the heat-stressed plants. Leaf transcriptomics, proteomics and metabolomics analyses were carried out and mapped onto metabolic pathways of photosynthesis, respiration, carbon/nitrogen metabolism and hormone synthesis and signaling. Overall, upregulation of a number of stress-signaling pathways was observed, consistent with multiple potent signals leading to reduced plant growth. A systems model of plant response is presented based on oxidative stress, hormone and sugar signaling pathways.","creator":"Zhang, P., Sharwood, R. E., Carroll, A. J., von Caemmerer, S., Furbank, R. T."},{"id":"2023.11.08.566134v1","slug":"clair-an-integrated-lipid-database-across-multiple-crop-species","title":"CLAIR: An integrated lipid database across multiple crop species","link":"http://biorxiv.org/cgi/content/short/2023.11.08.566134v1?rss=1","abstract":"Oilseed crops, which are rich in plant lipids, provide essential fatty acids for human consumption and serve as major sources of biofuels and essential raw materials for the chemical industry. As a result of population growth and ecological changes, the demand for vegetable oil is increasingly outpacing supply. A comprehensive understanding of the genes involved in lipid metabolism in oilseed crops and the regulatory relationships among these genes is essential for improving oil content. However, current studies on lipid metabolism genes rely heavily on a decade-old database of genes involved in lipid metabolism in Arabidopsis thaliana. To address this issue, we mined the literature, integrated data from various databases and studies, and aligned homologs of lipid metabolism genes from nine oilseed crops to construct a comprehensive set of lipid metabolism genes in plants. Using this approach, we identified 221 additional lipid metabolism genes. In addition, we created a user-friendly lipid database called CLAIR (Crop Lipid-Associated Information Resource) by integrating and mining multi-omics data from nine major oil crops. The database is available at http://www.clipair.cn/. These resources should facilitate further research and exploration of lipid metabolism in oil crops, ultimately contributing to improved oil production.","creator":"He, B., Bu, M., Lin, Q., Fu, Z., Xie, J., Fan, W., Li, J., Li, R., Hua, W., Liu, W., Cui, P."},{"id":"2023.11.09.566286v1","slug":"genetic-insights-into-agronomic-and-morphological-traits-of-drug-type-cannabis-revealed-by-genome-wide-association-studies","title":"Genetic Insights into Agronomic and Morphological Traits of Drug-Type Cannabis Revealed by Genome-Wide Association Studies","link":"http://biorxiv.org/cgi/content/short/2023.11.09.566286v1?rss=1","abstract":"Cannabis (Cannabis sativa L.), once shrouded in the shadows of prohibition, is now emerging as a versatile and promising plant species, riding the wave of recent legalization. This transformation has unlocked opportunities for both medical research and industry growth, propelling cannabis into the global spotlight. Yet, years of prohibition have hindered the cannabis research community, which is hugely undersized and suffers from a scarcity of understanding of cannabis genetics and how key traits are expressed or inherited. To bridge this gap, we conducted a comprehensive genome-wide association study (GWAS), using a panel of 176 drug-type cannabis accessions, curated to represent the Canadian legal market. This pioneering GWAS harnessed the power of high-density genotyping-by-sequencing (HD-GBS), resulting in an exhaustive catalog of 800K genetic variants. These variants served as the bedrock for a GWAS designed to dissect the genetic foundations of nine key traits. To identify the most robust markers associated with these traits, two sophisticated statistical methodologies were used (SUPER and BLINK), ultimately identifying 33 markers significantly associated with agronomic and morphological traits. These markers, several of which exert a substantial phenotypic impact, guided us to a rich trove of putative candidate genes that reside in high linkage-disequilibrium (LD) with the markers. Markers uncovered in this study hold enormous promise, poised to revolutionize molecular breeding for the development of enhanced cannabis varieties that can cater to an array of diverse needs. In doing so, they lay the solid foundation for a vibrant and innovative cannabis industry poised to reshape the future.","creator":"de Ronne, M., Lapierre, E., Torkamaneh, D."},{"id":"2023.11.09.566436v1","slug":"udp-glucosyltransferase-71c4-regulates-seed-development-by-redistributing-phenylpropanoid-metabolism-in-cotton","title":"UDP-glucosyltransferase 71C4 regulates seed development by redistributing phenylpropanoid metabolism in cotton","link":"http://biorxiv.org/cgi/content/short/2023.11.09.566436v1?rss=1","abstract":"Seeds are important for plant reproduction, and hence it is important to identify genes regulating seed development. Here, we focused on a member of the glycosyltransferase (GT) family, UDP-glucosyltransferase 71C4 (UGT71C4), which influences the seed width, seed length, and yield traits (lint percentage and seed index) by regulating the lignin and flavonoid pathways of phenylpropane metabolism, affects the oil and protein contents of mature seeds, and controls the seed size by regulating cell proliferation. Overexpression of UGT71C4 leads to seed enlargement by activating expression of peroxiredoxins and the flavonoid metabolism pathway; induces accumulation of ROS, which promotes cell proliferation; and significantly improves yield traits, with the seed index increasing from 10.66 to 11.91 and protein increasing by 5.34%, but oil content decreasing 8.98%. Conversely, knockout of UGT71C4 causes seeds to become smaller; the lignin metabolism pathway to be activated, especially enzymes relating to lignin synthesis leading to increased ectopic deposition of lignin in the ovule and constrained ovule growth and development; and significant improvement of yield traits, with lint percentage increasing from 39.62% to 41.94%, seed index decreasing from 10.66 to 8.60, protein content decreasing 4.28%, and no significant change in oil content. Our research provides new insights into seed size regulation through UDP-glucosyltransferase, providing potential methods for improving plant yield.","creator":"Cao, Y., Han, Z., He, L., Huang, C., Chen, J., Dai, F., Xuan, L., Yan, S., Si, Z., Hu, Y., Zhang, T."},{"id":"2023.11.08.566295v1","slug":"cellular-copi-components-promote-geminivirus-infections-by-facilitating-the-chloroplast-localization-of-viral-c4-ac4-proteins","title":"Cellular COPI components promote geminivirus infections by facilitating the chloroplast localization of viral C4/AC4 proteins","link":"http://biorxiv.org/cgi/content/short/2023.11.08.566295v1?rss=1","abstract":"Geminiviruses are a family of viruses that infect numerous crops and cause extensive agricultural losses worldwide. During viral infection, geminiviral C4/AC4 proteins relocate from the plasma membrane (PM) to chloroplasts, where they inhibit chloroplast-mediated host defense, including the biosynthesis of salicylic acid (SA). However, how are C4/AC4 proteins transported to chloroplasts is unknown. We report here that the Coat Protein I (COPI) components play a critical role in redistributing Tomato yellow leaf curl virus (TYLCV) C4 protein to chloroplasts. TYLCV C4 interacts with the {beta} subunit of COPI, and the coexpression of both in Nicotiana benthamiana cells promotes the enrichment of C4 in chloroplasts, which also occurs during TYLCV infection and is blocked by an inhibitor of the COPI pathway. Overexpression of COPI components promotes but knockdown of gene expression inhibits TYLCV infection. The COPI pathway plays similar roles in C4/AC4 transport and infections of other geminiviruses, including Beet curly top virus and East African cassava mosaic virus. Our results identify an unconventional role of the COPI pathway in protein trafficking to chloroplasts during geminiviruses infections in plants, and suggest a broad-spectrum antiviral strategy in controlling geminiviruses by manipulating COPI components.","creator":"Zhao, W., Ji, Y., Zhou, Y., Wang, X."},{"id":"2023.11.08.566267v1","slug":"antisense-transcription-interferes-with-heterologous-expression-of-a-codon-optimised-mneongreen-fluorescent-reporter-in-the-chloroplast-of-chlamydomonas-reinhardtii","title":"Antisense transcription interferes with heterologous expression of a codon-optimised mNeonGreen fluorescent reporter in the chloroplast of Chlamydomonas reinhardtii.","link":"http://biorxiv.org/cgi/content/short/2023.11.08.566267v1?rss=1","abstract":"Although over 30 years have passed since Chlamydomonas reinhardtii chloroplast transformation was first achieved, genetic engineering of the chloroplast still remains an arduous task. The glass-bead transformation method has enabled simple and accessible chloroplast transformation of the C. reinhardtii TN72 strain, allowing generation of marker-free transplastomic strains for low-cost experimentation. However, lack of functional fluorescent reporters limit research and widespread development of chloroplast engineering. Here, we developed a codon-optimised mNeonGreen fluorescent reporter, which can be detected in vivo through fluorometry and microscopy. We found evidence for chloroplast post-transcriptional regulation of gene expression derived from formation of antisense pairing of mRNAs due to readthrough of convergent adjacent genes. In addition, synthetic biology approaches were used to modulate transcriptional readthrough, allowing a better understanding of context effects relevant for heterologous expression. This work provides new tools to study basic aspects of the molecular biology in the chloroplast in C. reinhardtii, as well as evidence for fundamental processes of gene regulation that may enable developing rules for more efficient chloroplast engineering.","creator":"Navarrete, A., Pollak, B."},{"id":"2023.11.06.565859v1","slug":"gibberellin-perception-sensors-1-and-2-reveal-cellular-ga-dynamics-articulated-by-cop1-and-ga20ox1-that-are-necessary-but-not-sufficient-to-pattern-hypocotyl-cell-elongation","title":"Gibberellin Perception Sensors 1 and 2 reveal cellular GA dynamics articulated by COP1 and GA20ox1 that are necessary but not sufficient to pattern hypocotyl cell elongation","link":"http://biorxiv.org/cgi/content/short/2023.11.06.565859v1?rss=1","abstract":"The phytohormone gibberellin (GA) is critical for environmentally sensitive plant development including germination, skotomorphogenesis and flowering. The FRET biosensor GIBBERELLIN PERCEPTION SENSOR1, which permits single-cell GA measurements in vivo, was previously used to observe a GA gradient correlated with cell length in dark-grown but not light-grown hypocotyls. We sought to understand how light signalling integrates into cellular GA regulation. Here we show how the E3 ligase COP1 and transcription factor HY5 play central roles in directing cellular GA distribution in skoto- and photomorphogenic hypocotyls, respectively. We demonstrate that the expression pattern of biosynthetic enzyme GA20ox1 is the key determinant of the GA gradient in dark-grown hypocotyls and is a target of COP1 signalling. We engineered a second generation GPS2 biosensor with improved orthogonality and reversibility to show the cellular pattern of GA depletion during the transition to growth in the light. This GA depletion partly explains the resetting of hypocotyl growth dynamics during photomorphogenesis. Achieving cell-level resolution has revealed how GA distributions link environmental conditions with morphology and morphological plasticity and the GPS2 biosensor is an ideal tool for GA studies in further conditions, organs and plant species.","creator":"Griffiths, J., Rizza, A., Tang, B., Frommer, W. B., Jones, A. M."},{"id":"2023.11.07.566062v1","slug":"dissection-of-figured-wood-trait-in-curly-birch-betula-pendula-var-carelica-using-high-throughput-genotyping","title":"Dissection of figured wood trait in curly birch (Betula pendula var. carelica) using high-throughput genotyping","link":"http://biorxiv.org/cgi/content/short/2023.11.07.566062v1?rss=1","abstract":"Curly (Karelian) birch is a special variety of Betula pendula distributed in the northwestern part of Europe. Karelian birch is well-known for its valuable figured curly wood also known as \"wooden marble\". The genetic basis underlying curly wood formation has been debated since last century, however, there was no data about loci responsible for the curly wood trait. In the present study, we analyzed two full-sibs populations derived from experimental crosses of curly birches and segregating for the trait. RADseq genotyping was applied to reveal how many loci are involved in  curliness formation and to search for genetic variants associated with this trait. One single interval on chromosome 10 was detected containing possible candidate genes. InDel marker BpCW1 was suggested for the first time for marker-assisted selection of trees with curly wood at their earliest stages of development.","creator":"Gubaev, R., Karzhaev, D., Grigoreva, E., Lytkin, K., Safronycheva, E., Volkov, V., Nesterchuk, V., Vetchinnikova, L., Zhigunov, A., Potokina, E."},{"id":"2023.11.08.566006v1","slug":"thermal-imaging-can-reveal-variation-in-stay-green-functionality-of-wheat-canopies-under-temperate-conditions","title":"Thermal imaging can reveal variation in stay-green functionality of wheat canopies under temperate conditions","link":"http://biorxiv.org/cgi/content/short/2023.11.08.566006v1?rss=1","abstract":"Canopy temperature (CT) is often interpreted as representing leaf activity traits such as photosynthetic rates, gas exchange rates, or stomatal conductance. Accordingly, CT measurements may provide a basis for high throughput assessments of the productivity of wheat canopies during early grain filling, which would allow distinguishing functional from dysfunctional stay-green. However, whereas the usefulness of CT as a fast surrogate measure of sustained vigor under soil drying is well established, its potential to quantify leaf activity traits under high-yielding conditions is less clear. To better understand sensitivity limits of CT measurements under high yielding conditions, we generated within-genotype variability in stay-green functionality by means of differential short-term pre-anthesis canopy shading that modified the sink:source balance. We quantified the effects of these modifications on stay-green properties through a combination of gold standard physiological measurements of leaf activity and newly developed methods for organ-level senescence monitoring based on timeseries of high-resolution imagery and deep-learning-based semantic image segmentation. In parallel, we monitored CT by means of a pole-mounted thermal camera that delivered continuous, ultra-high temporal resolution CT data. Our results show that differences in leaf activity stemming from differences in stay-green functionality translate into measurable differences in CT in the absence of major confounding factors. Differences amounted to approximately 0.8{degrees}C and 1.5{degrees}C for a very high-yielding source-limited genotype, and a medium-yielding sink-limited genotype, respectively. The gradual nature of the effects of shading on CT during the stay-green phase underscore the importance of a high measurement frequency and a time-integrated analysis of CT, whilst modest effect sizes confirm the importance of restricting screenings to a limited range of morphological and phenological diversity.","creator":"Anderegg, J., Kirchgessner, N., Aasen, H., Zumsteg, O., Keller, B., Zenkl, R., Walter, A., Hund, A."},{"id":"2023.11.08.566204v1","slug":"mobile-tuberigen-impacts-tuber-onset-synchronization-and-canopy-senescence-timing-in-potato","title":"Mobile tuberigen impacts tuber onset synchronization and canopy senescence timing in potato","link":"http://biorxiv.org/cgi/content/short/2023.11.08.566204v1?rss=1","abstract":"Yield of harvestable organs is a complex function of photosynthetic output, and sink-strength and timing of competing carbon sinks. In potato (Solanum tuberosum) the effect of tuber onset timing and post-tuberization canopy senescence on growth dynamics and tuber fresh weight are poorly understood. To advance our understanding we compared above- and belowground traits of wildtype plants (WT) with StSP6A, i.e., tuberigen, knockdown plants (SP6Ai) and developed simple computational models to aid interpretation of results. We find that SP6Ai results in a delay of approximately 2 weeks in tuber onset, yet has a 4-to-5-week delayed canopy senescence. Together this results in a prolonged tuber growth phase, with reduced synchronization in tuber onset and a resulting increased variance in tuber sizes, while overall final tuber fresh weight remains similar. Using a leaf and tuber growth model comparing various leaf senescence mechanisms, we find that resource competition, and not a shared signal for tuberization and senescence, is able to explain how delayed tuberization leads to further delayed senescence. Our results point to a role for resource competition in the correlated timing of tuber onset and canopy senescence, as well as a leading role for StSP6A in tuber onset synchronization and tuber size uniformity.  Graphical Abstract  O_FIG O_LINKSMALLFIG WIDTH=144 HEIGHT=200 SRC=\"FIGDIR/small/566204v1_ufig1.gif\" ALT=\"Figure 1\"> View larger version (33K): org.highwire.dtl.DTLVardef@15aaea0org.highwire.dtl.DTLVardef@7ea4b7org.highwire.dtl.DTLVardef@6fedb5org.highwire.dtl.DTLVardef@5f3996_HPS_FORMAT_FIGEXP  M_FIG C_FIG","creator":"van den Herik, B., Bergonzi, S., Bachem, C. W. B., Tusscher, K. H. W. J."},{"id":"2023.11.07.566092v1","slug":"globally-deployed-sorghum-aphid-resistance-gene-rmes1-is-vulnerable-to-biotype-shifts-but-being-bolstered-by-rmes2","title":"Globally-deployed sorghum aphid resistance gene RMES1 is vulnerable to biotype shifts but being bolstered by RMES2","link":"http://biorxiv.org/cgi/content/short/2023.11.07.566092v1?rss=1","abstract":"Durable host plant resistance (HPR) to insect pests is critical for sustainable agriculture. Natural variation exists for aphid HPR in sorghum (Sorghum bicolor) but the genetic architecture and phenotype has not been clarified for most sources. To assess the threat of a sorghum aphid (Melanaphis sorghi) biotype shift, we characterized the phenotype of Resistance to Melanaphis sorghi 1 (RMES1) and contributing HPR architecture in globally-admixed populations selected under severe aphid infestation in Haiti. We found RMES1 reduces sorghum aphid fecundity but not bird cherry-oat aphid (Rhopalosiphum padi) fecundity, suggesting a discriminant HPR response typical of gene-for-gene interaction. A second resistant gene, RMES2, were more frequent than RMES1 resistant alleles in landraces and historic breeding lines. RMES2 contributes early and mid-season aphid resistance in a segregating F2 population, however RMES1 was only significant with mid-season fitness. In a fixed population with high aphid resistance, RMES1 and RMES2 were selected for demonstrating a lack of significant antagonistic pleiotropy. Associations with resistance co-located with cyanogenic glucoside biosynthesis genes support additional HPR sources. Globally, therefore, a vulnerable HPR source (RMES1) is bolstered by a second common source of resistance in breeding programs (RMES2) which may be staving off a biotype shift.  HIGHLIGHTThe globally-deployed sorghum aphid resistance gene, RMES1, reduces aphid reproduction and therefore is vulnerable to a biotype shift. A second major gene, RMES2, and cyanogenesis may increase global durability of resistance.","creator":"VanGessel, C., Rice, B., Felderhoff, T., Charles, J. R., Pressoir, G., Nalam, V., Morris, G. P."},{"id":"2023.11.07.565979v1","slug":"repression-of-pattern-triggered-immune-responses-by-hypoxia","title":"Repression of pattern-triggered immune responses by hypoxia","link":"http://biorxiv.org/cgi/content/short/2023.11.07.565979v1?rss=1","abstract":"Combined abiotic/biotic stresses frequently occur in nature. Yet, relatively little is known about how plants regulate the crosstalk between stress response pathways to trigger a coordinated response to combined stresses. Protein degradation by the ubiquitin/proteasome system (UPS) is central to the regulation of plant responses to multiple stresses, including the crosstalk between pathways. The Arg/N-degron pathway, a subset of the UPS, targets proteins based on their N-termini. In plants, it has been implicated in the responses to both biotic and abiotic stresses, while being a key regulator of hypoxia response through the degradation of ERF-VII transcription factors, which orchestrate the onset of the hypoxia response program. Because of its central position in regulating multiple (a)biotic stresses, we hypothesized that the Arg/N-degron pathway could act in the crosstalk between abiotic/biotic stresses. In exploring this possibility using the model pathogen-associated molecular pattern flg22 to elicit pattern-triggered immunity (PTI), we uncovered a link between the transcriptional response programs to hypoxia and to flg22. Combined hypoxia/flg22 treatments further showed that hypoxia represses the flg22 transcriptional program, as well as the expression of pattern recognition receptors, MAPK signalling and callose deposition during PTI, through mechanisms that are at least partly dependent on the ERF-VIIs. These findings are of relevance to understanding the trade-offs between plant responses to combined abiotic/biotic stresses in the context of our efforts to increase crop resilience to global climate change. Our results also show that the well-known repressive effect of hypoxia on innate immunity in animals also applies to plants.  Significance statementUnderstanding how plants regulate the crosstalk between stress response pathways is key to our efforts to increase crop resilience and mitigate yield losses caused by global climate change. Despite the urgency to do so, relatively little remains known about how plants respond to combined stresses, which frequently occur in nature. Here, we show that the hypoxia response program and the basal layer of plant immunity (pattern-triggered immunity or PTI) share components. Our data also show that hypoxia represses several key aspects of the plants innate immune response, a situation akin to that discovered in animals decades ago. These findings have implications for our ability to develop resilient crops by limiting the negative trade-offs that exist between hypoxia response and immunity.","creator":"Mooney, B. C., Doorly, C. M., Mantz, M., Garcia, P., Huesgen, P. F., Graciet, E."},{"id":"2023.11.06.565838v1","slug":"the-arabidopsis-information-resource-in-2024","title":"The Arabidopsis Information Resource in 2024","link":"http://biorxiv.org/cgi/content/short/2023.11.06.565838v1?rss=1","abstract":"Since 1999, The Arabidopsis Information Resource (www.arabidopsis.org) has been curating data about the Arabidopsis thaliana genome. Its primary focus is integrating experimental gene function information from the peer-reviewed literature and codifying it as controlled vocabulary annotations. Our goal is to produce a  gold standard functional annotation set that reflects the current state of knowledge about the Arabidopsis genome. At the same time, the resource serves as a nexus for community-based collaborations aimed at improving data quality, access and reuse. For the past decade, our work has been made possible by subscriptions from our global user base. This update covers our ongoing biocuration work, some of our modernization efforts that contribute to the first major infrastructure overhaul since 2011, the introduction of JBrowse2, and the resources role in community activities such as organizing the structural reannotation of the genome. For gene function assessment, we used Gene Ontology annotations as a metric to evaluate: (1) what is currently known about Arabidopsis gene function, and (2) the set of  unknown genes. Currently, 74% of the proteome has been annotated to at least one Gene Ontology term. Of those loci, half have experimental support for at least one of the following aspects: molecular function, biological process, or cellular component. Our work sheds light on the genes for which we have not yet identified any published experimental data and have no functional annotation. Drawing attention to these unknown genes highlights knowledge gaps and potential sources of novel discoveries.  Article SummaryThe Arabidopsis Information Resource (TAIR, www.arabidopsis.org) is a comprehensive website about Arabidopsis thaliana, a small plant thats very easy to grow and analyze in the laboratory and is used to understand how many other plants function. We share our progress in data collection and organization, website and tool improvement, and our involvement in community projects.","creator":"Reiser, L., Bakker, E., Subramaniam, S., Chen, X., Sawant, S., Khosa, K., Prithvi, T., Berardini, T. Z."},{"id":"2023.11.06.565694v1","slug":"can-biocrust-moss-hide-from-climate-change-multiscale-habitat-buffering-improves-summer-stress-resistance-in-syntrichia-caninervis","title":"Can biocrust moss hide from climate change? Multiscale habitat buffering improves summer-stress resistance in Syntrichia caninervis","link":"http://biorxiv.org/cgi/content/short/2023.11.06.565694v1?rss=1","abstract":"PremiseDryland mosses provide many ecosystem functions but are the most vulnerable of biocrust organisms to climate change due to sensitive water relations particularly stressed by summer aridity. However, potential mitigating roles of habitat buffering on moss aridity exposure and stress resistance remain largely unexplored. We predicted the most buffered and healthiest biocrust mosses would occur in high-elevation forests on north-facing slopes beneath shrub canopies in the Mojave Desert.  MethodsWe located three life zone populations of a keystone biocrust moss, Syntrichia caninervis, spanning 1200-m of altitude in Nevada. We selected 96 microsites stratified by life zone and topography zone (aspect and hydrological position), and microhabitat type (shrub proximity). We quantified end-of-summer photosynthetic stress (Fv/Fm), and aridity at three scales: macroclimate, mesoscale exposure, and microscale shade time.  ResultsMoss habitat structure varied greatly across scales, revealing exposed and buffered microsites in all life zones. Moss stress did not differ by life zone despite the extensive macroclimate gradient but was lowest on N-facing slopes and microhabitats with higher shade, while the importance and interactions of topography, exposure, and shade varied by life zone.  ConclusionsOur findings support an emerging vulnerability paradigm for small dryland organisms: microrefugia may be more important than high-elevation macrorefugia for increasing resistance to climate stress. We demonstrate, for the first time, that multiple scales of interacting habitat structure appear to create physiologically significant buffered habitats for S. caninervis, which may allow this species to hide from the brunt of climate change in widespread microrefugia.","creator":"Clark, T. A., Russell, A., Greenwood, J. L., Devitt, D., Stanton, D., Stark, L. R."}]},{"name":"Economics","feed":[{"id":"2311.07754","slug":"efficient-prior-free-mechanisms-for-no-regret-agents-arxiv-2311-07754v1-cs-gt","title":"Efficient Prior-Free Mechanisms for No-Regret Agents.","link":"http://arxiv.org/abs/2311.07754","abstract":"We study a repeated Principal Agent problem between a long lived Principal and Agent pair in a prior free setting. In our setting, the sequence of realized states of nature may be adversarially chosen, the Agent is non-myopic, and the Principal aims for a strong form of policy regret. Following Camara, Hartline, and Johnson, we model the Agent's long-run behavior with behavioral assumptions that relax the common prior assumption (for example, that the Agent has no swap regret). Within this framework, we revisit the mechanism proposed by Camara et al., which informally uses calibrated forecasts of the unknown states of nature in place of a common prior. We give two main improvements. First, we give a mechanism that has an exponentially improved dependence (in terms of both running time and regret bounds) on the number of distinct states of nature. To do this, we show that our mechanism does not require truly calibrated forecasts, but rather forecasts that are unbiased subject to only a polynomially sized collection of events -- which can be produced with polynomial overhead. Second, in several important special cases -- including the focal linear contracting setting -- we show how to remove strong ``Alignment'' assumptions (which informally require that near-ties are always broken in favor of the Principal) by specifically deploying ``stable'' policies that do not have any near ties that are payoff relevant to the Principal. Taken together, our new mechanism makes the compelling framework proposed by Camara et al. much more powerful, now able to be realized over polynomially sized state spaces, and while requiring only mild assumptions on Agent behavior.","creator":"Natalie Collina, Aaron Roth, Han Shao"},{"id":"2311.07905","slug":"considering-risk-aversion-in-economic-evaluation-a-rank-dependent-approach-arxiv-2311-07905v1-econ-th","title":"Considering Risk Aversion in Economic Evaluation: A Rank Dependent Approach.","link":"http://arxiv.org/abs/2311.07905","abstract":"This paper presents a method for incorporating risk aversion into existing decision tree models used in economic evaluations. The method involves applying a probability weighting function based on rank dependent utility theory to reduced lotteries in the decision tree model. This adaptation embodies the fact that different decision makers can observe the same decision tree model structure but come to different conclusions about the optimal treatment. The proposed solution to this problem is to compensate risk-averse decision makers to use the efficient technology that they are reluctant to adopt.","creator":"Jacob Smith"},{"id":"2311.07920","slug":"dynamic-incentives-in-centralized-matching-the-case-of-japanese-daycare-arxiv-2311-07920v1-econ-gn","title":"Dynamic Incentives in Centralized Matching: The Case of Japanese Daycare.","link":"http://arxiv.org/abs/2311.07920","abstract":"This study investigates the strategic behavior of applicants in the Japanese daycare market, where waitlisted applicants are granted additional priority points in subsequent application rounds. Utilizing data from Tokyo's Bunkyo municipality, this paper provides evidence of considerable manipulation, with parents strategically choosing to be waitlisted to enhance the likelihood of their child's admission into more selective daycare centers. I extend the static framework of school choice posited by Agarwal and Somaini (2018) to incorporate dynamic incentives and estimate a structural model that allows for reapplication if waitlisted. Empirical findings indicate that approximately 30% of applicants forgo listing safer options in their initial application, a behavior significantly pronounced among those who stand to benefit from the waitlist prioritization. Counterfactual simulations, conducted under the scenario of no additional waitlist priority, predict a 17.7% decrease in the number of waitlisted applicants and a 1.2% increase in overall welfare. These findings highlight the profound influence of dynamic incentives on applicant behavior and underscore the necessity for reevaluating current priority mechanisms.","creator":"Kan Kuno"},{"id":"2311.08218","slug":"estimating-conditional-value-at-risk-with-nonstationary-quantile-predictive-regression-models-arxiv-2311-08218v1-econ-em","title":"Estimating Conditional Value-at-Risk with Nonstationary Quantile Predictive Regression Models.","link":"http://arxiv.org/abs/2311.08218","abstract":"This paper develops an asymptotic distribution theory for a two-stage instrumentation estimation approach in quantile predictive regressions when both generated covariates and persistent predictors are used. The generated covariates are obtained from an auxiliary quantile regression model and our main interest is the robust estimation and inference of the primary quantile predictive regression in which this generated covariate is added to the set of nonstationary regressors. We find that the proposed doubly IVX estimator is robust to the abstract degree of persistence regardless of the presence of generated regressor obtained from the first stage procedure. The asymptotic properties of the two-stage IVX estimator such as mixed Gaussianity are established while the asymptotic covariance matrix is adjusted to account for the first-step estimation error.","creator":"Christis Katsouris"},{"id":"2311.08256","slug":"consensus-and-disagreement-information-aggregation-under-not-so-naive-learning-arxiv-2311-08256v1-econ-gn","title":"Consensus and Disagreement: Information Aggregation under (not so) Naive Learning.","link":"http://arxiv.org/abs/2311.08256","abstract":"We explore a model of non-Bayesian information aggregation in networks. Agents non-cooperatively choose among Friedkin-Johnsen type aggregation rules to maximize payoffs. The DeGroot rule is chosen in equilibrium if and only if there is noiseless information transmission, leading to consensus. With noisy transmission, while some disagreement is inevitable, the optimal choice of rule amplifies the disagreement: even with little noise, individuals place substantial weight on their own initial opinion in every period, exacerbating the disagreement. We use this framework to think about equilibrium versus socially efficient choice of rules and its connection to polarization of opinions across groups.","creator":"Abhijit Banerjee, Olivier Compte"},{"id":"2212.06736","slug":"the-role-of-mandated-mental-health-treatment-in-the-criminal-justice-system-arxiv-2212-06736v2-econ-gn-updated","title":"The Role of Mandated Mental Health Treatment in the Criminal Justice System.","link":"http://arxiv.org/abs/2212.06736","abstract":"Mental health disorders are particularly prevalent among those in the criminal justice system and may be a contributing factor in recidivism. Using North Carolina court cases from 1994 to 2009, this paper evaluates how mandated mental health treatment as a term of probation impacts the likelihood that individuals return to the criminal justice system. I use random variation in judge assignment to compare those who were required to seek weekly mental health counseling to those who were not. The main findings are that being assigned to seek mental health treatment decreases the likelihood of three-year recidivism by about 12 percentage points, or 36 percent. This effect persists over time, and is similar among various types of individuals on probation. In addition, I show that mental health treatment operates distinctly from drug addiction interventions in a multiple-treatment framework. I provide evidence that mental health treatment's longer-term effectiveness is strongest among more financially-advantaged probationers, consistent with this setting, in which the cost of mandated treatment is shouldered by offenders. Finally, conservative calculations result in a 5:1 benefit-to-cost ratio which suggests that the treatment-induced decrease in future crime would be more than sufficient to offset the costs of treatment.","creator":"Rachel Nesbit"},{"id":"2302.00469","slug":"regression-adjustment-in-randomized-controlled-trials-with-many-covariates-arxiv-2302-00469v3-econ-em-updated","title":"Regression adjustment in randomized controlled trials with many covariates.","link":"http://arxiv.org/abs/2302.00469","abstract":"This paper is concerned with estimation and inference on average treatment effects in randomized controlled trials when researchers observe potentially many covariates. By employing Neyman's (1923) finite population perspective, we propose a bias-corrected regression adjustment estimator using cross-fitting, and show that the proposed estimator has favorable properties over existing alternatives. For inference, we derive the first and second order terms in the stochastic component of the regression adjustment estimators, study higher order properties of the existing inference methods, and propose a bias-corrected version of the HC3 standard error. The proposed methods readily extend to stratified experiments with large strata. Simulation studies show our cross-fitted estimator, combined with the bias-corrected HC3, delivers precise point estimates and robust size controls over a wide range of DGPs. To illustrate, the proposed methods are applied to real dataset on randomized experiments of incentives and services for college achievement following Angrist, Lang, and Oreopoulos (2009).","creator":"Harold D Chiang, Yukitoshi Matsushita, Taisuke Otsu"},{"id":"2302.14440","slug":"intergenerational-mobility-trends-and-the-changing-role-of-female-labor-arxiv-2302-14440v2-econ-gn-updated","title":"Intergenerational Mobility Trends and the Changing Role of Female Labor.","link":"http://arxiv.org/abs/2302.14440","abstract":"Using harmonized administrative data from Scandinavia, we find that intergenerational rank associations in income have increased uniformly across Sweden, Denmark, and Norway for cohorts born between 1951 and 1979. Splitting these trends by gender, we find that father-son mobility has been stable, while family correlations for mothers and daughters trend upward. Similar patterns appear in US survey data, albeit with slightly different timing. Finally, based on evidence from records on occupations and educational attainments, we argue that the observed decline in intergenerational mobility is consistent with female skills becoming increasingly valued in the labor market.","creator":"Ulrika Ahrsj&#xf6;, Ren&#xe9; Karadakic, Joachim Kahr Rasmussen"},{"id":"2309.12945","slug":"the-micro-aggregated-profit-share-arxiv-2309-12945v3-econ-gn-updated","title":"The Micro-Aggregated Profit Share.","link":"http://arxiv.org/abs/2309.12945","abstract":"How much has market power increased in the United States in the last fifty years? And how did the rise in market power affect aggregate profits? Using micro-level data from U.S. Compustat, we find that several indicators of market power have steadily increased since 1970. In particular, the aggregate markup has gone up from 10% of price over marginal cost in 1970 to 23% in 2020, and aggregate returns to scale have risen from 1.00 to 1.13. We connect these market-power indicators to profitability by showing that the aggregate profit share can be expressed in terms of the aggregate markup, aggregate returns to scale, and a sufficient statistic for production networks that captures double marginalization in the economy. We find that despite the rise in market power, the profit share has been constant at 18% of GDP because the increase in monopoly rents has been completely offset by rising fixed costs and changes in technology. Our empirical results have subtle implications for policymakers: overly aggressive enforcement of antitrust law could decrease firm dynamism and paradoxically lead to lower competition and higher market power.","creator":"Thomas Hasenzagl, Luis Perez"}]}]