[
  {
    "name": "Artificial Intelligence",
    "feed": [
      {
        "title": "Through their eyes: multi-subject Brain Decoding with simple alignment techniques.",
        "link": "http://arxiv.org/abs/2309.00627",
        "abstract": "Previous brain decoding research primarily involves single-subject studies, reconstructing stimuli via fMRI activity from the same subject. Our study aims to introduce a generalization technique for cross-subject brain decoding, facilitated by exploring data alignment methods. We utilized the NSD dataset, a comprehensive 7T fMRI vision experiment involving multiple subjects exposed to 9841 images, 982 of which were viewed by all. Our approach involved training a decoding model on one subject, aligning others' data to this space, and testing the decoding on the second subject. We compared ridge regression, hyper alignment, and anatomical alignment techniques for fMRI data alignment. We established that cross-subject brain decoding is feasible, even using around 10% of the total data, or 982 common images, with comparable performance to single-subject decoding. Ridge regression was the best method for functional alignment. Through subject alignment, we achieved superior brain decoding and a potential 90% reduction in scan time. This could pave the way for more efficient experiments and further advancements in the field, typically requiring an exorbitant 20-hour scan time per subject.",
        "creator": "Matteo Ferrante, Tommaso Boccato, Nicola Toschi"
      },
      {
        "title": "Generative AI for End-to-End Limit Order Book Modelling: A Token-Level Autoregressive Generative Model of Message Flow Using a Deep State Space Network.",
        "link": "http://arxiv.org/abs/2309.00638",
        "abstract": "Developing a generative model of realistic order flow in financial markets is a challenging open problem, with numerous applications for market participants. Addressing this, we propose the first end-to-end autoregressive generative model that generates tokenized limit order book (LOB) messages. These messages are interpreted by a Jax-LOB simulator, which updates the LOB state. To handle long sequences efficiently, the model employs simplified structured state-space layers to process sequences of order book states and tokenized messages. Using LOBSTER data of NASDAQ equity LOBs, we develop a custom tokenizer for message data, converting groups of successive digits to tokens, similar to tokenization in large language models. Out-of-sample results show promising performance in approximating the data distribution, as evidenced by low model perplexity. Furthermore, the mid-price returns calculated from the generated order flow exhibit a significant correlation with the data, indicating impressive conditional forecast performance. Due to the granularity of generated data, and the accuracy of the model, it offers new application areas for future work beyond forecasting, e.g. acting as a world model in high-frequency financial reinforcement learning applications. Overall, our results invite the use and extension of the model in the direction of autoregressive large financial models for the generation of high-frequency financial data and we commit to open-sourcing our code to facilitate future research.",
        "creator": "Peer Nagy, Sascha Frey, Silvia Sapora, Kang Li, Anisoara Calinescu, Stefan Zohren, Jakob Foerster"
      },
      {
        "title": "Ten New Benchmarks for Optimization.",
        "link": "http://arxiv.org/abs/2309.00644",
        "abstract": "Benchmarks are used for testing new optimization algorithms and their variants to evaluate their performance. Most existing benchmarks are smooth functions. This chapter introduces ten new benchmarks with different properties, including noise, discontinuity, parameter estimation and unknown paths.",
        "creator": "Xin-She Yang"
      },
      {
        "title": "Intelligence as a Measure of Consciousness.",
        "link": "http://arxiv.org/abs/2309.00646",
        "abstract": "Evaluating artificial systems for signs of consciousness is increasingly becoming a pressing concern, and a rigorous psychometric measurement framework may be of crucial importance in evaluating large language models in this regard. Most prominent theories of consciousness, both scientific and metaphysical, argue for different kinds of information coupling as a necessary component of human-like consciousness. By comparing information coupling in human and animal brains, human cognitive development, emergent abilities, and mental representation development to analogous phenomena in large language models, I argue that psychometric measures of intelligence, such as the g-factor or IQ, indirectly approximate the extent of conscious experience.  Based on a broader source of both scientific and metaphysical theories of consciousness, I argue that all systems possess a degree of consciousness ascertainable psychometrically and that psychometric measures of intelligence may be used to gauge relative similarities of conscious experiences across disparate systems, be they artificial or human.",
        "creator": "Igor &#x160;evo"
      },
      {
        "title": "GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice.",
        "link": "http://arxiv.org/abs/2309.00649",
        "abstract": "We assess the ability of GPT -- a large language model -- to serve as a financial robo-advisor for the masses, by using a financial literacy test. Davinci and ChatGPT based on GPT-3.5 score 66% and 65% on the financial literacy test, respectively, compared to a baseline of 33%. However, ChatGPT based on GPT-4 achieves a near-perfect 99% score, pointing to financial literacy becoming an emergent ability of state-of-the-art models. We use the Judge-Advisor System and a savings dilemma to illustrate how researchers might assess advice-utilization from large language models. We also present a number of directions for future research.",
        "creator": "Pawe&#x142; Niszczota, Sami Abbas"
      },
      {
        "title": "The Use of Synthetic Data to Train AI Models: Opportunities and Risks for Sustainable Development.",
        "link": "http://arxiv.org/abs/2309.00652",
        "abstract": "In the current data driven era, synthetic data, artificially generated data that resembles the characteristics of real world data without containing actual personal information, is gaining prominence. This is due to its potential to safeguard privacy, increase the availability of data for research, and reduce bias in machine learning models. This paper investigates the policies governing the creation, utilization, and dissemination of synthetic data. Synthetic data can be a powerful instrument for protecting the privacy of individuals, but it also presents challenges, such as ensuring its quality and authenticity. A well crafted synthetic data policy must strike a balance between privacy concerns and the utility of data, ensuring that it can be utilized effectively without compromising ethical or legal standards. Organizations and institutions must develop standardized guidelines and best practices in order to capitalize on the benefits of synthetic data while addressing its inherent challenges.",
        "creator": "Tshilidzi Marwala, Eleonore Fournier-Tombs, Serge Stinckwich"
      },
      {
        "title": "ICDARTS: Improving the Stability and Performance of Cyclic DARTS.",
        "link": "http://arxiv.org/abs/2309.00664",
        "abstract": "This work introduces improvements to the stability and generalizability of Cyclic DARTS (CDARTS). CDARTS is a Differentiable Architecture Search (DARTS)-based approach to neural architecture search (NAS) that uses a cyclic feedback mechanism to train search and evaluation networks concurrently. This training protocol aims to optimize the search process by enforcing that the search and evaluation networks produce similar outputs. However, CDARTS introduces a loss function for the evaluation network that is dependent on the search network. The dissimilarity between the loss functions used by the evaluation networks during the search and retraining phases results in a search-phase evaluation network that is a sub-optimal proxy for the final evaluation network that is utilized during retraining. We present ICDARTS, a revised approach that eliminates the dependency of the evaluation network weights upon those of the search network, along with a modified process for discretizing the search network's \\textit{zero} operations that allows these operations to be retained in the final evaluation networks. We pair the results of these changes with ablation studies on ICDARTS' algorithm and network template. Finally, we explore methods for expanding the search space of ICDARTS by expanding its operation set and exploring alternate methods for discretizing its continuous search cells. These experiments resulted in networks with improved generalizability and the implementation of a novel method for incorporating a dynamic search space into ICDARTS.",
        "creator": "Emily Herron, Derek Rose, Steven Young"
      },
      {
        "title": "Jointly Exploring Client Drift and Catastrophic Forgetting in Dynamic Learning.",
        "link": "http://arxiv.org/abs/2309.00688",
        "abstract": "Federated and Continual Learning have emerged as potential paradigms for the robust and privacy-aware use of Deep Learning in dynamic environments. However, Client Drift and Catastrophic Forgetting are fundamental obstacles to guaranteeing consistent performance. Existing work only addresses these problems separately, which neglects the fact that the root cause behind both forms of performance deterioration is connected. We propose a unified analysis framework for building a controlled test environment for Client Drift -- by perturbing a defined ratio of clients -- and Catastrophic Forgetting -- by shifting all clients with a particular strength. Our framework further leverages this new combined analysis by generating a 3D landscape of the combined performance impact from both. We demonstrate that the performance drop through Client Drift, caused by a certain share of shifted clients, is correlated to the drop from Catastrophic Forgetting resulting from a corresponding shift strength. Correlation tests between both problems for Computer Vision (CelebA) and Medical Imaging (PESO) support this new perspective, with an average Pearson rank correlation coefficient of over 0.94. Our framework's novel ability of combined spatio-temporal shift analysis allows us to investigate how both forms of distribution shift behave in mixed scenarios, opening a new pathway for better generalization. We show that a combination of moderate Client Drift and Catastrophic Forgetting can even improve the performance of the resulting model (causing a \"Generalization Bump\") compared to when only one of the shifts occurs individually. We apply a simple and commonly used method from Continual Learning in the federated setting and observe this phenomenon to be reoccurring, leveraging the ability of our framework to analyze existing and novel methods for Federated and Continual Learning.",
        "creator": "Niklas Babendererde, Moritz Fuchs, Camila Gonzalez, Yuri Tolkach, Anirban Mukhopadhyay"
      },
      {
        "title": "Geometric Deep Learning: a Temperature Based Analysis of Graph Neural Networks.",
        "link": "http://arxiv.org/abs/2309.00699",
        "abstract": "We examine a Geometric Deep Learning model as a thermodynamic system treating the weights as non-quantum and non-relativistic particles. We employ the notion of temperature previously defined in [7] and study it in the various layers for GCN and GAT models. Potential future applications of our findings are discussed.",
        "creator": "M. Lapenna, F. Faglioni, F. Zanchetta, R. Fioresi"
      },
      {
        "title": "Reinforcement Learning with Human Feedback for Realistic Traffic Simulation.",
        "link": "http://arxiv.org/abs/2309.00709",
        "abstract": "In light of the challenges and costs of real-world testing, autonomous vehicle developers often rely on testing in simulation for the creation of reliable systems. A key element of effective simulation is the incorporation of realistic traffic models that align with human knowledge, an aspect that has proven challenging due to the need to balance realism and diversity. This works aims to address this by developing a framework that employs reinforcement learning with human preference (RLHF) to enhance the realism of existing traffic models. This study also identifies two main challenges: capturing the nuances of human preferences on realism and the unification of diverse traffic simulation models. To tackle these issues, we propose using human feedback for alignment and employ RLHF due to its sample efficiency. We also introduce the first dataset for realism alignment in traffic modeling to support such research. Our framework, named TrafficRLHF, demonstrates its proficiency in generating realistic traffic scenarios that are well-aligned with human preferences, as corroborated by comprehensive evaluations on the nuScenes dataset.",
        "creator": "Yulong Cao, Boris Ivanovic, Chaowei Xiao, Marco Pavone"
      },
      {
        "title": "Contextual Biasing of Named-Entities with Large Language Models.",
        "link": "http://arxiv.org/abs/2309.00723",
        "abstract": "This paper studies contextual biasing with Large Language Models (LLMs), where during second-pass rescoring additional contextual information is provided to a LLM to boost Automatic Speech Recognition (ASR) performance. We propose to leverage prompts for a LLM without fine tuning during rescoring which incorporate a biasing list and few-shot examples to serve as additional information when calculating the score for the hypothesis. In addition to few-shot prompt learning, we propose multi-task training of the LLM to predict both the entity class and the next token. To improve the efficiency for contextual biasing and to avoid exceeding LLMs' maximum sequence lengths, we propose dynamic prompting, where we select the most likely class using the class tag prediction, and only use entities in this class as contexts for next token prediction. Word Error Rate (WER) evaluation is performed on i) an internal calling, messaging, and dictation dataset, and ii) the SLUE-Voxpopuli dataset. Results indicate that biasing lists and few-shot examples can achieve 17.8% and 9.6% relative improvement compared to first pass ASR, and that multi-task training and dynamic prompting can achieve 20.0% and 11.3% relative WER improvement, respectively.",
        "creator": "Chuanneng Sun, Zeeshan Ahmed, Yingyi Ma, Zhe Liu, Yutong Pang, Ozlem Kalinli"
      },
      {
        "title": "Backdoor Attack on Hash-based Image Retrieval via Clean-label Data Poisoning.",
        "link": "http://arxiv.org/abs/2109.08868",
        "abstract": "A backdoored deep hashing model is expected to behave normally on original query images and return the images with the target label when a specific trigger pattern presents. To this end, we propose the confusing perturbations-induced backdoor attack (CIBA). It injects a small number of poisoned images with the correct label into the training data, which makes the attack hard to be detected. To craft the poisoned images, we first propose the confusing perturbations to disturb the hashing code learning. As such, the hashing model can learn more about the trigger. The confusing perturbations are imperceptible and generated by optimizing the intra-class dispersion and inter-class shift in the Hamming space. We then employ the targeted adversarial patch as the backdoor trigger to improve the attack performance. We have conducted extensive experiments to verify the effectiveness of our proposed CIBA. Our code is available at https://github.com/KuofengGao/CIBA.",
        "creator": "Kuofeng Gao, Jiawang Bai, Bin Chen, Dongxian Wu, Shu-Tao Xia"
      },
      {
        "title": "LoNLI: An Extensible Framework for Testing Diverse Logical Reasoning Capabilities for NLI.",
        "link": "http://arxiv.org/abs/2112.02333",
        "abstract": "Natural Language Inference (NLI) is considered a representative task to test natural language understanding (NLU). In this work, we propose an extensible framework to collectively yet categorically test diverse Logical reasoning capabilities required for NLI (and, by extension, NLU). Motivated by behavioral testing, we create a semi-synthetic large test bench (363 templates, 363k examples) and an associated framework that offers the following utilities: 1) individually test and analyze reasoning capabilities along 17 reasoning dimensions (including pragmatic reasoning); 2) design experiments to study cross-capability information content (leave one out or bring one in); and 3) the synthetic nature enables us to control for artifacts and biases. We extend a publicly available framework of automated test case instantiation from free-form natural language templates (CheckList) and a well-defined taxonomy of capabilities to cover a wide range of increasingly harder test cases while varying the complexity of natural language. Through our analysis of state-of-the-art NLI systems, we observe that our benchmark is indeed hard (and non-trivial even with training on additional resources). Some capabilities stand out as harder. Further, fine-grained analysis and fine-tuning experiments reveal more insights about these capabilities and the models -- supporting and extending previous observations; thus showing the utility of the proposed testbench.",
        "creator": "Ishan Tarunesh, Somak Aditya, Monojit Choudhury"
      },
      {
        "title": "Knowledge-informed Molecular Learning: A Survey on Paradigm Transfer.",
        "link": "http://arxiv.org/abs/2202.10587",
        "abstract": "Machine learning, notably deep learning, has significantly propelled molecular investigations within the biochemical sphere. Traditionally, modeling for such research has centered around a handful of paradigms. For instance, the prediction paradigm is frequently deployed for tasks such as molecular property prediction. To enhance the generation and decipherability of purely data-driven models, scholars have integrated biochemical domain knowledge into these molecular study models. This integration has sparked a surge in paradigm transfer, which is solving one molecular learning task by reformulating it as another one. With the emergence of Large Language Models, these paradigms have demonstrated an escalating trend towards harmonized unification. In this work, we delineate a literature survey focused on knowledge-informed molecular learning from the perspective of paradigm transfer. We classify the paradigms, scrutinize their methodologies, and dissect the contribution of domain knowledge. Moreover, we encapsulate prevailing trends and identify intriguing avenues for future exploration in molecular learning.",
        "creator": "Yin Fang, Zhuo Chen, Xiaohui Fan, Ningyu Zhang"
      },
      {
        "title": "Engineering flexible machine learning systems by traversing functionally-invariant paths.",
        "link": "http://arxiv.org/abs/2205.00334",
        "abstract": "Transformers have emerged as the state of the art neural network architecture for natural language processing and computer vision. In the foundation model paradigm, large transformer models (BERT, GPT3/4, Bloom, ViT) are pre-trained on self-supervised tasks such as word or image masking, and then, adapted through fine-tuning for downstream user applications including instruction following and Question Answering. While many approaches have been developed for model fine-tuning including low-rank weight update strategies (eg. LoRA), underlying mathematical principles that enable network adaptation without knowledge loss remain poorly understood. Here, we introduce a differential geometry framework, functionally invariant paths (FIP), that provides flexible and continuous adaptation of neural networks for a range of machine learning goals and network sparsification objectives. We conceptualize the weight space of a neural network as a curved Riemannian manifold equipped with a metric tensor whose spectrum defines low rank subspaces in weight space that accommodate network adaptation without loss of prior knowledge. We formalize adaptation as movement along a geodesic path in weight space while searching for networks that accommodate secondary objectives. With modest computational resources, the FIP algorithm achieves comparable to state of the art performance on continual learning and sparsification tasks for language models (BERT), vision transformers (ViT, DeIT), and the CNNs. Broadly, we conceptualize a neural network as a mathematical object that can be iteratively transformed into distinct configurations by the path-sampling algorithm to define a sub-manifold of weight space that can be harnessed to achieve user goals.",
        "creator": "Guruprasad Raghavan, Bahey Tharwat, Surya Narayanan Hari, Dhruvil Satani, Matt Thomson"
      },
      {
        "title": "Introspective Deep Metric Learning for Image Retrieval.",
        "link": "http://arxiv.org/abs/2205.04449",
        "abstract": "This paper proposes an introspective deep metric learning (IDML) framework for uncertainty-aware comparisons of images. Conventional deep metric learning methods produce confident semantic distances between images regardless of the uncertainty level. However, we argue that a good similarity model should consider the semantic discrepancies with caution to better deal with ambiguous images for more robust training. To achieve this, we propose to represent an image using not only a semantic embedding but also an accompanying uncertainty embedding, which describes the semantic characteristics and ambiguity of an image, respectively. We further propose an introspective similarity metric to make similarity judgments between images considering both their semantic differences and ambiguities. The proposed IDML framework improves the performance of deep metric learning through uncertainty modeling and attains state-of-the-art results on the widely used CUB-200-2011, Cars196, and Stanford Online Products datasets for image retrieval and clustering. We further provide an in-depth analysis of our framework to demonstrate the effectiveness and reliability of IDML. Code is available at: https://github.com/wzzheng/IDML.",
        "creator": "Wenzhao Zheng, Chengkun Wang, Jie Zhou, Jiwen Lu"
      },
      {
        "title": "Hierarchical Distribution-Aware Testing of Deep Learning.",
        "link": "http://arxiv.org/abs/2205.08589",
        "abstract": "Deep Learning (DL) is increasingly used in safety-critical applications, raising concerns about its reliability. DL suffers from a well-known problem of lacking robustness, especially when faced with adversarial perturbations known as Adversarial Examples (AEs). Despite recent efforts to detect AEs using advanced attack and testing methods, these approaches often overlook the input distribution and perceptual quality of the perturbations. As a result, the detected AEs may not be relevant in practical applications or may appear unrealistic to human observers. This can waste testing resources on rare AEs that seldom occur during real-world use, limiting improvements in DL model dependability.  In this paper, we propose a new robustness testing approach for detecting AEs that considers both the feature level distribution and the pixel level distribution, capturing the perceptual quality of adversarial perturbations. The two considerations are encoded by a novel hierarchical mechanism. First, we select test seeds based on the density of feature level distribution and the vulnerability of adversarial robustness. The vulnerability of test seeds are indicated by the auxiliary information, that are highly correlated with local robustness. Given a test seed, we then develop a novel genetic algorithm based local test case generation method, in which two fitness functions work alternatively to control the perceptual quality of detected AEs. Finally, extensive experiments confirm that our holistic approach considering hierarchical distributions is superior to the state-of-the-arts that either disregard any input distribution or only consider a single (non-hierarchical) distribution, in terms of not only detecting imperceptible AEs but also improving the overall robustness of the DL model under testing.",
        "creator": "Wei Huang, Xingyu Zhao, Alec Banks, Victoria Cox, Xiaowei Huang"
      },
      {
        "title": "Customs Import Declaration Datasets.",
        "link": "http://arxiv.org/abs/2208.02484",
        "abstract": "Given the huge volume of cross-border flows, effective and efficient control of trade becomes more crucial in protecting people and society from illicit trade. However, limited accessibility of the transaction-level trade datasets hinders the progress of open research, and lots of customs administrations have not benefited from the recent progress in data-based risk management. In this paper, we introduce an import declaration dataset to facilitate the collaboration between domain experts in customs administrations and researchers from diverse domains, such as data science and machine learning. The dataset contains 54,000 artificially generated trades with 22 key attributes, and it is synthesized with conditional tabular GAN while maintaining correlated features. Synthetic data has several advantages. First, releasing the dataset is free from restrictions that do not allow disclosing the original import data. The fabrication step minimizes the possible identity risk which may exist in trade statistics. Second, the published data follow a similar distribution to the source data so that it can be used in various downstream tasks. Hence, our dataset can be used as a benchmark for testing the performance of any classification algorithm. With the provision of data and its generation process, we open baseline codes for fraud detection tasks, as we empirically show that more advanced algorithms can better detect fraud.",
        "creator": "Chaeyoon Jeong, Sundong Kim, Jaewoo Park, Yeonsoo Choi"
      },
      {
        "title": "Learning Efficient Abstract Planning Models that Choose What to Predict.",
        "link": "http://arxiv.org/abs/2208.07737",
        "abstract": "An effective approach to solving long-horizon tasks in robotics domains with continuous state and action spaces is bilevel planning, wherein a high-level search over an abstraction of an environment is used to guide low-level decision-making. Recent work has shown how to enable such bilevel planning by learning abstract models in the form of symbolic operators and neural samplers. In this work, we show that existing symbolic operator learning approaches fall short in many robotics domains where a robot's actions tend to cause a large number of irrelevant changes in the abstract state. This is primarily because they attempt to learn operators that exactly predict all observed changes in the abstract state. To overcome this issue, we propose to learn operators that 'choose what to predict' by only modelling changes necessary for abstract planning to achieve specified goals. Experimentally, we show that our approach learns operators that lead to efficient planning across 10 different hybrid robotics domains, including 4 from the challenging BEHAVIOR-100 benchmark, while generalizing to novel initial states, goals, and objects.",
        "creator": "Nishanth Kumar, Willie McClinton, Rohan Chitnis, Tom Silver, Tom&#xe1;s Lozano-P&#xe9;rez, Leslie Pack Kaelbling"
      },
      {
        "title": "The alignment problem from a deep learning perspective.",
        "link": "http://arxiv.org/abs/2209.00626",
        "abstract": "In coming decades, artificial general intelligence (AGI) may surpass human capabilities at many critical tasks. We argue that, without substantial effort to prevent it, AGIs could learn to pursue goals that conflict (i.e., are misaligned) with human interests. If trained like today's most capable models, AGIs could learn to act deceptively to receive higher reward, learn internally-represented goals which generalize beyond their fine-tuning distributions, and pursue those goals using power-seeking strategies. We review emerging evidence for these properties. AGIs with these properties would be difficult to align and may appear aligned even when they are not. We outline how the deployment of misaligned AGIs might irreversibly undermine human control over the world, and briefly review research directions aimed at preventing this outcome.",
        "creator": "Richard Ngo, Lawrence Chan, S&#xf6;ren Mindermann"
      },
      {
        "title": "Faked Speech Detection with Zero Knowledge.",
        "link": "http://arxiv.org/abs/2209.12573",
        "abstract": "Audio is one of the most used ways of human communication, but at the same time it can be easily misused to trick people. With the revolution of AI, the related technologies are now accessible to almost everyone thus making it simple for the criminals to commit crimes and forgeries. In this work, we introduce a neural network method to develop a classifier that will blindly classify an input audio as real or mimicked; the word 'blindly' refers to the ability to detect mimicked audio without references or real sources. The proposed model was trained on a set of important features extracted from a large dataset of audios to get a classifier that was tested on the same set of features from different audios. The data was extracted from two raw datasets, especially composed for this work; an all English dataset and a mixed dataset (Arabic plus English). These datasets have been made available, in raw form, through GitHub for the use of the research community at https://github.com/SaSs7/Dataset. For the purpose of comparison, the audios were also classified through human inspection with the subjects being the native speakers. The ensued results were interesting and exhibited formidable accuracy.",
        "creator": "Sahar Al Ajmi, Khizar Hayat, Alaa M. Al Obaidi, Naresh Kumar, Munaf Najmuldeen, Baptiste Magnier"
      },
      {
        "title": "Unraveling Key Elements Underlying Molecular Property Prediction: A Systematic Study.",
        "link": "http://arxiv.org/abs/2209.13492",
        "abstract": "Artificial intelligence (AI) has been widely applied in drug discovery with a major task as molecular property prediction. Despite booming techniques in molecular representation learning, key elements underlying molecular property prediction remain largely unexplored, which impedes further advancements in this field. Herein, we conduct an extensive evaluation of representative models using various representations on the MoleculeNet datasets, a suite of opioids-related datasets and two additional activity datasets from the literature. To investigate the predictive power in low-data and high-data space, a series of descriptors datasets of varying sizes are also assembled to evaluate the models. In total, we have trained 62,820 models, including 50,220 models on fixed representations, 4,200 models on SMILES sequences and 8,400 models on molecular graphs. Based on extensive experimentation and rigorous comparison, we show that representation learning models exhibit limited performance in molecular property prediction in most datasets. Besides, multiple key elements underlying molecular property prediction can affect the evaluation results. Furthermore, we show that activity cliffs can significantly impact model prediction. Finally, we explore into potential causes why representation learning models can fail and show that dataset size is essential for representation learning models to excel.",
        "creator": "Jianyuan Deng, Zhibo Yang, Hehe Wang, Iwao Ojima, Dimitris Samaras, Fusheng Wang"
      },
      {
        "title": "A Secure Federated Data-Driven Evolutionary Multi-objective Optimization Algorithm.",
        "link": "http://arxiv.org/abs/2210.08295",
        "abstract": "Data-driven evolutionary algorithms usually aim to exploit the information behind a limited amount of data to perform optimization, which have proved to be successful in solving many complex real-world optimization problems. However, most data-driven evolutionary algorithms are centralized, causing privacy and security concerns. Existing federated Bayesian algorithms and data-driven evolutionary algorithms mainly protect the raw data on each client. To address this issue, this paper proposes a secure federated data-driven evolutionary multi-objective optimization algorithm to protect both the raw data and the newly infilled solutions obtained by optimizing the acquisition function conducted on the server. We select the query points on a randomly selected client at each round of surrogate update by calculating the acquisition function values of the unobserved points on this client, thereby reducing the risk of leaking the information about the solution to be sampled. In addition, since the predicted objective values of each client may contain sensitive information, we mask the objective values with Diffie-Hellmann-based noise, and then send only the masked objective values of other clients to the selected client via the server. Since the calculation of the acquisition function also requires both the predicted objective value and the uncertainty of the prediction, the predicted mean objective and uncertainty are normalized to reduce the influence of noise. Experimental results on a set of widely used multi-objective optimization benchmarks show that the proposed algorithm can protect privacy and enhance security with only negligible sacrifice in the performance of federated data-driven evolutionary optimization.",
        "creator": "Qiqi Liu, Yuping Yan, Peter Ligeti, Yaochu Jin"
      },
      {
        "title": "Towards Human-centered Explainable AI: A Survey of User Studies for Model Explanations.",
        "link": "http://arxiv.org/abs/2210.11584",
        "abstract": "Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI research. A better understanding of the needs of XAI users, as well as human-centered evaluations of explainable models are both a necessity and a challenge. In this paper, we explore how HCI and AI researchers conduct user studies in XAI applications based on a systematic literature review. After identifying and thoroughly analyzing 97core papers with human-based XAI evaluations over the past five years, we categorize them along the measured characteristics of explanatory methods, namely trust, understanding, usability, and human-AI collaboration performance. Our research shows that XAI is spreading more rapidly in certain application domains, such as recommender systems than in others, but that user evaluations are still rather sparse and incorporate hardly any insights from cognitive or social sciences. Based on a comprehensive discussion of best practices, i.e., common models, design choices, and measures in user studies, we propose practical guidelines on designing and conducting user studies for XAI researchers and practitioners. Lastly, this survey also highlights several open research directions, particularly linking psychological science and human-centered XAI.",
        "creator": "Yao Rong, Tobias Leemann, Thai-trang Nguyen, Lisa Fiedler, Peizhu Qian, Vaibhav Unhelkar, Tina Seidel, Gjergji Kasneci, Enkelejda Kasneci"
      },
      {
        "title": "JAX-DIPS: Neural bootstrapping of finite discretization methods and application to elliptic problems with discontinuities.",
        "link": "http://arxiv.org/abs/2210.14312",
        "abstract": "We present a scalable strategy for development of mesh-free hybrid neuro-symbolic partial differential equation solvers based on existing mesh-based numerical discretization methods. Particularly, this strategy can be used to efficiently train neural network surrogate models of partial differential equations by (i) leveraging the accuracy and convergence properties of advanced numerical methods, solvers, and preconditioners, as well as (ii) better scalability to higher order PDEs by strictly limiting optimization to first order automatic differentiation. The presented neural bootstrapping method (hereby dubbed NBM) is based on evaluation of the finite discretization residuals of the PDE system obtained on implicit Cartesian cells centered on a set of random collocation points with respect to trainable parameters of the neural network. Importantly, the conservation laws and symmetries present in the bootstrapped finite discretization equations inform the neural network about solution regularities within local neighborhoods of training points. We apply NBM to the important class of elliptic problems with jump conditions across irregular interfaces in three spatial dimensions. We show the method is convergent such that model accuracy improves by increasing number of collocation points in the domain and predonditioning the residuals. We show NBM is competitive in terms of memory and training speed with other PINN-type frameworks. The algorithms presented here are implemented using \\texttt{JAX} in a software package named \\texttt{JAX-DIPS} (https://github.com/JAX-DIPS/JAX-DIPS), standing for differentiable interfacial PDE solver. We open sourced \\texttt{JAX-DIPS} to facilitate research into use of differentiable algorithms for developing hybrid PDE solvers.",
        "creator": "Pouria Mistani, Samira Pakravan, Rajesh Ilango, Frederic Gibou"
      },
      {
        "title": "Observable Perfect Equilibrium.",
        "link": "http://arxiv.org/abs/2210.16506",
        "abstract": "While Nash equilibrium has emerged as the central game-theoretic solution concept, many important games contain several Nash equilibria and we must determine how to select between them in order to create real strategic agents. Several Nash equilibrium refinement concepts have been proposed and studied for sequential imperfect-information games, the most prominent being trembling-hand perfect equilibrium, quasi-perfect equilibrium, and recently one-sided quasi-perfect equilibrium. These concepts are robust to certain arbitrarily small mistakes, and are guaranteed to always exist; however, we argue that neither of these is the correct concept for developing strong agents in sequential games of imperfect information. We define a new equilibrium refinement concept for extensive-form games called observable perfect equilibrium in which the solution is robust over trembles in publicly-observable action probabilities (not necessarily over all action probabilities that may not be observable by opposing players). Observable perfect equilibrium correctly captures the assumption that the opponent is playing as rationally as possible given mistakes that have been observed (while previous solution concepts do not). We prove that observable perfect equilibrium is always guaranteed to exist, and demonstrate that it leads to a different solution than the prior extensive-form refinements in no-limit poker. We expect observable perfect equilibrium to be a useful equilibrium refinement concept for modeling many important imperfect-information games of interest in artificial intelligence.",
        "creator": "Sam Ganzfried"
      },
      {
        "title": "MemoNet: Memorizing All Cross Features' Representations Efficiently via Multi-Hash Codebook Network for CTR Prediction.",
        "link": "http://arxiv.org/abs/2211.01334",
        "abstract": "New findings in natural language processing (NLP) demonstrate that the strong memorization capability contributes a lot to the success of Large Language Models (LLM). This inspires us to explicitly bring an independent memory mechanism into CTR ranking model to learn and memorize cross features' representations. In this paper, we propose multi-Hash Codebook NETwork (HCNet) as the memory mechanism for efficiently learning and memorizing representations of cross features in CTR tasks. HCNet uses a multi-hash codebook as the main memory place and the whole memory procedure consists of three phases: multi-hash addressing, memory restoring, and feature shrinking. We also propose a new CTR model named MemoNet which combines HCNet with a DNN backbone. Extensive experimental results on three public datasets and online test show that MemoNet reaches superior performance over state-of-the-art approaches. Besides, MemoNet shows scaling law of large language model in NLP, which means we can enlarge the size of the codebook in HCNet to sustainably obtain performance gains. Our work demonstrates the importance and feasibility of learning and memorizing representations of cross features, which sheds light on a new promising research direction.",
        "creator": "Pengtao Zhang, Junlin Zhang"
      },
      {
        "title": "Semantic Representations of Mathematical Expressions in a Continuous Vector Space.",
        "link": "http://arxiv.org/abs/2211.08142",
        "abstract": "Mathematical notation makes up a large portion of STEM literature, yet finding semantic representations for formulae remains a challenging problem. Because mathematical notation is precise, and its meaning changes significantly with small character shifts, the methods that work for natural text do not necessarily work well for mathematical expressions. This work describes an approach for representing mathematical expressions in a continuous vector space. We use the encoder of a sequence-to-sequence architecture, trained on visually different but mathematically equivalent expressions, to generate vector representations (or embeddings). We compare this approach with a structural approach that considers visual layout to embed an expression and show that our proposed approach is better at capturing mathematical semantics. Finally, to expedite future research, we publish a corpus of equivalent transcendental and algebraic expression pairs.",
        "creator": "Neeraj Gangwar, Nickvash Kani"
      },
      {
        "title": "Social media mining for toxicovigilance of prescription medications: End-to-end pipeline, challenges and future work.",
        "link": "http://arxiv.org/abs/2211.10443",
        "abstract": "Substance use, substance use disorder, and overdoses related to substance use are major public health problems globally and in the United States. A key aspect of addressing these problems from a public health standpoint is improved surveillance. Traditional surveillance systems are laggy, and social media are potentially useful sources of timely data. However, mining knowledge from social media is challenging, and requires the development of advanced artificial intelligence, specifically natural language processing (NLP) and machine learning methods. We developed a sophisticated end-to-end pipeline for mining information about nonmedical prescription medication use from social media, namely Twitter and Reddit. Our pipeline employs supervised machine learning and NLP for filtering out noise and characterizing the chatter. In this paper, we describe our end-to-end pipeline developed over four years. In addition to describing our data mining infrastructure, we discuss existing challenges in social media mining for toxicovigilance, and possible future research directions.",
        "creator": "Abeed Sarker"
      },
      {
        "title": "Learning Markov Random Fields for Combinatorial Structures via Sampling through Lov\\'asz Local Lemma.",
        "link": "http://arxiv.org/abs/2212.00296",
        "abstract": "Learning to generate complex combinatorial structures satisfying constraints will have transformative impacts in many application domains. However, it is beyond the capabilities of existing approaches due to the highly intractable nature of the embedded probabilistic inference. Prior works spend most of the training time learning to separate valid from invalid structures but do not learn the inductive biases of valid structures. We develop NEural Lov\\'asz Sampler (Nelson), which embeds the sampler through Lov\\'asz Local Lemma (LLL) as a fully differentiable neural network layer. Our Nelson-CD embeds this sampler into the contrastive divergence learning process of Markov random fields. Nelson allows us to obtain valid samples from the current model distribution. Contrastive divergence is then applied to separate these samples from those in the training set. Nelson is implemented as a fully differentiable neural net, taking advantage of the parallelism of GPUs. Experimental results on several real-world domains reveal that Nelson learns to generate 100\\% valid structures, while baselines either time out or cannot ensure validity. Nelson also outperforms other approaches in running time, log-likelihood, and MAP scores.",
        "creator": "Nan Jiang, Yi Gu, Yexiang Xue"
      },
      {
        "title": "Rethinking Vision Transformers for MobileNet Size and Speed.",
        "link": "http://arxiv.org/abs/2212.08059",
        "abstract": "With the success of Vision Transformers (ViTs) in computer vision tasks, recent arts try to optimize the performance and complexity of ViTs to enable efficient deployment on mobile devices. Multiple approaches are proposed to accelerate attention mechanism, improve inefficient designs, or incorporate mobile-friendly lightweight convolutions to form hybrid architectures. However, ViT and its variants still have higher latency or considerably more parameters than lightweight CNNs, even true for the years-old MobileNet. In practice, latency and size are both crucial for efficient deployment on resource-constraint hardware. In this work, we investigate a central question, can transformer models run as fast as MobileNet and maintain a similar size? We revisit the design choices of ViTs and propose a novel supernet with low latency and high parameter efficiency. We further introduce a novel fine-grained joint search strategy for transformer models that can find efficient architectures by optimizing latency and number of parameters simultaneously. The proposed models, EfficientFormerV2, achieve 3.5% higher top-1 accuracy than MobileNetV2 on ImageNet-1K with similar latency and parameters. This work demonstrate that properly designed and optimized vision transformers can achieve high performance even with MobileNet-level size and speed.",
        "creator": "Yanyu Li, Ju Hu, Yang Wen, Georgios Evangelidis, Kamyar Salahi, Yanzhi Wang, Sergey Tulyakov, Jian Ren"
      },
      {
        "title": "Backward Curriculum Reinforcement Learning.",
        "link": "http://arxiv.org/abs/2212.14214",
        "abstract": "Current reinforcement learning algorithms train an agent using forward-generated trajectories, which provide little guidance so that the agent can explore as much as possible. While realizing the value of reinforcement learning results from sufficient exploration, this approach leads to a trade-off in losing sample efficiency, an essential factor impacting algorithm performance. Previous tasks use reward-shaping techniques and network structure modification to increase sample efficiency. However, these methods require many steps to implement. In this work, we propose novel backward curriculum reinforcement learning that begins training the agent using the backward trajectory of the episode instead of the original forward trajectory. This approach provides the agent with a strong reward signal, enabling more sample-efficient learning. Moreover, our method only requires a minor change in the algorithm of reversing the order of the trajectory before agent training, allowing a straightforward application to any state-of-the-art algorithm.",
        "creator": "KyungMin Ko"
      },
      {
        "title": "SPTS v2: Single-Point Scene Text Spotting.",
        "link": "http://arxiv.org/abs/2301.01635",
        "abstract": "End-to-end scene text spotting has made significant progress due to its intrinsic synergy between text detection and recognition. Previous methods commonly regard manual annotations such as horizontal rectangles, rotated rectangles, quadrangles, and polygons as a prerequisite, which are much more expensive than using single-point. Our new framework, SPTS v2, allows us to train high-performing text-spotting models using a single-point annotation. SPTS v2 reserves the advantage of the auto-regressive Transformer with an Instance Assignment Decoder (IAD) through sequentially predicting the center points of all text instances inside the same predicting sequence, while with a Parallel Recognition Decoder (PRD) for text recognition in parallel, which significantly reduces the requirement of the length of the sequence. These two decoders share the same parameters and are interactively connected with a simple but effective information transmission process to pass the gradient and information. Comprehensive experiments on various existing benchmark datasets demonstrate the SPTS v2 can outperform previous state-of-the-art single-point text spotters with fewer parameters while achieving 19$\\times$ faster inference speed. Within the context of our SPTS v2 framework, our experiments suggest a potential preference for single-point representation in scene text spotting when compared to other representations. Such an attempt provides a significant opportunity for scene text spotting applications beyond the realms of existing paradigms. Code is available at: https://github.com/Yuliang-Liu/SPTSv2.",
        "creator": "Yuliang Liu, Jiaxin Zhang, Dezhi Peng, Mingxin Huang, Xinyu Wang, Jingqun Tang, Can Huang, Dahua Lin, Chunhua Shen, Xiang Bai, Lianwen Jin"
      },
      {
        "title": "Backpropagation of Unrolled Solvers with Folded Optimization.",
        "link": "http://arxiv.org/abs/2301.12047",
        "abstract": "The integration of constrained optimization models as components in deep networks has led to promising advances on many specialized learning tasks. A central challenge in this setting is backpropagation through the solution of an optimization problem, which typically lacks a closed form. One typical strategy is algorithm unrolling, which relies on automatic differentiation through the operations of an iterative solver. While flexible and general, unrolling can encounter accuracy and efficiency issues in practice. These issues can be avoided by analytical differentiation of the optimization, but current frameworks impose rigid requirements on the optimization problem's form. This paper provides theoretical insights into the backward pass of unrolled optimization, leading to a system for generating efficiently solvable analytical models of backpropagation. Additionally, it proposes a unifying view of unrolling and analytical differentiation through optimization mappings. Experiments over various model-based learning tasks demonstrate the advantages of the approach both computationally and in terms of enhanced expressiveness.",
        "creator": "James Kotary, My H. Dinh, Ferdinando Fioretto"
      },
      {
        "title": "A novel automatic wind power prediction framework based on multi-time scale and temporal attention mechanisms.",
        "link": "http://arxiv.org/abs/2302.01222",
        "abstract": "Wind energy is a widely distributed, renewable, and environmentally friendly energy source that plays a crucial role in mitigating global warming and addressing energy shortages. Nevertheless, wind power generation is characterized by volatility, intermittence, and randomness, which hinder its ability to serve as a reliable power source for the grid. Accurate wind power forecasting is crucial for developing a new power system that heavily relies on renewable energy sources. However, traditional wind power forecasting systems primarily focus on ultra-short-term or short-term forecasts, limiting their ability to address the diverse adjustment requirements of the power system simultaneously. To overcome these challenges, We propose an automatic framework capable of forecasting wind power across multi-time scale. The framework based on the tree-structured Parzen estimator (TPE) and temporal fusion transformer (TFT) that can provide ultra-short-term, short-term and medium-term wind power forecasting power.Our approach employs the TFT for wind power forecasting and categorizes features based on their properties. Additionally, we introduce a generic algorithm to simultaneously fine-tune the hyperparameters of the decomposition method and model. We evaluate the performance of our framework by conducting ablation experiments using three commonly used decomposition algorithms and six state-of-the-art models for forecasting multi-time scale. The experimental results demonstrate that our proposed method considerably improves prediction accuracy on the public dataset Engie https://opendata-renewables.engie.com. Compared to the second-best state-of-the-art model, our approach exhibits a reduction of 31.75% and 28.74% in normalized mean absolute error (nMAE) for 24-hour forecasting, and 20.79% and 16.93% in nMAE for 48-hour forecasting, respectively.",
        "creator": "Meiyu Jiang, Jun Shen, Xuetao Jiang, Lihui Luo, Rui Zhou, Qingguo Zhou"
      },
      {
        "title": "Adding Conditional Control to Text-to-Image Diffusion Models.",
        "link": "http://arxiv.org/abs/2302.05543",
        "abstract": "We present ControlNet, a neural network architecture to add spatial conditioning controls to large, pretrained text-to-image diffusion models. ControlNet locks the production-ready large diffusion models, and reuses their deep and robust encoding layers pretrained with billions of images as a strong backbone to learn a diverse set of conditional controls. The neural architecture is connected with \"zero convolutions\" (zero-initialized convolution layers) that progressively grow the parameters from zero and ensure that no harmful noise could affect the finetuning. We test various conditioning controls, eg, edges, depth, segmentation, human pose, etc, with Stable Diffusion, using single or multiple conditions, with or without prompts. We show that the training of ControlNets is robust with small (&lt;50k) and large (&gt;1m) datasets. Extensive results show that ControlNet may facilitate wider applications to control image diffusion models.",
        "creator": "Lvmin Zhang, Anyi Rao, Maneesh Agrawala"
      },
      {
        "title": "\"An Adapt-or-Die Type of Situation\": Perception, Adoption, and Use of Text-To-Image-Generation AI by Game Industry Professionals.",
        "link": "http://arxiv.org/abs/2302.12601",
        "abstract": "Text-to-image generation (TTIG) models, a recent addition to creative AI, can generate images based on a text description. These models have begun to rival the work of professional creatives, and sparked discussions on the future of creative work, loss of jobs, and copyright issues, amongst other important implications. To support the sustainable adoption of TTIG, we must provide rich, reliable and transparent insights into how professionals perceive, adopt and use TTIG. Crucially though, the public debate is shallow, narrow and lacking transparency, while academic work has focused on studying the use of TTIG in a general artist population, but not on the perceptions and attitudes of professionals in a specific industry. In this paper, we contribute a qualitative, exploratory interview study on TTIG in the Finnish videogame industry. Through a Template Analysis on semi-structured interviews with 14 game professionals, we reveal 12 overarching themes, structured into 49 sub-themes on professionals' perception, adoption and use of TTIG systems in games industry practice. Experiencing (yet another) change of roles and creative processes, our participants' reflections can inform discussions within the industry, be used by policymakers to inform urgently needed legislation, and support researchers in games, HCI and AI to support the sustainable, professional use of TTIG to benefit people and games as cultural artefacts.",
        "creator": "Veera Vimpari, Annakaisa Kultima, Perttu H&#xe4;m&#xe4;l&#xe4;inen, Christian Guckelsberger"
      },
      {
        "title": "Bridging the Global Divide in AI Regulation: A Proposal for a Contextual, Coherent, and Commensurable Framework.",
        "link": "http://arxiv.org/abs/2303.11196",
        "abstract": "This paper examines the current landscape of AI regulations, highlighting the divergent approaches being taken, and proposes an alternative contextual, coherent, and commensurable (3C) framework. The EU, Canada, South Korea, and Brazil follow a horizontal or lateral approach that postulates the homogeneity of AI systems, seeks to identify common causes of harm, and demands uniform human interventions. In contrast, the U.K., Israel, Switzerland, Japan, and China have pursued a context-specific or modular approach, tailoring regulations to the specific use cases of AI systems. The U.S. is reevaluating its strategy, with growing support for controlling existential risks associated with AI. Addressing such fragmentation of AI regulations is crucial to ensure the interoperability of AI. The present degree of proportionality, granularity, and foreseeability of the EU AI Act is not sufficient to garner consensus. The context-specific approach holds greater promises but requires further development in terms of details, coherency, and commensurability. To strike a balance, this paper proposes a hybrid 3C framework. To ensure contextuality, the framework categorizes AI into distinct types based on their usage and interaction with humans: autonomous, allocative, punitive, cognitive, and generative AI. To ensure coherency, each category is assigned specific regulatory objectives: safety for autonomous AI; fairness and explainability for allocative AI; accuracy and explainability for punitive AI; accuracy, robustness, and privacy for cognitive AI; and the mitigation of infringement and misuse for generative AI. To ensure commensurability, the framework promotes the adoption of international industry standards that convert principles into quantifiable metrics. In doing so, the framework is expected to foster international collaboration and standardization without imposing excessive compliance costs.",
        "creator": "Sangchul Park"
      },
      {
        "title": "Critical Sampling for Robust Evolution Operator Learning of Unknown Dynamical Systems.",
        "link": "http://arxiv.org/abs/2304.07485",
        "abstract": "Given an unknown dynamical system, what is the minimum number of samples needed for effective learning of its governing laws and accurate prediction of its future evolution behavior, and how to select these critical samples? In this work, we propose to explore this problem based on a design approach. Starting from a small initial set of samples, we adaptively discover critical samples to achieve increasingly accurate learning of the system evolution. One central challenge here is that we do not know the network modeling error since the ground-truth system state is unknown, which is however needed for critical sampling. To address this challenge, we introduce a multi-step reciprocal prediction network where forward and backward evolution networks are designed to learn the temporal evolution behavior in the forward and backward time directions, respectively. Very interestingly, we find that the desired network modeling error is highly correlated with the multi-step reciprocal prediction error, which can be directly computed from the current system state. This allows us to perform a dynamic selection of critical samples from regions with high network modeling errors for dynamical systems. Additionally, a joint spatial-temporal evolution network is introduced which incorporates spatial dynamics modeling into the temporal evolution prediction for robust learning of the system evolution operator with few samples. Our extensive experimental results demonstrate that our proposed method is able to dramatically reduce the number of samples needed for effective learning and accurate prediction of evolution behaviors of unknown dynamical systems by up to hundreds of times.",
        "creator": "Ce Zhang, Kailiang Wu, Zhihai He"
      },
      {
        "title": "The Future of ChatGPT-enabled Labor Market: A Preliminary Study.",
        "link": "http://arxiv.org/abs/2304.09823",
        "abstract": "As a phenomenal large language model, ChatGPT has achieved unparalleled success in various real-world tasks and increasingly plays an important role in our daily lives and work. However, extensive concerns are also raised about the potential ethical issues, especially about whether ChatGPT-like artificial general intelligence (AGI) will replace human jobs. To this end, in this paper, we introduce a preliminary data-driven study on the future of ChatGPT-enabled labor market from the view of Human-AI Symbiosis instead of Human-AI Confrontation. To be specific, we first conduct an in-depth analysis of large-scale job posting data in BOSS Zhipin, the largest online recruitment platform in China. The results indicate that about 28% of occupations in the current labor market require ChatGPT-related skills. Furthermore, based on a large-scale occupation-centered knowledge graph, we develop a semantic information enhanced collaborative filtering algorithm to predict the future occupation-skill relations in the labor market. As a result, we find that additional 45% occupations in the future will require ChatGPT-related skills. In particular, industries related to technology, products, and operations are expected to have higher proficiency requirements for ChatGPT-related skills, while the manufacturing, services, education, and health science related industries will have lower requirements for ChatGPT-related skills.",
        "creator": "Lan Chen, Xi Chen, Shiyu Wu, Yaqi Yang, Meng Chang, Hengshu Zhu"
      },
      {
        "title": "Multi-Prompt with Depth Partitioned Cross-Modal Learning.",
        "link": "http://arxiv.org/abs/2305.06221",
        "abstract": "In recent years, soft prompt learning methods have been proposed to fine-tune large-scale vision-language pre-trained models for various downstream tasks. These methods typically combine learnable textual tokens with class tokens as input for models with frozen parameters. However, they often employ a single prompt to describe class contexts, failing to capture categories' diverse attributes adequately. This study introduces the Partitioned Multi-modal Prompt (PMPO), a multi-modal prompting technique that extends the soft prompt from a single learnable prompt to multiple prompts. Our method divides the visual encoder depths and connects learnable prompts to the separated visual depths, enabling different prompts to capture the hierarchical contextual depths of visual representations. Furthermore, to maximize the advantages of multi-prompt learning, we incorporate prior information from manually designed templates and learnable multi-prompts, thus improving the generalization capabilities of our approach. We evaluate the effectiveness of our approach on three challenging tasks: new class generalization, cross-dataset evaluation, and domain generalization. For instance, our method achieves a $79.28$ harmonic mean, averaged over 11 diverse image recognition datasets ($+7.62$ compared to CoOp), demonstrating significant competitiveness compared to state-of-the-art prompting methods.",
        "creator": "Yingjie Tian, Yiqi Wang, Xianda Guo, Zheng Zhu, Long Chen"
      },
      {
        "title": "Multi-Robot Coordination and Layout Design for Automated Warehousing.",
        "link": "http://arxiv.org/abs/2305.06436",
        "abstract": "With the rapid progress in Multi-Agent Path Finding (MAPF), researchers have studied how MAPF algorithms can be deployed to coordinate hundreds of robots in large automated warehouses. While most works try to improve the throughput of such warehouses by developing better MAPF algorithms, we focus on improving the throughput by optimizing the warehouse layout. We show that, even with state-of-the-art MAPF algorithms, commonly used human-designed layouts can lead to congestion for warehouses with large numbers of robots and thus have limited scalability. We extend existing automatic scenario generation methods to optimize warehouse layouts. Results show that our optimized warehouse layouts (1) reduce traffic congestion and thus improve throughput, (2) improve the scalability of the automated warehouses by doubling the number of robots in some cases, and (3) are capable of generating layouts with user-specified diversity measures. We include the source code at: https://github.com/lunjohnzhang/warehouse_env_gen_public",
        "creator": "Yulun Zhang, Matthew C. Fontaine, Varun Bhatt, Stefanos Nikolaidis, Jiaoyang Li"
      },
      {
        "title": "An Empirical Study on the Language Modal in Visual Question Answering.",
        "link": "http://arxiv.org/abs/2305.10143",
        "abstract": "Generalization beyond in-domain experience to out-of-distribution data is of paramount significance in the AI domain. Of late, state-of-the-art Visual Question Answering (VQA) models have shown impressive performance on in-domain data, partially due to the language priors bias which, however, hinders the generalization ability in practice. This paper attempts to provide new insights into the influence of language modality on VQA performance from an empirical study perspective. To achieve this, we conducted a series of experiments on six models. The results of these experiments revealed that, 1) apart from prior bias caused by question types, there is a notable influence of postfix-related bias in inducing biases, and 2) training VQA models with word-sequence-related variant questions demonstrated improved performance on the out-of-distribution benchmark, and the LXMERT even achieved a 10-point gain without adopting any debiasing methods. We delved into the underlying reasons behind these experimental results and put forward some simple proposals to reduce the models' dependency on language priors. The experimental results demonstrated the effectiveness of our proposed method in improving performance on the out-of-distribution benchmark, VQA-CPv2. We hope this study can inspire novel insights for future research on designing bias-reduction approaches.",
        "creator": "Daowan Peng, Wei Wei, Xian-Ling Mao, Yuanyuan Fu, Dangyang Chen"
      },
      {
        "title": "Improved Multi-Scale Grid Rendering of Point Clouds for Radar Object Detection Networks.",
        "link": "http://arxiv.org/abs/2305.15836",
        "abstract": "Architectures that first convert point clouds to a grid representation and then apply convolutional neural networks achieve good performance for radar-based object detection. However, the transfer from irregular point cloud data to a dense grid structure is often associated with a loss of information, due to the discretization and aggregation of points. In this paper, we propose a novel architecture, multi-scale KPPillarsBEV, that aims to mitigate the negative effects of grid rendering. Specifically, we propose a novel grid rendering method, KPBEV, which leverages the descriptive power of kernel point convolutions to improve the encoding of local point cloud contexts during grid rendering. In addition, we propose a general multi-scale grid rendering formulation to incorporate multi-scale feature maps into convolutional backbones of detection networks with arbitrary grid rendering methods. We perform extensive experiments on the nuScenes dataset and evaluate the methods in terms of detection performance and computational complexity. The proposed multi-scale KPPillarsBEV architecture outperforms the baseline by 5.37% and the previous state of the art by 2.88% in Car AP4.0 (average precision for a matching threshold of 4 meters) on the nuScenes validation set. Moreover, the proposed single-scale KPBEV grid rendering improves the Car AP4.0 by 2.90% over the baseline while maintaining the same inference speed.",
        "creator": "Daniel K&#xf6;hler, Maurice Quach, Michael Ulrich, Frank Meinl, Bastian Bischoff, Holger Blume"
      },
      {
        "title": "Optimized Custom Dataset for Efficient Detection of Underwater Trash.",
        "link": "http://arxiv.org/abs/2305.16460",
        "abstract": "Accurately quantifying and removing submerged underwater waste plays a crucial role in safeguarding marine life and preserving the environment. While detecting floating and surface debris is relatively straightforward, quantifying submerged waste presents significant challenges due to factors like light refraction, absorption, suspended particles, and color distortion. This paper addresses these challenges by proposing the development of a custom dataset and an efficient detection approach for submerged marine debris. The dataset encompasses diverse underwater environments and incorporates annotations for precise labeling of debris instances. Ultimately, the primary objective of this custom dataset is to enhance the diversity of litter instances and improve their detection accuracy in deep submerged environments by leveraging state-of-the-art deep learning architectures.",
        "creator": "Jaskaran Singh Walia, Karthik Seemakurthy"
      },
      {
        "title": "Improved Sales Forecasting using Trend and Seasonality Decomposition with LightGBM.",
        "link": "http://arxiv.org/abs/2305.17201",
        "abstract": "Retail sales forecasting presents a significant challenge for large retailers such as Walmart and Amazon, due to the vast assortment of products, geographical location heterogeneity, seasonality, and external factors including weather, local economic conditions, and geopolitical events. Various methods have been employed to tackle this challenge, including traditional time series models, machine learning models, and neural network mechanisms, but the difficulty persists. Categorizing data into relevant groups has been shown to improve sales forecast accuracy as time series from different categories may exhibit distinct patterns. In this paper, we propose a new measure to indicate the unique impacts of the trend and seasonality components on a time series and suggest grouping time series based on this measure. We apply this approach to Walmart sales data from 01/29/2011 to 05/22/2016 and generate sales forecasts from 05/23/2016 to 06/19/2016. Our experiments show that the proposed strategy can achieve improved accuracy. Furthermore, we present a robust pipeline for conducting retail sales forecasting.",
        "creator": "Tong Zhou"
      },
      {
        "title": "RL + Model-based Control: Using On-demand Optimal Control to Learn Versatile Legged Locomotion.",
        "link": "http://arxiv.org/abs/2305.17842",
        "abstract": "This paper presents a control framework that combines model-based optimal control and reinforcement learning (RL) to achieve versatile and robust legged locomotion. Our approach enhances the RL training process by incorporating on-demand reference motions generated through finite-horizon optimal control, covering a broad range of velocities and gaits. These reference motions serve as targets for the RL policy to imitate, leading to the development of robust control policies that can be learned with reliability. Furthermore, by utilizing realistic simulation data that captures whole-body dynamics, RL effectively overcomes the inherent limitations in reference motions imposed by modeling simplifications. We validate the robustness and controllability of the RL training process within our framework through a series of experiments. In these experiments, our method showcases its capability to generalize reference motions and effectively handle more complex locomotion tasks that may pose challenges for the simplified model, thanks to RL's flexibility. Additionally, our framework effortlessly supports the training of control policies for robots with diverse dimensions, eliminating the necessity for robot-specific adjustments in the reward function and hyperparameters.",
        "creator": "Dongho Kang, Jin Cheng, Miguel Zamora, Fatemeh Zargarbashi, Stelian Coros"
      },
      {
        "title": "AnoOnly: Semi-Supervised Anomaly Detection without Loss on Normal Data.",
        "link": "http://arxiv.org/abs/2305.18798",
        "abstract": "Semi-supervised anomaly detection (SSAD) methods have demonstrated their effectiveness in enhancing unsupervised anomaly detection (UAD) by leveraging few-shot but instructive abnormal instances. However, the dominance of homogeneous normal data over anomalies biases the SSAD models against effectively perceiving anomalies. To address this issue and achieve balanced supervision between heavily imbalanced normal and abnormal data, we develop a novel framework called AnoOnly (Anomaly Only). Unlike existing SSAD methods that resort to strict loss supervision, AnoOnly suspends it and introduces a form of weak supervision for normal data. This weak supervision is instantiated through the utilization of batch normalization, which implicitly performs cluster learning on normal data. When integrated into existing SSAD methods, the proposed AnoOnly demonstrates remarkable performance enhancements across various models and datasets, achieving new state-of-the-art performance. Additionally, our AnoOnly is natively robust to label noise when suffering from data contamination. Our code is publicly available at https://github.com/cool-xuan/AnoOnly.",
        "creator": "Yixuan Zhou, Peiyu Yang, Yi Qu, Xing Xu, Zhe Sun, Andrzej Cichocki"
      },
      {
        "title": "DocumentCLIP: Linking Figures and Main Body Text in Reflowed Documents.",
        "link": "http://arxiv.org/abs/2306.06306",
        "abstract": "Vision-language pretraining models have achieved great success in supporting multimedia applications by understanding the alignments between images and text. While existing vision-language pretraining models primarily focus on understanding single image associated with a single piece of text, they often ignore the alignment at the intra-document level, consisting of multiple sentences with multiple images. In this work, we propose DocumentCLIP, a salience-aware contrastive learning framework to enforce vision-language pretraining models to comprehend the interaction between images and longer text within documents. Our model is beneficial for the real-world multimodal document understanding like news article, magazines, product descriptions, which contain linguistically and visually richer content. To the best of our knowledge, we are the first to explore multimodal intra-document links by contrastive learning. In addition, we collect a large Wikipedia dataset for pretraining, which provides various topics and structures. Experiments show DocumentCLIP not only outperforms the state-of-the-art baselines in the supervised setting, but also achieves the best zero-shot performance in the wild after human evaluation. Our code is available at https://github.com/FuxiaoLiu/DocumentCLIP.",
        "creator": "Fuxiao Liu, Hao Tan, Chris Tensmeyer"
      },
      {
        "title": "Improving the Validity of Decision Trees as Explanations.",
        "link": "http://arxiv.org/abs/2306.06777",
        "abstract": "In classification and forecasting with tabular data, one often utilizes tree-based models. Those can be competitive with deep neural networks on tabular data [cf. Grinsztajn et al., NeurIPS 2022, arXiv:2207.08815] and, under some conditions, explainable. The explainability depends on the depth of the tree and the accuracy in each leaf of the tree. Decision trees containing leaves with unbalanced accuracy can provide misleading explanations. Low-accuracy leaves give less valid explanations, which could be interpreted as unfairness among explanations. Here, we train a shallow tree with the objective of minimizing the maximum misclassification error across each leaf node. Then, we extend each leaf with a separate tree-based model. The shallow tree provides a global explanation, while the overall statistical performance of the shallow tree with extended leaves improves upon decision trees of unlimited depth trained using classical methods (e.g., CART) and is comparable to state-of-the-art methods (e.g., well-tuned XGBoost).",
        "creator": "Jiri Nemecek, Tomas Pevny, Jakub Marecek"
      },
      {
        "title": "STUDY: Socially Aware Temporally Causal Decoder Recommender Systems.",
        "link": "http://arxiv.org/abs/2306.07946",
        "abstract": "Recommender systems are widely used to help people find items that are tailored to their interests. These interests are often influenced by social networks, making it important to use social network information effectively in recommender systems. This is especially true for demographic groups with interests that differ from the majority. This paper introduces STUDY, a Socially-aware Temporally caUsal Decoder recommender sYstem. STUDY introduces a new socially-aware recommender system architecture that is significantly more efficient to learn and train than existing methods. STUDY performs joint inference over socially connected groups in a single forward pass of a modified transformer decoder network. We demonstrate the benefits of STUDY in the recommendation of books for students who are dyslexic, or struggling readers. Dyslexic students often have difficulty engaging with reading material, making it critical to recommend books that are tailored to their interests. We worked with our non-profit partner Learning Ally to evaluate STUDY on a dataset of struggling readers. STUDY was able to generate recommendations that more accurately predicted student engagement, when compared with existing methods.",
        "creator": "Eltayeb Ahmed, Diana Mincu, Lauren Harrell, Katherine Heller, Subhrajit Roy"
      },
      {
        "title": "SCALE: Scaling up the Complexity for Advanced Language Model Evaluation.",
        "link": "http://arxiv.org/abs/2306.09237",
        "abstract": "Recent strides in Large Language Models (LLMs) have saturated many NLP benchmarks (even professional domain-specific ones), emphasizing the need for novel, more challenging novel ones to properly assess LLM capabilities. In this paper, we introduce a novel NLP benchmark that poses challenges to current LLMs across four key dimensions: processing long documents (up to 50K tokens), utilizing domain specific knowledge (embodied in legal texts), multilingual understanding (covering five languages), and multitasking (comprising legal document to document Information Retrieval, Court View Generation, Leading Decision Summarization, Citation Extraction, and eight challenging Text Classification tasks). Our benchmark comprises diverse legal NLP datasets from the Swiss legal system, allowing for a comprehensive study of the underlying Non-English, inherently multilingual, federal legal system. Despite recent advances, efficiently processing long documents for intense review/analysis tasks remains an open challenge for language models. Also, comprehensive, domain-specific benchmarks requiring high expertise to develop are rare, as are multilingual benchmarks. This scarcity underscores our contribution's value, considering most public models are trained predominantly on English corpora, while other languages remain understudied, particularly for practical domain-specific NLP tasks. Our benchmark allows for testing and advancing the state-of-the-art LLMs. As part of our study, we evaluate several pre-trained multilingual language models on our benchmark to establish strong baselines as a point of reference. Despite the large size of our datasets (tens to hundreds of thousands of examples), existing publicly available models struggle with most tasks, even after in-domain pretraining. We publish all resources (benchmark suite, pre-trained models, code) under a fully permissive open CC BY-SA license.",
        "creator": "Vishvaksenan Rasiah, Ronja Stern, Veton Matoshi, Matthias St&#xfc;rmer, Ilias Chalkidis, Daniel E. Ho, Joel Niklaus"
      },
      {
        "title": "Reasoning over the Air: A Reasoning-based Implicit Semantic-Aware Communication Framework.",
        "link": "http://arxiv.org/abs/2306.11229",
        "abstract": "Semantic-aware communication is a novel paradigm that draws inspiration from human communication focusing on the delivery of the meaning of messages. It has attracted significant interest recently due to its potential to improve the efficiency and reliability of communication and enhance users' QoE. Most existing works focus on transmitting and delivering the explicit semantic meaning that can be directly identified from the source signal. This paper investigates the implicit semantic-aware communication in which the hidden information that cannot be directly observed from the source signal must be recognized and interpreted by the intended users. To this end, a novel implicit semantic-aware communication (iSAC) architecture is proposed for representing, communicating, and interpreting the implicit semantic meaning between source and destination users. A projection-based semantic encoder is proposed to convert the high-dimensional graphical representation of explicit semantics into a low-dimensional semantic constellation space for efficient physical channel transmission. To enable the destination user to learn and imitate the implicit semantic reasoning process of source user, a generative adversarial imitation learning-based solution, called G-RML, is proposed. Different from existing communication solutions, the source user in G-RML does not focus only on sending as much of the useful messages as possible; but, instead, it tries to guide the destination user to learn a reasoning mechanism to map any observed explicit semantics to the corresponding implicit semantics that are most relevant to the semantic meaning. Compared to the existing solutions, our proposed G-RML requires much less communication and computational resources and scales well to the scenarios involving the communication of rich semantic meanings consisting of a large number of concepts and relations.",
        "creator": "Yong Xiao, Yiwei Liao, Yingyu Li, Guangming Shi, H. Vincent Poor, Walid Saad, Merouane Debbah, Mehdi Bennis"
      },
      {
        "title": "Proactive Human-Robot Co-Assembly: Leveraging Human Intention Prediction and Robust Safe Control.",
        "link": "http://arxiv.org/abs/2306.11862",
        "abstract": "Human-robot collaboration (HRC) is one key component to achieving flexible manufacturing to meet the different needs of customers. However, it is difficult to build intelligent robots that can proactively assist humans in a safe and efficient way due to several challenges. First, it is challenging to achieve efficient collaboration due to diverse human behaviors and data scarcity. Second, it is difficult to ensure interactive safety due to uncertainty in human behaviors. This paper presents an integrated framework for proactive HRC. A robust intention prediction module, which leverages prior task information and human-in-the-loop training, is learned to guide the robot for efficient collaboration. The proposed framework also uses robust safe control to ensure interactive safety under uncertainty. The developed framework is applied to a co-assembly task using a Kinova Gen3 robot. The experiment demonstrates that our solution is robust to environmental changes as well as different human preferences and behaviors. In addition, it improves task efficiency by approximately 15-20%. Moreover, the experiment demonstrates that our solution can guarantee interactive safety during proactive collaboration.",
        "creator": "Ruixuan Liu, Rui Chen, Abulikemu Abuduweili, Changliu Liu"
      },
      {
        "title": "SoftGPT: Learn Goal-oriented Soft Object Manipulation Skills by Generative Pre-trained Heterogeneous Graph Transformer.",
        "link": "http://arxiv.org/abs/2306.12677",
        "abstract": "Soft object manipulation tasks in domestic scenes pose a significant challenge for existing robotic skill learning techniques due to their complex dynamics and variable shape characteristics. Since learning new manipulation skills from human demonstration is an effective way for robot applications, developing prior knowledge of the representation and dynamics of soft objects is necessary. In this regard, we propose a pre-trained soft object manipulation skill learning model, namely SoftGPT, that is trained using large amounts of exploration data, consisting of a three-dimensional heterogeneous graph representation and a GPT-based dynamics model. For each downstream task, a goal-oriented policy agent is trained to predict the subsequent actions, and SoftGPT generates the consequences of these actions. Integrating these two approaches establishes a thinking process in the robot's mind that provides rollout for facilitating policy learning. Our results demonstrate that leveraging prior knowledge through this thinking process can efficiently learn various soft object manipulation skills, with the potential for direct learning from human demonstrations.",
        "creator": "Junjia Liu, Zhihao Li, Wanyu Lin, Sylvain Calinon, Kay Chen Tan, Fei Chen"
      },
      {
        "title": "Group-based Robustness: A General Framework for Customized Robustness in the Real World.",
        "link": "http://arxiv.org/abs/2306.16614",
        "abstract": "Machine-learning models are known to be vulnerable to evasion attacks that perturb model inputs to induce misclassifications. In this work, we identify real-world scenarios where the true threat cannot be assessed accurately by existing attacks. Specifically, we find that conventional metrics measuring targeted and untargeted robustness do not appropriately reflect a model's ability to withstand attacks from one set of source classes to another set of target classes. To address the shortcomings of existing methods, we formally define a new metric, termed group-based robustness, that complements existing metrics and is better-suited for evaluating model performance in certain attack scenarios. We show empirically that group-based robustness allows us to distinguish between models' vulnerability against specific threat models in situations where traditional robustness metrics do not apply. Moreover, to measure group-based robustness efficiently and accurately, we 1) propose two loss functions and 2) identify three new attack strategies. We show empirically that with comparable success rates, finding evasive samples using our new loss functions saves computation by a factor as large as the number of targeted classes, and finding evasive samples using our new attack strategies saves time by up to 99\\% compared to brute-force search methods. Finally, we propose a defense method that increases group-based robustness by up to 3.52$\\times$.",
        "creator": "Weiran Lin, Keane Lucas, Neo Eyal, Lujo Bauer, Michael K. Reiter, Mahmood Sharif"
      },
      {
        "title": "Rearrangement Planning for General Part Assembly.",
        "link": "http://arxiv.org/abs/2307.00206",
        "abstract": "Most successes in autonomous robotic assembly have been restricted to single target or category. We propose to investigate general part assembly, the task of creating novel target assemblies with unseen part shapes. As a fundamental step to a general part assembly system, we tackle the task of determining the precise poses of the parts in the target assembly, which we we term ``rearrangement planning''. We present General Part Assembly Transformer (GPAT), a transformer-based model architecture that accurately predicts part poses by inferring how each part shape corresponds to the target shape. Our experiments on both 3D CAD models and real-world scans demonstrate GPAT's generalization abilities to novel and diverse target and part shapes.",
        "creator": "Yulong Li, Andy Zeng, Shuran Song"
      },
      {
        "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners.",
        "link": "http://arxiv.org/abs/2307.01928",
        "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities -- from step-by-step planning to commonsense reasoning -- that may provide utility for robots, but remain prone to confidently hallucinated predictions. In this work, we present KnowNo, which is a framework for measuring and aligning the uncertainty of LLM-based planners such that they know when they don't know and ask for help when needed. KnowNo builds on the theory of conformal prediction to provide statistical guarantees on task completion while minimizing human help in complex multi-step planning settings. Experiments across a variety of simulated and real robot setups that involve tasks with different modes of ambiguity (e.g., from spatial to numeric uncertainties, from human preferences to Winograd schemas) show that KnowNo performs favorably over modern baselines (which may involve ensembles or extensive prompt tuning) in terms of improving efficiency and autonomy, while providing formal assurances. KnowNo can be used with LLMs out of the box without model-finetuning, and suggests a promising lightweight approach to modeling uncertainty that can complement and scale with the growing capabilities of foundation models. Website: https://robot-help.github.io",
        "creator": "Allen Z. Ren, Anushri Dixit, Alexandra Bodrova, Sumeet Singh, Stephen Tu, Noah Brown, Peng Xu, Leila Takayama, Fei Xia, Jake Varley, Zhenjia Xu, Dorsa Sadigh, Andy Zeng, Anirudha Majumdar"
      },
      {
        "title": "The FormAI Dataset: Generative AI in Software Security Through the Lens of Formal Verification.",
        "link": "http://arxiv.org/abs/2307.02192",
        "abstract": "This paper presents the FormAI dataset, a large collection of 112, 000 AI-generated compilable and independent C programs with vulnerability classification. We introduce a dynamic zero-shot prompting technique constructed to spawn diverse programs utilizing Large Language Models (LLMs). The dataset is generated by GPT-3.5-turbo and comprises programs with varying levels of complexity. Some programs handle complicated tasks like network management, table games, or encryption, while others deal with simpler tasks like string manipulation. Every program is labeled with the vulnerabilities found within the source code, indicating the type, line number, and vulnerable function name. This is accomplished by employing a formal verification method using the Efficient SMT-based Bounded Model Checker (ESBMC), which uses model checking, abstract interpretation, constraint programming, and satisfiability modulo theories to reason over safety/security properties in programs. This approach definitively detects vulnerabilities and offers a formal model known as a counterexample, thus eliminating the possibility of generating false positive reports. We have associated the identified vulnerabilities with Common Weakness Enumeration (CWE) numbers. We make the source code available for the 112, 000 programs, accompanied by a separate file containing the vulnerabilities detected in each program, making the dataset ideal for training LLMs and machine learning algorithms. Our study unveiled that according to ESBMC, 51.24% of the programs generated by GPT-3.5 contained vulnerabilities, thereby presenting considerable risks to software safety and security.",
        "creator": "Norbert Tihanyi, Tamas Bisztray, Ridhi Jain, Mohamed Amine Ferrag, Lucas C. Cordeiro, Vasileios Mavroeidis"
      },
      {
        "title": "Frontier AI Regulation: Managing Emerging Risks to Public Safety.",
        "link": "http://arxiv.org/abs/2307.03718",
        "abstract": "Advanced AI models hold the promise of tremendous benefits for humanity, but society needs to proactively manage the accompanying risks. In this paper, we focus on what we term \"frontier AI\" models: highly capable foundation models that could possess dangerous capabilities sufficient to pose severe risks to public safety. Frontier AI models pose a distinct regulatory challenge: dangerous capabilities can arise unexpectedly; it is difficult to robustly prevent a deployed model from being misused; and, it is difficult to stop a model's capabilities from proliferating broadly. To address these challenges, at least three building blocks for the regulation of frontier models are needed: (1) standard-setting processes to identify appropriate requirements for frontier AI developers, (2) registration and reporting requirements to provide regulators with visibility into frontier AI development processes, and (3) mechanisms to ensure compliance with safety standards for the development and deployment of frontier AI models. Industry self-regulation is an important first step. However, wider societal discussions and government intervention will be needed to create standards and to ensure compliance with them. We consider several options to this end, including granting enforcement powers to supervisory authorities and licensure regimes for frontier AI models. Finally, we propose an initial set of safety standards. These include conducting pre-deployment risk assessments; external scrutiny of model behavior; using risk assessments to inform deployment decisions; and monitoring and responding to new information about model capabilities and uses post-deployment. We hope this discussion contributes to the broader conversation on how to balance public safety risks and innovation benefits from advances at the frontier of AI development.",
        "creator": "Markus Anderljung, Joslyn Barnhart, Anton Korinek, Jade Leung, Cullen O&#x27;Keefe, Jess Whittlestone, Shahar Avin, Miles Brundage, Justin Bullock, Duncan Cass-Beggs, Ben Chang, Tantum Collins, Tim Fist, Gillian Hadfield, Alan Hayes, Lewis Ho, Sara Hooker, Eric Horvitz, Noam Kolt, Jonas Schuett, Yonadav Shavit, Divya Siddarth, Robert Trager, Kevin Wolf"
      },
      {
        "title": "Diffusion Policies for Out-of-Distribution Generalization in Offline Reinforcement Learning.",
        "link": "http://arxiv.org/abs/2307.04726",
        "abstract": "Offline Reinforcement Learning (RL) methods leverage previous experiences to learn better policies than the behavior policy used for data collection. In contrast to behavior cloning, which assumes the data is collected from expert demonstrations, offline RL can work with non-expert data and multimodal behavior policies. However, offline RL algorithms face challenges in handling distribution shifts and effectively representing policies due to the lack of online interaction during training. Prior work on offline RL uses conditional diffusion models to represent multimodal behavior in the dataset. Nevertheless, these methods are not tailored toward alleviating the out-of-distribution state generalization. We introduce a novel method named State Reconstruction for Diffusion Policies (SRDP), incorporating state reconstruction feature learning in the recent class of diffusion policies to address the out-of-distribution generalization problem. State reconstruction loss promotes generalizable representation learning of states to alleviate the distribution shift incurred by the out-of-distribution (OOD) states. We design a novel 2D Multimodal Contextual Bandit environment to illustrate the OOD generalization and faster convergence of SRDP compared to prior algorithms. In addition, we assess the performance of our model on D4RL continuous control benchmarks, namely the navigation of an 8-DoF ant and forward locomotion of half-cheetah, hopper, and walker2d, achieving state-of-the-art results.",
        "creator": "Suzan Ece Ada, Erhan Oztop, Emre Ugur"
      },
      {
        "title": "Retrieval-augmented GPT-3.5-based Text-to-SQL Framework with Sample-aware Prompting and Dynamic Revision Chain.",
        "link": "http://arxiv.org/abs/2307.05074",
        "abstract": "Text-to-SQL aims at generating SQL queries for the given natural language questions and thus helping users to query databases. Prompt learning with large language models (LLMs) has emerged as a recent approach, which designs prompts to lead LLMs to understand the input question and generate the corresponding SQL. However, it faces challenges with strict SQL syntax requirements. Existing work prompts the LLMs with a list of demonstration examples (i.e. question-SQL pairs) to generate SQL, but the fixed prompts can hardly handle the scenario where the semantic gap between the retrieved demonstration and the input question is large. In this paper, we propose a retrieval-augmented prompting method for a LLM-based Text-to-SQL framework, involving sample-aware prompting and a dynamic revision chain. Our approach incorporates sample-aware demonstrations, which include the composition of SQL operators and fine-grained information related to the given question. To retrieve questions sharing similar intents with input questions, we propose two strategies for assisting retrieval. Firstly, we leverage LLMs to simplify the original questions, unifying the syntax and thereby clarifying the users' intentions. To generate executable and accurate SQLs without human intervention, we design a dynamic revision chain which iteratively adapts fine-grained feedback from the previously generated SQL. Experimental results on three Text-to-SQL benchmarks demonstrate the superiority of our method over strong baseline models.",
        "creator": "Chunxi Guo, Zhiliang Tian, Jintao Tang, Shasha Li, Zhihua Wen, Kaixuan Wang, Ting Wang"
      },
      {
        "title": "ACTI at EVALITA 2023: Overview of the Conspiracy Theory Identification Task.",
        "link": "http://arxiv.org/abs/2307.06954",
        "abstract": "Conspiracy Theory Identication task is a new shared task proposed for the first time at the Evalita 2023. The ACTI challenge, based exclusively on comments published on conspiratorial channels of telegram, is divided into two subtasks: (i) Conspiratorial Content Classification: identifying conspiratorial content and (ii) Conspiratorial Category Classification about specific conspiracy theory classification. A total of fifteen teams participated in the task for a total of 81 submissions. We illustrate the best performing approaches were based on the utilization of large language models. We finally draw conclusions about the utilization of these models for counteracting the spreading of misinformation in online platforms.",
        "creator": "Giuseppe Russo, Niklas Stoehr, Manoel Horta Ribeiro"
      },
      {
        "title": "Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization.",
        "link": "http://arxiv.org/abs/2307.10053",
        "abstract": "In this paper, we investigate the convergence properties of the stochastic gradient descent (SGD) method and its variants, especially in training neural networks built from nonsmooth activation functions. We develop a novel framework that assigns different timescales to stepsizes for updating the momentum terms and variables, respectively. Under mild conditions, we prove the global convergence of our proposed framework in both single-timescale and two-timescale cases. We show that our proposed framework encompasses a wide range of well-known SGD-type methods, including heavy-ball SGD, SignSGD, Lion, normalized SGD and clipped SGD. Furthermore, when the objective function adopts a finite-sum formulation, we prove the convergence properties for these SGD-type methods based on our proposed framework. In particular, we prove that these SGD-type methods find the Clarke stationary points of the objective function with randomly chosen stepsizes and initial points under mild assumptions. Preliminary numerical experiments demonstrate the high efficiency of our analyzed SGD-type methods.",
        "creator": "Nachuan Xiao, Xiaoyin Hu, Kim-Chuan Toh"
      },
      {
        "title": "On the Learning Dynamics of Attention Networks.",
        "link": "http://arxiv.org/abs/2307.13421",
        "abstract": "Attention models are typically learned by optimizing one of three standard loss functions that are variously called -- soft attention, hard attention, and latent variable marginal likelihood (LVML) attention. All three paradigms are motivated by the same goal of finding two models -- a `focus' model that `selects' the right \\textit{segment} of the input and a `classification' model that processes the selected segment into the target label. However, they differ significantly in the way the selected segments are aggregated, resulting in distinct dynamics and final results. We observe a unique signature of models learned using these paradigms and explain this as a consequence of the evolution of the classification model under gradient descent when the focus model is fixed. We also analyze these paradigms in a simple setting and derive closed-form expressions for the parameter trajectory under gradient flow. With the soft attention loss, the focus model improves quickly at initialization and splutters later on. On the other hand, hard attention loss behaves in the opposite fashion. Based on our observations, we propose a simple hybrid approach that combines the advantages of the different loss functions and demonstrates it on a collection of semi-synthetic and real-world datasets",
        "creator": "Rahul Vashisht, Harish G. Ramaswamy"
      },
      {
        "title": "eXplainable Artificial Intelligence (XAI) in aging clock models.",
        "link": "http://arxiv.org/abs/2307.13704",
        "abstract": "eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of machine learning, aiming to unravel the predictions of complex models. XAI is especially required in sensitive applications, e.g. in health care, when diagnosis, recommendations and treatment choices might rely on the decisions made by artificial intelligence systems. AI approaches have become widely used in aging research as well, in particular, in developing biological clock models and identifying biomarkers of aging and age-related diseases. However, the potential of XAI here awaits to be fully appreciated. We discuss the application of XAI for developing the \"aging clocks\" and present a comprehensive analysis of the literature categorized by the focus on particular physiological systems.",
        "creator": "Alena Kalyakulina, Igor Yusipov, Maria Giulia Bacalini, Alexey Moskalev, Claudio Franceschi, Mikhail Ivanchenko"
      },
      {
        "title": "A new Gradient TD Algorithm with only One Step-size: Convergence Rate Analysis using $L$-$\\lambda$ Smoothness.",
        "link": "http://arxiv.org/abs/2307.15892",
        "abstract": "Gradient Temporal Difference (GTD) algorithms (Sutton et al., 2008, 2009) are the first $O(d)$ ($d$ is the number features) algorithms that have convergence guarantees for off-policy learning with linear function approximation. Liu et al. (2015) and Dalal et. al. (2018) proved the convergence rates of GTD, GTD2 and TDC are $O(t^{-\\alpha/2})$ for some $\\alpha \\in (0,1)$. This bound is tight (Dalal et al., 2020), and slower than $O(1/\\sqrt{t})$. GTD algorithms also have two step-size parameters, which are difficult to tune. In literature, there is a \"single-time-scale\" formulation of GTD. However, this formulation still has two step-size parameters.  This paper presents a truly single-time-scale GTD algorithm for minimizing the Norm of Expected td Update (NEU) objective, and it has only one step-size parameter. We prove that the new algorithm, called Impression GTD, converges at least as fast as $O(1/t)$. Furthermore, based on a generalization of the expected smoothness (Gower et al. 2019), called $L$-$\\lambda$ smoothness, we are able to prove that the new GTD converges even faster, in fact, with a linear rate. Our rate actually also improves Gower et al.'s result with a tighter bound under a weaker assumption. Besides Impression GTD, we also prove the rates of three other GTD algorithms, one by Yao and Liu (2008), another called A-transpose-TD (Sutton et al., 2008), and a counterpart of A-transpose-TD. The convergence rates of all the four GTD algorithms are proved in a single generic GTD framework to which $L$-$\\lambda$ smoothness applies. Empirical results on Random walks, Boyan chain, and Baird counterexample show that Impression GTD converges much faster than existing GTD algorithms for both on-policy and off-policy learning problems, with well-performing step-sizes in a big range.",
        "creator": "Hengshuai Yao"
      },
      {
        "title": "BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models.",
        "link": "http://arxiv.org/abs/2307.16489",
        "abstract": "The rise in popularity of text-to-image generative artificial intelligence (AI) has attracted widespread public interest. We demonstrate that this technology can be attacked to generate content that subtly manipulates its users. We propose a Backdoor Attack on text-to-image Generative Models (BAGM), which upon triggering, infuses the generated images with manipulative details that are naturally blended in the content. Our attack is the first to target three popular text-to-image generative models across three stages of the generative process by modifying the behaviour of the embedded tokenizer, the language model or the image generative model. Based on the penetration level, BAGM takes the form of a suite of attacks that are referred to as surface, shallow and deep attacks in this article. Given the existing gap within this domain, we also contribute a comprehensive set of quantitative metrics designed specifically for assessing the effectiveness of backdoor attacks on text-to-image models. The efficacy of BAGM is established by attacking state-of-the-art generative models, using a marketing scenario as the target domain. To that end, we contribute a dataset of branded product images. Our embedded backdoors increase the bias towards the target outputs by more than five times the usual, without compromising the model robustness or the generated content utility. By exposing generative AI's vulnerabilities, we encourage researchers to tackle these challenges and practitioners to exercise caution when using pre-trained models. Relevant code, input prompts and supplementary material can be found at https://github.com/JJ-Vice/BAGM, and the dataset is available at: https://ieee-dataport.org/documents/marketable-foods-mf-dataset.  Keywords: Generative Artificial Intelligence, Generative Models, Text-to-Image generation, Backdoor Attacks, Trojan, Stable Diffusion.",
        "creator": "Jordan Vice, Naveed Akhtar, Richard Hartley, Ajmal Mian"
      },
      {
        "title": "Benchmarking Jetson Edge Devices with an End-to-end Video-based Anomaly Detection System.",
        "link": "http://arxiv.org/abs/2307.16834",
        "abstract": "Innovative enhancement in embedded system platforms, specifically hardware accelerations, significantly influence the application of deep learning in real-world scenarios. These innovations translate human labor efforts into automated intelligent systems employed in various areas such as autonomous driving, robotics, Internet-of-Things (IoT), and numerous other impactful applications. NVIDIA's Jetson platform is one of the pioneers in offering optimal performance regarding energy efficiency and throughput in the execution of deep learning algorithms. Previously, most benchmarking analysis was based on 2D images with a single deep learning model for each comparison result. In this paper, we implement an end-to-end video-based crime-scene anomaly detection system inputting from surveillance videos and the system is deployed and completely operates on multiple Jetson edge devices (Nano, AGX Xavier, Orin Nano). The comparison analysis includes the integration of Torch-TensorRT as a software developer kit from NVIDIA for the model performance optimisation. The system is built based on the PySlowfast open-source project from Facebook as the coding template. The end-to-end system process comprises the videos from camera, data preprocessing pipeline, feature extractor and the anomaly detection. We provide the experience of an AI-based system deployment on various Jetson Edge devices with Docker technology. Regarding anomaly detectors, a weakly supervised video-based deep learning model called Robust Temporal Feature Magnitude Learning (RTFM) is applied in the system. The approach system reaches 47.56 frames per second (FPS) inference speed on a Jetson edge device with only 3.11 GB RAM usage total. We also discover the promising Jetson device that the AI system achieves 15% better performance than the previous version of Jetson devices while consuming 50% less energy power.",
        "creator": "Hoang Viet Pham, Thinh Gia Tran, Chuong Dinh Le, An Dinh Le, Hien Bich Vo"
      },
      {
        "title": "Reasoning before Responding: Integrating Commonsense-based Causality Explanation for Empathetic Response Generation.",
        "link": "http://arxiv.org/abs/2308.00085",
        "abstract": "Recent approaches to empathetic response generation try to incorporate commonsense knowledge or reasoning about the causes of emotions to better understand the user's experiences and feelings. However, these approaches mainly focus on understanding the causalities of context from the user's perspective, ignoring the system's perspective. In this paper, we propose a commonsense-based causality explanation approach for diverse empathetic response generation that considers both the user's perspective (user's desires and reactions) and the system's perspective (system's intentions and reactions). We enhance ChatGPT's ability to reason for the system's perspective by integrating in-context learning with commonsense knowledge. Then, we integrate the commonsense-based causality explanation with both ChatGPT and a T5-based model. Experimental evaluations demonstrate that our method outperforms other comparable methods on both automatic and human evaluations.",
        "creator": "Yahui Fu, Koji Inoue, Chenhui Chu, Tatsuya Kawahara"
      },
      {
        "title": "Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach.",
        "link": "http://arxiv.org/abs/2308.01011",
        "abstract": "Time series analysis is a fundamental task in various application domains, and deep learning approaches have demonstrated remarkable performance in this area. However, many real-world time series data exhibit significant periodic or quasi-periodic dynamics that are often not adequately captured by existing deep learning-based solutions. This results in an incomplete representation of the underlying dynamic behaviors of interest. To address this gap, we propose an unsupervised method called Floss that automatically regularizes learned representations in the frequency domain. The Floss method first automatically detects major periodicities from the time series. It then employs periodic shift and spectral density similarity measures to learn meaningful representations with periodic consistency. In addition, Floss can be easily incorporated into both supervised, semi-supervised, and unsupervised learning frameworks. We conduct extensive experiments on common time series classification, forecasting, and anomaly detection tasks to demonstrate the effectiveness of Floss. We incorporate Floss into several representative deep learning solutions to justify our design choices and demonstrate that it is capable of automatically discovering periodic dynamics and improving state-of-the-art deep learning models.",
        "creator": "Chunwei Yang, Xiaoxu Chen, Lijun Sun, Hongyu Yang, Yuankai Wu"
      },
      {
        "title": "CausalOps -- Towards an Industrial Lifecycle for Causal Probabilistic Graphical Models.",
        "link": "http://arxiv.org/abs/2308.01375",
        "abstract": "Causal probabilistic graph-based models have gained widespread utility, enabling the modeling of cause-and-effect relationships across diverse domains. With their rising adoption in new areas, such as automotive system safety and machine learning, the need for an integrated lifecycle framework akin to DevOps and MLOps has emerged. Currently, a process reference for organizations interested in employing causal engineering is missing. To address this gap and foster widespread industrial adoption, we propose CausalOps, a novel lifecycle framework for causal model development and application. By defining key entities, dependencies, and intermediate artifacts generated during causal engineering, we establish a consistent vocabulary and workflow model. This work contextualizes causal model usage across different stages and stakeholders, outlining a holistic view of creating and maintaining them. CausalOps' aim is to drive the adoption of causal methods in practical applications within interested organizations and the causality community.",
        "creator": "Robert Maier, Andreas Schlattl, Thomas Guess, J&#xfc;rgen Mottok"
      },
      {
        "title": "Edge of stability echo state networks.",
        "link": "http://arxiv.org/abs/2308.02902",
        "abstract": "Echo State Networks (ESNs) are time-series processing models working under the Echo State Property (ESP) principle. The ESP is a notion of stability that imposes an asymptotic fading of the memory of the input. On the other hand, the resulting inherent architectural bias of ESNs may lead to an excessive loss of information, which in turn harms the performance in certain tasks with long short-term memory requirements. With the goal of bringing together the fading memory property and the ability to retain as much memory as possible, in this paper we introduce a new ESN architecture, called the Edge of Stability Echo State Network (ES$^2$N). The introduced ES$^2$N model is based on defining the reservoir layer as a convex combination of a nonlinear reservoir (as in the standard ESN), and a linear reservoir that implements an orthogonal transformation. We provide a thorough mathematical analysis of the introduced model, proving that the whole eigenspectrum of the Jacobian of the ES$^2$N map can be contained in an annular neighbourhood of a complex circle of controllable radius, and exploit this property to demonstrate that the ES$^2$N's forward dynamics evolves close to the edge-of-chaos regime by design. Remarkably, our experimental analysis shows that the newly introduced reservoir model is able to reach the theoretical maximum short-term memory capacity. At the same time, in comparison to standard ESN, ES$^2$N is shown to offer an excellent trade-off between memory and nonlinearity, as well as a significant improvement of performance in autoregressive nonlinear modeling.",
        "creator": "Andrea Ceni, Claudio Gallicchio"
      },
      {
        "title": "Provably Efficient Learning in Partially Observable Contextual Bandit.",
        "link": "http://arxiv.org/abs/2308.03572",
        "abstract": "In this paper, we investigate transfer learning in partially observable contextual bandits, where agents have limited knowledge from other agents and partial information about hidden confounders. We first convert the problem to identifying or partially identifying causal effects between actions and rewards through optimization problems. To solve these optimization problems, we discretize the original functional constraints of unknown distributions into linear constraints, and sample compatible causal models via sequentially solving linear programmings to obtain causal bounds with the consideration of estimation error. Our sampling algorithms provide desirable convergence results for suitable sampling distributions. We then show how causal bounds can be applied to improving classical bandit algorithms and affect the regrets with respect to the size of action sets and function spaces. Notably, in the task with function approximation which allows us to handle general context distributions, our method improves the order dependence on function space size compared with previous literatures. We formally prove that our causally enhanced algorithms outperform classical bandit algorithms and achieve orders of magnitude faster convergence rates. Finally, we perform simulations that demonstrate the efficiency of our strategy compared to the current state-of-the-art methods. This research has the potential to enhance the performance of contextual bandit agents in real-world applications where data is scarce and costly to obtain.",
        "creator": "Xueping Gong, Jiheng Zhang"
      },
      {
        "title": "Recurrent Multi-scale Transformer for High-Resolution Salient Object Detection.",
        "link": "http://arxiv.org/abs/2308.03826",
        "abstract": "Salient Object Detection (SOD) aims to identify and segment the most conspicuous objects in an image or video. As an important pre-processing step, it has many potential applications in multimedia and vision tasks. With the advance of imaging devices, SOD with high-resolution images is of great demand, recently. However, traditional SOD methods are largely limited to low-resolution images, making them difficult to adapt to the development of High-Resolution SOD (HRSOD). Although some HRSOD methods emerge, there are no large enough datasets for training and evaluating. Besides, current HRSOD methods generally produce incomplete object regions and irregular object boundaries. To address above issues, in this work, we first propose a new HRS10K dataset, which contains 10,500 high-quality annotated images at 2K-8K resolution. As far as we know, it is the largest dataset for the HRSOD task, which will significantly help future works in training and evaluating models. Furthermore, to improve the HRSOD performance, we propose a novel Recurrent Multi-scale Transformer (RMFormer), which recurrently utilizes shared Transformers and multi-scale refinement architectures. Thus, high-resolution saliency maps can be generated with the guidance of lower-resolution predictions. Extensive experiments on both high-resolution and low-resolution benchmarks show the effectiveness and superiority of the proposed framework. The source code and dataset are released at: https://github.com/DrowsyMon/RMFormer.",
        "creator": "Xinhao Deng, Pingping Zhang, Wei Liu, Huchuan Lu"
      },
      {
        "title": "Measure of Uncertainty in Human Emotions.",
        "link": "http://arxiv.org/abs/2308.04032",
        "abstract": "Many research explore how well computers are able to examine emotions displayed by humans and use that data to perform different tasks. However, there have been very few research which evaluate the computers ability to generate emotion classification information in an attempt to help the user make decisions or perform tasks. This is a crucial area to explore as it is paramount to the two way communication between humans and computers. This research conducted an experiment to investigate the impact of different uncertainty information displays of emotion classification on the human decision making process. Results show that displaying more uncertainty information can help users to be more confident when making decisions.",
        "creator": "Balaram Panda"
      },
      {
        "title": "Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques.",
        "link": "http://arxiv.org/abs/2308.04455",
        "abstract": "The growing use of voice user interfaces has led to a surge in the collection and storage of speech data. While data collection allows for the development of efficient tools powering most speech services, it also poses serious privacy issues for users as centralized storage makes private personal speech data vulnerable to cyber threats. With the increasing use of voice-based digital assistants like Amazon's Alexa, Google's Home, and Apple's Siri, and with the increasing ease with which personal speech data can be collected, the risk of malicious use of voice-cloning and speaker/gender/pathological/etc. recognition has increased.  This thesis proposes solutions for anonymizing speech and evaluating the degree of the anonymization. In this work, anonymization refers to making personal speech data unlinkable to an identity while maintaining the usefulness (utility) of the speech signal (e.g., access to linguistic content). We start by identifying several challenges that evaluation protocols need to consider to evaluate the degree of privacy protection properly. We clarify how anonymization systems must be configured for evaluation purposes and highlight that many practical deployment configurations do not permit privacy evaluation. Furthermore, we study and examine the most common voice conversion-based anonymization system and identify its weak points before suggesting new methods to overcome some limitations. We isolate all components of the anonymization system to evaluate the degree of speaker PPI associated with each of them. Then, we propose several transformation methods for each component to reduce as much as possible speaker PPI while maintaining utility. We promote anonymization algorithms based on quantization-based transformation as an alternative to the most-used and well-known noise-based approach. Finally, we endeavor a new attack method to invert anonymization.",
        "creator": "Pierre Champion"
      },
      {
        "title": "Evidence of Human-Like Visual-Linguistic Integration in Multimodal Large Language Models During Predictive Language Processing.",
        "link": "http://arxiv.org/abs/2308.06035",
        "abstract": "The advanced language processing abilities of large language models (LLMs) have stimulated debate over their capacity to replicate human-like cognitive processes. One differentiating factor between language processing in LLMs and humans is that language input is often grounded in several perceptual modalities, whereas most LLMs process solely text-based information. Multimodal grounding allows humans to integrate - e.g. visual context with linguistic information and thereby place constraints on the space of upcoming words, reducing cognitive load and improving comprehension. Recent multimodal LLMs (mLLMs) combine a visual-linguistic embedding space with a transformer type attention mechanism for next-word prediction. Here we ask whether predictive language processing based on multimodal input in mLLMs aligns with humans. Two-hundred participants watched short audio-visual clips and estimated predictability of an upcoming verb or noun. The same clips were processed by the mLLM CLIP, with predictability scores based on comparing image and text feature vectors. Eye-tracking was used to estimate what visual features participants attended to, and CLIP's visual attention weights were recorded. We find that alignment of predictability scores was driven by multimodality of CLIP (no alignment for a unimodal state-of-the-art LLM) and by the attention mechanism (no alignment when attention weights were perturbated or when the same input was fed to a multimodal model without attention). We further find a significant spatial overlap between CLIP's visual attention weights and human eye-tracking data. Results suggest that comparable processes of integrating multimodal information, guided by attention to relevant visual features, supports predictive language processing in mLLMs and humans.",
        "creator": "Viktor Kewenig, Christopher Edwards, Quitterie Lacome DEstalenx, Akilles Rechardt, Jeremy I Skipper, Gabriella Vigliocco"
      },
      {
        "title": "Precipitation nowcasting with generative diffusion models.",
        "link": "http://arxiv.org/abs/2308.06733",
        "abstract": "In recent years traditional numerical methods for accurate weather prediction have been increasingly challenged by deep learning methods. Numerous historical datasets used for short and medium-range weather forecasts are typically organized into a regular spatial grid structure. This arrangement closely resembles images: each weather variable can be visualized as a map or, when considering the temporal axis, as a video. Several classes of generative models, comprising Generative Adversarial Networks, Variational Autoencoders, or the recent Denoising Diffusion Models have largely proved their applicability to the next-frame prediction problem, and is thus natural to test their performance on the weather prediction benchmarks. Diffusion models are particularly appealing in this context, due to the intrinsically probabilistic nature of weather forecasting: what we are really interested to model is the probability distribution of weather indicators, whose expected value is the most likely prediction.  In our study, we focus on a specific subset of the ERA-5 dataset, which includes hourly data pertaining to Central Europe from the years 2016 to 2021. Within this context, we examine the efficacy of diffusion models in handling the task of precipitation nowcasting. Our work is conducted in comparison to the performance of well-established U-Net models, as documented in the existing literature. Our proposed approach of Generative Ensemble Diffusion (GED) utilizes a diffusion model to generate a set of possible weather scenarios which are then amalgamated into a probable prediction via the use of a post-processing network. This approach, in comparison to recent deep learning models, substantially outperformed them in terms of overall performance.",
        "creator": "Andrea Asperti, Fabio Merizzi, Alberto Paparella, Giorgio Pedrazzi, Matteo Angelinelli, Stefano Colamonaco"
      },
      {
        "title": "Baird Counterexample is Solved: with an example of How to Debug a Two-time-scale Algorithm.",
        "link": "http://arxiv.org/abs/2308.09732",
        "abstract": "Baird counterexample was proposed by Leemon Baird in 1995, first used to show that the Temporal Difference (TD(0)) algorithm diverges on this example. Since then, it is often used to test and compare off-policy learning algorithms. Gradient TD algorithms solved the divergence issue of TD on Baird counterexample. However, their convergence on this example is still very slow, and the nature of the slowness is not well understood, e.g., see (Sutton and Barto 2018).  This note is to understand in particular, why TDC is slow on this example, and provide a debugging analysis to understand this behavior. Our debugging technique can be used to study the convergence behavior of two-time-scale stochastic approximation algorithms. We also provide empirical results of the recent Impression GTD algorithm on this example, showing the convergence is very fast, in fact, in a linear rate. We conclude that Baird counterexample is solved, by an algorithm with the convergence guarantee to the TD solution in general, and a fast convergence rate.",
        "creator": "Hengshuai Yao"
      },
      {
        "title": "Event-based Dynamic Graph Representation Learning for Patent Application Trend Prediction.",
        "link": "http://arxiv.org/abs/2308.09780",
        "abstract": "Accurate prediction of what types of patents that companies will apply for in the next period of time can figure out their development strategies and help them discover potential partners or competitors in advance. Although important, this problem has been rarely studied in previous research due to the challenges in modelling companies' continuously evolving preferences and capturing the semantic correlations of classification codes. To fill in this gap, we propose an event-based dynamic graph learning framework for patent application trend prediction. In particular, our method is founded on the memorable representations of both companies and patent classification codes. When a new patent is observed, the representations of the related companies and classification codes are updated according to the historical memories and the currently encoded messages. Moreover, a hierarchical message passing mechanism is provided to capture the semantic proximities of patent classification codes by updating their representations along the hierarchical taxonomy. Finally, the patent application trend is predicted by aggregating the representations of the target company and classification codes from static, dynamic, and hierarchical perspectives. Experiments on real-world data demonstrate the effectiveness of our approach under various experimental conditions, and also reveal the abilities of our method in learning semantics of classification codes and tracking technology developing trajectories of companies.",
        "creator": "Tao Zou, Le Yu, Leilei Sun, Bowen Du, Deqing Wang, Fuzhen Zhuang"
      },
      {
        "title": "Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis.",
        "link": "http://arxiv.org/abs/2308.09830",
        "abstract": "This paper explores the integration of two AI subdisciplines employed in the development of artificial agents that exhibit intelligent behavior: Large Language Models (LLMs) and Cognitive Architectures (CAs). We present three integration approaches, each grounded in theoretical models and supported by preliminary empirical evidence. The modular approach, which introduces four models with varying degrees of integration, makes use of chain-of-thought prompting, and draws inspiration from augmented LLMs, the Common Model of Cognition, and the simulation theory of cognition. The agency approach, motivated by the Society of Mind theory and the LIDA cognitive architecture, proposes the formation of agent collections that interact at micro and macro cognitive levels, driven by either LLMs or symbolic components. The neuro-symbolic approach, which takes inspiration from the CLARION cognitive architecture, proposes a model where bottom-up learning extracts symbolic representations from an LLM layer and top-down guidance utilizes symbolic representations to direct prompt engineering in the LLM layer. These approaches aim to harness the strengths of both LLMs and CAs, while mitigating their weaknesses, thereby advancing the development of more robust AI systems. We discuss the tradeoffs and challenges associated with each approach.",
        "creator": "Oscar J. Romero, John Zimmerman, Aaron Steinfeld, Anthony Tomasic"
      },
      {
        "title": "Learning Multiscale Consistency for Self-supervised Electron Microscopy Instance Segmentation.",
        "link": "http://arxiv.org/abs/2308.09917",
        "abstract": "Instance segmentation in electron microscopy (EM) volumes is tough due to complex shapes and sparse annotations. Self-supervised learning helps but still struggles with intricate visual patterns in EM. To address this, we propose a pretraining framework that enhances multiscale consistency in EM volumes. Our approach leverages a Siamese network architecture, integrating both strong and weak data augmentations to effectively extract multiscale features. We uphold voxel-level coherence by reconstructing the original input data from these augmented instances. Furthermore, we incorporate cross-attention mechanisms to facilitate fine-grained feature alignment between these augmentations. Finally, we apply contrastive learning techniques across a feature pyramid, allowing us to distill distinctive representations spanning various scales. After pretraining on four large-scale EM datasets, our framework significantly improves downstream tasks like neuron and mitochondria segmentation, especially with limited finetuning data. It effectively captures voxel and feature consistency, showing promise for learning transferable representations for EM analysis.",
        "creator": "Yinda Chen, Wei Huang, Xiaoyu Liu, Shiyu Deng, Qi Chen, Zhiwei Xiong"
      },
      {
        "title": "Large Language Models for Software Engineering: A Systematic Literature Review.",
        "link": "http://arxiv.org/abs/2308.10620",
        "abstract": "Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a systematic literature review on LLM4SE, with a particular focus on understanding how LLMs can be exploited to optimize processes and outcomes. We collect and analyze 229 research papers from 2017 to 2023 to answer four key research questions (RQs). In RQ1, we categorize different LLMs that have been employed in SE tasks, characterizing their distinctive features and uses. In RQ2, we analyze the methods used in data collection, preprocessing, and application highlighting the role of well-curated datasets for successful LLM for SE implementation. RQ3 investigates the strategies employed to optimize and evaluate the performance of LLMs in SE. Finally, RQ4 examines the specific SE tasks where LLMs have shown success to date, illustrating their practical contributions to the field. From the answers to these RQs, we discuss the current state-of-the-art and trends, identifying gaps in existing research, and flagging promising areas for future study.",
        "creator": "Xinyi Hou, Yanjie Zhao, Yue Liu, Zhou Yang, Kailong Wang, Li Li, Xiapu Luo, David Lo, John Grundy, Haoyu Wang"
      },
      {
        "title": "UniDoc: A Universal Large Multimodal Model for Simultaneous Text Detection, Recognition, Spotting and Understanding.",
        "link": "http://arxiv.org/abs/2308.11592",
        "abstract": "In the era of Large Language Models (LLMs), tremendous strides have been made in the field of multimodal understanding. However, existing advanced algorithms are limited to effectively utilizing the immense representation capabilities and rich world knowledge inherent to these large pre-trained models, and the beneficial connections among tasks within the context of text-rich scenarios have not been sufficiently explored. In this work, we introduce UniDoc, a novel multimodal model equipped with text detection and recognition capabilities, which are deficient in existing approaches. Moreover, UniDoc capitalizes on the beneficial interactions among tasks to enhance the performance of each individual task. To implement UniDoc, we perform unified multimodal instruct tuning on the contributed large-scale instruction following datasets. Quantitative and qualitative experimental results show that UniDoc sets state-of-the-art scores across multiple challenging benchmarks. To the best of our knowledge, this is the first large multimodal model capable of simultaneous text detection, recognition, spotting, and understanding.",
        "creator": "Hao Feng, Zijian Wang, Jingqun Tang, Jinghui Lu, Wengang Zhou, Houqiang Li, Can Huang"
      },
      {
        "title": "Does Misclassifying Non-confounding Covariates as Confounders Affect the Causal Inference within the Potential Outcomes Framework?.",
        "link": "http://arxiv.org/abs/2308.11676",
        "abstract": "The Potential Outcome Framework (POF) plays a prominent role in the field of causal inference. Most causal inference models based on the POF (CIMs-POF) are designed for eliminating confounding bias and default to an underlying assumption of Confounding Covariates. This assumption posits that the covariates consist solely of confounders. However, the assumption of Confounding Covariates is challenging to maintain in practice, particularly when dealing with high-dimensional covariates. While certain methods have been proposed to differentiate the distinct components of covariates prior to conducting causal inference, the consequences of treating non-confounding covariates as confounders remain unclear. This ambiguity poses a potential risk when conducting causal inference in practical scenarios. In this paper, we present a unified graphical framework for the CIMs-POF, which greatly enhances the comprehension of these models' underlying principles. Using this graphical framework, we quantitatively analyze the extent to which the inference performance of CIMs-POF is influenced when incorporating various types of non-confounding covariates, such as instrumental variables, mediators, colliders, and adjustment variables. The key findings are: in the task of eliminating confounding bias, the optimal scenario is for the covariates to exclusively encompass confounders; in the subsequent task of inferring counterfactual outcomes, the adjustment variables contribute to more accurate inferences. Furthermore, extensive experiments conducted on synthetic datasets consistently validate these theoretical conclusions.",
        "creator": "Yonghe Zhao, Qiang Huang, Shuai Fu, Huiyan Sun"
      },
      {
        "title": "Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge Reasoning via Promoting Causal Consistency in LLMs.",
        "link": "http://arxiv.org/abs/2308.11914",
        "abstract": "Despite advancements in LLMs, knowledge-based reasoning remains a longstanding issue due to the fragility of knowledge recall and inference. Existing methods primarily encourage LLMs to autonomously plan and solve problems or to extensively sample reasoning chains without addressing the conceptual and inferential fallacies. Attempting to alleviate inferential fallacies and drawing inspiration from multi-agent collaboration, we present a framework to increase faithfulness and causality for knowledge-based reasoning. Specifically, we propose to employ multiple intelligent agents (i.e., reasoners and an evaluator) to work collaboratively in a reasoning-and-consensus paradigm for elevated reasoning faithfulness. The reasoners focus on providing solutions with human-like causality to solve open-domain problems. On the other hand, the \\textit{evaluator} agent scrutinizes if a solution is deducible from a non-causal perspective and if it still holds when challenged by a counterfactual candidate. According to the extensive and comprehensive evaluations on a variety of knowledge reasoning tasks (e.g., science question answering and commonsense reasoning), our framework outperforms all compared state-of-the-art approaches by large margins.",
        "creator": "Ziyi Tang, Ruilin Wang, Weixing Chen, Keze Wang, Yang Liu, Tianshui Chen, Liang Lin"
      },
      {
        "title": "LFS-GAN: Lifelong Few-Shot Image Generation.",
        "link": "http://arxiv.org/abs/2308.11917",
        "abstract": "We address a challenging lifelong few-shot image generation task for the first time. In this situation, a generative model learns a sequence of tasks using only a few samples per task. Consequently, the learned model encounters both catastrophic forgetting and overfitting problems at a time. Existing studies on lifelong GANs have proposed modulation-based methods to prevent catastrophic forgetting. However, they require considerable additional parameters and cannot generate high-fidelity and diverse images from limited data. On the other hand, the existing few-shot GANs suffer from severe catastrophic forgetting when learning multiple tasks. To alleviate these issues, we propose a framework called Lifelong Few-Shot GAN (LFS-GAN) that can generate high-quality and diverse images in lifelong few-shot image generation task. Our proposed framework learns each task using an efficient task-specific modulator - Learnable Factorized Tensor (LeFT). LeFT is rank-constrained and has a rich representation ability due to its unique reconstruction technique. Furthermore, we propose a novel mode seeking loss to improve the diversity of our model in low-data circumstances. Extensive experiments demonstrate that the proposed LFS-GAN can generate high-fidelity and diverse images without any forgetting and mode collapse in various domains, achieving state-of-the-art in lifelong few-shot image generation task. Surprisingly, we find that our LFS-GAN even outperforms the existing few-shot GANs in the few-shot image generation task. The code is available at Github.",
        "creator": "Juwon Seo, Ji-Su Kang, Gyeong-Moon Park"
      },
      {
        "title": "From Instructions to Intrinsic Human Values -- A Survey of Alignment Goals for Big Models.",
        "link": "http://arxiv.org/abs/2308.12014",
        "abstract": "Big models, exemplified by Large Language Models (LLMs), are models typically pre-trained on massive data and comprised of enormous parameters, which not only obtain significantly improved performance across diverse tasks but also present emergent capabilities absent in smaller models. However, the growing intertwining of big models with everyday human lives poses potential risks and might cause serious social harm. Therefore, many efforts have been made to align LLMs with humans to make them better follow user instructions and satisfy human preferences. Nevertheless, `what to align with' has not been fully discussed, and inappropriate alignment goals might even backfire. In this paper, we conduct a comprehensive survey of different alignment goals in existing work and trace their evolution paths to help identify the most essential goal. Particularly, we investigate related works from two perspectives: the definition of alignment goals and alignment evaluation. Our analysis encompasses three distinct levels of alignment goals and reveals a goal transformation from fundamental abilities to value orientation, indicating the potential of intrinsic human values as the alignment goal for enhanced LLMs. Based on such results, we further discuss the challenges of achieving such intrinsic value alignment and provide a collection of available resources for future research on the alignment of big models.",
        "creator": "Jing Yao, Xiaoyuan Yi, Xiting Wang, Jindong Wang, Xing Xie"
      },
      {
        "title": "CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from Unbounded Synthesized Images.",
        "link": "http://arxiv.org/abs/2308.12288",
        "abstract": "We present a method for teaching machines to understand and model the underlying spatial common sense of diverse human-object interactions in 3D in a self-supervised way. This is a challenging task, as there exist specific manifolds of the interactions that can be considered human-like and natural, but the human pose and the geometry of objects can vary even for similar interactions. Such diversity makes the annotating task of 3D interactions difficult and hard to scale, which limits the potential to reason about that in a supervised way. One way of learning the 3D spatial relationship between humans and objects during interaction is by showing multiple 2D images captured from different viewpoints when humans interact with the same type of objects. The core idea of our method is to leverage a generative model that produces high-quality 2D images from an arbitrary text prompt input as an \"unbounded\" data generator with effective controllability and view diversity. Despite its imperfection of the image quality over real images, we demonstrate that the synthesized images are sufficient to learn the 3D human-object spatial relations. We present multiple strategies to leverage the synthesized images, including (1) the first method to leverage a generative image model for 3D human-object spatial relation learning; (2) a framework to reason about the 3D spatial relations from inconsistent 2D cues in a self-supervised manner via 3D occupancy reasoning with pose canonicalization; (3) semantic clustering to disambiguate different types of interactions with the same object types; and (4) a novel metric to assess the quality of 3D spatial learning of interaction.",
        "creator": "Sookwan Han, Hanbyul Joo"
      },
      {
        "title": "Dance with You: The Diversity Controllable Dancer Generation via Diffusion Models.",
        "link": "http://arxiv.org/abs/2308.13551",
        "abstract": "Recently, digital humans for interpersonal interaction in virtual environments have gained significant attention. In this paper, we introduce a novel multi-dancer synthesis task called partner dancer generation, which involves synthesizing virtual human dancers capable of performing dance with users. The task aims to control the pose diversity between the lead dancer and the partner dancer. The core of this task is to ensure the controllable diversity of the generated partner dancer while maintaining temporal coordination with the lead dancer. This scenario varies from earlier research in generating dance motions driven by music, as our emphasis is on automatically designing partner dancer postures according to pre-defined diversity, the pose of lead dancer, as well as the accompanying tunes. To achieve this objective, we propose a three-stage framework called Dance-with-You (DanY). Initially, we employ a 3D Pose Collection stage to collect a wide range of basic dance poses as references for motion generation. Then, we introduce a hyper-parameter that coordinates the similarity between dancers by masking poses to prevent the generation of sequences that are over-diverse or consistent. To avoid the rigidity of movements, we design a Dance Pre-generated stage to pre-generate these masked poses instead of filling them with zeros. After that, a Dance Motion Transfer stage is adopted with leader sequences and music, in which a multi-conditional sampling formula is rewritten to transfer the pre-generated poses into a sequence with a partner style. In practice, to address the lack of multi-person datasets, we introduce AIST-M, a new dataset for partner dancer generation, which is publicly availiable. Comprehensive evaluations on our AIST-M dataset demonstrate that the proposed DanY can synthesize satisfactory partner dancer results with controllable diversity.",
        "creator": "Siyue Yao, Mingjie Sun, Bingliang Li, Fengyu Yang, Junle Wang, Ruimao Zhang"
      },
      {
        "title": "Stochastic Configuration Machines for Industrial Artificial Intelligence.",
        "link": "http://arxiv.org/abs/2308.13570",
        "abstract": "Real-time predictive modelling with desired accuracy is highly expected in industrial artificial intelligence (IAI), where neural networks play a key role. Neural networks in IAI require powerful, high-performance computing devices to operate a large number of floating point data. Based on stochastic configuration networks (SCNs), this paper proposes a new randomized learner model, termed stochastic configuration machines (SCMs), to stress effective modelling and data size saving that are useful and valuable for industrial applications. Compared to SCNs and random vector functional-link (RVFL) nets with binarized implementation, the model storage of SCMs can be significantly compressed while retaining favourable prediction performance. Besides the architecture of the SCM learner model and its learning algorithm, as an important part of this contribution, we also provide a theoretical basis on the learning capacity of SCMs by analysing the model's complexity. Experimental studies are carried out over some benchmark datasets and three industrial applications. The results demonstrate that SCM has great potential for dealing with industrial data analytics.",
        "creator": "Dianhui Wang, Matthew J. Felicetti"
      },
      {
        "title": "An Open Hyperspectral Dataset with Sea-Land-Cloud Ground-Truth from the HYPSO-1 Satellite.",
        "link": "http://arxiv.org/abs/2308.13679",
        "abstract": "Hyperspectral Imaging, employed in satellites for space remote sensing, like HYPSO-1, faces constraints due to few labeled data sets, affecting the training of AI models demanding these ground-truth annotations. In this work, we introduce The HYPSO-1 Sea-Land-Cloud-Labeled Dataset, an open dataset with 200 diverse hyperspectral images from the HYPSO-1 mission, available in both raw and calibrated forms for scientific research in Earth observation. Moreover, 38 of these images from different countries include ground-truth labels at pixel-level totaling about 25 million spectral signatures labeled for sea/land/cloud categories. To demonstrate the potential of the dataset and its labeled subset, we have additionally optimized a deep learning model (1D Fully Convolutional Network), achieving superior performance to the current state of the art. The complete dataset, ground-truth labels, deep learning model, and software code are openly accessible for download at the website https://ntnu-smallsat-lab.github.io/hypso1_sea_land_clouds_dataset/ .",
        "creator": "Jon A. Justo, Joseph Garrett, Dennis D. Langer, Marie B. Henriksen, Radu T. Ionescu, Tor A. Johansen"
      },
      {
        "title": "Label Denoising through Cross-Model Agreement.",
        "link": "http://arxiv.org/abs/2308.13976",
        "abstract": "Learning from corrupted labels is very common in real-world machine-learning applications. Memorizing such noisy labels could affect the learning of the model, leading to sub-optimal performances. In this work, we propose a novel framework to learn robust machine-learning models from noisy labels. Through an empirical study, we find that different models make relatively similar predictions on clean examples, while the predictions on noisy examples vary much more across different models. Motivated by this observation, we propose \\em denoising with cross-model agreement \\em (DeCA) which aims to minimize the KL-divergence between the true label distributions parameterized by two machine learning models while maximizing the likelihood of data observation. We employ the proposed DeCA on both the binary label scenario and the multiple label scenario. For the binary label scenario, we select implicit feedback recommendation as the downstream task and conduct experiments with four state-of-the-art recommendation models on four datasets. For the multiple-label scenario, the downstream application is image classification on two benchmark datasets. Experimental results demonstrate that the proposed methods significantly improve the model performance compared with normal training and other denoising methods on both binary and multiple-label scenarios.",
        "creator": "Yu Wang, Xin Xin, Zaiqiao Meng, Xiangnan He, Joemon Jose, Fuli Feng"
      },
      {
        "title": "Intergrated Segmentation and Detection Models for Dentex Challenge 2023.",
        "link": "http://arxiv.org/abs/2308.14161",
        "abstract": "Dental panoramic x-rays are commonly used in dental diagnosing. With the development of deep learning, auto detection of diseases from dental panoramic x-rays can help dentists to diagnose diseases more efficiently.The Dentex Challenge 2023 is a competition for automatic detection of abnormal teeth along with their enumeration ids from dental panoramic x-rays. In this paper, we propose a method integrating segmentation and detection models to detect abnormal teeth as well as obtain their enumeration ids.Our codes are available at https://github.com/xyzlancehe/DentexSegAndDet.",
        "creator": "Lanshan He, Yusheng Liu, Lisheng Wang"
      },
      {
        "title": "LLM Powered Sim-to-real Transfer for Traffic Signal Control.",
        "link": "http://arxiv.org/abs/2308.14284",
        "abstract": "Numerous solutions are proposed for the Traffic Signal Control (TSC) tasks aiming to provide efficient transportation and mitigate congestion waste. In recent, promising results have been attained by Reinforcement Learning (RL) methods through trial and error in simulators, bringing confidence in solving cities' congestion headaches. However, there still exist performance gaps when simulator-trained policies are deployed to the real world. This issue is mainly introduced by the system dynamic difference between the training simulator and the real-world environments. The Large Language Models (LLMs) are trained on mass knowledge and proved to be equipped with astonishing inference abilities. In this work, we leverage LLMs to understand and profile the system dynamics by a prompt-based grounded action transformation. Accepting the cloze prompt template, and then filling in the answer based on accessible context, the pre-trained LLM's inference ability is exploited and applied to understand how weather conditions, traffic states, and road types influence traffic dynamics, being aware of this, the policies' action is taken and grounded based on realistic dynamics, thus help the agent learn a more realistic policy. We conduct experiments using DQN to show the effectiveness of the proposed PromptGAT's ability in mitigating the performance gap from simulation to reality (sim-to-real).",
        "creator": "Longchao Da, Minchiuan Gao, Hao Mei, Hua Wei"
      },
      {
        "title": "Conflict-Aware Active Automata Learning (Extended Version).",
        "link": "http://arxiv.org/abs/2308.14781",
        "abstract": "Active automata learning algorithms cannot easily handle conflict in the observation data (different outputs observed for the same inputs). This inherent inability to recover after a conflict impairs their effective applicability in scenarios where noise is present or the system under learning is mutating.  We propose the Conflict-Aware Active Automata Learning (C3AL) framework to enable handling conflicting information during the learning process. The core idea is to consider the so-called observation tree as a first-class citizen in the learning process. Though this idea is explored in recent work, we take it to its full effect by enabling its use with any existing learner and minimizing the number of tests performed on the system under learning, specially in the face of conflicts. We evaluate C3AL in a large set of benchmarks, covering over 30 different realistic targets, and over 18,000 different scenarios. The results of the evaluation show that C3AL is a suitable alternative framework for closed-box learning that can better handle noise and mutations.",
        "creator": "Tiago Ferreira, L&#xe9;o Henry, Raquel Fernandes da Silva, Alexandra Silva"
      },
      {
        "title": "ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer.",
        "link": "http://arxiv.org/abs/2308.15459",
        "abstract": "Textual style transfer is the task of transforming stylistic properties of text while preserving meaning. Target \"styles\" can be defined in numerous ways, ranging from single attributes (e.g, formality) to authorship (e.g, Shakespeare). Previous unsupervised style-transfer approaches generally rely on significant amounts of labeled data for only a fixed set of styles or require large language models. In contrast, we introduce a novel diffusion-based framework for general-purpose style transfer that can be flexibly adapted to arbitrary target styles at inference time. Our parameter-efficient approach, ParaGuide, leverages paraphrase-conditioned diffusion models alongside gradient-based guidance from both off-the-shelf classifiers and strong existing style embedders to transform the style of text while preserving semantic information. We validate the method on the Enron Email Corpus, with both human and automatic evaluations, and find that it outperforms strong baselines on formality, sentiment, and even authorship style transfer.",
        "creator": "Zachary Horvitz, Ajay Patel, Chris Callison-Burch, Zhou Yu, Kathleen McKeown"
      },
      {
        "title": "Over-Squashing in Graph Neural Networks: A Comprehensive survey.",
        "link": "http://arxiv.org/abs/2308.15568",
        "abstract": "Graph Neural Networks (GNNs) have emerged as a revolutionary paradigm in the realm of machine learning, offering a transformative approach to dissect intricate relationships inherent in graph-structured data. The foundational architecture of most GNNs involves the dissemination of information through message aggregation and transformation among interconnected nodes, a mechanism that has demonstrated remarkable efficacy across diverse applications encompassing node classification, link prediction, and recommendation systems. Nonetheless, their potential prowess encounters a restraint intrinsic to scenarios necessitating extensive contextual insights. In certain contexts, accurate predictions hinge not only upon a node's immediate local surroundings but also on interactions spanning far-reaching domains. This intricate demand for long-range information dissemination exposes a pivotal challenge recognized as \"over-squashing,\" wherein the fidelity of information flow from distant nodes becomes distorted. This phenomenon significantly curtails the efficiency of message-passing mechanisms, particularly for tasks reliant on intricate long-distance interactions. In this comprehensive article, we illuminate the prevalent constraint of over-squashing pervading GNNs. Our exploration entails a meticulous exposition of the ongoing efforts by researchers to improve the ramifications posed by this limitation. Through systematic elucidation, we delve into strategies, methodologies, and innovations proposed thus far, all aimed at mitigating the detriments of over-squashing. By shedding light on this intricately woven issue, we aim to contribute to a nuanced understanding of the challenges within the GNN landscape and the evolving solutions designed to surmount them.",
        "creator": "Singh Akansha"
      },
      {
        "title": "Multimodal Foundation Models For Echocardiogram Interpretation.",
        "link": "http://arxiv.org/abs/2308.15670",
        "abstract": "Multimodal deep learning foundation models can learn the relationship between images and text. In the context of medical imaging, mapping images to language concepts reflects the clinical task of diagnostic image interpretation, however current general-purpose foundation models do not perform well in this context because their training corpus have limited medical text and images. To address this challenge and account for the range of cardiac physiology, we leverage 1,032,975 cardiac ultrasound videos and corresponding expert interpretations to develop EchoCLIP, a multimodal foundation model for echocardiography. EchoCLIP displays strong zero-shot (not explicitly trained) performance in cardiac function assessment (external validation left ventricular ejection fraction mean absolute error (MAE) of 7.1%) and identification of implanted intracardiac devices (areas under the curve (AUC) between 0.84 and 0.98 for pacemakers and artificial heart valves). We also developed a long-context variant (EchoCLIP-R) with a custom echocardiography report text tokenizer which can accurately identify unique patients across multiple videos (AUC of 0.86), identify clinical changes such as orthotopic heart transplants (AUC of 0.79) or cardiac surgery (AUC 0.77), and enable robust image-to-text search (mean cross-modal retrieval rank in the top 1% of candidate text reports). These emergent capabilities can be used for preliminary assessment and summarization of echocardiographic findings.",
        "creator": "Matthew Christensen, Milos Vukadinovic, Neal Yuan, David Ouyang"
      },
      {
        "title": "Is the U.S. Legal System Ready for AI's Challenges to Human Values?.",
        "link": "http://arxiv.org/abs/2308.15906",
        "abstract": "Our interdisciplinary study investigates how effectively U.S. laws confront the challenges posed by Generative AI to human values. Through an analysis of diverse hypothetical scenarios crafted during an expert workshop, we have identified notable gaps and uncertainties within the existing legal framework regarding the protection of fundamental values, such as privacy, autonomy, dignity, diversity, equity, and physical/mental well-being. Constitutional and civil rights, it appears, may not provide sufficient protection against AI-generated discriminatory outputs. Furthermore, even if we exclude the liability shield provided by Section 230, proving causation for defamation and product liability claims is a challenging endeavor due to the intricate and opaque nature of AI systems. To address the unique and unforeseeable threats posed by Generative AI, we advocate for legal frameworks that evolve to recognize new threats and provide proactive, auditable guidelines to industry stakeholders. Addressing these issues requires deep interdisciplinary collaborations to identify harms, values, and mitigation strategies.",
        "creator": "Inyoung Cheong, Aylin Caliskan, Tadayoshi Kohno"
      },
      {
        "title": "LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models.",
        "link": "http://arxiv.org/abs/2308.16137",
        "abstract": "In recent years, there have been remarkable advancements in the performance of Transformer-based Large Language Models (LLMs) across various domains. As these LLMs are deployed for increasingly complex tasks, they often face the need to conduct longer reasoning processes or understand larger contexts. In these situations, the length generalization failure of LLMs on long sequences becomes more prominent. Most pre-training schemes truncate training sequences to a fixed length. LLMs often struggle to generate fluent and coherent texts, let alone carry out downstream tasks, after longer contexts, even with relative positional encoding designed to cope with this problem. Common solutions such as finetuning on longer corpora often involve daunting hardware and time costs and require careful training process design. To more efficiently leverage the generation capacity of existing LLMs, we theoretically and empirically investigate the main out-of-distribution (OOD) factors contributing to this problem. Inspired by this diagnosis, we propose a simple yet effective solution for on-the-fly length generalization, LM-Infinite. It involves only a $\\Lambda$-shaped attention mask (to avoid excessive attended tokens) and a distance limit (to avoid unseen distances) while requiring no parameter updates or learning. We find it applicable to a variety of LLMs using relative-position encoding methods. LM-Infinite is computationally efficient with $O(n)$ time and space, and demonstrates consistent text generation fluency and quality to as long as 32k tokens on ArXiv and OpenWebText2 datasets, with 2.72x decoding speedup. On downstream tasks such as passkey retrieval, it continues to work on inputs much longer than training lengths where vanilla models fail immediately.",
        "creator": "Chi Han, Qifan Wang, Wenhan Xiong, Yu Chen, Heng Ji, Sinong Wang"
      },
      {
        "title": "Causal Strategic Learning with Competitive Selection.",
        "link": "http://arxiv.org/abs/2308.16262",
        "abstract": "We study the problem of agent selection in causal strategic learning under multiple decision makers and address two key challenges that come with it. Firstly, while much of prior work focuses on studying a fixed pool of agents that remains static regardless of their evaluations, we consider the impact of selection procedure by which agents are not only evaluated, but also selected. When each decision maker unilaterally selects agents by maximising their own utility, we show that the optimal selection rule is a trade-off between selecting the best agents and providing incentives to maximise the agents' improvement. Furthermore, this optimal selection rule relies on incorrect predictions of agents' outcomes. Hence, we study the conditions under which a decision maker's optimal selection rule will not lead to deterioration of agents' outcome nor cause unjust reduction in agents' selection chance. To that end, we provide an analytical form of the optimal selection rule and a mechanism to retrieve the causal parameters from observational data, under certain assumptions on agents' behaviour. Secondly, when there are multiple decision makers, the interference between selection rules introduces another source of biases in estimating the underlying causal parameters. To address this problem, we provide a cooperative protocol which all decision makers must collectively adopt to recover the true causal parameters. Lastly, we complement our theoretical results with simulation studies. Our results highlight not only the importance of causal modeling as a strategy to mitigate the effect of gaming, as suggested by previous work, but also the need of a benevolent regulator to enable it.",
        "creator": "Kiet Q. H. Vo, Muneeb Aadil, Siu Lun Chau, Krikamol Muandet"
      },
      {
        "title": "BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge.",
        "link": "http://arxiv.org/abs/2308.16458",
        "abstract": "Pre-trained language models like ChatGPT have significantly improved code generation. As these models scale up, there is an increasing need for the output to handle more intricate tasks. Moreover, in bioinformatics, generating functional programs poses additional notable challenges due to the amount of domain knowledge, the need for complicated data operations, and intricate functional dependencies between the operations. Here, we present BioCoder, a benchmark developed to evaluate existing pre-trained models in generating bioinformatics code. In relation to function-code generation, BioCoder covers potential package dependencies, class declarations, and global variables. It incorporates 1026 functions and 1243 methods in Python and Java from GitHub and 253 examples from the Rosalind Project. BioCoder incorporates a fuzz-testing framework for evaluation, and we have applied it to evaluate many models including InCoder, CodeGen, CodeGen2, SantaCoder, StarCoder, StarCoder+, InstructCodeT5+, and ChatGPT. Our detailed analysis of these models emphasizes the importance of domain knowledge, pragmatic code generation, and contextual understanding. Our dataset, benchmark, Docker images, and scripts required for testing are all available at https://github.com/gersteinlab/biocoder.",
        "creator": "Xiangru Tang, Bill Qian, Rick Gao, Jiakang Chen, Xinyun Chen, Mark Gerstein"
      },
      {
        "title": "Point-TTA: Test-Time Adaptation for Point Cloud Registration Using Multitask Meta-Auxiliary Learning.",
        "link": "http://arxiv.org/abs/2308.16481",
        "abstract": "We present Point-TTA, a novel test-time adaptation framework for point cloud registration (PCR) that improves the generalization and the performance of registration models. While learning-based approaches have achieved impressive progress, generalization to unknown testing environments remains a major challenge due to the variations in 3D scans. Existing methods typically train a generic model and the same trained model is applied on each instance during testing. This could be sub-optimal since it is difficult for the same model to handle all the variations during testing. In this paper, we propose a test-time adaptation approach for PCR. Our model can adapt to unseen distributions at test-time without requiring any prior knowledge of the test data. Concretely, we design three self-supervised auxiliary tasks that are optimized jointly with the primary PCR task. Given a test instance, we adapt our model using these auxiliary tasks and the updated model is used to perform the inference. During training, our model is trained using a meta-auxiliary learning approach, such that the adapted model via auxiliary tasks improves the accuracy of the primary task. Experimental results demonstrate the effectiveness of our approach in improving generalization of point cloud registration and outperforming other state-of-the-art approaches.",
        "creator": "Ahmed Hatem, Yiming Qian, Yang Wang"
      },
      {
        "title": "Test-Time Adaptation for Point Cloud Upsampling Using Meta-Learning.",
        "link": "http://arxiv.org/abs/2308.16484",
        "abstract": "Affordable 3D scanners often produce sparse and non-uniform point clouds that negatively impact downstream applications in robotic systems. While existing point cloud upsampling architectures have demonstrated promising results on standard benchmarks, they tend to experience significant performance drops when the test data have different distributions from the training data. To address this issue, this paper proposes a test-time adaption approach to enhance model generality of point cloud upsampling. The proposed approach leverages meta-learning to explicitly learn network parameters for test-time adaption. Our method does not require any prior information about the test data. During meta-training, the model parameters are learned from a collection of instance-level tasks, each of which consists of a sparse-dense pair of point clouds from the training data. During meta-testing, the trained model is fine-tuned with a few gradient updates to produce a unique set of network parameters for each test instance. The updated model is then used for the final prediction. Our framework is generic and can be applied in a plug-and-play manner with existing backbone networks in point cloud upsampling. Extensive experiments demonstrate that our approach improves the performance of state-of-the-art models.",
        "creator": "Ahmed Hatem, Yiming Qian, Yang Wang"
      },
      {
        "title": "Latent Painter.",
        "link": "http://arxiv.org/abs/2308.16490",
        "abstract": "Latent diffusers revolutionized the generative AI and inspired creative art. When denoising the latent, the predicted original image at each step collectively animates the formation. However, the animation is limited by the denoising nature of the diffuser, and only renders a sharpening process. This work presents Latent Painter, which uses the latent as the canvas, and the diffuser predictions as the plan, to generate painting animation. Latent Painter also transits one generated image to another, which can happen between images from two different sets of checkpoints.",
        "creator": "Shih-Chieh Su"
      },
      {
        "title": "Towards Long-Tailed Recognition for Graph Classification via Collaborative Experts.",
        "link": "http://arxiv.org/abs/2308.16609",
        "abstract": "Graph classification, aiming at learning the graph-level representations for effective class assignments, has received outstanding achievements, which heavily relies on high-quality datasets that have balanced class distribution. In fact, most real-world graph data naturally presents a long-tailed form, where the head classes occupy much more samples than the tail classes, it thus is essential to study the graph-level classification over long-tailed data while still remaining largely unexplored. However, most existing long-tailed learning methods in visions fail to jointly optimize the representation learning and classifier training, as well as neglect the mining of the hard-to-classify classes. Directly applying existing methods to graphs may lead to sub-optimal performance, since the model trained on graphs would be more sensitive to the long-tailed distribution due to the complex topological characteristics. Hence, in this paper, we propose a novel long-tailed graph-level classification framework via Collaborative Multi-expert Learning (CoMe) to tackle the problem. To equilibrate the contributions of head and tail classes, we first develop balanced contrastive learning from the view of representation learning, and then design an individual-expert classifier training based on hard class mining. In addition, we execute gated fusion and disentangled knowledge distillation among the multiple experts to promote the collaboration in a multi-expert framework. Comprehensive experiments are performed on seven widely-used benchmark datasets to demonstrate the superiority of our method CoMe over state-of-the-art baselines.",
        "creator": "Siyu Yi, Zhengyang Mao, Wei Ju, Yongdao Zhou, Luchen Liu, Xiao Luo, Ming Zhang"
      },
      {
        "title": "Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack.",
        "link": "http://arxiv.org/abs/2308.16684",
        "abstract": "The vulnerabilities to backdoor attacks have recently threatened the trustworthiness of machine learning models in practical applications. Conventional wisdom suggests that not everyone can be an attacker since the process of designing the trigger generation algorithm often involves significant effort and extensive experimentation to ensure the attack's stealthiness and effectiveness. Alternatively, this paper shows that there exists a more severe backdoor threat: anyone can exploit an easily-accessible algorithm for silent backdoor attacks. Specifically, this attacker can employ the widely-used lossy image compression from a plethora of compression tools to effortlessly inject a trigger pattern into an image without leaving any noticeable trace; i.e., the generated triggers are natural artifacts. One does not require extensive knowledge to click on the \"convert\" or \"save as\" button while using tools for lossy image compression. Via this attack, the adversary does not need to design a trigger generator as seen in prior works and only requires poisoning the data. Empirically, the proposed attack consistently achieves 100% attack success rate in several benchmark datasets such as MNIST, CIFAR-10, GTSRB and CelebA. More significantly, the proposed attack can still achieve almost 100% attack success rate with very small (approximately 10%) poisoning rates in the clean label setting. The generated trigger of the proposed attack using one lossy compression algorithm is also transferable across other related compression algorithms, exacerbating the severity of this backdoor threat. This work takes another crucial step toward understanding the extensive risks of backdoor attacks in practice, urging practitioners to investigate similar attacks and relevant backdoor mitigation methods.",
        "creator": "Sze Jue Yang, Quang Nguyen, Chee Seng Chan, Khoa D. Doan"
      },
      {
        "title": "Towards Low-Barrier Cybersecurity Research and Education for Industrial Control Systems.",
        "link": "http://arxiv.org/abs/2308.16769",
        "abstract": "The protection of Industrial Control Systems (ICS) that are employed in public critical infrastructures is of utmost importance due to catastrophic physical damages cyberattacks may cause. The research community requires testbeds for validation and comparing various intrusion detection algorithms to protect ICS. However, there exist high barriers to entry for research and education in the ICS cybersecurity domain due to expensive hardware, software, and inherent dangers of manipulating real-world systems. To close the gap, built upon recently developed 3D high-fidelity simulators, we further showcase our integrated framework to automatically launch cyberattacks, collect data, train machine learning models, and evaluate for practical chemical and manufacturing processes. On our testbed, we validate our proposed intrusion detection model called Minimal Threshold and Window SVM (MinTWin SVM) that utilizes unsupervised machine learning via a one-class SVM in combination with a sliding window and classification threshold. Results show that MinTWin SVM minimizes false positives and is responsive to physical process anomalies. Furthermore, we incorporate our framework with ICS cybersecurity education by using our dataset in an undergraduate machine learning course where students gain hands-on experience in practicing machine learning theory with a practical ICS dataset. All of our implementations have been open-sourced.",
        "creator": "Colman McGuan, Chansu Yu, Qin Lin"
      },
      {
        "title": "StratMed: Relevance Stratification for Low-resource Medication Recommendation.",
        "link": "http://arxiv.org/abs/2308.16781",
        "abstract": "With the growing imbalance between limited medical resources and escalating demands, AI-based clinical tasks have become paramount. Medication recommendation, as a sub-domain, aims to amalgamate longitudinal patient history with medical knowledge, assisting physicians in prescribing safer and more accurate medication combinations. Existing methods overlook the inherent long-tail distribution in medical data, lacking balanced representation between head and tail data, which leads to sub-optimal model performance. To address this challenge, we introduce StratMed, a model that incorporates an innovative relevance stratification mechanism. It harmonizes discrepancies in data long-tail distribution and strikes a balance between the safety and accuracy of medication combinations. Specifically, we first construct a pre-training method using deep learning networks to obtain entity representation. After that, we design a pyramid-like data stratification method to obtain more generalized entity relationships by reinforcing the features of unpopular entities. Based on this relationship, we designed two graph structures to express medication precision and safety at the same level to obtain visit representations. Finally, the patient's historical clinical information is fitted to generate medication combinations for the current health condition. Experiments on the MIMIC-III dataset demonstrate that our method has outperformed current state-of-the-art methods in four evaluation metrics (including safety and accuracy).",
        "creator": "Xiang Li, Shunpan Liang, Tengfei Ma, Yulei Hou"
      },
      {
        "title": "Agent Teaming Situation Awareness (ATSA): A Situation Awareness Framework for Human-AI Teaming.",
        "link": "http://arxiv.org/abs/2308.16785",
        "abstract": "The rapid advancements in artificial intelligence (AI) have led to a growing trend of human-AI teaming (HAT) in various fields. As machines continue to evolve from mere automation to a state of autonomy, they are increasingly exhibiting unexpected behaviors and human-like cognitive/intelligent capabilities, including situation awareness (SA). This shift has the potential to enhance the performance of mixed human-AI teams over all-human teams, underscoring the need for a better understanding of the dynamic SA interactions between humans and machines. To this end, we provide a review of leading SA theoretical models and a new framework for SA in the HAT context based on the key features and processes of HAT. The Agent Teaming Situation Awareness (ATSA) framework unifies human and AI behavior, and involves bidirectional, and dynamic interaction. The framework is based on the individual and team SA models and elaborates on the cognitive mechanisms for modeling HAT. Similar perceptual cycles are adopted for the individual (including both human and AI) and the whole team, which is tailored to the unique requirements of the HAT context. ATSA emphasizes cohesive and effective HAT through structures and components, including teaming understanding, teaming control, and the world, as well as adhesive transactive part. We further propose several future research directions to expand on the distinctive contributions of ATSA and address the specific and pressing next steps.",
        "creator": "Qi Gao, Wei Xu, Mowei Shen, Zaifeng Gao"
      },
      {
        "title": "Can Programming Languages Boost Each Other via Instruction Tuning?.",
        "link": "http://arxiv.org/abs/2308.16824",
        "abstract": "When human programmers have mastered a programming language, it would be easier when they learn a new programming language. In this report, we focus on exploring whether programming languages can boost each other during the instruction fine-tuning phase of code large language models. We conduct extensive experiments of 8 popular programming languages (Python, JavaScript, TypeScript, C, C++, Java, Go, HTML) on StarCoder. Results demonstrate that programming languages can significantly improve each other. For example, CodeM-Python 15B trained on Python is able to increase Java by an absolute 17.95% pass@1 on HumanEval-X. More surprisingly, we found that CodeM-HTML 7B trained on the HTML corpus can improve Java by an absolute 15.24% pass@1. Our training data is released at https://github.com/NL2Code/CodeM.",
        "creator": "Daoguang Zan, Ailun Yu, Bo Shen, Jiaxin Zhang, Taihong Chen, Bing Geng, Bei Chen, Jichuan Ji, Yafen Yao, Yongji Wang, Qianxiang Wang"
      },
      {
        "title": "Video based Object 6D Pose Estimation using Transformers.",
        "link": "http://arxiv.org/abs/2210.13540",
        "abstract": "We introduce a Transformer based 6D Object Pose Estimation framework VideoPose, comprising an end-to-end attention based modelling architecture, that attends to previous frames in order to estimate accurate 6D Object Poses in videos. Our approach leverages the temporal information from a video sequence for pose refinement, along with being computationally efficient and robust. Compared to existing methods, our architecture is able to capture and reason from long-range dependencies efficiently, thus iteratively refining over video sequences. Experimental evaluation on the YCB-Video dataset shows that our approach is on par with the state-of-the-art Transformer methods, and performs significantly better relative to CNN based approaches. Further, with a speed of 33 fps, it is also more efficient and therefore applicable to a variety of applications that require real-time object pose estimation. Training code and pretrained models are available at https://github.com/ApoorvaBeedu/VideoPose",
        "creator": "Apoorva Beedu, Huda Alamri, Irfan Essa"
      }
    ]
  },
  {
    "name": "Plant Biology",
    "feed": [
      {
        "title": "Establishing a comprehensive web-based analysis platform for Nicotiana benthamiana genome and transcriptome",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.03.556139v1?rss=1",
        "abstract": "Nicotiana benthamiana has long served as a crucial plant material extensively used in plant physiology research, particularly in the field of plant pathology, because of its high susceptibility to plant viruses. Additionally, it serves as a production platform to test vaccines and other valuable substances. Among its approximately 3.1 Gb genome, 57,583 genes have been annotated within a 61 Mb region. We created a comprehensive and easy-to-use platform to use transcriptomes for modern annotation. These tools allow to visualize gene expression profiles, draw molecular evolutionary phylogenetic trees of gene families, perform functional enrichment analyses, and facilitate output downloads. To demonstrate their utility, we analyzed the gene expression profiles of enzymes within the nicotine biosynthesis pathway, a secondary metabolic pathway characteristic of the Nicotiana genus. Using the developed tool, expression profiles of the nicotine biosynthesis pathway genes were generated. The expression patterns of eight gene groups in the pathway were strongly expressed in the roots and weakly expressed in leaves and flowers of N. benthamiana. The results were consistent with the established gene expression profiles in Nicotiana tabacum and provided insights into gene family composition and expression trends. The compilation of this database tool can facilitate genetic analysis of N. benthamiana in the future.",
        "creator": "Kurotani, K.-i., Hirakawa, H., Shirasawa, K., Tagiri, K., Mori, M., Ichihashi, Y., Suzuki, T., Tanizawa, Y., Nakamura, Y., Isobe, S., Notaguchi, M."
      },
      {
        "title": "A transcription factor module mediating C2 photosynthesis",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.05.556297v1?rss=1",
        "abstract": "C4 photosynthesis has arisen from the ancestral C3 state in over sixty lineages of angiosperms. It is widely accepted that an early step in C4 evolution is restriction of glycine decarboxylase activity to bundle sheath cells to generate the so-called C2 pathway. In C2 Moricandia species, changes to the cis-regulatory region controlling expression of the P-subunit of GLYCINE DECARBOXYLASE (GLDP) in mesophyll cells enables this trait, but the mechanism underpinning GLDP expression in the bundle sheath is not known. We identify a MYC-MYB transcription factor module previously associated with the control of glucosinolate biosynthesis as the basis of GLDP expression in bundle sheath cells. In C3 Arabidopsis thaliana this module drives GLDP expression in bundle sheath cells along with as yet unidentified factors driving expression in mesophyll cells. In the C2 species Moricandia arvensis, GLDP expression is lost from mesophyll cells and the MYC-MYB dependent expression in the bundle sheath is revealed. Evolution of C2 photosynthesis is thus associated with a MYC-MYB based transcriptional network already present in the C3 state. This work identifies a molecular genetic mechanism underlying the bundle sheath accumulation of glycine decarboxylase required for C2 photosynthesis and thus a foundational step in the evolution of C4 photosynthesis.",
        "creator": "Dickinson, P. J., Triesch, S., Schluter, U., Weber, A. P. M., Hibberd, J. M."
      },
      {
        "title": "An atypical endomembrane localized CNL-type immune receptor with a conserved deletion in the N-terminal signaling domain functions in cell death and immunity",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.04.556214v1?rss=1",
        "abstract": "Plants have evolved intracellular nucleotide-binding leucine rich repeat receptors (NLRs) to induce a superior immune response. Upon activation, coiled-coil (CC) domain containing NLRs (CNLs) oligomerize to form apparent cation channels that promote calcium influx and cell death induction, with the alpha-1 helix of the individual CC domains penetrating membranes. Some members of a monophyletic subclass of CNLs, the ancient and autonomous NLRs (ANLs), are characterized by putative N-myristoylation and S-acylation sites at the N-terminus of their CCG10/GA domain, potentially mediating permanent membrane association. Whether these Potentially Membrane Localized NLRs (PMLs) mediate cell death upon activation in a similar way as reported for other CNLs has been unknown. We integrated phylogenetic, cell-biological, and functional studies to uncover the cell death function of an atypical but conserved Arabidopsis PML, PML5, which has a 113 amino acid deletion in its CCG10/GA domain. Active PML5 oligomers localize in Golgi membranes and the tonoplast, changes vacuolar morphology, and induce cell death, with the short N-terminus being sufficient for cell death. Mutant analysis supports a potential key role of PMLs in plant immunity. Similar deletions as in Arabidopsis PML5 are found in several Brassicales paralogs, pointing to the evolutionary importance of this innovation. PML5 is thus a naturally occurring CNL variant with a minimal signaling domain and its further study should help in understanding the functional importance of this minimal domain for NLR signaling.",
        "creator": "Sunil, S., Beeh, S., Stoebbe, E., Fischer, K. M., Wilhelm, F., Paris, C., Meral, A., Teasdale, L., Jiang, Z., Zhang, l., Aguilar Parras, E., Nuernberger, T., Weigel, D., Lozano-Duran, R., El Kasmi, F."
      },
      {
        "title": "Cell layer specific roles for hormones in root development: Gibberellins suppress infection thread progression, promote nodule and lateral root development in the endodermis and interact with auxin and cytokinin",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.04.555035v1?rss=1",
        "abstract": "Gibberellins have a profound influence on the formation of lateral root organs. However, the precise role this hormone plays in the cell-specific events during lateral root formation, rhizobial infection and nodule organogenesis, including interactions with auxin and cytokinin, is not clear. In this study, we performed epidermal- and endodermal-specific complementation of the severely gibberellin-deficient na pea (Pisum sativum) mutant with Agrobacterium rhizogenes. Gibberellin mutants were used to examine the spatial expression pattern of cytokinin (TCSn) and auxin (DR5) responsive promoters and hormone levels. We found that gibberellins produced in the endodermis promotes lateral root and nodule organogenesis and can induce a mobile signal(s) that suppresses rhizobial infection. In contrast, epidermal-derived gibberellins suppress infection but have little influence on root or nodule development. Gibberellins suppress the cytokinin-responsive TCSn promoter in the cortex and are required for normal auxin activation during nodule primordia formation. Our findings indicate that GA regulates the checkpoints between infection thread penetration of the cortex and invasion of nodule primordial cells, and also promotes the subsequent progression of nodule development. It appears that GA may limit the progression and branching of infection threads in the cortex by restricting cytokinin response and may activate auxin response to promote nodule primordia development.",
        "creator": "Velandia, K., Correa-Lozano, A., McGuiness, P. M., Reid, J., Foo, E."
      },
      {
        "title": "Assessing variation in Citrus limon \"Assam lemon\": morphological, seed availability pattern, and biochemical diversity across different districts of Assam",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.01.555945v1?rss=1",
        "abstract": "The Assam lemon is a highly valued Citrus cultivar known for its unique aroma, flavor, and seedless fruit characteristic. This study aimed to investigate for the first time the morphological, seeding pattern, and biochemical, variations within 133 populations of Assam lemon cultivar growing across 22 districts of Assam, India, and including control population, with the objective to offer comprehensive understanding that could facilitate the improvement of breeding programs and further improvement of this important cultivar. Using the dendrogram-based UPGMA algorithm, morphological and seeding pattern data were analyzed at both district and population levels. The resulting dendrograms revealed two major clusters, where all the populations of Upper Assam districts were in the same cluster with the original stock (control population). However, populations from Tinsukia and Dhemaji districts displayed more close similarities with the control population in comparison to other populations of Upper Assam districts. Another interesting observation was regarding flowering patterns, while some populations displayed both bisexual and unisexual flowers with less concentration of unisexual flowers, others had bisexual and unisexual flowers of almost equal concentration. Unisexual flowers contained only the male reproductive organs with 40 anthers, while bisexual flowers had 36 anthers. Seeding patterns were examined across the districts, and it was found that populations from Tinsukia, Dhemaji, Lakhimpur, Dibrugarh, Jorhat, and the control population exhibited seedless characteristic while populations from other selected districts displayed a combination of seedless and seeded traits. Interestingly, Golaghat district appears as the linking district and showed availability of both seeded and seedless Assam lemon fruit, connecting the regions of Upper, Central, Lower and North Assam and Barak valley. Biochemical analysis showed significant variations across districts, however, the populations from Dhemaji, Tinsukia, Lakhimpur, Dibrugarh, and Jorhat districts displayed similarity with the control population. The study also investigated variability in soil nutrient content revealing substantial variation among the populations studied, potentially influencing observed morphological variations. This comprehensive investigation provides valuable insights into the morphological, seeding pattern, and biochemical diversity within the Assam lemon cultivar. These findings can be instrumental in breeding programs to enhance this Citrus cultivar, particularly in producing high-quality seedless fruits to meet consumer demands.",
        "creator": "Akhtar, S., Ahmed, R., Begum, K., Das, A., Saikia, S., Banu, S."
      },
      {
        "title": "Historical causes for the greater proportion of polyploid plants in higher latitudes",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.01.555981v1?rss=1",
        "abstract": "The proportion of polyploid plants in a community increases with latitude, and different hypotheses have been proposed about which factors drive this pattern. Here, we aim to understand the historical causes of the latitudinal polyploidy gradient using a combination of ancestral state reconstruction methods. Specifically, we assess whether (1) polyploidization enables movement to higher latitudes (i.e., polyploidization precedes occurrences in higher latitudes) or (2) higher latitudes facilitate polyploidization (i.e., occurrence in higher latitudes precedes polyploidization). We reconstruct the ploidy states and ancestral niches of 1,032 angiosperm species at four paleoclimatic time slices ranging from 3.3 million years ago to the present, comprising taxa from four well-represented clades: Onagraceae, Primulaceae, Solanum (Solanaceae), and Pooideae (Poaceae). We use ancestral niche reconstruction models alongside a customized discrete character evolution model to allow reconstruction of states at specific time slices. Patterns of latitudinal movement are reconstructed and compared in relation to inferred ploidy shifts. We find that no single hypothesis applies equally well across all analyzed clades. While significant differences in median latitudinal occurrence were detected in the largest clade, Pooideae, no significant differences were detected in latitudinal movement in any clade. Our preliminary study is the first to attempt to connect ploidy changes to continuous latitudinal movement, but we cannot favor one hypothesis over another. Given that patterns seem to be clade-specific, a larger number of clades must be analyzed in future studies for generalities to be drawn.",
        "creator": "Hagen, E. R., Vasconcelos, T., Boyko, J. D., Beaulieu, J. M."
      },
      {
        "title": "Localization of four class I glutaredoxins in the cytosol and the secretory pathway and characterization of their biochemical diversification",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.01.555924v1?rss=1",
        "abstract": "Class I glutaredoxins (GRXs) are catalytically active oxidoreductases and considered key proteins mediating reversible glutathionylation and deglutathionylation of protein thiols during development and stress responses. To narrow in on putative target proteins, it is mandatory to know the subcellular localization of the respective GRXs and to understand their catalytic activities and putative redundancy between isoforms in the same compartment. We show that GRXC1 and GRXC2 are cytosolic proteins with GRXC1 being attached to membranes through myristoylation. GRXC3 and GRXC4 are identified as type II membrane proteins along the early secretory pathway with their enzymatic function on the luminal side. Comparison of all four studied GRXs for their oxidoreductase function highlights biochemical diversification with GRXC1 and GRXC2 being better reductants than GRXC3 and GRXC4 with bis(2-hydroxyethyl) disulfide and oxidized roGFP2 as substrates. Vice versa, GRXC3 and GRXC4 are better oxidants of reduced roGFP2 in the reverse reaction. Analysis of electrostatic surface potentials mirrors the phylogenetic classification of class I GRXs but cannot fully account for the observed kinetic differences in their interaction with roGPF2. Despite localization of two class I GRXs each in the cytosol and the endomembrane system, the respective double null mutants are viable without obvious phenotypes.",
        "creator": "Schloesser, M., Moseler, A., Bodnar, Y., Homagk, M., Wagner, S., Pedroletti, L., Gellert, M., Ugalde, J. M., Lillig, C. H., Meyer, A. J."
      },
      {
        "title": "Investigating the genetic control of plant development under speed breeding conditions",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.04.555916v1?rss=1",
        "abstract": "Speed breeding is a powerful tool to accelerate breeding and research programmes by shortening generation time and has been widely adopted for a range of crop species. Despite its success and growing popularity with breeders the genetic basis of plant development under speed breeding remains unknown. In this study, we explored how genotypes respond in terms of developmental advancement under different photoperiod regimes in the context of speed breeding. A subset of the barley HEB-25 Nested Association Mapping population was evaluated for days to heading and maturity under two contrasting photoperiod conditions: 1) Speed Breeding (SB) consisting of 22 hours of light and 2 hours of darkness), and 2) Normal Breeding (NB) consisting of 16 hours of light and 8 hours of darkness. GWAS revealed that developmental responses under both conditions were largely controlled by two loci: PPDH-1 and ELF3. Allelic variants at these genes determine whether plants display early flowering and maturity under both NB and SB. At key QTL regions, domesticated alleles were associated with late flowering and maturity in NB and early flowering and maturity in SB, whereas wild alleles were associated with early flowering under both conditions. We hypothesise that this may be related to the dark dependent repression of PPD-H1 by ELF3 which might be more prominent in NB conditions. Furthermore, by comparing development under two contrasting photoperiod regimes, we were able to derive an estimate of plasticity for the two traits. Interestingly, plasticity in development was largely attributed to allelic variation at ELF3. Our results have important implications for our understanding and optimisation of speed breeding protocols particularly when incorporating genetics from wild relatives into breeding programmes and the design of breeding programmes to support the delivery of climate resilient crops.",
        "creator": "Rossi, N., Powell, W., Mackay, I., Hickey, L., Maurer, A., Pillen, K., Halliday, K., Sharma, R."
      },
      {
        "title": "Rho of plant GTPases with geranylgeranylation motif modulate monoterpene indole alkaloid biosynthesis in Catharanthus roseus",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.04.554920v1?rss=1",
        "abstract": "Rho Of Plant (ROP) GTPases function as molecular switches that control signaling processes essential for growth, development, and defense. However, their role in specialized metabolism is poorly understood. Previously, we demonstrated that inhibition of protein geranylgeranyl transferase (PGGT-I) negatively impacts the biosynthesis of monoterpenoid indole alkaloids (MIA) in Catharanthus roseus, indicating the involvement of prenylated proteins in signaling. Here, we show through biochemical, molecular and in planta approaches that specific geranylgeranylated ROPs modulate C. roseus MIA biosynthesis. Among the six C. roseus ROP GTPases (CrROPs), only CrROP3 and CrROP5, having a C-terminal CSIL motif, were specifically prenylated by PGGT-I. Additionally, both of their transcripts showed higher expression in most parts compared to other CrROPs. Protein-protein interaction studies revealed that both CrROP3 and CrROP5, but not CrROP2 (lacking CSIL motif), interacted with CrPGGT-I. Further, CrROP3 and CrROP5 exhibited nuclear localization, whereas CrROP2 was localized to plasma membrane. In planta functional studies revealed that silencing of CrROP3 and CrROP5 negatively affected MIA biosynthesis, while their overexpression upregulated MIA formation. In contrast, silencing and overexpression of CrROP2 had no effect on MIA biosynthesis. Moreover, overexpression of deltaCrROP3 and deltaCrROP5 mutants lacking the CSIL motif failed to enhance MIA biosynthesis. Taken together, these results implicate that CrROP3 and CrROP5 have positive regulatory role on MIA biosynthesis and thus shed light on how geranylgeranylated ROP GTPases mediate the modulation of specialized metabolism in C. roseus.",
        "creator": "Bomzan, D. P., Sharma, A., Cruz, P. L., Carqueijeiro, I., Bellenger, L., Rai, A., Thippesh, A. K., C, V. S., Parihar, D., Ducos, E., Courdavault, V., Nagegowda, D. A."
      },
      {
        "title": "Leaf and shoot apical meristem transcriptomes of quinoa (Chenopodium quinoa Willd.) in response to photoperiod and plant development",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.31.555728v1?rss=1",
        "abstract": "Our study aimed to identify candidate genes for flowering time regulation and photoperiod response in quinoa. We investigated the timing of photoperiod-driven floral transition and analyzed the transcriptomes of leaf and shoot apical meristems in photoperiod-sensitive and -insensitive quinoa accessions. Histology analysis of the apical meristem showed that floral transition in quinoa initiates two to three weeks after sowing. We found four groups of differentially expressed genes responding to plant development and floral transition, which were annotated in the QQ74-V2 reference genome, including (i) 222 genes differentially responding to photoperiod in leaves, (ii) 1,812 genes differentially expressed between accessions under long-day conditions in leaves, (iii) 57 genes responding to developmental changes between weeks under short-day conditions in leaves, and (iv) 911 genes responding to floral transition within the shoot apical meristem. Interestingly, out of the thousands of candidates, two putative FT orthologues and several others have been reported as key regulators of flowering time in other species (e.g., SOC1, COL, AP1). Additionally, we used co-expression networks to associate novel transcripts to a putative biological process based on the annotated genes within the same co-expression cluster. The candidate genes in this study would benefit quinoa breeding by identifying and integrating their beneficial haplotypes in crossing programs to develop adapted cultivars to diverse environmental conditions.",
        "creator": "Taipe, N. M., Rey, E., Tester, M., Jung, C., Emrani, N."
      },
      {
        "title": "Arabidopsis CML13 and CML14 Have Essential And Overlapping Roles In Plant Development",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.30.555572v1?rss=1",
        "abstract": "Calmodulin-like proteins (CaM-like; CML) are the largest family of calcium-binding proteins in plants, yet the functions of most CMLs are unknown. Arabidopsis CML13 and CML14 are closely related paralogs that interact with the isoleucine-glutamine (IQ) domains of myosins, IQ-domain (IQD) proteins, and CaM-activated transcription factors (CAMTAs). Here, we explored the physiological roles of CML13 and CML14 during development by using dexamethasone-inducible RNA silencing to suppress either CML13 or CML14 transcript levels. In the absence of inducible suppression, CML13- and CML14-RNA-interference lines were indistinguishable from WT plants throughout development. In contrast, induction of silencing treatment led to rapid increases in RNA-hairpin production that correlated with a targeted reduction in CML13 or CML14 transcript levels and a range of developmental and morphological effects. RNA suppression treatment did not impair the germination of CML13- or 14-RNA-interference lines, but these seedlings were chlorotic, displayed high mortality, and failed to achieve seedling establishment. Induced RNA suppression of mature plants led to reduced silique length, shorter roots, and rapid leaf senescence in CML13- and 14-RNA-interference plants. Plants induced for RNA suppression at 2 weeks post-germination exhibited a much stronger phenotype than treatment of 3-, 4-, or 5-week-old plants. Collectively, our data indicate that both CML13 and CML14 are essential for normal development and function across a broad range of tissues and developmental stages.  HighlightCML13 and CML14 are biochemically unique among the CML family and interact with proteins that possess IQ domains. Here, we show that both paralogs are essential for normal plant growth and development.",
        "creator": "Symonds, K., Teresinski, H., Hau, B., Chiasson, D., Snedden, W. A."
      },
      {
        "title": "Nepenthes pitchers versus thermogenic flowers: thermal patterns and their role in prey capture and pollination",
        "link": "http://biorxiv.org/cgi/content/short/2023.09.01.555905v1?rss=1",
        "abstract": "Prey capture in Nepenthes and pollination in angiosperms are two antithetical events; one designed to trap insects and other arthropods (carnivory) and the other to transfer pollen through pollinators (reproduction). In this study, infrared thermography was extensively used to obtain thermal profiles of Nepenthes pitchers and thermogenic and non-thermogenic flowers in field conditions. Confocal and scanning electron microscopy were used to record peristome cross-sectional features and pitcher morphology. N. khasiana pitchers displayed below ambient temperatures during evening-night-morning hours (5 pm to 8-9-10 am); pitcher spots recorded lowest and highest temperatures as 14.4 (6-7 am) and 45.6{degrees}C (2 pm), respectively. The average humidities in the night and day periods were 77.15% and 50.15%, respectively. The prey capturing zones in Nepenthes pitchers (peristome, lid and their intersection) are colder favoring prey capture, whereas in thermogenic flowers, floral portions are hotter, providing the thermal requirements for the pollinator. In thermogenic plants, floral zones assist pollination by offering a  thermal reward through enzymatic processes; but Nepenthes traps achieve lower temperature spots by physical (surface microstructures), chemical (nectar) and ecological (rain, humidity) factors. Both are contrasting  life and  death adaptations in nature.",
        "creator": "Sujatha, G. B., Johnson, A. J., Hussain, A. A., Baby, S."
      },
      {
        "title": "Evaluation of morpho-physiological and yield-associated traits of rice (Oryza sativa L.) landraces combined with marker-assisted selection under high temperature stress and elevated atmospheric CO2 levels",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.31.555684v1?rss=1",
        "abstract": "Rice (Oryza sativa L.) has a tremendous domestication history and is presently used as a major cereal all over the world. In Asia, India is considered as one of the centers of origin of indica rice and has several native landraces, especially in North-Eastern India (NEI), which have the potential to cope with the negative impact of present-day climate change. The current investigation aimed to evaluate the NEI rice landraces potential under high temperatures and elevated CO2 levels in comparison with a check variety for phenological, morphological, physiological and yield-associated parameters and molecularly validated with marker-assisted genotyping. The initial experiment was carried out with 75 rice landraces to evaluate their high heat tolerance ability. Seven better-performing landraces along with the check variety (N22) were further evaluated for aforesaid traits across two years (2019 and 2020) under control (or T1) and two stress treatments - (i) mild stress or T2 [CO2 550 ppm + 4{degrees} C more than ambient temperature] and (ii) severe stress or T3 [CO2 750 ppm + 6{degrees} C more than ambient temperature] using bioreactors. In the molecular analysis, the eight selected genotypes were evaluated through 25 Start Codon Targeted (SCoT) markers. The results revealed that the mild stress (T2) had a positive impact on various morpho-physiological parameters like plant height, number of leaves, leaf area and yield parameters like spikelets panicle-1 (S/P), thousand-grain weight (TGW) and grain yield (GY). This effect could be attributed to the genotypes ability to maintain a higher photosynthetic rate and possess better tolerance ability to moderately high temperatures. However, under high-temperature conditions in T3, all genotypes exhibited a significant decrease in the studied parameters including GY. It was found that pollen traits were significantly and positively correlated to spikelet fertility% at maturity, which was further significantly associated with GY under applied stress conditions. The physiological traits including shoot biomass were evident to have a significant positive effect on yield-associated parameters like S/P, harvest index (HI), TGW and GY. Overall, two landraces Kohima special and Lisem were found to be better responsive compared to other landraces as well as the check variety N22 under stress conditions. SCoT genotyping amplified a total of 77 alleles out of which 55 were polymorphic with the PIC value ranging from 0.22 to 0.67. The investigation suggests the presence of genetic variation among the tested rice lines and further supports evidence of the closely relatedness of Kohima special and Lisem. These two are two better-performing rice landraces from North-East India based on their improving morpho-physiological parameters and yield attributes in mild and severe high temperature and elevated CO2 stress environments. The shortlisted two rice landraces can be used as valuable pre-breeding materials for future rice breeding programs to improve the stress tolerance properties, particularly to high temperatures and elevated CO2 levels under ongoing changing climatic scenarios.",
        "creator": "Mollier, M., Roychowdhury, R., Tzudir, L., Sharma, R., Gogoi, B., Kalita, P., Jain, D., Das, R."
      },
      {
        "title": "Rapid redirection of auxin fluxes during root gravitropism by translocation of NGR proteins driving polarization of PIN-activating kinases",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.30.555533v1?rss=1",
        "abstract": "Root gravitropic bending represents a fundamental aspect of terrestrial plant physiology. Gravity is perceived by sedimentation of starch-rich plastids (statoliths) to the bottom of the central root cap cells. Following gravity perception, intercellular auxin transport is redirected downwards leading to an asymmetric auxin accumulation at the lower root side causing inhibition of cell expansion, ultimately resulting in downwards bending. How gravity-induced statoliths repositioning is translated into asymmetric auxin distribution remains unclear despite PIN auxin efflux carriers and the Negative Gravitropic Response of roots (NGR) proteins polarize along statolith sedimentation, thus providing a plausible mechanism for auxin flow redirection. In this study, using a functional NGR1-GFP construct, we visualized the NGR1 localization on the statolith surface and plasma membrane (PM) domains in close proximity to the statoliths, correlating with their movements. We determined that NGR1 binding to these PM domains is indispensable for NGR1 functionality and relies on cysteine acylation and adjacent polybasic regions as well as on lipid and sterol PM composition. Detailed timing of the early events following graviperception suggested that both NGR1 repolarization and initial auxin asymmetry precede the visible PIN3 polarization. This discrepancy motivated us to unveil a rapid, NGR-dependent translocation of PIN-activating AGCVIII kinase D6PK towards lower PMs of gravity-perceiving cells, thus providing an attractive model for rapid redirection of auxin fluxes following gravistimulation.",
        "creator": "Kulich, I., Schmid, J., Teplova, A., Qi, L., Friml, J."
      },
      {
        "title": "Strain-specific differences in the interactions of the cucumber mosaic virus 2b protein with the viral 1a and host Argonaute 1 proteins",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.31.555694v1?rss=1",
        "abstract": "Abstract/SummaryThe cucumber mosaic virus (CMV) 2b protein is a potent counter-defense protein and symptom determinant that inhibits antiviral silencing by titration of short double-stranded RNAs. Expression of the 2b protein from the CMV Subgroup IA strain Fny-CMV in transgenic Arabidopsis thaliana plants disrupts microRNA-mediated cleavage of host mRNAs by binding ARGONAUTE 1 (AGO1), leading to symptom-like phenotypes. This also triggers AGO2-mediated resistance against CMV and strong resistance to CMVs aphid vectors, which would be deleterious to viral fitness. However, in authentic viral infections the Fny-CMV 1a protein modulates 2b-AGO1 interactions, which inhibits induction of AGO2-mediated virus resistance and resistance to aphid vectors. Contrastingly, the 2b proteins encoded by the Subgroup II LS-CMV strain or the recently discovered Subgroup IA strain Ho-CMV induce no apparent symptoms. Confocal laser scanning microscopy, bimolecular fluorescence complementation and co-immunoprecipitation showed that the Fny-CMV and Ho-CMV 2b proteins interact with the Fny-CMV and LS-CMV 1a proteins whilst the CMV-LS 2b protein does not. However, the Fny-CMV, Ho-CMV and LS-CMV 2b proteins all interacted with AGO1, but while AGO1-Fny2b complexes occurred in the host cell nucleus and cytoplasm, the corresponding AGO1-2b complexes for LS-CMV and Ho-CMV accumulated almost exclusively in nuclei. AGO2 transcript accumulation was used to assess the inhibition of AGO1-mediated miRNA-regulated mRNA cleavage. While Fny-CMV 2b induced a five-fold increase in AGO2 accumulation, the LS-CMV and Ho-CMV 2b proteins induced only two-fold increases. Thus, these 2b proteins bind AGO1 but are less effective at inhibiting AGO1 activity. We conclude that the intracellular localization sites of 2b-AGO1 complexes influences the degree to which a 2b protein can inhibit microRNA-mediated host mRNA degradation and that cytoplasmic AGO1 has the strongest influence on miRNA-mediated cellular mRNA turnover.",
        "creator": "Crawshaw, S., Watt, L. G., Murphy, A. M., Carr, J. P."
      },
      {
        "title": "Insights into Phakopsora pachyrhizi effector-effector interactions",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.30.555440v1?rss=1",
        "abstract": "The multifaceted role of pathogen-encoded effectors in plant-pathogen interactions is complex and not fully understood. Effectors operate within intricate host environments, interacting with host proteins and other effectors to modulate virulence. The complex interplay between effectors raises the concept of metaeffectors, where some effectors regulate the activity of others. While previous research has demonstrated the importance of effector repertoires in pathogen virulence, only a limited number of studies have investigated the interactions between these effectors. This study explores the interactions among Phakopsora pachyrhizi effector candidates (PpECs). P. pachyrhizi haustorial transcriptome analysis identified a collection of predicted PpECs. Among these, PpEC23 was found to interact with PpEC48, prompting further exploration into their potential interaction with other effectors. Here, we utilized a yeast-two-hybrid screen to explore protein-protein interactions between PpECs. A split-luciferase complementation assay also demonstrated that these interactions could occur within soybean cells. Interestingly, PpEC48 displayed the ability to interact with several small cysteine-rich proteins (SCRP), suggesting its affinity for this specific class of effectors. We show that these interactions involve a histidine-rich domain within PpEC48, emphasizing the significance of structural motifs in mediating effector interactions. The unique nature of PpEC48, showing no sequence matches in other organisms, suggests its relatively recent evolution and potential orphan gene status. Our work reveals insights into the intricate network of interactions among P. pachyrhizi effector-effector interactions.",
        "creator": "Qi, M., Yu, H., Bredow, M., Chicowski, A. S., Fields, L. D., Whitham, S. A."
      },
      {
        "title": "Colour-analyzer: A new dual colour model-based imaging tool to quantify plant disease",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.30.555631v1?rss=1",
        "abstract": "Despite major efforts over the last decades, the rising demands of the growing global population makes it of paramount importance to increase crop yields and reduce losses caused by plant pathogens. One way to tackle this is to screen novel resistant genotypes and immunity-inducing agents, which must be conducted in a high-throughput manner. Colour-analyzer is a free web-based tool that can be used to rapidly measure the formation of lesions on leaves. Pixel colour values are often used to distinguish infected from healthy tissues. Some programs employ colour models, such as RGB, HSV or L*a*b*. Colour-analyzer uses two colour models, utilizing both HSV (Hue, Saturation, Value) and L*a*b* values. We found that the a* b* values of the L*a*b* colour model provided the clearest distinction between infected and healthy tissue, while the H and S channels were best to distinguish the leaf area from the background. By combining the a* and b* channels to determine the lesion area, while using the H and S channels to determine the leaf area, Colour-analyzer provides highly accurate information on the size of the lesion as well as the percentage of infected tissue in a high throughput manner and can accelerate the plant immunity research field.",
        "creator": "Loranger, M. E. W., Yim, W., Accomazzi, V., Morales Liszcano, N., Moeder, W., Yoshioka, K."
      },
      {
        "title": "Comparative omics reveals unanticipated metabolic rearrangements in a high-oil mutant of plastid acetyl-CoA carboxylase",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.31.555777v1?rss=1",
        "abstract": "Heteromeric acetyl-CoA carboxylase (ACCase) catalyzes the ATP-dependent carboxylation of acetyl-CoA to produce malonyl-CoA, the committed step for de novo fatty acid synthesis. In plants, ACCase activity is controlled at multiple levels, including negative regulation by biotin attachment domain-containing (BADC) proteins, of which the badc1/3 double mutant leads to increased seed triacylglycerol accumulation. Unexpectedly, the Arabidopsis badc1/3 mutant also accumulates more protein. The metabolic consequences from both higher oil and protein was investigated in developing badc1/3 seed using global transcriptomics, translatomics, proteomics, and metabolomics. Changes include: reduced plastid pyruvate dehydrogenase; increased acetyl-CoA synthetase; increased storage and lipid-droplet packaging proteins; increased lipases; and increased {beta}-oxidation fatty acid catabolism. We present a model of how Arabidopsis adapted to deregulated ACCase, limiting total oil accumulation, and altering flux through pathways of carbon accumulation that presents possible targets for future bioengineering of valuable seed storage reserves.",
        "creator": "Kataya, A., da Silva Nascimento, J. R., Xu, C., Garneau, M. G., Koley, S., Kimberlin, A. N., Mooney, B. P., Allen, D. K., Bates, P. D., Koo, A. J., Xu, D., Thelen, J. J."
      },
      {
        "title": "Altered iron-sulfur cluster transfer in Arabidopsis mitochondria reveals lipoyl synthase as a Janus-faced enzyme that generates toxic sulfide",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.30.555573v1?rss=1",
        "abstract": "Iron-sulfur (Fe-S) cluster are vital cofactors in all domains of life. Mitochondrial Fe-S cluster assembly occurs in two major steps to first build [2Fe-2S] clusters and subsequently assemble these into [4Fe-4S] clusters. The two assembly machineries are interconnected by glutaredoxin S15 (GRXS15) that transfers [2Fe-2S] clusters to the second machinery. Diminished cluster transfer activity of GRXS15 in Arabidopsis mitochondria causes specific defects associated with lipoyl synthase (LIP1) activity. Conversely, overexpression of LIP1 in wild-type plants causes the release of toxic amounts of sulfide that can be detoxified by increasing the capacity for sulfide fixation through overexpression of O-acetylserine-(thiol)-lyase. The release of sulfide by lipoyl synthase causes a disturbance of mitochondrial sulfide homeostasis resulting in distinct and readily observable macroscopic phenotypes. These phenotypes enable a direct readout of consequences resulting from defects in Fe-S cluster assembly or targeted modulation of Fe-S cluster flux in mitochondria.",
        "creator": "Pedroletti, L., Moseler, A., Timm, S., Poschet, G., Homagk, M., The, J. X., Wagner, S., Wirtz, M., Hell, R., Meyer, A. J."
      },
      {
        "title": "Upstream regulator of genomic imprinting in rice endosperm is a small RNA-associated chromatin remodeler",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.31.555833v1?rss=1",
        "abstract": "Genomic imprinting is observed in endosperm, a placenta-like seed tissue, where transposable elements (TEs) and repeat-derived small(s)RNAs mediate epigenetic changes in plants. In imprinting, uniparental gene expression arises due to parent-specific epigenetic marks on one allele but not on the other. The importance of sRNAs and their regulation in endosperm development or in imprinting is poorly understood in crops. Here we show that a previously uncharacterized CLASSY (CLSY)-family chromatin remodeler named OsCLSY3 is essential for rice endosperm development and imprinting, acting as an upstream player in sRNA pathway. Comparative transcriptome and genetic analysis indicated its endosperm-preferred expression and its paternally imprinted nature. These important features were modulated by RNA-directed DNA methylation (RdDM) of tandemly arranged TEs in its promoter. Upon perturbation of OsCLSY3 in transgenic lines we observed defects in endosperm development and loss of around 70% of all sRNAs. Interestingly, well-conserved endosperm-specific sRNAs (siren) that are vital for reproductive fitness in angiosperms were dependent on OsCLSY3. We also observed many imprinted genes and seed development-associated genes under the control of CLSY3-dependent RdDM. These results support an essential role of OsCLSY3 in rice endosperm development and imprinting, and propose similar regulatory strategies involving CLSY3 homologs among other cereals.  HighlightsO_LIUnlike among dicots, in rice and maize, CLSY3 is a maternally expressed imprinted gene majorly expressed in endosperm. C_LIO_LIEndosperm-preferred expression of OsCLSY3 is regulated by RNA-directed DNA methylation at two tandem transposon elements present in its promoter. C_LIO_LIOsCLSY3 is crucial for endosperm development and grain filling. It regulates expression of key seed development and endosperm-specific imprinted genes through RNA directed DNA methylation. C_LI",
        "creator": "Pal, A., Sundar, V. H., Nambiar, A., Shivaprasad, P. V."
      },
      {
        "title": "Machine learning general transcriptional predictors of plant disease",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.30.555529v1?rss=1",
        "abstract": "Plants utilize an innate immune system to defend against all classes of microbial invaders. While we understand specific genetic determinants of host-pathogen interactions, it remains less clear how generalized the immune response is to diverse pathogens. Using a data-driven approach, and utilizing feature selection based on network science and topology, we developed machine learning models that could predict host disease development across diverse pathosystems. These machine learning models identified early transcriptional responses predictive of later disease development, regardless of pathogen class, using a fraction of the host transcriptome. The identified gene sets were not enriched for canonical defense genes, but where statistically enriched for genes previously identified from independent data sets, including those described as representing a general plant stress response. These results highlight novel components of a general plant immune response, and demonstrate the application of machine learning to address biological hypotheses of a complex multigenic outcome.  TeaserA machine learning approach can predict plant disease development caused by diverse microbial invaders, and newly identified genes may represent novel components of a general plant response to infection.",
        "creator": "Sia, J., Zhang, W., Cheng, M., Bogdan, P., Cook, D. E."
      },
      {
        "title": "Heterochromatin re-organization associated with the transcriptional reprogramming under viral infection in Arabidopsis",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.30.555647v1?rss=1",
        "abstract": "Epigenetic mechanisms are key regulators of genomic integrity and genic expression. Emerging evidence shows that epigenetic regulation is an important component of the transcriptional reprogramming during stress. Despite this, the overall stress-induced reprogramming of the different epigenetic marks and their targets are unknown. Here, we uncovered multiple epigenetic changes taking place during viral infection in Arabidopsis thaliana and their connection with gene expression. We find that cucumber mosaic virus (CMV) infection induces an overall reorganization of the repressive epigenetic marks H3K9me2, H3K27me3, and DNA methylation, which interact between them and are dynamic during infection. Overall, these epigenetic changes are involved in the reprogramming of the transcriptional program to adapt to the biotic stress, and might ensure genome stability through the transcriptional control of transposable elements (TEs). Mechanistically, we demonstrate that the catalytic component of the Polycomb Repressive Complex 2 (PRC2) CURLY LEAF (CLF) mediates the transcriptional repression of genes gaining H3K27me3 during viral infection and that mutants on that component induce resistance against CMV. Altogether, our results provide a complete picture of the epigenetic changes that occur during biotic stress and exemplify the overall dynamism of epigenetic regulation in eukaryotic organisms.",
        "creator": "Annacondia, M. L., Juarez-Gonzalez, V. T., Cheng, J., Reig-Valiente, J. L., Martinez, G."
      },
      {
        "title": "Genome assembly of the bearded iris Iris pallida Lam.",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.29.555454v1?rss=1",
        "abstract": "Irises are perennial plants, representing a large genus with hundreds of species. While cultivated extensively for their ornamental value, commercial interest in irises lies in the secondary metabolites present in their rhizomes. The Dalmatian Iris (Iris pallida Lam.) is an ornamental plant that also produces secondary metabolites with potential value to the fragrance and pharmaceutical industries. In addition to providing base notes for the fragrance industry, iris tissues and extracts possess anti-oxidant, anti- inflammatory, and immunomodulatory effects. However, study of these secondary metabolites has been hampered by a lack of genomic information, instead requiring difficult extraction and analysis techniques. Here, we report the genome sequence of Iris pallida Lam., generated with Pacific Bioscience long-read sequencing, resulting in a 10.04 Gbp assembly with a scaffold N50 of 14.34 Mbp and 91.8% complete BUSCOs. This reference genome will allow researchers to study the biosynthesis of these secondary metabolites in much greater detail, opening new avenues of investigation for drug discovery and fragrance formulations.  Research area: Genetics and Genomics; Botany; Plant Genetics",
        "creator": "Bruccoleri, R. E., Oakeley, E. J., Faust, A. M. E., Altorfer, M., Dessus-Babus, S., Burckhardt, D., Oertli, M., Naumann, U., Petersen, F., Wong, J."
      },
      {
        "title": "Comparative GWAS identifies a role for Mendel green pea gene in the nonphotochemical quenching kinetics of sorghum, maize, and arabidopsis",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.29.555201v1?rss=1",
        "abstract": "Photosynthetic organisms must cope with rapid fluctuations in light intensity. Nonphotochemical quenching (NPQ) enables the dissipation of excess light energy as heat under high light conditions, whereas its relaxation under low light maximizes photosynthetic productivity. We quantified variation in NPQ kinetics across a large sorghum (Sorghum bicolor) association panel in four environments, uncovering significant genetic control for NPQ. A genome-wide association study (GWAS) identified 20 unique regions in the sorghum genome associated with NPQ. We detected strong signals from the sorghum ortholog of Arabidopsis thaliana SUPPRESSOR OF VARIEGATION3 (SVR3) involved in plastid-nucleus signaling and tolerance to cold. By integrating GWAS results for NPQ across maize (Zea mays) and sorghum association panels, we identified a second gene, NON-YELLOWING 1 (NYE1), originally identified by Gregor Mendel in pea (Pisum sativum) and involved in the degradation of photosynthetic pigments in light-harvesting complexes, along with OUTER ENVELOPE PROTEIN 37 (OEP37), that encodes a transporter in chloroplast envelope. Analysis of nye1 insertion alleles in A. thaliana confirmed the effect of this gene on NPQ kinetics across monocots and eudicots. We extended our comparative genomics GWAS framework across the entire maize and sorghum genomes, identifying four additional loci involved in NPQ kinetics. These results provide a baseline for engineering crops with improved NPQ kinetics and increasing the accuracy and speed of candidate gene identification for GWAS in species with high linkage disequilibrium.",
        "creator": "Sahay, S., Shrestha, N., Dias, H. M., Mural, R. V., Grzybowski, M., Schnable, J. C., Glowacka, K."
      },
      {
        "title": "Allelic promoter variation causes a switch in reproductive tissue expression in an Arabidopsis exonuclease gene",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.29.555143v1?rss=1",
        "abstract": "Among candidate genes underlying the control components of apomixis, APOLLO is known for its strong linkage to apomeiosis in the genus Boechera. The gene has (Apo-alleles), which are characterized by a set of linked apomixis-specific polymorphisms, and (Sex-alleles). All apomictic Boechera genotypes being heterozygous for the Apo/Sex-alleles, while all sexual genotypes are homozygous for Sex-alleles. In this study native and synthetic APOLLO promoters were made and their functions were characterized by detecting the expression level of the {beta}-glucuronidase (GUS) gene in Arabidopsis and an apomictic Boechera. The data show that there are differences in GUS activity between Apo-vs. Sex-alleles, though no GUS activity was observed in pre-meiotic ovules of Apo-allele transformants. This may mean that the 1 kb and 2 kb regions do not carry all needed regulatory elements and hence a longer promoter region can be tested for future study. Comparing various flower developmental stages in transgenic lines containing the different constructs with the 2 kb native transgenic lines revealed that changes to the APOLLO promoter causes shifts in tissue- and developmental-stage specificity. In conclusion, the 20 bp apomixis-specific polymorphism along with other sequences of the 5UTR gives rise to ovule-specific GUS activity only when adjacent to 2 kb of the Sex-allele.",
        "creator": "Honari, M., Ernest, J., Sharbel, T."
      },
      {
        "title": "Lignin, glutathione and kinases play important roles in  Paspalum regnellii  defense against spittlebug (Mahanarva spectabilis) attack",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.29.555367v1?rss=1",
        "abstract": "O_LISpittlebugs cause large production losses that affect agribusiness worldwide. Understanding plant-herbivore interactions at molecular level may be the key to developing resistant cultivars. C_LIO_LIWe assembled a de novo transcriptome for elucidate the roots response from two Paspalum regnellii genotypes (BGP 248 and 344) to spittlebug (Mahanarva spectabilis) nymph attack, integrating differential expression analysis and complex network modeling, supplemented by a resistance field experiment and root anatomical analysis. C_LIO_LIGO terms related to different stress responses were enriched in BGP 248, such as salicylic acid catabolic process, while some specific to spittlebugs like response to herbivores were enriched in BP 344. KEGG enriched pathways were related to structural differences between genotypes, for example, cutin, suberin and wax biosynthesis. BP 344 also presented pathways related to induced defense, such as glutathione metabolism. Metabolic networks highlighted kinases, and coexpression networks demonstrated a greater complexity in their response cascade, which includes lncRNAs. C_LIO_LIThis study provides the first molecular insights into the defense mechanisms of P. regnellii against M. spectabilis. It was identified that the genotype with the highest nymph mortality (BGP 344) has constitutive barriers, such as lignin, which delay the attack. In addition to presenting a glutathione pathway enriched and greater presence of kinases. C_LI",
        "creator": "Begnami, I. S., Aono, A. H., Graciano, D. S., Carmello-Guerreiro, S. M., Ferreira, R. C. U., Malago, W., Gusmao, M. R., Souza, A. P., Vigna, B. B. Z."
      },
      {
        "title": "Enhanced metabolic detoxification is associated with fluroxypyr resistance in Bassia scoparia",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.29.554743v1?rss=1",
        "abstract": "Auxin-mimic herbicides chemically mimic the phytohormone indole-3-acetic-acid (IAA). Within the auxin-mimic herbicide class, the herbicide fluroxypyr has been extensively used to control an agronomically problematic Great Plains tumbleweed, kochia (Bassia scoparia). A 2014 field survey for herbicide resistance in kochia populations across Colorado identified a putative fluroxypyr resistant population that was assessed for response to five different herbicides representing four different herbicide modes of action. These included fluroxypyr and dicamba (auxin-mimics), atrazine (photosystem II inhibitor), glyphosate (EPSPS inhibitor), and chlorsulfuron (acetolactate synthase inhibitor). The greenhouse screen identified that this kochia population was resistant to fluroxypyr and chlorsulfuron, but sensitive to glyphosate, atrazine, and dicamba. This population was designated Flur-R. Subsequent dose response studies determined that 75% of the Flur-R population survived 628 g ae ha-1 of fluroxypyr (4x the label application rate in wheat fallow, which is 157 g ae ha-1 at 1x). Flur-R was 40 times more resistant to fluroxypyr than a susceptible population (J01-S) collected from the same field survey (LD50 720 and 20 g ae ha-1, respectively). Auxin-responsive gene expression increased following fluroxypyr treatment in Flur-R, J01-S, and in a dicamba-resistant, fluroxypyr-susceptible line 9425 in an RNA-sequencing experiment. In Flur-R, several transcripts with molecular functions for conjugation and transport were constitutively higher expressed, such as glutathione S-transferases (GSTs), UDP-glucosyl transferase (GT), and ATP binding cassette transporters (ABC transporters). After analyzing metabolic profiles over time, both Flur-R and J01-S rapidly converted [14C]-fluroxypyr ester, the herbicide formulation applied to plants, to [14C]-fluroxypyr acid, the biologically active form of the herbicide, and three unknown metabolites. Formation and flux of these metabolites was faster in Flur-R than J01-S, reducing the concentration of phytotoxic fluroxypyr acid. One unique metabolite was present in Flur-R that was not present in the J01-S metabolic profile. Gene sequence variant analysis specifically for auxin receptor and signaling proteins revealed the absence of non-synonymous mutations affecting auxin signaling and binding in candidate auxin target site genes, further supporting our hypothesis that non-target site metabolic degradation is contributing to fluroxypyr resistance in Flur-R.",
        "creator": "Todd, O. E., Patterson, E., Westra, E. P., Simoes Araujo, A. L., Kramer, W. B., Dayan, F. E., Gaines, T. A."
      },
      {
        "title": "RdDM mutants reduce histone methylation rather than DNA methylation at the paramutated maize b1 enhancer",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.29.555344v1?rss=1",
        "abstract": "Paramutation is the transfer of mitotically and meiotically heritable silencing information between two alleles. With paramutation at the maize booster1 (b1) locus, the low expressed B epiallele heritably changes the high expressed B-I epiallele into B with 100% frequency. This requires specific tandem repeats and multiple components of the RNA-directed DNA methylation (RdDM) pathway, including the RNA-dependent RNA polymerase (RdRP, mediator of paramutation1, MOP1), the second-largest subunit of RNA polymerase IV and V (NRP(D/E)2a, mediator of paramutation2, MOP2), and the largest subunit of RNA Polymerase IV (NRPD1, mediator of paramutation3, MOP3). Mutations in mop genes prevent paramutation and release silencing at the B epiallele. In this study we investigated the effect of mutations in mop1, mop2 and mop3 on chromatin structure and DNA methylation at the B epiallele, and especially the regulatory hepta-repeat 100 kb upstream of the b1 gene.  We show that mutations in mop1 and mop3 result in decreased repressive histone modifications H3K9me2 and H3K27me2 at the hepta-repeat. Associated with this decrease are partial activation of the hepta-repeat enhancer function, formation of a multi-loop structure, and elevated b1 expression. In mop2 mutants, which do not show elevated b1 expression, H3K9me2 and H3K27me2 and a single-loop structure like in wild type B are retained. Surprisingly, high DNA methylation levels at the B hepta-repeat remains in all three mutants. Our results raise the possibility of MOP factors mediating RNA-directed histone methylation rather than RNA-directed DNA methylation at the b1 locus.",
        "creator": "Hovel, I., Bader, R., Louwers, M., Haring, M., Peek, K., Gent, J. I., Stam, M."
      },
      {
        "title": "Small RNA Analysis of Virus-virus Interaction between Two Orthotospoviruses",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.28.555202v1?rss=1",
        "abstract": "Mixed infections of plant viruses are commonly found in natural patho-systems and pre-sent a valuable opportunity to understand how multiple viruses can co-infect the same host. Tomato spotted wilt orthotospovirus (TSWV) and impatiens necrotic spot orthotospovirus (INSV) are pre-sent in the same geographic areas and are closely related. More mixed infections of TSWV and INSV have been reported in recent years, and the INSV host range has been reported to be increasing. In a previous study, we have isolated one strain of INSV and one of TSWV and showed that they have an antagonistic relationship in their vectors, but we were unable to determine, the underlying mech-anisms governing their antagonism in planta and the contribution of the host to this. Here, we used small RNA sequencing to study TSWV-INSV antagonistic interaction and showed that INSV alters plant responses and the processing of TSWV.",
        "creator": "Zhao, K., Islam, M. T., Johnson, N., Axtell, M. J., Rosa, C."
      },
      {
        "title": "Fungal hacking of the plant sex-determination pathway via interference with AGL24 in Silene latifolia",
        "link": "http://biorxiv.org/cgi/content/short/2023.08.28.555088v1?rss=1",
        "abstract": "Plants have evolved lineage-specific sex-determination systems that is determined not only by genetic factors, but also the surrounding environmental conditions, including interactions with pathogens. Silene latifolia is a model dioecious plant whose sexuality is genetically regulated by X/Y chromosomes; however, anther smut fungus mimics the plant Y chromosome and forcibly converts female plants to male. Here, transcriptome analyses of healthy or fungus-infected S. latifolia inflorescence meristems suggested that an orthologue of AGL24 (SlAGL24), a flowering activator, is a key factor in sex conversion via fungus infection. Overexpression of SlAGL24 in Arabidopsis thaliana suppressed stamen development, whereas knock-down of SlAGL24 in S. latifolia converted males into hermaphrodites. Furthermore, SlAGL24 expression affected sexual dimorphisms in S. latifolia. Our results propose an adaptive scenario wherein the anther smut fungus targets SlAGL24, as a master regulator connecting the fungal signal to sex determination, to confer male and potentially male-beneficial traits, effectively transmitting its teliospores.",
        "creator": "Fujita, N., Hood, M. E., Komoda, Y., Akagi, T."
      }
    ]
  },
  {
    "name": "Economics",
    "feed": [
      {
        "title": "Theoretical foundation for the Pareto distribution of international trade strength and introduction of an equation for international trade forecasting.",
        "link": "http://arxiv.org/abs/2309.00635",
        "abstract": "I propose a new terminology, international trade strength, which is defined as the ratio of a country's total international trade to its GDP. This parameter represents a country's ability to generate international trade by utilizing its GDP. This figure is equivalent to GDP per capita, which represents a country's ability to use its population to generate GDP. Trade strength varies by country. The intriguing question is, what distribution function does the trade strength fulfill? In this paper, a theoretical foundation for predicting the distribution of trade strength and the rate of change of trade strength were developed. These two quantities were found to satisfy the Pareto distribution function. The equations were confirmed using data from the World Integrated Trade Solution (WITS) and the World Bank by comparing the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) to five types of distribution functions (exponential, lognormal, gamma, Pareto, and Weibull). I also discovered that the fitting Pareto power parameter is fairly close to the theoretical parameter. In addition, a formula for forecasting a country's total international trade in the following years was also developed.",
        "creator": "Mikrajuddin Abdullah"
      },
      {
        "title": "GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice.",
        "link": "http://arxiv.org/abs/2309.00649",
        "abstract": "We assess the ability of GPT -- a large language model -- to serve as a financial robo-advisor for the masses, by using a financial literacy test. Davinci and ChatGPT based on GPT-3.5 score 66% and 65% on the financial literacy test, respectively, compared to a baseline of 33%. However, ChatGPT based on GPT-4 achieves a near-perfect 99% score, pointing to financial literacy becoming an emergent ability of state-of-the-art models. We use the Judge-Advisor System and a savings dilemma to illustrate how researchers might assess advice-utilization from large language models. We also present a number of directions for future research.",
        "creator": "Pawe&#x142; Niszczota, Sami Abbas"
      },
      {
        "title": "Fairness Implications of Heterogeneous Treatment Effect Estimation with Machine Learning Methods in Policy-making.",
        "link": "http://arxiv.org/abs/2309.00805",
        "abstract": "Causal machine learning methods which flexibly generate heterogeneous treatment effect estimates could be very useful tools for governments trying to make and implement policy. However, as the critical artificial intelligence literature has shown, governments must be very careful of unintended consequences when using machine learning models. One way to try and protect against unintended bad outcomes is with AI Fairness methods which seek to create machine learning models where sensitive variables like race or gender do not influence outcomes. In this paper we argue that standard AI Fairness approaches developed for predictive machine learning are not suitable for all causal machine learning applications because causal machine learning generally (at least so far) uses modelling to inform a human who is the ultimate decision-maker while AI Fairness approaches assume a model that is making decisions directly. We define these scenarios as indirect and direct decision-making respectively and suggest that policy-making is best seen as a joint decision where the causal machine learning model usually only has indirect power. We lay out a definition of fairness for this scenario - a model that provides the information a decision-maker needs to accurately make a value judgement about just policy outcomes - and argue that the complexity of causal machine learning models can make this difficult to achieve. The solution here is not traditional AI Fairness adjustments, but careful modelling and awareness of some of the decision-making biases that these methods might encourage which we describe.",
        "creator": "Patrick Rehill, Nicholas Biddle"
      },
      {
        "title": "There is power in general equilibrium.",
        "link": "http://arxiv.org/abs/2309.00909",
        "abstract": "The article develops a general equilibrium model where power relations are central in the determination of unemployment, profitability, and income distribution. The paper contributes to the market forces versus institutions debate by providing a unified model capable of identifying key interrelations between technical and institutional changes in the economy. Empirically, the model is used to gauge the relative roles of technology and institutions in the behavior of the labor share, the unemployment rate, the capital-output ratio, and business profitability and demonstrates how they complement each other in providing an adequate narrative to the structural changes of the US economy.",
        "creator": "Juan Jacobo"
      },
      {
        "title": "iCOS: Option-Implied COS Method.",
        "link": "http://arxiv.org/abs/2309.00943",
        "abstract": "This paper proposes the option-implied Fourier-cosine method, iCOS, for non-parametric estimation of risk-neutral densities, option prices, and option sensitivities. The iCOS method leverages the Fourier-based COS technique, proposed by Fang and Oosterlee (2008), by utilizing the option-implied cosine series coefficients. Notably, this procedure does not rely on any model assumptions about the underlying asset price dynamics, it is fully non-parametric, and it does not involve any numerical optimization. These features make it rather general and computationally appealing. Furthermore, we derive the asymptotic properties of the proposed non-parametric estimators and study their finite-sample behavior in Monte Carlo simulations. Our empirical analysis using S&amp;P 500 index options and Amazon equity options illustrates the effectiveness of the iCOS method in extracting valuable information from option prices under different market conditions.",
        "creator": "Evgenii Vladimirov"
      },
      {
        "title": "Constructing a type-adjustable mechanism to yield Pareto-optimal outcomes.",
        "link": "http://arxiv.org/abs/2309.01096",
        "abstract": "In mechanism design theory, agents' types are described as their private information, and the designer may reveal some public information to affect agents' types in order to obtain more payoffs. Traditionally, both each agent's private type and the public information are represented as a random variable respectively. In this paper, we propose a type-adjustable mechanism where each agent's private type is represented as a function of two parameters, \\emph{i.e.}, his intrinsic factor and an external control factor. Each agent's intrinsic factor is modeled as a private random variable, and the external control factor is modeled as a solution of the designer's optimization problem. The advantage of the type-adjustable mechanism is that by choosing an optimal value of control factor as public information, the designer may obtain Pareto-optimal outcomes, beneficial not only to herself but also to all agents. As a comparison, in an auction with interdependent values where the public information is represented as a random variable, only the seller will benefit from public information. In the end, we compare the type-adjustable mechanism with other relevant models.",
        "creator": "Haoyang Wu"
      },
      {
        "title": "Logistic modelling of economic dynamics.",
        "link": "http://arxiv.org/abs/2309.01139",
        "abstract": "We demonstrate the effectiveness of the logistic function to model the evolution of two economic systems. The first is the GDP and trade growth of the USA, and the second is the revenue and human resource growth of IBM. Our modelling is based on the World Bank data in the case of the USA, and on the company data in the case of IBM. The coupled dynamics of the two relevant variables in both systems - GDP and trade for the USA, and revenue and human resource for IBM - follows a power-law behaviour.",
        "creator": "Arnab K. Ray"
      },
      {
        "title": "Nash's bargaining problem and the scale-invariant Hirsch citation index.",
        "link": "http://arxiv.org/abs/2309.01192",
        "abstract": "A number of citation indices have been proposed for measuring and ranking the research publication records of scholars. Some of the best known indices, such as those proposed by Hirsch and Woeginger, are designed to reward most highly those records that strike some balance between productivity (number of papers published), and impact (frequency with which those papers are cited). A large number of rarely cited publications will not score well, nor will a very small number of heavily cited papers. We discuss three new citation indices, one of which was independently proposed in \\cite{FHLB}. Each rests on the notion of scale invariance, fundamental to John Nash's solution of the two-person bargaining problem. Our main focus is on one of these -- a scale invariant version of the Hirsch index. We argue that it has advantages over the original; it produces fairer rankings within subdisciplines, is more decisive (discriminates more finely, yielding fewer ties) and more dynamic (growing over time via more frequent, smaller increments), and exhibits enhanced centrality and tail balancedness. Simulations suggest that scale invariance improves robustness under Poisson noise, with increased decisiveness having no cost in terms of the number of ``accidental\" reversals, wherein random irregularities cause researcher A to receive a lower index value than B, although A's productivity and impact are both slightly higher than B's. Moreover, we provide an axiomatic characterization of the scale invariant Hirsch index, via axioms that bear a close relationship, in discrete analogue, to those used by Nash in \\cite{Nas50}. This argues for the mathematical naturality of the new index.  An earlier version was presented at the 5th World Congress of the Game Theory Society, Maastricht, Netherlands in 2016.",
        "creator": "Josep Freixas, Roger Hoerl, William S. Zwicker"
      },
      {
        "title": "A Trimming Estimator for the Latent-Diffusion-Observed-Adoption Model.",
        "link": "http://arxiv.org/abs/2309.01471",
        "abstract": "Network diffusion models are applicable to many socioeconomic interactions, yet network interaction is hard to observe or measure. Whenever the diffusion process is unobserved, the number of possible realizations of the latent matrix that captures agents' diffusion statuses grows exponentially with the size of network. Due to interdependencies, the log likelihood function can not be factorized in individual components. As a consequence, exact estimation of latent diffusion models with more than one round of interaction is computationally infeasible. In the present paper, I propose a trimming estimator that enables me to establish and maximize an approximate log likelihood function that almost exactly identifies the peak of the true log likelihood function whenever no more than one third of eligible agents are subject to trimming.",
        "creator": "L.S. Sanna Stephan"
      },
      {
        "title": "Moment-Based Estimation of Diffusion and Adoption Parameters in Networks.",
        "link": "http://arxiv.org/abs/2309.01489",
        "abstract": "According to standard econometric theory, Maximum Likelihood estimation (MLE) is the efficient estimation choice, however, it is not always a feasible one. In network diffusion models with unobserved signal propagation, MLE requires integrating out a large number of latent variables, which quickly becomes computationally infeasible even for moderate network sizes and time horizons. Limiting the model time horizon on the other hand entails loss of important information while approximation techniques entail a (small) error that. Searching for a viable alternative is thus potentially highly beneficial. This paper proposes two estimators specifically tailored to the network diffusion model of partially observed adoption and unobserved network diffusion.",
        "creator": "L.S. Sanna Stephan"
      },
      {
        "title": "Do Losses Matter? The Effect of Information-Search Technologies on Risky Choices.",
        "link": "http://arxiv.org/abs/2309.01495",
        "abstract": "Despite its importance, relatively little attention has been devoted to studying the effects of exposing individuals to digital choice interfaces. In two pre-registered lottery-choice experiments, we administer three information-search technologies that are based on well-known heuristics: in the ABS (alternative-based search) treatment, subjects explore outcomes and corresponding probabilities within lotteries; in the CBS (characteristic-based search) treatment, subjects explore outcomes and corresponding probabilities across lotteries; in the Baseline treatment, subjects view outcomes and corresponding probabilities all at once. We find that (i) when lottery outcomes comprise gains and losses (experiment 1), exposing subjects to the CBS technology systematically makes them choose safer lotteries, compared to the subjects that are exposed to the other technologies, and (ii) when lottery outcomes comprise gains only (experiment 2), the above results are reversed: exposing subjects to the CBS technology systematically makes them choose riskier lotteries. By combining the information-search and choice analysis, we offer an interpretation of our results that is based on prospect theory, whereby the information-search technology subjects are exposed to contributes to determine the level of attention that the lottery attributes receive, which in turn has an effect on the reference point.",
        "creator": "Luigi Mittone, Mauro Papi"
      },
      {
        "title": "The Robust F-Statistic as a Test for Weak Instruments.",
        "link": "http://arxiv.org/abs/2309.01637",
        "abstract": "Montiel Olea and Pflueger (2013) proposed the effective F-statistic as a test for weak instruments in terms of the Nagar bias of the two-stage least squares (2SLS) estimator relative to a benchmark worst-case bias. We show that their methodology applies to a class of linear generalized method of moments (GMM) estimators with an associated class of generalized effective F-statistics. The standard nonhomoskedasticity robust F-statistic is a member of this class. The associated GMMf estimator, with the extension f for first-stage, is a novel and unusual estimator as the weight matrix is based on the first-stage residuals. As the robust F-statistic can also be used as a test for underidentification, expressions for the calculation of the weak-instruments critical values in terms of the Nagar bias of the GMMf estimator relative to the benchmark simplify and no simulation methods or Patnaik (1949) distributional approximations are needed. In the grouped-data IV designs of Andrews (2018), where the robust F-statistic is large but the effective F-statistic is small, the GMMf estimator is shown to behave much better in terms of bias than the 2SLS estimator, as expected by the weak-instruments test results.",
        "creator": "Frank Windmeijer"
      },
      {
        "title": "Design-Based Multi-Way Clustering.",
        "link": "http://arxiv.org/abs/2309.01658",
        "abstract": "This paper extends the design-based framework to settings with multi-way cluster dependence, and shows how multi-way clustering can be justified when clustered assignment and clustered sampling occurs on different dimensions, or when either sampling or assignment is multi-way clustered. Unlike one-way clustering, the plug-in variance estimator in multi-way clustering is no longer conservative, so valid inference either requires an assumption on the correlation of treatment effects or a more conservative variance estimator. Simulations suggest that the plug-in variance estimator is usually robust, and the conservative variance estimator is often too conservative.",
        "creator": "Luther Yap"
      },
      {
        "title": "Generalized Information Criteria for Structured Sparse Models.",
        "link": "http://arxiv.org/abs/2309.01764",
        "abstract": "Regularized m-estimators are widely used due to their ability of recovering a low-dimensional model in high-dimensional scenarios. Some recent efforts on this subject focused on creating a unified framework for establishing oracle bounds, and deriving conditions for support recovery. Under this same framework, we propose a new Generalized Information Criteria (GIC) that takes into consideration the sparsity pattern one wishes to recover. We obtain non-asymptotic model selection bounds and sufficient conditions for model selection consistency of the GIC. Furthermore, we show that the GIC can also be used for selecting the regularization parameter within a regularized $m$-estimation framework, which allows practical use of the GIC for model selection in high-dimensional scenarios. We provide examples of group LASSO in the context of generalized linear regression and low rank matrix regression.",
        "creator": "Eduardo F. Mendes, Gabriel J. P. Pinto"
      },
      {
        "title": "Non-transitivity of the Win Ratio and Area Under the Receiver Operating Characteristics Curve (AUC): a case for evaluating the strength of stochastic comparisons.",
        "link": "http://arxiv.org/abs/2309.01791",
        "abstract": "The win ratio (WR) is a novel statistic used in randomized controlled trials that can account for hierarchies within event outcomes. In this paper we report and study the long-run non-transitive behavior of the win ratio and the closely related Area Under the Receiver Operating Characteristics Curve (AUC) and argue that their transitivity cannot be taken for granted. Crucially, traditional within-group statistics (i.e., comparison of means) are always transitive, while the WR can detect non-transitivity. Non-transitivity provides valuable information on the stochastic relationship between two treatment groups, which should be tested and reported. We specify the necessary conditions for transitivity, the sufficient conditions for non-transitivity and demonstrate non-transitivity in a real-life large randomized controlled trial for the WR of time-to-death. Our results can be used to rule out or evaluate possibility of non-transitivity and show the importance of studying the strength of stochastic relationships.",
        "creator": "Olga V. Demler, Ilona A. Demler"
      },
      {
        "title": "The Local Projection Residual Bootstrap for AR(1) Models.",
        "link": "http://arxiv.org/abs/2309.01889",
        "abstract": "This paper contributes to a growing literature on confidence interval construction for impulse response coefficients based on the local projection (LP) approach. We propose an LP-residual bootstrap method to construct confidence intervals for the impulse response coefficients of AR(1) models. The method uses the LP approach and a residual bootstrap procedure to compute critical values. We present two theoretical results. First, we prove the uniform consistency of the LP-residual bootstrap under general conditions, which implies that the proposed confidence intervals are uniformly asymptotically valid. Second, we show that the LP-residual bootstrap can provide asymptotic refinements to the confidence intervals under certain conditions. We illustrate our results with a simulation study.",
        "creator": "Amilcar Velez"
      },
      {
        "title": "DeepVol: A Deep Transfer Learning Approach for Universal Asset Volatility Modeling.",
        "link": "http://arxiv.org/abs/2309.02072",
        "abstract": "This paper introduces DeepVol, a promising new deep learning volatility model that outperforms traditional econometric models in terms of model generality. DeepVol leverages the power of transfer learning to effectively capture and model the volatility dynamics of all financial assets, including previously unseen ones, using a single universal model. This contrasts to the prevailing practice in econometrics literature, which necessitates training separate models for individual datasets. The introduction of DeepVol opens up new avenues for volatility modeling and forecasting in the finance industry, potentially transforming the way volatility is understood and predicted.",
        "creator": "Chen Liu, Minh-Ngoc Tran, Chao Wang, Richard Gerlach, Robert Kohn"
      },
      {
        "title": "On the use of U-statistics for linear dyadic interaction models.",
        "link": "http://arxiv.org/abs/2309.02089",
        "abstract": "Even though dyadic regressions are widely used in empirical applications, the (asymptotic) properties of estimation methods only began to be studied recently in the literature. This paper aims to provide in a step-by-step manner how U-statistics tools can be applied to obtain the asymptotic properties of pairwise differences estimators for a two-way fixed effects model of dyadic interactions. More specifically, we first propose an estimator for the model that relies on pairwise differencing such that the fixed effects are differenced out. As a result, the summands of the influence function will not be independent anymore, showing dependence on the individual level and translating to the fact that the usual law of large numbers and central limit theorems do not straightforwardly apply. To overcome such obstacles, we show how to generalize tools of U-statistics for single-index variables to the double-indices context of dyadic datasets. A key result is that there can be different ways of defining the Hajek projection for a directed dyadic structure, which will lead to distinct, but equivalent, consistent estimators for the asymptotic variances. The results presented in this paper are easily extended to non-linear models.",
        "creator": "G. M. Szini"
      },
      {
        "title": "Instrumental variable estimation of the proportional hazards model by presmoothing.",
        "link": "http://arxiv.org/abs/2309.02183",
        "abstract": "We consider instrumental variable estimation of the proportional hazards model of Cox (1972). The instrument and the endogenous variable are discrete but there can be (possibly continuous) exogenous covariables. By making a rank invariance assumption, we can reformulate the proportional hazards model into a semiparametric version of the instrumental variable quantile regression model of Chernozhukov and Hansen (2005). A na\\\"ive estimation approach based on conditional moment conditions generated by the model would lead to a highly nonconvex and nonsmooth objective function. To overcome this problem, we propose a new presmoothing methodology. First, we estimate the model nonparametrically - and show that this nonparametric estimator has a closed-form solution in the leading case of interest of randomized experiments with one-sided noncompliance. Second, we use the nonparametric estimator to generate ``proxy'' observations for which exogeneity holds. Third, we apply the usual partial likelihood estimator to the ``proxy'' data. While the paper focuses on the proportional hazards model, our presmoothing approach could be applied to estimate other semiparametric formulations of the instrumental variable quantile regression model. Our estimation procedure allows for random right-censoring. We show asymptotic normality of the resulting estimator. The approach is illustrated via simulation studies and an empirical application to the Illinois",
        "creator": "Lorenzo Tedesco, Jad Beyhum, Ingrid Van Keilegom"
      },
      {
        "title": "Dual Effects of the US-China Trade War and COVID-19 on United States Imports: Transfer of China's industrial chain?.",
        "link": "http://arxiv.org/abs/2309.02271",
        "abstract": "The trade tension between the U.S. and China since 2018 has caused a steady decoupling of the world's two largest economies. The pandemic outbreak in 2020 complicated this process and had numerous unanticipated repercussions. This paper investigates how U.S. importers reacted to the trade war and worldwide lockdowns due to the COVID-19 pandemic. We examine the effects of the two incidents on U.S. imports separately and collectively, with various economic scopes. Our findings uncover intricate trading dynamics among the U.S., China, and Southeast Asia, through which businesses relocated portions of their global supply chain away from China to avoid high tariffs. Our analysis indicates that increased tariffs cause the U.S. to import less from China. Meanwhile, Southeast Asian exporters have integrated more into value chains centered on Chinese suppliers by participating more in assembling and completing products. However, the worldwide lockdowns over pandemic have reversed this trend as, over this period, the U.S. effectively imported more goods directly from China and indirectly through Southeast Asian exporters that imported from China.",
        "creator": "Wei Luo, Siyuan Kang, Sheng Hu, Lixian Su, Rui Dai"
      },
      {
        "title": "Projections of Economic Impacts of Climate Change on Marine Protected Areas: Palau, the Great Barrier Reef, and the Bering Sea.",
        "link": "http://arxiv.org/abs/2309.02323",
        "abstract": "Climate change substantially impacts ecological systems. Marine species are shifting their distribution because of climate change towards colder waters, potentially compromising the benefits of currently established Marine Protected Areas (MPAs). Therefore, we demonstrate how three case study regions will be impacted by warming ocean waters to prepare stakeholders to understand how the fisheries around the MPAs is predicted to change. We chose the case studies to focus on large scale MPAs in i) a cold, polar region, ii) a tropical region near the equator, and iii) a tropical region farther from the equator. We quantify the biological impacts of shifts in species distribution due to climate change for fishing communities that depend on the Palau National Marine Sanctuary, the Great Barrier Reef Marine National Park Zone, and the North Bering Sea Research Area MPAs. We find that fisheries sectors will be impacted differently in different regions and show that all three regions can be supported by this methodology for decision making that joins sector income and species diversity.",
        "creator": "Talya ten Brink"
      },
      {
        "title": "Sustainability assessment of Low Earth Orbit (LEO) satellite broadband mega-constellations.",
        "link": "http://arxiv.org/abs/2309.02338",
        "abstract": "The growth of mega-constellations is rapidly increasing the number of rocket launches required to place new satellites in space. While Low Earth Orbit (LEO) broadband satellites help to connect unconnected communities and achieve the Sustainable Development Goals, there are also a range of negative environmental externalities, from the burning of rocket fuels and resulting environmental emissions. We present sustainability analytics for phase 1 of the three main LEO constellations including Amazon Kuiper (3,236 satellites), OneWeb (648 satellites), and SpaceX Starlink (4,425 satellites). In baseline scenarios over five years, we find a per subscriber carbon dioxide equivalent (CO$_2$eq) of 0.70$\\pm$0.34 tonnes for Kuiper, 1.41$\\pm$0.71 tonnes for OneWeb and 0.47$\\pm$0.15 tonnes CO$_2$eq/subscriber for Starlink. However, in the worst-case emissions scenario these values increase to 3.02$\\pm$1.48 tonnes for Kuiper, 1.7$\\pm$0.71 tonnes for OneWeb and 1.04$\\pm$0.33 tonnes CO$_2$eq/subscriber for Starlink, more than 31-91 times higher than equivalent terrestrial mobile broadband. Importantly, phase 2 constellations propose to increase the number of satellites by an order-of-magnitude higher, highlighting the pressing need to mitigate negative environmental impacts. Strategic choices in rocket design and fuel options can help to substantially mitigate negative sustainability impacts.",
        "creator": "Ogutu B. Osoro, Edward J. Oughton, Andrew R. Wilson, Akhil Rao"
      },
      {
        "title": "Bibliometric indices as a measure of performance and competitive balance in the knockout stage of the UEFA Champions League.",
        "link": "http://arxiv.org/abs/2005.13416",
        "abstract": "We argue for the application of bibliometric indices to quantify the long-term uncertainty of outcome in sports. The Euclidean index is proposed to reward quality over quantity, while the rectangle index can be an appropriate measure of core performance. Their differences are highlighted through an axiomatic analysis and several examples. Our approach also requires a weighting scheme to compare different achievements. The methodology is illustrated by studying the knockout stage of the UEFA Champions League in the 20 seasons played between 2003 and 2023: club and country performances as well as three types of competitive balance are considered. Measuring competition at the level of national associations is a novelty. All results are remarkably robust concerning the bibliometric index and the assigned weights. Since the performances of national associations are more stable than the results of individual clubs, it would be better to build the seeding in the UEFA Champions League group stage upon association coefficients adjusted for league finishing positions rather than club coefficients.",
        "creator": "L&#xe1;szl&#xf3; Csat&#xf3;, D&#xf3;ra Gr&#xe9;ta Petr&#xf3;czy"
      },
      {
        "title": "Beyond Unbounded Beliefs: How Preferences and Information Interplay in Social Learning.",
        "link": "http://arxiv.org/abs/2103.02754",
        "abstract": "When does society eventually learn the truth, or take the correct action, via observational learning? In a general model of sequential learning over social networks, we identify a simple condition for learning dubbed excludability. Excludability is a joint property of agents' preferences and their information. When required to hold for all preferences, it is equivalent to information having \"unbounded beliefs\", which demands that any agent can individually identify the truth, even if only with small probability. But unbounded beliefs may be untenable with more than two states: e.g., it is incompatible with the monotone likelihood ratio property. Excludability reveals that what is crucial for learning, instead, is that a single agent must be able to displace any wrong action, even if she cannot take the correct action. We develop two classes of preferences and information that jointly satisfy excludability: (i) for a one-dimensional state, preferences with single-crossing differences and a new informational condition, directionally unbounded beliefs; and (ii) for a multi-dimensional state, Euclidean preferences and subexponential location-shift information.",
        "creator": "Navin Kartik, SangMok Lee, Tianhao Liu, Daniel Rappoport"
      },
      {
        "title": "Correlated Equilibria in Large Anonymous Bayesian Games.",
        "link": "http://arxiv.org/abs/2107.06312",
        "abstract": "We consider multi-population Bayesian games with a large number of players. Each player aims at minimizing a cost function that depends on this player's own action, the distribution of players' actions in all populations, and an unknown state parameter. We study the nonatomic limit versions of these games and introduce the concept of Bayes correlated Wardrop equilibrium, which extends the concept of Bayes correlated equilibrium to nonatomic games. We prove that Bayes correlated Wardrop equilibria are limits of action flows induced by Bayes correlated equilibria of the game with a large finite set of small players. For nonatomic games with complete information admitting a convex potential, we prove that the set of correlated and of coarse correlated Wardrop equilibria coincide with the set of probability distributions over Wardrop equilibria, and that all equilibrium outcomes have the same costs. We get the following consequences. First, all flow distributions of (coarse) correlated equilibria in convex potential games with finitely many players converge to Wardrop equilibria when the weight of each player tends to zero. Second, for any sequence of flows satisfying a no-regret property, its empirical distribution converges to the set of distributions over Wardrop equilibria and the average cost converges to the unique Wardrop cost.",
        "creator": "Frederic Koessler, Marco Scarsini, Tristan Tomala"
      },
      {
        "title": "Persuasion and Welfare.",
        "link": "http://arxiv.org/abs/2109.03061",
        "abstract": "Information policies such as scores, ratings, and recommendations are increasingly shaping society's choices in high-stakes domains. We provide a framework to study the welfare implications of information policies on a population of heterogeneous individuals. We define and characterize the Bayes welfare set, consisting of the population's utility profiles that are feasible under some information policy. The Pareto frontier of this set can be recovered by a series of standard Bayesian persuasion problems, in which a utilitarian planner takes the role of the information designer. We provide necessary and sufficient conditions under which an information policy exists that Pareto dominates the no-information policy. We illustrate our results with applications to data leakage, price discrimination, and credit ratings.",
        "creator": "Laura Doval, Alex Smolin"
      },
      {
        "title": "Bivariate Distribution Regression with Application to Insurance Data.",
        "link": "http://arxiv.org/abs/2203.12228",
        "abstract": "Understanding variable dependence, particularly eliciting their statistical properties given a set of covariates, provides the mathematical foundation in practical operations management such as risk analysis and decision-making given observed circumstances. This article presents an estimation method for modeling the conditional joint distribution of bivariate outcomes based on the distribution regression and factorization methods. This method is considered semiparametric in that it allows for flexible modeling of both the marginal and joint distributions conditional on covariates without imposing global parametric assumptions across the entire distribution. In contrast to existing parametric approaches, our method can accommodate discrete, continuous, or mixed variables, and provides a simple yet effective way to capture distributional dependence structures between bivariate outcomes and covariates. Various simulation results confirm that our method can perform similarly or better in finite samples compared to the alternative methods. In an application to the study of a motor third-party liability insurance portfolio, the proposed method effectively estimates risk measures such as the conditional Value-at-Risk and Expected Shortfall. This result suggests that this semiparametric approach can serve as an alternative in insurance risk management.",
        "creator": "Yunyun Wang, Tatsushi Oka, Dan Zhu"
      },
      {
        "title": "Boundary Adaptive Local Polynomial Conditional Density Estimators.",
        "link": "http://arxiv.org/abs/2204.10359",
        "abstract": "We begin by introducing a class of conditional density estimators based on local polynomial techniques. The estimators are boundary adaptive and easy to implement. We then study the (pointwise and) uniform statistical properties of the estimators, offering characterizations of both probability concentration and distributional approximation. In particular, we establish uniform convergence rates in probability and valid Gaussian distributional approximations for the Studentized t-statistic process. We also discuss implementation issues such as consistent estimation of the covariance function for the Gaussian approximation, optimal integrated mean squared error bandwidth selection, and valid robust bias-corrected inference. We illustrate the applicability of our results by constructing valid confidence bands and hypothesis tests for both parametric specification and shape constraints, explicitly characterizing their approximation errors. A companion R software package implementing our main results is provided.",
        "creator": "Matias D. Cattaneo, Rajita Chandak, Michael Jansson, Xinwei Ma"
      },
      {
        "title": "Improving the Deferred Acceptance with Minimal Compromise.",
        "link": "http://arxiv.org/abs/2205.00032",
        "abstract": "In school choice problems, the motivation for students' welfare (efficiency) is restrained by concerns to respect schools' priorities (fairness). Among the fair matchings, even the best one in terms of welfare (SOSM) is inefficient. Moreover, any mechanism that improves welfare over the SOSM is manipulable by the students. First, we characterize the \"least manipulable\" mechanisms in this class: monotonically-promoting transformation proofness ensures that no student is better off by promoting their assigned school under the true preferences. Second, we use the notion that a matching is less unfair if it yields a smaller set of students whose priorities are violated, and define minimal unfairness accordingly. We then show that the Efficiency Adjusted Deferred Acceptance (EADA) mechanism is minimally unfair in the class of efficient and monotonically-promoting transformation proof mechanisms. When the objective is to improve students' welfare over the SOSM, this characterization implies an important insight into the frontier of the main axioms in school choice.",
        "creator": "Mustafa Oguz Afacan, Umut Dur, A. Arda Gitmez, &#xd6;zg&#xfc;r Y&#x131;lmaz"
      },
      {
        "title": "Observable Perfect Equilibrium.",
        "link": "http://arxiv.org/abs/2210.16506",
        "abstract": "While Nash equilibrium has emerged as the central game-theoretic solution concept, many important games contain several Nash equilibria and we must determine how to select between them in order to create real strategic agents. Several Nash equilibrium refinement concepts have been proposed and studied for sequential imperfect-information games, the most prominent being trembling-hand perfect equilibrium, quasi-perfect equilibrium, and recently one-sided quasi-perfect equilibrium. These concepts are robust to certain arbitrarily small mistakes, and are guaranteed to always exist; however, we argue that neither of these is the correct concept for developing strong agents in sequential games of imperfect information. We define a new equilibrium refinement concept for extensive-form games called observable perfect equilibrium in which the solution is robust over trembles in publicly-observable action probabilities (not necessarily over all action probabilities that may not be observable by opposing players). Observable perfect equilibrium correctly captures the assumption that the opponent is playing as rationally as possible given mistakes that have been observed (while previous solution concepts do not). We prove that observable perfect equilibrium is always guaranteed to exist, and demonstrate that it leads to a different solution than the prior extensive-form refinements in no-limit poker. We expect observable perfect equilibrium to be a useful equilibrium refinement concept for modeling many important imperfect-information games of interest in artificial intelligence.",
        "creator": "Sam Ganzfried"
      },
      {
        "title": "Simultaneous Inference of a Partially Linear Model in Time Series.",
        "link": "http://arxiv.org/abs/2212.10359",
        "abstract": "We introduce a new methodology to conduct simultaneous inference of the nonparametric component in partially linear time series regression models where the nonparametric part is a multivariate unknown function. In particular, we construct a simultaneous confidence region (SCR) for the multivariate function by extending the high-dimensional Gaussian approximation to dependent processes with continuous index sets. Our results allow for a more general dependence structure compared to previous works and are widely applicable to a variety of linear and nonlinear autoregressive processes. We demonstrate the validity of our proposed methodology by examining the finite-sample performance in the simulation study. Finally, an application in time series, the forward premium regression, is presented, where we construct the SCR for the foreign exchange risk premium from the exchange rate and macroeconomic data.",
        "creator": "Jiaqi Li, Likai Chen, Kun Ho Kim, Tianwei Zhou"
      },
      {
        "title": "Identification- and many instrument-robust inference via invariant moment conditions.",
        "link": "http://arxiv.org/abs/2303.07822",
        "abstract": "Identification-robust hypothesis tests are commonly based on the continuous updating objective function or its score. When the number of moment conditions grows proportionally with the sample size, the large-dimensional weighting matrix prohibits the use of conventional asymptotic approximations and the behavior of these tests remains unknown. We show that the structure of the weighting matrix opens up an alternative route to asymptotic results when, under the null hypothesis, the distribution of the moment conditions is reflection invariant. In a heteroskedastic linear instrumental variables model, we then establish asymptotic normality of conventional tests statistics under many instrument sequences. A key result is that the additional terms that appear in the variance are negative. Revisiting a study on the elasticity of substitution between immigrant and native workers where the number of instruments is over a quarter of the sample size, the many instrument-robust approximation indeed leads to substantially narrower confidence intervals.",
        "creator": "Tom Boot, Johannes W. Ligtenberg"
      },
      {
        "title": "Decentralized Attack Search and the Design of Bug Bounty Schemes.",
        "link": "http://arxiv.org/abs/2304.00077",
        "abstract": "Systems and blockchains often have security vulnerabilities and can be attacked by adversaries, with potentially significant negative consequences. Therefore, infrastructure providers increasingly rely on bug bounty programs, where external individuals probe the system and report any vulnerabilities (bugs) in exchange for rewards (bounty). We develop a simple contest model of bug bounty. A group of individuals of arbitrary size is invited to undertake a costly search for bugs. The individuals differ with regard to their abilities, which we capture by different costs to achieve a certain probability to find bugs if any exist. Costs are private information. We study equilibria of the contest and characterize the optimal design of bug bounty schemes. In particular, the designer can vary the size of the group of individuals invited to search, add a paid expert, insert an artificial bug with some probability, and pay multiple prizes.",
        "creator": "Hans Gersbach, Akaki Mamageishvili, Fikri Pitsuwan"
      },
      {
        "title": "Child Care, Time Allocation, and Life Cycle.",
        "link": "http://arxiv.org/abs/2304.11531",
        "abstract": "This research investigates the impact of gender-related differences in preferences and efficiency in household tasks on the time distribution throughout marriages, aiming to uncover the underlying reasons behind gender-based discrepancies in labor earnings, especially regarding childcare duties. By utilizing aggregated data from Japan's \"Survey on Time Use and Leisure Activities,\" this study enhances the life cycle model introduced initially by Blundell et al. (2018) by integrating a heterogeneous range of ages for a child, covering her growth from infancy to adulthood. The outcomes derived from the model are then aligned with actual data through a fitting process, followed by simulations of policies catering to married couples' varying educational backgrounds. Our model's calculations indicate a reduction in maternal earnings after childbirth, consistent with the findings of the empirical investigation known as the \"child penalty.\" However, a notable disparity emerges between the projected outcomes of the model and the observed data during the subsequent phase of maternal earnings recovery, with a discrepancy of approximately 40 %. Furthermore, our calculations demonstrate that a 25 % increase in the income replacement rate for parental leave results in an almost 20 % increase in the utilization of parental leave. In contrast, a steady 10 % rise in wages leads to a modest 2.5 % increase in the utilization of parental leave.",
        "creator": "Hirokuni Iiboshi, Daikuke Ozaki, Yui Yoshii"
      },
      {
        "title": "Cognitive Aging and Labor Share.",
        "link": "http://arxiv.org/abs/2308.14982",
        "abstract": "Labor share, the fraction of economic output accrued as wages, is inexplicably declining in industrialized countries. Whilst numerous prior works attempt to explain the decline via economic factors, our novel approach links the decline to biological factors. Specifically, we propose a theoretical macroeconomic model where labor share reflects a dynamic equilibrium between the workforce automating existing outputs, and consumers demanding new output variants that require human labor. Industrialization leads to an aging population, and while cognitive performance is stable in the working years it drops sharply thereafter. Consequently, the declining cognitive performance of aging consumers reduces the demand for new output variants, leading to a decline in labor share. Our model expresses labor share as an algebraic function of median age, and is validated with surprising accuracy on historical data across industrialized economies via non-linear stochastic regression.",
        "creator": "B. N. Kausik"
      }
    ]
  }
]
