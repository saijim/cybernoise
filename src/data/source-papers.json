[{"name":"Artificial Intelligence","feed":[{"id":"2311.10723","slug":"large-language-models-in-finance-a-survey-arxiv-2311-10723v1-q-fin-gn","title":"Large Language Models in Finance: A Survey.","link":"http://arxiv.org/abs/2311.10723","abstract":"Recent advances in large language models (LLMs) have opened new possibilities for artificial intelligence applications in finance. In this paper, we provide a practical survey focused on two key aspects of utilizing LLMs for financial tasks: existing solutions and guidance for adoption.  First, we review current approaches employing LLMs in finance, including leveraging pretrained models via zero-shot or few-shot learning, fine-tuning on domain-specific data, and training custom LLMs from scratch. We summarize key models and evaluate their performance improvements on financial natural language processing tasks.  Second, we propose a decision framework to guide financial professionals in selecting the appropriate LLM solution based on their use case constraints around data, compute, and performance needs. The framework provides a pathway from lightweight experimentation to heavy investment in customized LLMs.  Lastly, we discuss limitations and challenges around leveraging LLMs in financial applications. Overall, this survey aims to synthesize the state-of-the-art and provide a roadmap for responsibly applying LLMs to advance financial AI.","creator":"Yinheng Li, Shaofei Wang, Han Ding, Hang Chen"},{"id":"2311.10725","slug":"should-they-mobile-biometrics-and-technopolicy-meet-queer-community-considerations-arxiv-2311-10725v1-cs-cy","title":"Should they? Mobile Biometrics and Technopolicy meet Queer Community Considerations.","link":"http://arxiv.org/abs/2311.10725","abstract":"Smartphones are integral to our daily lives and activities, providing us with basic functions like texting and phone calls to more complex motion-based functionalities like navigation, mobile gaming, and fitness-tracking. To facilitate these functionalities, smartphones rely on integrated sensors like accelerometers and gyroscopes. These sensors provide personalized measurements that, in turn, contribute to tasks such as analyzing biometric data for mobile health purposes. In addition to benefiting smartphone users, biometric data holds significant value for researchers engaged in biometric identification research. Nonetheless, utilizing this user data for biometric identification tasks, such as gait and gender recognition, raises serious privacy, normative, and ethical concerns, particularly within the queer community. Concerns of algorithmic bias and algorithmically-driven dysphoria surface from a historical backdrop of marginalization, surveillance, harassment, discrimination, and violence against the queer community. In this position paper, we contribute to the timely discourse on safeguarding human rights within AI-driven systems by providing a sense of challenges, tensions, and opportunities for new data protections and biometric collection practices in a way that grapples with the sociotechnical realities of the queer community.","creator":"Anaelia Ovalle, Davi Liang, Alicia Boyd"},{"id":"2311.10735","slug":"safe-navigation-training-autonomous-vehicles-using-deep-reinforcement-learning-in-carla-arxiv-2311-10735v1-cs-ai","title":"Safe Navigation: Training Autonomous Vehicles using Deep Reinforcement Learning in CARLA.","link":"http://arxiv.org/abs/2311.10735","abstract":"Autonomous vehicles have the potential to revolutionize transportation, but they must be able to navigate safely in traffic before they can be deployed on public roads. The goal of this project is to train autonomous vehicles to make decisions to navigate in uncertain environments using deep reinforcement learning techniques using the CARLA simulator. The simulator provides a realistic and urban environment for training and testing self-driving models. Deep Q-Networks (DQN) are used to predict driving actions. The study involves the integration of collision sensors, segmentation, and depth camera for better object detection and distance estimation. The model is tested on 4 different trajectories in presence of different types of 4-wheeled vehicles and pedestrians. The segmentation and depth cameras were utilized to ensure accurate localization of objects and distance measurement. Our proposed method successfully navigated the self-driving vehicle to its final destination with a high success rate without colliding with other vehicles, pedestrians, or going on the sidewalk. To ensure the optimal performance of our reinforcement learning (RL) models in navigating complex traffic scenarios, we implemented a pre-processing step to reduce the state space. This involved processing the images and sensor output before feeding them into the model. Despite significantly decreasing the state space, our approach yielded robust models that successfully navigated through traffic with high levels of safety and accuracy.","creator":"Ghadi Nehme, Tejas Y. Deo"},{"id":"2311.10737","slug":"ai-enhanced-auto-correction-of-programming-exercises-how-effective-is-gpt-3-5-arxiv-2311-10737v1-cs-cy","title":"AI-enhanced Auto-correction of Programming Exercises: How Effective is GPT-3.5?.","link":"http://arxiv.org/abs/2311.10737","abstract":"Timely formative feedback is considered as one of the most important drivers for effective learning. Delivering timely and individualized feedback is particularly challenging in large classes in higher education. Recently Large Language Models such as GPT-3 became available to the public that showed promising results on various tasks such as code generation and code explanation. This paper investigates the potential of AI in providing personalized code correction and generating feedback. Based on existing student submissions of two different real-world assignments, the correctness of the AI-aided e-assessment as well as the characteristics such as fault localization, correctness of hints, and code style suggestions of the generated feedback are investigated. The results show that 73 % of the submissions were correctly identified as either correct or incorrect. In 59 % of these cases, GPT-3.5 also successfully generated effective and high-quality feedback. Additionally, GPT-3.5 exhibited weaknesses in its evaluation, including localization of errors that were not the actual errors, or even hallucinated errors. Implications and potential new usage scenarios are discussed.","creator":"Imen Azaiz, Oliver Deckarm, Sven Strickroth"},{"id":"2311.10747","slug":"safety-aware-causal-representation-for-trustworthy-reinforcement-learning-in-autonomous-driving-arxiv-2311-10747v1-cs-ro","title":"Safety-aware Causal Representation for Trustworthy Reinforcement Learning in Autonomous Driving.","link":"http://arxiv.org/abs/2311.10747","abstract":"In the domain of autonomous driving, the Learning from Demonstration (LfD) paradigm has exhibited notable efficacy in addressing sequential decision-making problems. However, consistently achieving safety in varying traffic contexts, especially in safety-critical scenarios, poses a significant challenge due to the long-tailed and unforeseen scenarios absent from offline datasets. In this paper, we introduce the saFety-aware strUctured Scenario representatION (FUSION), a pioneering methodology conceived to facilitate the learning of an adaptive end-to-end driving policy by leveraging structured scenario information. FUSION capitalizes on the causal relationships between decomposed reward, cost, state, and action space, constructing a framework for structured sequential reasoning under dynamic traffic environments. We conduct rigorous evaluations in two typical real-world settings of distribution shift in autonomous vehicles, demonstrating the good balance between safety cost and utility reward of FUSION compared to contemporary state-of-the-art safety-aware LfD baselines. Empirical evidence under diverse driving scenarios attests that FUSION significantly enhances the safety and generalizability of autonomous driving agents, even in the face of challenging and unseen environments. Furthermore, our ablation studies reveal noticeable improvements in the integration of causal representation into the safe offline RL problem.","creator":"Haohong Lin, Wenhao Ding, Zuxin Liu, Yaru Niu, Jiacheng Zhu, Yuming Niu, Ding Zhao"},{"id":"2311.10749","slug":"measuring-five-accountable-talk-moves-to-improve-instruction-at-scale-arxiv-2311-10749v1-cs-cy","title":"Measuring Five Accountable Talk Moves to Improve Instruction at Scale.","link":"http://arxiv.org/abs/2311.10749","abstract":"Providing consistent, individualized feedback to teachers on their instruction can improve student learning outcomes. Such feedback can especially benefit novice instructors who teach on online platforms and have limited access to instructional training. To build scalable measures of instruction, we fine-tune RoBERTa and GPT models to identify five instructional talk moves inspired by accountable talk theory: adding on, connecting, eliciting, probing and revoicing students' ideas. We fine-tune these models on a newly annotated dataset of 2500 instructor utterances derived from transcripts of small group instruction in an online computer science course, Code in Place. Although we find that GPT-3 consistently outperforms RoBERTa in terms of precision, its recall varies significantly. We correlate the instructors' use of each talk move with indicators of student engagement and satisfaction, including students' section attendance, section ratings, and assignment completion rates. We find that using talk moves generally correlates positively with student outcomes, and connecting student ideas has the largest positive impact. These results corroborate previous research on the effectiveness of accountable talk moves and provide exciting avenues for using these models to provide instructors with useful, scalable feedback.","creator":"Ashlee Kupor, Candice Morgan, Dorottya Demszky"},{"id":"2311.10751","slug":"proagent-from-robotic-process-automation-to-agentic-process-automation-arxiv-2311-10751v1-cs-ro","title":"ProAgent: From Robotic Process Automation to Agentic Process Automation.","link":"http://arxiv.org/abs/2311.10751","abstract":"From ancient water wheels to robotic process automation (RPA), automation technology has evolved throughout history to liberate human beings from arduous tasks. Yet, RPA struggles with tasks needing human-like intelligence, especially in elaborate design of workflow construction and dynamic decision-making in workflow execution. As Large Language Models (LLMs) have emerged human-like intelligence, this paper introduces Agentic Process Automation (APA), a groundbreaking automation paradigm using LLM-based agents for advanced automation by offloading the human labor to agents associated with construction and execution. We then instantiate ProAgent, an LLM-based agent designed to craft workflows from human instructions and make intricate decisions by coordinating specialized agents. Empirical experiments are conducted to detail its construction and execution procedure of workflow, showcasing the feasibility of APA, unveiling the possibility of a new paradigm of automation driven by agents. Our code is public at https://github.com/OpenBMB/ProAgent.","creator":"Yining Ye, Xin Cong, Shizuo Tian, Jiannan Cao, Hao Wang, Yujia Qin, Yaxi Lu, Heyang Yu, Huadong Wang, Yankai Lin, Zhiyuan Liu, Maosong Sun"},{"id":"2311.10757","slug":"how-contentious-terms-about-people-and-cultures-are-used-in-linked-open-data-arxiv-2311-10757v1-cs-cl","title":"How Contentious Terms About People and Cultures are Used in Linked Open Data.","link":"http://arxiv.org/abs/2311.10757","abstract":"Web resources in linked open data (LOD) are comprehensible to humans through literal textual values attached to them, such as labels, notes, or comments. Word choices in literals may not always be neutral. When outdated and culturally stereotyping terminology is used in literals, they may appear as offensive to users in interfaces and propagate stereotypes to algorithms trained on them. We study how frequently and in which literals contentious terms about people and cultures occur in LOD and whether there are attempts to mark the usage of such terms. For our analysis, we reuse English and Dutch terms from a knowledge graph that provides opinions of experts from the cultural heritage domain about terms' contentiousness. We inspect occurrences of these terms in four widely used datasets: Wikidata, The Getty Art &amp; Architecture Thesaurus, Princeton WordNet, and Open Dutch WordNet. Some terms are ambiguous and contentious only in particular senses. Applying word sense disambiguation, we generate a set of literals relevant to our analysis. We found that outdated, derogatory, stereotyping terms frequently appear in descriptive and labelling literals, such as preferred labels that are usually displayed in interfaces and used for indexing. In some cases, LOD contributors mark contentious terms with words and phrases in literals (implicit markers) or properties linked to resources (explicit markers). However, such marking is rare and non-consistent in all datasets. Our quantitative and qualitative insights could be helpful in developing more systematic approaches to address the propagation of stereotypes via LOD.","creator":"Andrei Nesterov (1), Laura Hollink (1), Jacco van Ossenbruggen (2) ((1) Centrum Wiskunde &amp; Informatica, (2) VU University Amsterdam)"},{"id":"2311.10764","slug":"deep-group-interest-modeling-of-full-lifelong-user-behaviors-for-ctr-prediction-arxiv-2311-10764v1-cs-ir","title":"Deep Group Interest Modeling of Full Lifelong User Behaviors for CTR Prediction.","link":"http://arxiv.org/abs/2311.10764","abstract":"Extracting users' interests from their lifelong behavior sequence is crucial for predicting Click-Through Rate (CTR). Most current methods employ a two-stage process for efficiency: they first select historical behaviors related to the candidate item and then deduce the user's interest from this narrowed-down behavior sub-sequence. This two-stage paradigm, though effective, leads to information loss. Solely using users' lifelong click behaviors doesn't provide a complete picture of their interests, leading to suboptimal performance. In our research, we introduce the Deep Group Interest Network (DGIN), an end-to-end method to model the user's entire behavior history. This includes all post-registration actions, such as clicks, cart additions, purchases, and more, providing a nuanced user understanding. We start by grouping the full range of behaviors using a relevant key (like item_id) to enhance efficiency. This process reduces the behavior length significantly, from O(10^4) to O(10^2). To mitigate the potential loss of information due to grouping, we incorporate two categories of group attributes. Within each group, we calculate statistical information on various heterogeneous behaviors (like behavior counts) and employ self-attention mechanisms to highlight unique behavior characteristics (like behavior type). Based on this reorganized behavior data, the user's interests are derived using the Transformer technique. Additionally, we identify a subset of behaviors that share the same item_id with the candidate item from the lifelong behavior sequence. The insights from this subset reveal the user's decision-making process related to the candidate item, improving prediction accuracy. Our comprehensive evaluation, both on industrial and public datasets, validates DGIN's efficacy and efficiency.","creator":"Qi Liu, Xuyang Hou, Haoran Jin, jin Chen, Zhe Wang, Defu Lian, Tan Qu, Jia Cheng, Jun Lei"},{"id":"2311.10766","slug":"value-fulcra-mapping-large-language-models-to-the-multidimensional-spectrum-of-basic-human-values-arxiv-2311-10766v1-cs-cl","title":"Value FULCRA: Mapping Large Language Models to the Multidimensional Spectrum of Basic Human Values.","link":"http://arxiv.org/abs/2311.10766","abstract":"The rapid advancement of Large Language Models (LLMs) has attracted much attention to value alignment for their responsible development. However, how to define values in this context remains a largely unexplored question. Existing work mainly follows the Helpful, Honest, Harmless principle and specifies values as risk criteria formulated in the AI community, e.g., fairness and privacy protection, suffering from poor clarity, adaptability and transparency. Inspired by basic values in humanity and social science across cultures, this work proposes a novel basic value alignment paradigm and introduces a value space spanned by basic value dimensions. All LLMs' behaviors can be mapped into the space by identifying the underlying values, possessing the potential to address the three challenges. To foster future research, we apply the representative Schwartz's Theory of Basic Values as an initialized example and construct FULCRA, a dataset consisting of 5k (LLM output, value vector) pairs. Our extensive analysis of FULCRA reveals the underlying relation between basic values and LLMs' behaviors, demonstrating that our approach not only covers existing mainstream risks but also anticipates possibly unidentified ones. Additionally, we present an initial implementation of the basic value evaluation and alignment, paving the way for future research in this line.","creator":"Jing Yao, Xiaoyuan Yi, Xiting Wang, Yifan Gong, Xing Xie"},{"id":"2311.10767","slug":"optimizing-iac-configurations-a-case-study-using-nature-inspired-computing-arxiv-2311-10767v1-cs-se","title":"Optimizing IaC Configurations: a Case Study Using Nature-inspired Computing.","link":"http://arxiv.org/abs/2311.10767","abstract":"In the last years, one of the fields of artificial intelligence that has been investigated the most is nature-inspired computing. The research done on this specific topic showcases the interest that sparks in researchers and practitioners, who put their focus on this paradigm because of the adaptability and ability of nature-inspired algorithms to reach high-quality outcomes on a wide range of problems. In fact, this kind of methods has been successfully applied to solve real-world problems in heterogeneous fields such as medicine, transportation, industry, or software engineering. Our main objective with this paper is to describe a tool based on nature-inspired computing for solving a specific software engineering problem. The problem faced consists of optimizing Infrastructure as Code deployment configurations. For this reason, the name of the system is IaC Optimizer Platform. A prototypical version of the IOP was described in previous works, in which the functionality of this platform was introduced. With this paper, we take a step forward by describing the final release of the IOP, highlighting its main contribution regarding the current state-of-the-art, and justifying the decisions made on its implementation. Also, we contextualize the IOP within the complete platform in which it is embedded, describing how a user can benefit from its use. To do that, we also present and solve a real-world use case.","creator":"Eneko Osaba, Gorka Benguria, Jesus L. Lobo, Josu Diaz-de-Arcaya, Juncal Alonso, I&#xf1;aki Etxaniz"},{"id":"2311.10770","slug":"exponentially-faster-language-modelling-arxiv-2311-10770v1-cs-cl","title":"Exponentially Faster Language Modelling.","link":"http://arxiv.org/abs/2311.10770","abstract":"Language models only really need to use an exponential fraction of their neurons for individual inferences. As proof, we present FastBERT, a BERT variant that uses 0.3\\% of its neurons during inference while performing on par with similar BERT models. FastBERT selectively engages just 12 out of 4095 neurons for each layer inference. This is achieved by replacing feedforward networks with fast feedforward networks (FFFs). While no truly efficient implementation currently exists to unlock the full acceleration potential of conditional neural execution, we provide high-level CPU code achieving 78x speedup over the optimized baseline feedforward implementation, and a PyTorch implementation delivering 40x speedup over the equivalent batched feedforward inference. We publish our training code, benchmarking setup, and model weights.","creator":"Peter Belcak, Roger Wattenhofer"},{"id":"2311.10773","slug":"user-persona-identification-and-new-service-adaptation-recommendation-arxiv-2311-10773v1-cs-ir","title":"User Persona Identification and New Service Adaptation Recommendation.","link":"http://arxiv.org/abs/2311.10773","abstract":"Providing a personalized user experience on information dense webpages helps users in reaching their end-goals sooner. We explore an automated approach to identifying user personas by leveraging high dimensional trajectory information from user sessions on webpages. While neural collaborative filtering (NCF) approaches pay little attention to token semantics, our method introduces SessionBERT, a Transformer-backed language model trained from scratch on the masked language modeling (mlm) objective for user trajectories (pages, metadata, billing in a session) aiming to capture semantics within them. Our results show that representations learned through SessionBERT are able to consistently outperform a BERT-base model providing a 3% and 1% relative improvement in F1-score for predicting page links and next services. We leverage SessionBERT and extend it to provide recommendations (top-5) for the next most-relevant services that a user would be likely to use. We achieve a HIT@5 of 58% from our recommendation model.","creator":"Narges Tabari, Sandesh Swamy, Rashmi Gangadharaiah"},{"id":"2311.10774","slug":"mmc-advancing-multimodal-chart-understanding-with-large-scale-instruction-tuning-arxiv-2311-10774v1-cs-cl","title":"MMC: Advancing Multimodal Chart Understanding with Large-scale Instruction Tuning.","link":"http://arxiv.org/abs/2311.10774","abstract":"With the rapid development of large language models (LLMs) and their integration into large multimodal models (LMMs), there has been impressive progress in zero-shot completion of user-oriented vision-language tasks. However, a gap remains in the domain of chart image understanding due to the distinct abstract components in charts. To address this, we introduce a large-scale MultiModal Chart Instruction (MMC-Instruction) dataset comprising 600k instances supporting diverse tasks and chart types. Leveraging this data, we develop MultiModal Chart Assistant (MMCA), an LMM that achieves state-of-the-art performance on existing chart QA benchmarks. Recognizing the need for a comprehensive evaluation of LMM chart understanding, we also propose a MultiModal Chart Benchmark (MMC-Benchmark), a comprehensive human-annotated benchmark with 9 distinct tasks evaluating reasoning capabilities over charts. Extensive experiments on MMC-Benchmark reveal the limitations of existing LMMs on correctly interpreting charts, even for the most recent GPT-4V model. Our work provides an instruction-tuning methodology and benchmark to advance multimodal understanding of charts.","creator":"Fuxiao Liu, Xiaoyang Wang, Wenlin Yao, Jianshu Chen, Kaiqiang Song, Sangwoo Cho, Yaser Yacoob, Dong Yu"},{"id":"2311.10775","slug":"tooltalk-evaluating-tool-usage-in-a-conversational-setting-arxiv-2311-10775v1-cs-cl","title":"ToolTalk: Evaluating Tool-Usage in a Conversational Setting.","link":"http://arxiv.org/abs/2311.10775","abstract":"Large language models (LLMs) have displayed massive improvements in reasoning and decision-making skills and can hold natural conversations with users. Many recent works seek to augment LLM-based assistants with external tools so they can access private or up-to-date information and carry out actions on behalf of users. To better measure the performance of these assistants, this paper introduces ToolTalk, a benchmark consisting of complex user intents requiring multi-step tool usage specified through dialogue. ToolTalk contains 28 tools grouped into 7 plugins, and includes a complete simulated implementation of each tool, allowing for fully automated evaluation of assistants that rely on execution feedback. ToolTalk also emphasizes tools that externally affect the world rather than only tools for referencing or searching information. We evaluate GPT-3.5 and GPT-4 on ToolTalk resulting in success rates of 26% and 50% respectively. Our analysis of the errors reveals three major categories and suggests some future directions for improvement. We release ToolTalk at https://github.com/microsoft/ToolTalk.","creator":"Nicholas Farn, Richard Shin"},{"id":"2311.10776","slug":"towards-an-automatic-ai-agent-for-reaction-condition-recommendation-in-chemical-synthesis-arxiv-2311-10776v1-cs-ir","title":"Towards an Automatic AI Agent for Reaction Condition Recommendation in Chemical Synthesis.","link":"http://arxiv.org/abs/2311.10776","abstract":"Artificial intelligence (AI) for reaction condition optimization has become an important topic in the pharmaceutical industry, given that a data-driven AI model can assist drug discovery and accelerate reaction design. However, existing AI models lack the chemical insights and real-time knowledge acquisition abilities of experienced human chemists. This paper proposes a Large Language Model (LLM) empowered AI agent to bridge this gap. We put forth a novel three-phase paradigm and applied advanced intelligence-enhancement methods like in-context learning and multi-LLM debate so that the AI agent can borrow human insight and update its knowledge by searching the latest chemical literature. Additionally, we introduce a novel Coarse-label Contrastive Learning (CCL) based chemical fingerprint that greatly enhances the agent's performance in optimizing the reaction condition. With the above efforts, the proposed AI agent can autonomously generate the optimal reaction condition recommendation without any human interaction. Further, the agent is highly professional in terms of chemical reactions. It demonstrates close-to-human performance and strong generalization capability in both dry-lab and wet-lab experiments. As the first attempt in the chemical AI agent, this work goes a step further in the field of \"AI for chemistry\" and opens up new possibilities for computer-aided synthesis planning.","creator":"Kexin Chen, Junyou Li, Kunyi Wang, Yuyang Du, Jiahui Yu, Jiamin Lu, Guangyong Chen, Lanqing Li, Jiezhong Qiu, Qun Fang, Pheng Ann Heng"},{"id":"2311.10779","slug":"knowledge-plugins-enhancing-large-language-models-for-domain-specific-recommendations-arxiv-2311-10779v1-cs-ir","title":"Knowledge Plugins: Enhancing Large Language Models for Domain-Specific Recommendations.","link":"http://arxiv.org/abs/2311.10779","abstract":"The significant progress of large language models (LLMs) provides a promising opportunity to build human-like systems for various practical applications. However, when applied to specific task domains, an LLM pre-trained on a general-purpose corpus may exhibit a deficit or inadequacy in two types of domain-specific knowledge. One is a comprehensive set of domain data that is typically large-scale and continuously evolving. The other is specific working patterns of this domain reflected in the data. The absence or inadequacy of such knowledge impacts the performance of the LLM. In this paper, we propose a general paradigm that augments LLMs with DOmain-specific KnowledgE to enhance their performance on practical applications, namely DOKE. This paradigm relies on a domain knowledge extractor, working in three steps: 1) preparing effective knowledge for the task; 2) selecting the knowledge for each specific sample; and 3) expressing the knowledge in an LLM-understandable way. Then, the extracted knowledge is incorporated through prompts, without any computational cost of model fine-tuning. We instantiate the general paradigm on a widespread application, i.e. recommender systems, where critical item attributes and collaborative filtering signals are incorporated. Experimental results demonstrate that DOKE can substantially improve the performance of LLMs in specific domains.","creator":"Jing Yao, Wei Xu, Jianxun Lian, Xiting Wang, Xiaoyuan Yi, Xing Xie"},{"id":"2311.10780","slug":"extending-neural-network-verification-to-a-larger-family-of-piece-wise-linear-activation-functions-arxiv-2311-10780v1-cs-lg","title":"Extending Neural Network Verification to a Larger Family of Piece-wise Linear Activation Functions.","link":"http://arxiv.org/abs/2311.10780","abstract":"In this paper, we extend an available neural network verification technique to support a wider class of piece-wise linear activation functions. Furthermore, we extend the algorithms, which provide in their original form exact respectively over-approximative results for bounded input sets represented as start sets, to allow also unbounded input set. We implemented our algorithms and demonstrated their effectiveness in some case studies.","creator":"L&#xe1;szl&#xf3; Antal (RWTH Aachen University), Hana Masara (RWTH Aachen University), Erika &#xc1;brah&#xe1;m (RWTH Aachen University)"},{"id":"2311.10781","slug":"can-language-model-moderators-improve-the-health-of-online-discourse-arxiv-2311-10781v1-cs-cl","title":"Can Language Model Moderators Improve the Health of Online Discourse?.","link":"http://arxiv.org/abs/2311.10781","abstract":"Human moderation of online conversation is essential to maintaining civility and focus in a dialogue, but is challenging to scale and harmful to moderators. The inclusion of sophisticated natural language generation modules as a force multiplier aid moderators is a tantalizing prospect, but adequate evaluation approaches have so far been elusive. In this paper, we establish a systematic definition of conversational moderation effectiveness through a multidisciplinary lens that incorporates insights from social science. We then propose a comprehensive evaluation framework that uses this definition to asses models' moderation capabilities independently of human intervention. With our framework, we conduct the first known study of conversational dialogue models as moderators, finding that appropriately prompted models can provide specific and fair feedback on toxic behavior but struggle to influence users to increase their levels of respect and cooperation.","creator":"Hyundong Cho, Shuai Liu, Taiwei Shi, Darpan Jain, Basem Rizk, Yuyang Huang, Zixun Lu, Nuan Wen, Jonathan Gratch, Emilio Ferrara, Jonathan May"},{"id":"2311.10784","slug":"exfake-towards-an-explainable-fake-news-detection-based-on-content-and-social-context-information-arxiv-2311-10784v1-cs-cl","title":"ExFake: Towards an Explainable Fake News Detection Based on Content and Social Context Information.","link":"http://arxiv.org/abs/2311.10784","abstract":"ExFake is an explainable fake news detection system based on content and context-level information. It is concerned with the veracity analysis of online posts based on their content, social context (i.e., online users' credibility and historical behaviour), and data coming from trusted entities such as fact-checking websites and named entities. Unlike state-of-the-art systems, an Explainable AI (XAI) assistant is also adopted to help online social networks (OSN) users develop good reflexes when faced with any doubted information that spreads on social networks. The trustworthiness of OSN users is also addressed by assigning a credibility score to OSN users, as OSN users are one of the main culprits for spreading fake news. Experimental analysis on a real-world dataset demonstrates that ExFake significantly outperforms other baseline methods for fake news detection.","creator":"Sabrine Amri, Henri-Cedric Mputu Boleilanga, Esma A&#xef;meur"},{"id":"2311.10786","slug":"a-systems-theoretical-formalization-of-closed-systems-arxiv-2311-10786v1-cs-ai","title":"A Systems-Theoretical Formalization of Closed Systems.","link":"http://arxiv.org/abs/2311.10786","abstract":"There is a lack of formalism for some key foundational concepts in systems engineering. One of the most recently acknowledged deficits is the inadequacy of systems engineering practices for engineering intelligent systems. In our previous works, we proposed that closed systems precepts could be used to accomplish a required paradigm shift for the systems engineering of intelligent systems. However, to enable such a shift, formal foundations for closed systems precepts that expand the theory of systems engineering are needed. The concept of closure is a critical concept in the formalism underlying closed systems precepts. In this paper, we provide formal, systems- and information-theoretic definitions of closure to identify and distinguish different types of closed systems. Then, we assert a mathematical framework to evaluate the subjective formation of the boundaries and constraints of such systems. Finally, we argue that engineering an intelligent system can benefit from appropriate closed and open systems paradigms on multiple levels of abstraction of the system. In the main, this framework will provide the necessary fundamentals to aid in systems engineering of intelligent systems.","creator":"Niloofar Shadab, Tyler Cody, Alejandro Salado, Peter Beling"},{"id":"2311.10788","slug":"efficient-temporally-aware-deepfake-detection-using-h-264-motion-vectors-arxiv-2311-10788v1-cs-cv","title":"Efficient Temporally-Aware DeepFake Detection using H.264 Motion Vectors.","link":"http://arxiv.org/abs/2311.10788","abstract":"Video DeepFakes are fake media created with Deep Learning (DL) that manipulate a person's expression or identity. Most current DeepFake detection methods analyze each frame independently, ignoring inconsistencies and unnatural movements between frames. Some newer methods employ optical flow models to capture this temporal aspect, but they are computationally expensive. In contrast, we propose using the related but often ignored Motion Vectors (MVs) and Information Masks (IMs) from the H.264 video codec, to detect temporal inconsistencies in DeepFakes. Our experiments show that this approach is effective and has minimal computational costs, compared with per-frame RGB-only methods. This could lead to new, real-time temporally-aware DeepFake detection methods for video calls and streaming.","creator":"Peter Gr&#xf6;nquist, Yufan Ren, Qingyi He, Alessio Verardo, Sabine S&#xfc;sstrunk"},{"id":"2311.10792","slug":"attention-mechanism-for-lithium-ion-battery-lifespan-prediction-temporal-and-cyclic-attention-arxiv-2311-10792v1-cs-lg","title":"Attention Mechanism for Lithium-Ion Battery Lifespan Prediction: Temporal and Cyclic Attention.","link":"http://arxiv.org/abs/2311.10792","abstract":"Accurately predicting the lifespan of lithium-ion batteries (LIBs) is pivotal for optimizing usage and preventing accidents. Previous studies in constructing prediction models often relied on inputs challenging to measure in real-time operations and failed to capture intra-cycle and inter-cycle data patterns, essential features for accurate predictions, comprehensively. In this study, we employ attention mechanisms (AM) to develop data-driven models for predicting LIB lifespan using easily measurable inputs such as voltage, current, temperature, and capacity data. The developed model integrates recurrent neural network (RNN) and convolutional neural network (CNN) components, featuring two types of attention mechanisms: temporal attention (TA) and cyclic attention (CA). The inclusion of TA aims to identify important time steps within each cycle by scoring the hidden states of the RNN, whereas CA strives to capture key features of inter-cycle correlations through self-attention (SA). This enhances model accuracy and elucidates critical features in the input data. To validate our method, we apply it to publicly available cycling data consisting of three batches of cycling modes. The calculated TA scores highlight the rest phase as a key characteristic distinguishing LIB data among different batches. Additionally, CA scores reveal variations in the importance of cycles across batches. By leveraging CA scores, we explore the potential to reduce the number of cycles in the input data. The single-head and multi-head attentions enable us to decrease the input dimension from 100 to 50 and 30 cycles, respectively.","creator":"Jaewook Lee, Seongmin Heo, Jay H. Lee"},{"id":"2311.10793","slug":"traffic-sign-interpretation-in-real-road-scene-arxiv-2311-10793v1-cs-cv","title":"Traffic Sign Interpretation in Real Road Scene.","link":"http://arxiv.org/abs/2311.10793","abstract":"Most existing traffic sign-related works are dedicated to detecting and recognizing part of traffic signs individually, which fails to analyze the global semantic logic among signs and may convey inaccurate traffic instruction. Following the above issues, we propose a traffic sign interpretation (TSI) task, which aims to interpret global semantic interrelated traffic signs (e.g.,~driving instruction-related texts, symbols, and guide panels) into a natural language for providing accurate instruction support to autonomous or assistant driving. Meanwhile, we design a multi-task learning architecture for TSI, which is responsible for detecting and recognizing various traffic signs and interpreting them into a natural language like a human. Furthermore, the absence of a public TSI available dataset prompts us to build a traffic sign interpretation dataset, namely TSI-CN. The dataset consists of real road scene images, which are captured from the highway and the urban way in China from a driver's perspective. It contains rich location labels of texts, symbols, and guide panels, and the corresponding natural language description labels. Experiments on TSI-CN demonstrate that the TSI task is achievable and the TSI architecture can interpret traffic signs from scenes successfully even if there is a complex semantic logic among signs. The TSI-CN dataset and the source code of the TSI architecture will be publicly available after the revision process.","creator":"Chuang Yang, Kai Zhuang, Mulin Chen, Haozhao Ma, Xu Han, Tao Han, Changxing Guo, Han Han, Bingxuan Zhao, Qi Wang"},{"id":"2311.10796","slug":"emotion-aware-music-recommendation-system-enhancing-user-experience-through-real-time-emotional-context-arxiv-2311-10796v1-cs-ir","title":"Emotion-Aware Music Recommendation System: Enhancing User Experience Through Real-Time Emotional Context.","link":"http://arxiv.org/abs/2311.10796","abstract":"This study addresses the deficiency in conventional music recommendation systems by focusing on the vital role of emotions in shaping users music choices. These systems often disregard the emotional context, relying predominantly on past listening behavior and failing to consider the dynamic and evolving nature of users emotional preferences. This gap leads to several limitations. Users may receive recommendations that do not match their current mood, which diminishes the quality of their music experience. Furthermore, without accounting for emotions, the systems might overlook undiscovered or lesser-known songs that have a profound emotional impact on users. To combat these limitations, this research introduces an AI model that incorporates emotional context into the song recommendation process. By accurately detecting users real-time emotions, the model can generate personalized song recommendations that align with the users emotional state. This approach aims to enhance the user experience by offering music that resonates with their current mood, elicits the desired emotions, and creates a more immersive and meaningful listening experience. By considering emotional context in the song recommendation process, the proposed model offers an opportunity for a more personalized and emotionally resonant musical journey.","creator":"Tina Babu, Rekha R Nair, Geetha A"},{"id":"2311.10797","slug":"taco-enhancing-cross-lingual-transfer-for-low-resource-languages-in-llms-through-translation-assisted-chain-of-thought-processes-arxiv-2311-10797v1-cs-cl","title":"TaCo: Enhancing Cross-Lingual Transfer for Low-Resource Languages in LLMs through Translation-Assisted Chain-of-Thought Processes.","link":"http://arxiv.org/abs/2311.10797","abstract":"LLMs such as ChatGPT and PaLM can be utilized to train on a new language and revitalize low-resource languages. However, it is evidently very costly to pretrain pr fine-tune LLMs to adopt new languages. Another challenge is the limitation of benchmark datasets and the metrics used to measure the performance of models in multilingual settings. This paper proposes cost-effective solutions to both of the aforementioned challenges. We introduce the Multilingual Instruction-Tuning Dataset (MITS), which is comprised of the translation of Alpaca-52K, Dolly-15K, and Vicuna Benchmark in 132 languages. Also, we propose a new method called \\emph{TaCo: Translation-Assisted Cross-Linguality}, which make uses of translation in a chain-of-thought process to instruction-tune LLMs on a new languages through a curriculum learning process. As a proof of concept, we experimented with the instruction-tuned Guanaco-33B model and performed further instruction tuning using the TaCo method in three low-resource languages and one high-resource language. Our results show that the TaCo method impresses the GPT-4 with 82% for a low-resource language in the Vicuna Benchmark dataset, and boosts performance by double in contrast to the performance of instruction tuning only. Our results show that TaCo is a promising method for creating multilingual LLMs, even for low-resource languages. We have released our datasets and the model adapters, and encourage the research community to make use of these resources towards advancing work on multilingual LLMs.","creator":"Bibek Upadhayay, Vahid Behzadan"},{"id":"2311.10798","slug":"inspect-a-multimodal-dataset-for-pulmonary-embolism-diagnosis-and-prognosis-arxiv-2311-10798v1-cs-lg","title":"INSPECT: A Multimodal Dataset for Pulmonary Embolism Diagnosis and Prognosis.","link":"http://arxiv.org/abs/2311.10798","abstract":"Synthesizing information from multiple data sources plays a crucial role in the practice of modern medicine. Current applications of artificial intelligence in medicine often focus on single-modality data due to a lack of publicly available, multimodal medical datasets. To address this limitation, we introduce INSPECT, which contains de-identified longitudinal records from a large cohort of patients at risk for pulmonary embolism (PE), along with ground truth labels for multiple outcomes. INSPECT contains data from 19,402 patients, including CT images, radiology report impression sections, and structured electronic health record (EHR) data (i.e. demographics, diagnoses, procedures, vitals, and medications). Using INSPECT, we develop and release a benchmark for evaluating several baseline modeling approaches on a variety of important PE related tasks. We evaluate image-only, EHR-only, and multimodal fusion models. Trained models and the de-identified dataset are made available for non-commercial use under a data use agreement. To the best of our knowledge, INSPECT is the largest multimodal dataset integrating 3D medical imaging and EHR for reproducible methods evaluation and research.","creator":"Shih-Cheng Huang, Zepeng Huo, Ethan Steinberg, Chia-Chun Chiang, Matthew P. Lungren, Curtis P. Langlotz, Serena Yeung, Nigam H. Shah, Jason A. Fries"},{"id":"2311.10801","slug":"reinforcement-learning-with-maskable-stock-representation-for-portfolio-management-in-customizable-stock-pools-arxiv-2311-10801v1-q-fin-pm","title":"Reinforcement Learning with Maskable Stock Representation for Portfolio Management in Customizable Stock Pools.","link":"http://arxiv.org/abs/2311.10801","abstract":"Portfolio management (PM) is a fundamental financial trading task, which explores the optimal periodical reallocation of capitals into different stocks to pursue long-term profits. Reinforcement learning (RL) has recently shown its potential to train profitable agents for PM through interacting with financial markets. However, existing work mostly focuses on fixed stock pools, which is inconsistent with investors' practical demand. Specifically, the target stock pool of different investors varies dramatically due to their discrepancy on market states and individual investors may temporally adjust stocks they desire to trade (e.g., adding one popular stocks), which lead to customizable stock pools (CSPs). Existing RL methods require to retrain RL agents even with a tiny change of the stock pool, which leads to high computational cost and unstable performance. To tackle this challenge, we propose EarnMore, a rEinforcement leARNing framework with Maskable stOck REpresentation to handle PM with CSPs through one-shot training in a global stock pool (GSP). Specifically, we first introduce a mechanism to mask out the representation of the stocks outside the target pool. Second, we learn meaningful stock representations through a self-supervised masking and reconstruction process. Third, a re-weighting mechanism is designed to make the portfolio concentrate on favorable stocks and neglect the stocks outside the target pool. Through extensive experiments on 8 subset stock pools of the US stock market, we demonstrate that EarnMore significantly outperforms 14 state-of-the-art baselines in terms of 6 popular financial metrics with over 40% improvement on profit.","creator":"Wentao Zhang"},{"id":"2311.10804","slug":"a-study-on-altering-the-latent-space-of-pretrained-text-to-speech-models-for-improved-expressiveness-arxiv-2311-10804v1-cs-cl","title":"A Study on Altering the Latent Space of Pretrained Text to Speech Models for Improved Expressiveness.","link":"http://arxiv.org/abs/2311.10804","abstract":"This report explores the challenge of enhancing expressiveness control in Text-to-Speech (TTS) models by augmenting a frozen pretrained model with a Diffusion Model that is conditioned on joint semantic audio/text embeddings. The paper identifies the challenges encountered when working with a VAE-based TTS model and evaluates different image-to-image methods for altering latent speech features. Our results offer valuable insights into the complexities of adding expressiveness control to TTS systems and open avenues for future research in this direction.","creator":"Mathias Vogel"},{"id":"2311.10805","slug":"towards-a-standardized-reinforcement-learning-framework-for-aam-contingency-management-arxiv-2311-10805v1-cs-lg","title":"Towards a Standardized Reinforcement Learning Framework for AAM Contingency Management.","link":"http://arxiv.org/abs/2311.10805","abstract":"Advanced Air Mobility (AAM) is the next generation of air transportation that includes new entrants such as electric vertical takeoff and landing (eVTOL) aircraft, increasingly autonomous flight operations, and small UAS package delivery. With these new vehicles and operational concepts comes a desire to increase densities far beyond what occurs today in and around urban areas, to utilize new battery technology, and to move toward more autonomously-piloted aircraft. To achieve these goals, it becomes essential to introduce new safety management system capabilities that can rapidly assess risk as it evolves across a span of complex hazards and, if necessary, mitigate risk by executing appropriate contingencies via supervised or automated decision-making during flights. Recently, reinforcement learning has shown promise for real-time decision making across a wide variety of applications including contingency management. In this work, we formulate the contingency management problem as a Markov Decision Process (MDP) and integrate the contingency management MDP into the AAM-Gym simulation framework. This enables rapid prototyping of reinforcement learning algorithms and evaluation of existing systems, thus providing a community benchmark for future algorithm development. We report baseline statistical information for the environment and provide example performance metrics.","creator":"Luis E. Alvarez, Marc W. Brittain, Kara Breeden"},{"id":"2311.10806","slug":"sea-multi-graph-based-high-order-sensor-alignment-for-multivariate-time-series-unsupervised-domain-adaptation-arxiv-2311-10806v1-cs-lg","title":"SEA++: Multi-Graph-based High-Order Sensor Alignment for Multivariate Time-Series Unsupervised Domain Adaptation.","link":"http://arxiv.org/abs/2311.10806","abstract":"Unsupervised Domain Adaptation (UDA) methods have been successful in reducing label dependency by minimizing the domain discrepancy between a labeled source domain and an unlabeled target domain. However, these methods face challenges when dealing with Multivariate Time-Series (MTS) data. MTS data typically consist of multiple sensors, each with its own unique distribution. This characteristic makes it hard to adapt existing UDA methods, which mainly focus on aligning global features while overlooking the distribution discrepancies at the sensor level, to reduce domain discrepancies for MTS data. To address this issue, a practical domain adaptation scenario is formulated as Multivariate Time-Series Unsupervised Domain Adaptation (MTS-UDA). In this paper, we propose SEnsor Alignment (SEA) for MTS-UDA, aiming to reduce domain discrepancy at both the local and global sensor levels. At the local sensor level, we design endo-feature alignment, which aligns sensor features and their correlations across domains. To reduce domain discrepancy at the global sensor level, we design exo-feature alignment that enforces restrictions on global sensor features. We further extend SEA to SEA++ by enhancing the endo-feature alignment. Particularly, we incorporate multi-graph-based high-order alignment for both sensor features and their correlations. Extensive empirical results have demonstrated the state-of-the-art performance of our SEA and SEA++ on public MTS datasets for MTS-UDA.","creator":"Yucheng Wang, Yuecong Xu, Jianfei Yang, Min Wu, Xiaoli Li, Lihua Xie, Zhenghua Chen"},{"id":"2311.10807","slug":"senetv2-aggregated-dense-layer-for-channelwise-and-global-representations-arxiv-2311-10807v1-cs-cv","title":"SENetV2: Aggregated dense layer for channelwise and global representations.","link":"http://arxiv.org/abs/2311.10807","abstract":"Convolutional Neural Networks (CNNs) have revolutionized image classification by extracting spatial features and enabling state-of-the-art accuracy in vision-based tasks. The squeeze and excitation network proposed module gathers channelwise representations of the input. Multilayer perceptrons (MLP) learn global representation from the data and in most image classification models used to learn extracted features of the image. In this paper, we introduce a novel aggregated multilayer perceptron, a multi-branch dense layer, within the Squeeze excitation residual module designed to surpass the performance of existing architectures. Our approach leverages a combination of squeeze excitation network module with dense layers. This fusion enhances the network's ability to capture channel-wise patterns and have global knowledge, leading to a better feature representation. This proposed model has a negligible increase in parameters when compared to SENet. We conduct extensive experiments on benchmark datasets to validate the model and compare them with established architectures. Experimental results demonstrate a remarkable increase in the classification accuracy of the proposed model.","creator":"Mahendran Narayanan"},{"id":"2311.10809","slug":"extracting-periodontitis-diagnosis-in-clinical-notes-with-roberta-and-regular-expression-arxiv-2311-10809v1-cs-ai","title":"Extracting periodontitis diagnosis in clinical notes with RoBERTa and regular expression.","link":"http://arxiv.org/abs/2311.10809","abstract":"This study aimed to utilize text processing and natural language processing (NLP) models to mine clinical notes for the diagnosis of periodontitis and to evaluate the performance of a named entity recognition (NER) model on different regular expression (RE) methods. Two complexity levels of RE methods were used to extract and generate the training data. The SpaCy package and RoBERTa transformer models were used to build the NER model and evaluate its performance with the manual-labeled gold standards. The comparison of the RE methods with the gold standard showed that as the complexity increased in the RE algorithms, the F1 score increased from 0.3-0.4 to around 0.9. The NER models demonstrated excellent predictions, with the simple RE method showing 0.84-0.92 in the evaluation metrics, and the advanced and combined RE method demonstrating 0.95-0.99 in the evaluation. This study provided an example of the benefit of combining NER methods and NLP models in extracting target information from free-text to structured data and fulfilling the need for missing diagnoses from unstructured notes.","creator":"Yao-Shun Chuang, Chun-Teh Lee, Ryan Brandon, Trung Duong Tran, Oluwabunmi Tokede, Muhammad F. Walji, Xiaoqian Jiang"},{"id":"2311.10810","slug":"use-gpt-j-prompt-generation-with-roberta-for-ner-models-on-diagnosis-extraction-of-periodontal-diagnosis-from-electronic-dental-records-arxiv-2311-10810v1-cs-cl","title":"Use GPT-J Prompt Generation with RoBERTa for NER Models on Diagnosis Extraction of Periodontal Diagnosis from Electronic Dental Records.","link":"http://arxiv.org/abs/2311.10810","abstract":"This study explored the usability of prompt generation on named entity recognition (NER) tasks and the performance in different settings of the prompt. The prompt generation by GPT-J models was utilized to directly test the gold standard as well as to generate the seed and further fed to the RoBERTa model with the spaCy package. In the direct test, a lower ratio of negative examples with higher numbers of examples in prompt achieved the best results with a F1 score of 0.72. The performance revealed consistency, 0.92-0.97 in the F1 score, in all settings after training with the RoBERTa model. The study highlighted the importance of seed quality rather than quantity in feeding NER models. This research reports on an efficient and accurate way to mine clinical notes for periodontal diagnoses, allowing researchers to easily and quickly build a NER model with the prompt generation approach.","creator":"Yao-Shun Chuang, Xiaoqian Jiang, Chun-Teh Lee, Ryan Brandon, Duong Tran, Oluwabunmi Tokede, Muhammad F. Walji"},{"id":"2311.10811","slug":"a-novel-post-hoc-explanation-comparison-metric-and-applications-arxiv-2311-10811v1-cs-lg","title":"A novel post-hoc explanation comparison metric and applications.","link":"http://arxiv.org/abs/2311.10811","abstract":"Explanatory systems make the behavior of machine learning models more transparent, but are often inconsistent. To quantify the differences between explanatory systems, this paper presents the Shreyan Distance, a novel metric based on the weighted difference between ranked feature importance lists produced by such systems. This paper uses the Shreyan Distance to compare two explanatory systems, SHAP and LIME, for both regression and classification learning tasks. Because we find that the average Shreyan Distance varies significantly between these two tasks, we conclude that consistency between explainers not only depends on inherent properties of the explainers themselves, but also the type of learning task. This paper further contributes the XAISuite library, which integrates the Shreyan distance algorithm into machine learning pipelines.","creator":"Shreyan Mitra, Leilani Gilpin"},{"id":"2311.10813","slug":"a-language-agent-for-autonomous-driving-arxiv-2311-10813v1-cs-cv","title":"A Language Agent for Autonomous Driving.","link":"http://arxiv.org/abs/2311.10813","abstract":"Human-level driving is an ultimate goal of autonomous driving. Conventional approaches formulate autonomous driving as a perception-prediction-planning framework, yet their systems do not capitalize on the inherent reasoning ability and experiential knowledge of humans. In this paper, we propose a fundamental paradigm shift from current pipelines, exploiting Large Language Models (LLMs) as a cognitive agent to integrate human-like intelligence into autonomous driving systems. Our approach, termed Agent-Driver, transforms the traditional autonomous driving pipeline by introducing a versatile tool library accessible via function calls, a cognitive memory of common sense and experiential knowledge for decision-making, and a reasoning engine capable of chain-of-thought reasoning, task planning, motion planning, and self-reflection. Powered by LLMs, our Agent-Driver is endowed with intuitive common sense and robust reasoning capabilities, thus enabling a more nuanced, human-like approach to autonomous driving. We evaluate our approach on the large-scale nuScenes benchmark, and extensive experiments substantiate that our Agent-Driver significantly outperforms the state-of-the-art driving methods by a large margin. Our approach also demonstrates superior interpretability and few-shot learning ability to these methods. Project page: \\href{https://github.com/USC-GVL/Agent-Driver/blob/main/index.html}{here}.","creator":"Jiageng Mao, Junjie Ye, Yuxi Qian, Marco Pavone, Yue Wang"},{"id":"2311.10832","slug":"exploring-machine-learning-models-for-federated-learning-a-review-of-approaches-performance-and-limitations-arxiv-2311-10832v1-cs-lg","title":"Exploring Machine Learning Models for Federated Learning: A Review of Approaches, Performance, and Limitations.","link":"http://arxiv.org/abs/2311.10832","abstract":"In the growing world of artificial intelligence, federated learning is a distributed learning framework enhanced to preserve the privacy of individuals' data. Federated learning lays the groundwork for collaborative research in areas where the data is sensitive. Federated learning has several implications for real-world problems. In times of crisis, when real-time decision-making is critical, federated learning allows multiple entities to work collectively without sharing sensitive data. This distributed approach enables us to leverage information from multiple sources and gain more diverse insights. This paper is a systematic review of the literature on privacy-preserving machine learning in the last few years based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Specifically, we have presented an extensive review of supervised/unsupervised machine learning algorithms, ensemble methods, meta-heuristic approaches, blockchain technology, and reinforcement learning used in the framework of federated learning, in addition to an overview of federated learning applications. This paper reviews the literature on the components of federated learning and its applications in the last few years. The main purpose of this work is to provide researchers and practitioners with a comprehensive overview of federated learning from the machine learning point of view. A discussion of some open problems and future research directions in federated learning is also provided.","creator":"Elaheh Jafarigol, Theodore Trafalis, Talayeh Razzaghi, Mona Zamankhani"},{"id":"2311.10840","slug":"integration-and-implementation-strategies-for-ai-algorithm-deployment-with-smart-routing-rules-and-workflow-management-arxiv-2311-10840v1-cs-ai","title":"Integration and Implementation Strategies for AI Algorithm Deployment with Smart Routing Rules and Workflow Management.","link":"http://arxiv.org/abs/2311.10840","abstract":"This paper reviews the challenges hindering the widespread adoption of artificial intelligence (AI) solutions in the healthcare industry, focusing on computer vision applications for medical imaging, and how interoperability and enterprise-grade scalability can be used to address these challenges. The complex nature of healthcare workflows, intricacies in managing large and secure medical imaging data, and the absence of standardized frameworks for AI development pose significant barriers and require a new paradigm to address them. The role of interoperability is examined in this paper as a crucial factor in connecting disparate applications within healthcare workflows. Standards such as DICOM, Health Level 7 HL7, and Integrating the Healthcare Enterprise (IHE) are highlighted as foundational for common imaging workflows. A specific focus is placed on the role of DICOM gateways, with Laurel Bridge leading transformational efforts in this area. To drive enterprise scalability, new tools are needed. Project MONAI, established in 2019, is introduced as an initiative aiming to redefine the development of medical AI applications. The MONAI Deploy App SDK, a component of Project MONAI, is identified as a key tool in simplifying the packaging and deployment process, enabling repeatable, scalable, and standardized deployment patterns for AI applications. The abstract underscores the potential impact of successful AI adoption in healthcare, offering physicians both life-saving and time-saving insights and driving efficiencies in radiology department workflows. The collaborative efforts between academia and industry, exemplified by collaborations with organizations like NVIDIA and Laurel Bridge, are emphasized as essential for advancing the adoption of healthcare AI solutions.","creator":"Barbaros Selnur Erdal, Vikash Gupta, Mutlu Demirer, Kim H. Fair, Richard D. White, Jeff Blair, Barbara Deichert, Laurie Lafleur, Ming Melvin Qin, David Bericat, Brad Genereaux"},{"id":"2311.10844","slug":"artificial-intelligence-in-fetal-resting-state-functional-mri-brain-segmentation-a-comparative-analysis-of-3d-unet-vnet-and-highres-net-models-arxiv-2311-10844v1-q-bio-nc","title":"Artificial Intelligence in Fetal Resting-State Functional MRI Brain Segmentation: A Comparative Analysis of 3D UNet, VNet, and HighRes-Net Models.","link":"http://arxiv.org/abs/2311.10844","abstract":"Introduction: Fetal resting-state functional magnetic resonance imaging (rs-fMRI) is a rapidly evolving field that provides valuable insight into brain development before birth. Accurate segmentation of the fetal brain from the surrounding tissue in nonstationary 3D brain volumes poses a significant challenge in this domain. Current available tools have 0.15 accuracy. Aim: This study introduced a novel application of artificial intelligence (AI) for automated brain segmentation in fetal brain fMRI, magnetic resonance imaging (fMRI). Open datasets were employed to train AI models, assess their performance, and analyze their capabilities and limitations in addressing the specific challenges associated with fetal brain fMRI segmentation. Method: We utilized an open-source fetal functional MRI (fMRI) dataset consisting of 160 cases (reference: fetal-fMRI - OpenNeuro). An AI model for fMRI segmentation was developed using a 5-fold cross-validation methodology. Three AI models were employed: 3D UNet, VNet, and HighResNet. Optuna, an automated hyperparameter-tuning tool, was used to optimize these models. Results and Discussion: The Dice scores of the three AI models (VNet, UNet, and HighRes-net) were compared, including a comparison between manually tuned and automatically tuned models using Optuna. Our findings shed light on the performance of different AI models for fetal resting-state fMRI brain segmentation. Although the VNet model showed promise in this application, further investigation is required to fully explore the potential and limitations of each model, including the HighRes-net model. This study serves as a foundation for further extensive research into the applications of AI in fetal brain fMRI segmentation.","creator":"Farzan Vahedifard, Xuchu Liu, Mehmet Kocak, H. Asher Ai, Mark Supanich, Christopher Sica., Kranthi K Marathu, Seth Adler, Maysam Orouskhani, Sharon Byrd"},{"id":"2311.10856","slug":"exploring-the-consistency-quality-and-challenges-in-manual-and-automated-coding-of-free-text-diagnoses-from-hospital-outpatient-letters-arxiv-2311-10856v1-cs-ai","title":"Exploring the Consistency, Quality and Challenges in Manual and Automated Coding of Free-text Diagnoses from Hospital Outpatient Letters.","link":"http://arxiv.org/abs/2311.10856","abstract":"Coding of unstructured clinical free-text to produce interoperable structured data is essential to improve direct care, support clinical communication and to enable clinical research.However, manual clinical coding is difficult and time consuming, which motivates the development and use of natural language processing for automated coding. This work evaluates the quality and consistency of both manual and automated clinical coding of diagnoses from hospital outpatient letters. Using 100 randomly selected letters, two human clinicians performed coding of diagnosis lists to SNOMED CT. Automated coding was also performed using IMO's Concept Tagger. A gold standard was constructed by a panel of clinicians from a subset of the annotated diagnoses. This was used to evaluate the quality and consistency of both manual and automated coding via (1) a distance-based metric, treating SNOMED CT as a graph, and (2) a qualitative metric agreed upon by the panel of clinicians. Correlation between the two metrics was also evaluated. Comparing human and computer-generated codes to the gold standard, the results indicate that humans slightly out-performed automated coding, while both performed notably better when there was only a single diagnosis contained in the free-text description. Automated coding was considered acceptable by the panel of clinicians in approximately 90% of cases.","creator":"Warren Del-Pinto, George Demetriou, Meghna Jani, Rikesh Patel, Leanne Gray, Alex Bulcock, Niels Peek, Andrew S. Kanter, William G Dixon, Goran Nenadic"},{"id":"2311.10862","slug":"formal-concept-analysis-for-evaluating-intrinsic-dimension-of-a-natural-language-arxiv-2311-10862v1-cs-cl","title":"Formal concept analysis for evaluating intrinsic dimension of a natural language.","link":"http://arxiv.org/abs/2311.10862","abstract":"Some results of a computational experiment for determining the intrinsic dimension of linguistic varieties for the Bengali and Russian languages are presented. At the same time, both sets of words and sets of bigrams in these languages were considered separately. The method used to solve this problem was based on formal concept analysis algorithms. It was found that the intrinsic dimensions of these languages are significantly less than the dimensions used in popular neural network models in natural language processing.","creator":"Sergei O. Kuznetsov, Vasilii A. Gromov, Nikita S. Borodin, Andrei M. Divavin"},{"id":"2311.10863","slug":"verified-compositional-neuro-symbolic-control-for-stochastic-systems-with-temporal-logic-tasks-arxiv-2311-10863v1-cs-ro","title":"Verified Compositional Neuro-Symbolic Control for Stochastic Systems with Temporal Logic Tasks.","link":"http://arxiv.org/abs/2311.10863","abstract":"Several methods have been proposed recently to learn neural network (NN) controllers for autonomous agents, with unknown and stochastic dynamics, tasked with complex missions captured by Linear Temporal Logic (LTL). Due to the sample-inefficiency of the majority of these works, compositional learning methods have been proposed decomposing the LTL specification into smaller sub-tasks. Then, separate controllers are learned and composed to satisfy the original task. A key challenge within these approaches is that they often lack safety guarantees or the provided guarantees are impractical. This paper aims to address this challenge. Particularly, we consider autonomous systems with unknown and stochastic dynamics and LTL-encoded tasks. We assume that the system is equipped with a finite set of base skills modeled by trained NN feedback controllers. Our goal is to check if there exists a temporal composition of the trained NN controllers - and if so, to compute it - that will yield a composite system behavior that satisfies the assigned LTL task with probability one. We propose a new approach that relies on a novel integration of automata theory and data-driven reachability analysis tools for NN-controlled stochastic systems. The resulting neuro-symbolic controller allows the agent to generate safe behaviors for unseen complex temporal logic tasks in a zero-shot fashion by leveraging its base skills. We show correctness of the proposed method and we provide conditions under which it is complete. To the best of our knowledge, this is the first work that designs verified temporal compositions of NN controllers for unknown and stochastic systems. Finally, we provide extensive numerical simulations and hardware experiments on robot navigation tasks to demonstrate the proposed method.","creator":"Jun Wang, Kaiyuan Tan, Zihe Sun, Yiannis Kantaros"},{"id":"2311.10892","slug":"the-hidden-linear-structure-in-score-based-models-and-its-application-arxiv-2311-10892v1-cs-ai","title":"The Hidden Linear Structure in Score-Based Models and its Application.","link":"http://arxiv.org/abs/2311.10892","abstract":"Score-based models have achieved remarkable results in the generative modeling of many domains. By learning the gradient of smoothed data distribution, they can iteratively generate samples from complex distribution e.g. natural images.  However, is there any universal structure in the gradient field that will eventually be learned by any neural network? Here, we aim to find such structures through a normative analysis of the score function.  First, we derived the closed-form solution to the scored-based model with a Gaussian score. We claimed that for well-trained diffusion models, the learned score at a high noise scale is well approximated by the linear score of Gaussian. We demonstrated this through empirical validation of pre-trained images diffusion model and theoretical analysis of the score function. This finding enabled us to precisely predict the initial diffusion trajectory using the analytical solution and to accelerate image sampling by 15-30\\% by skipping the initial phase without sacrificing image quality. Our finding of the linear structure in the score-based model has implications for better model design and data pre-processing.","creator":"Binxu Wang, John J. Vastola"},{"id":"2311.10898","slug":"on-functional-activations-in-deep-neural-networks-arxiv-2311-10898v1-cs-ai","title":"On Functional Activations in Deep Neural Networks.","link":"http://arxiv.org/abs/2311.10898","abstract":"Background: Deep neural networks have proven to be powerful computational tools for modeling, prediction, and generation. However, the workings of these models have generally been opaque. Recent work has shown that the performance of some models are modulated by overlapping functional networks of connections within the models. Here the techniques of functional neuroimaging are applied to an exemplary large language model to probe its functional structure. Methods: A series of block-designed task-based prompt sequences were generated to probe the Facebook Galactica-125M model. Tasks included prompts relating to political science, medical imaging, paleontology, archeology, pathology, and random strings presented in an off/on/off pattern with prompts about other random topics. For the generation of each output token, all layer output values were saved to create an effective time series. General linear models were fit to the data to identify layer output values which were active with the tasks. Results: Distinct, overlapping networks were identified with each task. Most overlap was observed between medical imaging and pathology networks. These networks were repeatable across repeated performance of related tasks, and correspondence of identified functional networks and activation in tasks not used to define the functional networks was shown to accurately identify the presented task. Conclusion: The techniques of functional neuroimaging can be applied to deep neural networks as a means to probe their workings. Identified functional networks hold the potential for use in model alignment, modulation of model output, and identifying weights to target in fine-tuning.","creator":"Andrew S. Nencka, L. Tugan Muftuler, Peter LaViolette, Kevin M. Koch"},{"id":"2311.10905","slug":"flexible-model-interpretability-through-natural-language-model-editing-arxiv-2311-10905v1-cs-cl","title":"Flexible Model Interpretability through Natural Language Model Editing.","link":"http://arxiv.org/abs/2311.10905","abstract":"Model interpretability and model editing are crucial goals in the age of large language models. Interestingly, there exists a link between these two goals: if a method is able to systematically edit model behavior with regard to a human concept of interest, this editor method can help make internal representations more interpretable by pointing towards relevant representations and systematically manipulating them.","creator":"Karel D&#x27;Oosterlinck, Thomas Demeester, Chris Develder, Christopher Potts"},{"id":"2311.10920","slug":"understanding-and-mitigating-classification-errors-through-interpretable-token-patterns-arxiv-2311-10920v1-cs-cl","title":"Understanding and Mitigating Classification Errors Through Interpretable Token Patterns.","link":"http://arxiv.org/abs/2311.10920","abstract":"State-of-the-art NLP methods achieve human-like performance on many tasks, but make errors nevertheless. Characterizing these errors in easily interpretable terms gives insight into whether a classifier is prone to making systematic errors, but also gives a way to act and improve the classifier. We propose to discover those patterns of tokens that distinguish correct and erroneous predictions as to obtain global and interpretable descriptions for arbitrary NLP classifiers. We formulate the problem of finding a succinct and non-redundant set of such patterns in terms of the Minimum Description Length principle. Through an extensive set of experiments, we show that our method, Premise, performs well in practice. Unlike existing solutions, it recovers ground truth, even on highly imbalanced data over large vocabularies. In VQA and NER case studies, we confirm that it gives clear and actionable insight into the systematic errors made by NLP classifiers.","creator":"Michael A. Hedderich, Jonas Fischer, Dietrich Klakow, Jilles Vreeken"},{"id":"2311.10921","slug":"compact-and-intuitive-airfoil-parameterization-method-through-physics-aware-variational-autoencoder-arxiv-2311-10921v1-cs-lg","title":"Compact and Intuitive Airfoil Parameterization Method through Physics-aware Variational Autoencoder.","link":"http://arxiv.org/abs/2311.10921","abstract":"Airfoil shape optimization plays a critical role in the design of high-performance aircraft. However, the high-dimensional nature of airfoil representation causes the challenging problem known as the \"curse of dimensionality\". To overcome this problem, numerous airfoil parameterization methods have been developed, which can be broadly classified as polynomial-based and data-driven approaches. Each of these methods has desirable characteristics such as flexibility, parsimony, feasibility, and intuitiveness, but a single approach that encompasses all of these attributes has yet to be found. For example, polynomial-based methods struggle to balance parsimony and flexibility, while data-driven methods lack in feasibility and intuitiveness. In recent years, generative models, such as generative adversarial networks and variational autoencoders, have shown promising potential in airfoil parameterization. However, these models still face challenges related to intuitiveness due to their black-box nature. To address this issue, we developed a novel airfoil parameterization method using physics-aware variational autoencoder. The proposed method not only explicitly separates the generation of thickness and camber distributions to produce smooth and non-intersecting airfoils, thereby improving feasibility, but it also directly aligns its latent dimensions with geometric features of the airfoil, significantly enhancing intuitiveness. Finally, extensive comparative studies were performed to demonstrate the effectiveness of our approach.","creator":"Yu-Eop Kang, Dawoon Lee, Kwanjung Yee"},{"id":"2311.10922","slug":"explainable-product-classification-for-customs-arxiv-2311-10922v1-cs-ai","title":"Explainable Product Classification for Customs.","link":"http://arxiv.org/abs/2311.10922","abstract":"The task of assigning internationally accepted commodity codes (aka HS codes) to traded goods is a critical function of customs offices. Like court decisions made by judges, this task follows the doctrine of precedent and can be nontrivial even for experienced officers. Together with the Korea Customs Service (KCS), we propose a first-ever explainable decision supporting model that suggests the most likely subheadings (i.e., the first six digits) of the HS code. The model also provides reasoning for its suggestion in the form of a document that is interpretable by customs officers. We evaluated the model using 5,000 cases that recently received a classification request. The results showed that the top-3 suggestions made by our model had an accuracy of 93.9\\% when classifying 925 challenging subheadings. A user study with 32 customs experts further confirmed that our algorithmic suggestions accompanied by explainable reasonings, can substantially reduce the time and effort taken by customs officers for classification reviews.","creator":"Eunji Lee, Sihyeon Kim, Sundong Kim, Soyeon Jung, Heeja Kim, Meeyoung Cha"},{"id":"2311.10928","slug":"camra-copilot-for-amr-annotation-arxiv-2311-10928v1-cs-cl","title":"CAMRA: Copilot for AMR Annotation.","link":"http://arxiv.org/abs/2311.10928","abstract":"In this paper, we introduce CAMRA (Copilot for AMR Annotatations), a cutting-edge web-based tool designed for constructing Abstract Meaning Representation (AMR) from natural language text. CAMRA offers a novel approach to deep lexical semantics annotation such as AMR, treating AMR annotation akin to coding in programming languages. Leveraging the familiarity of programming paradigms, CAMRA encompasses all essential features of existing AMR editors, including example lookup, while going a step further by integrating Propbank roleset lookup as an autocomplete feature within the tool. Notably, CAMRA incorporates AMR parser models as coding co-pilots, greatly enhancing the efficiency and accuracy of AMR annotators. To demonstrate the tool's capabilities, we provide a live demo accessible at: https://camra.colorado.edu","creator":"Jon Z. Cai, Shafiuddin Rehan Ahmed, Julia Bonn, Kristin Wright-Bettner, Martha Palmer, James H. Martin"},{"id":"2311.10931","slug":"florida-fake-looking-real-images-dataset-arxiv-2311-10931v1-cs-cv","title":"FLORIDA: Fake-looking Real Images Dataset.","link":"http://arxiv.org/abs/2311.10931","abstract":"Although extensive research has been carried out to evaluate the effectiveness of AI tools and models in detecting deep fakes, the question remains unanswered regarding whether these models can accurately identify genuine images that appear artificial. In this study, as an initial step towards addressing this issue, we have curated a dataset of 510 genuine images that exhibit a fake appearance and conducted an assessment using two AI models. We show that two models exhibited subpar performance when applied to our dataset. Additionally, our dataset can serve as a valuable tool for assessing the ability of deep learning models to comprehend complex visual stimuli. We anticipate that this research will stimulate further discussions and investigations in this area. Our dataset is accessible at https://github.com/aliborji/FLORIDA.","creator":"Ali Borji"},{"id":"2311.10932","slug":"cognitive-bias-in-large-language-models-cautious-optimism-meets-anti-panglossian-meliorism-arxiv-2311-10932v1-cs-ai","title":"Cognitive bias in large language models: Cautious optimism meets anti-Panglossian meliorism.","link":"http://arxiv.org/abs/2311.10932","abstract":"Traditional discussions of bias in large language models focus on a conception of bias closely tied to unfairness, especially as affecting marginalized groups. Recent work raises the novel possibility of assessing the outputs of large language models for a range of cognitive biases familiar from research in judgment and decisionmaking. My aim in this paper is to draw two lessons from recent discussions of cognitive bias in large language models: cautious optimism about the prevalence of bias in current models coupled with an anti-Panglossian willingness to concede the existence of some genuine biases and work to reduce them. I draw out philosophical implications of this discussion for the rationality of human cognitive biases as well as the role of unrepresentative data in driving model biases.","creator":"David Thorstad"},{"id":"2311.10933","slug":"representing-visual-classification-as-a-linear-combination-of-words-arxiv-2311-10933v1-cs-ai","title":"Representing visual classification as a linear combination of words.","link":"http://arxiv.org/abs/2311.10933","abstract":"Explainability is a longstanding challenge in deep learning, especially in high-stakes domains like healthcare. Common explainability methods highlight image regions that drive an AI model's decision. Humans, however, heavily rely on language to convey explanations of not only \"where\" but \"what\". Additionally, most explainability approaches focus on explaining individual AI predictions, rather than describing the features used by an AI model in general. The latter would be especially useful for model and dataset auditing, and potentially even knowledge generation as AI is increasingly being used in novel tasks. Here, we present an explainability strategy that uses a vision-language model to identify language-based descriptors of a visual classification task. By leveraging a pre-trained joint embedding space between images and text, our approach estimates a new classification task as a linear combination of words, resulting in a weight for each word that indicates its alignment with the vision-based classifier. We assess our approach using two medical imaging classification tasks, where we find that the resulting descriptors largely align with clinical knowledge despite a lack of domain-specific language training. However, our approach also identifies the potential for 'shortcut connections' in the public datasets used. Towards a functional measure of explainability, we perform a pilot reader study where we find that the AI-identified words can enable non-expert humans to perform a specialized medical task at a non-trivial level. Altogether, our results emphasize the potential of using multimodal foundational models to deliver intuitive, language-based explanations of visual tasks.","creator":"Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter"},{"id":"2311.10934","slug":"case-repositories-towards-case-based-reasoning-for-ai-alignment-arxiv-2311-10934v1-cs-ai","title":"Case Repositories: Towards Case-Based Reasoning for AI Alignment.","link":"http://arxiv.org/abs/2311.10934","abstract":"Case studies commonly form the pedagogical backbone in law, ethics, and many other domains that face complex and ambiguous societal questions informed by human values. Similar complexities and ambiguities arise when we consider how AI should be aligned in practice: when faced with vast quantities of diverse (and sometimes conflicting) values from different individuals and communities, with whose values is AI to align, and how should AI do so? We propose a complementary approach to constitutional AI alignment, grounded in ideas from case-based reasoning (CBR), that focuses on the construction of policies through judgments on a set of cases. We present a process to assemble such a case repository by: 1) gathering a set of ``seed'' cases -- questions one may ask an AI system -- in a particular domain from discussions in online communities, 2) eliciting domain-specific key dimensions for cases through workshops with domain experts, 3) using LLMs to generate variations of cases not seen in the wild, and 4) engaging with the public to judge and improve cases. We then discuss how such a case repository could assist in AI alignment, both through directly acting as precedents to ground acceptable behaviors, and as a medium for individuals and communities to engage in moral reasoning around AI","creator":"K. J. Kevin Feng, Quan Ze (Jim) Chen, Inyoung Cheong, King Xia, Amy X. Zhang"},{"id":"2311.10940","slug":"practical-estimation-of-ensemble-accuracy-arxiv-2311-10940v1-cs-ai","title":"Practical Estimation of Ensemble Accuracy.","link":"http://arxiv.org/abs/2311.10940","abstract":"Ensemble learning combines several individual models to obtain better generalization performance. In this work we present a practical method for estimating the joint power of several classifiers which differs from existing approaches by {\\em not relying on labels}, hence enabling the work in unsupervised setting of huge datasets. It differs from existing methods which define a \"diversity measure\".  The heart of the method is a combinatorial bound on the number of mistakes the ensemble is likely to make. The bound can be efficiently approximated in time linear in the number of samples. Thus allowing an efficient search for a combination of classifiers that are likely to produce higher joint accuracy. Moreover, having the bound applicable to unlabeled data makes it both accurate and practical in modern setting of unsupervised learning. We demonstrate the method on popular large-scale face recognition datasets which provide a useful playground for fine-grain classification tasks using noisy data over many classes.  The proposed framework fits neatly in trending practices of unsupervised learning. It is a measure of the inherent independence of a set of classifiers not relying on extra information such as another classifier or labeled data.","creator":"Simi Haber, Yonatan Wexler"},{"id":"2311.10945","slug":"an-empirical-bayes-framework-for-open-domain-dialogue-generation-arxiv-2311-10945v1-cs-cl","title":"An Empirical Bayes Framework for Open-Domain Dialogue Generation.","link":"http://arxiv.org/abs/2311.10945","abstract":"To engage human users in meaningful conversation, open-domain dialogue agents are required to generate diverse and contextually coherent dialogue. Despite recent advancements, which can be attributed to the usage of pretrained language models, the generation of diverse and coherent dialogue remains an open research problem. A popular approach to address this issue involves the adaptation of variational frameworks. However, while these approaches successfully improve diversity, they tend to compromise on contextual coherence. Hence, we propose the Bayesian Open-domain Dialogue with Empirical Bayes (BODEB) framework, an empirical bayes framework for constructing an Bayesian open-domain dialogue agent by leveraging pretrained parameters to inform the prior and posterior parameter distributions. Empirical results show that BODEB achieves better results in terms of both diversity and coherence compared to variational frameworks.","creator":"Jing Yang Lee, Kong Aik Lee, Woon-Seng Gan"},{"id":"2311.10947","slug":"recexplainer-aligning-large-language-models-for-recommendation-model-interpretability-arxiv-2311-10947v1-cs-ir","title":"RecExplainer: Aligning Large Language Models for Recommendation Model Interpretability.","link":"http://arxiv.org/abs/2311.10947","abstract":"Recommender systems are widely used in various online services, with embedding-based models being particularly popular due to their expressiveness in representing complex signals. However, these models often lack interpretability, making them less reliable and transparent for both users and developers. With the emergence of large language models (LLMs), we find that their capabilities in language expression, knowledge-aware reasoning, and instruction following are exceptionally powerful. Based on this, we propose a new model interpretation approach for recommender systems, by using LLMs as surrogate models and learn to mimic and comprehend target recommender models. Specifically, we introduce three alignment methods: behavior alignment, intention alignment, and hybrid alignment. Behavior alignment operates in the language space, representing user preferences and item information as text to learn the recommendation model's behavior; intention alignment works in the latent space of the recommendation model, using user and item representations to understand the model's behavior; hybrid alignment combines both language and latent spaces for alignment training. To demonstrate the effectiveness of our methods, we conduct evaluation from two perspectives: alignment effect, and explanation generation ability on three public datasets. Experimental results indicate that our approach effectively enables LLMs to comprehend the patterns of recommendation models and generate highly credible recommendation explanations.","creator":"Yuxuan Lei, Jianxun Lian, Jing Yao, Xu Huang, Defu Lian, Xing Xie"},{"id":"2311.10953","slug":"hungergist-an-interpretable-predictive-model-for-food-insecurity-arxiv-2311-10953v1-cs-ai","title":"HungerGist: An Interpretable Predictive Model for Food Insecurity.","link":"http://arxiv.org/abs/2311.10953","abstract":"The escalating food insecurity in Africa, caused by factors such as war, climate change, and poverty, demonstrates the critical need for advanced early warning systems. Traditional methodologies, relying on expert-curated data encompassing climate, geography, and social disturbances, often fall short due to data limitations, hindering comprehensive analysis and potential discovery of new predictive factors. To address this, this paper introduces \"HungerGist\", a multi-task deep learning model utilizing news texts and NLP techniques. Using a corpus of over 53,000 news articles from nine African countries over four years, we demonstrate that our model, trained solely on news data, outperforms the baseline method trained on both traditional risk factors and human-curated keywords. In addition, our method has the ability to detect critical texts that contain interpretable signals known as \"gists.\" Moreover, our examination of these gists indicates that this approach has the potential to reveal latent factors that would otherwise remain concealed in unstructured texts.","creator":"Yongsu Ahn, Muheng Yan, Yu-Ru Lin, Zian Wang"},{"id":"2311.10983","slug":"multiple-view-geometry-transformers-for-3d-human-pose-estimation-arxiv-2311-10983v1-cs-cv","title":"Multiple View Geometry Transformers for 3D Human Pose Estimation.","link":"http://arxiv.org/abs/2311.10983","abstract":"In this work, we aim to improve the 3D reasoning ability of Transformers in multi-view 3D human pose estimation. Recent works have focused on end-to-end learning-based transformer designs, which struggle to resolve geometric information accurately, particularly during occlusion. Instead, we propose a novel hybrid model, MVGFormer, which has a series of geometric and appearance modules organized in an iterative manner. The geometry modules are learning-free and handle all viewpoint-dependent 3D tasks geometrically which notably improves the model's generalization ability. The appearance modules are learnable and are dedicated to estimating 2D poses from image signals end-to-end which enables them to achieve accurate estimates even when occlusion occurs, leading to a model that is both accurate and generalizable to new cameras and geometries. We evaluate our approach for both in-domain and out-of-domain settings, where our model consistently outperforms state-of-the-art methods, and especially does so by a significant margin in the out-of-domain setting. We will release the code and models: https://github.com/XunshanMan/MVGFormer.","creator":"Ziwei Liao, Jialiang Zhu, Chunyu Wang, Han Hu, Steven L. Waslander"},{"id":"2311.11014","slug":"lesion-search-with-self-supervised-learning-arxiv-2311-11014v1-cs-cv","title":"Lesion Search with Self-supervised Learning.","link":"http://arxiv.org/abs/2311.11014","abstract":"Content-based image retrieval (CBIR) with self-supervised learning (SSL) accelerates clinicians' interpretation of similar images without manual annotations. We develop a CBIR from the contrastive learning SimCLR and incorporate a generalized-mean (GeM) pooling followed by L2 normalization to classify lesion types and retrieve similar images before clinicians' analysis. Results have shown improved performance. We additionally build an open-source application for image analysis and retrieval. The application is easy to integrate, relieving manual efforts and suggesting the potential to support clinicians' everyday activities.","creator":"Kristin Qi, Jiali Cheng, Daniel Haehn"},{"id":"2311.11029","slug":"geometric-data-augmentations-to-mitigate-distribution-shifts-in-pollen-classification-from-microscopic-images-arxiv-2311-11029v1-cs-cv","title":"Geometric Data Augmentations to Mitigate Distribution Shifts in Pollen Classification from Microscopic Images.","link":"http://arxiv.org/abs/2311.11029","abstract":"Distribution shifts are characterized by differences between the training and test data distributions. They can significantly reduce the accuracy of machine learning models deployed in real-world scenarios. This paper explores the distribution shift problem when classifying pollen grains from microscopic images collected in the wild with a low-cost camera sensor. We leverage the domain knowledge that geometric features are highly important for accurate pollen identification and introduce two novel geometric image augmentation techniques to significantly narrow the accuracy gap between the model performance on the train and test datasets. In particular, we show that Tenengrad and ImageToSketch filters are highly effective to balance the shape and texture information while leaving out unimportant details that may confuse the model. Extensive evaluations on various model architectures demonstrate a consistent improvement of the model generalization to field data of up to 14% achieved by the geometric augmentation techniques when compared to a wide range of standard image augmentations. The approach is validated through an ablation study using pollen hydration tests to recover the shape of dry pollen grains. The proposed geometric augmentations also receive the highest scores according to the affinity and diversity measures from the literature.","creator":"Nam Cao, Olga Saukh"},{"id":"2311.11030","slug":"data-center-audio-video-intelligence-on-device-david-an-edge-ai-platform-for-smart-toys-arxiv-2311-11030v1-cs-ai","title":"Data Center Audio/Video Intelligence on Device (DAVID) -- An Edge-AI Platform for Smart-Toys.","link":"http://arxiv.org/abs/2311.11030","abstract":"An overview is given of the DAVID Smart-Toy platform, one of the first Edge AI platform designs to incorporate advanced low-power data processing by neural inference models co-located with the relevant image or audio sensors. There is also on-board capability for in-device text-to-speech generation. Two alternative embodiments are presented: a smart Teddy-bear, and a roving dog-like robot. The platform offers a speech-driven user interface and can observe and interpret user actions and facial expressions via its computer vision sensor node. A particular benefit of this design is that no personally identifiable information passes beyond the neural inference nodes thus providing inbuilt compliance with data protection regulations.","creator":"Gabriel Cosache, Francisco Salgado, Cosmin Rotariu, George Sterpu, Rishabh Jain, Peter Corcoran"},{"id":"2311.11039","slug":"synthetic-data-generation-for-bridging-sim2real-gap-in-a-production-environment-arxiv-2311-11039v1-cs-cv","title":"Synthetic Data Generation for Bridging Sim2Real Gap in a Production Environment.","link":"http://arxiv.org/abs/2311.11039","abstract":"Synthetic data is being used lately for training deep neural networks in computer vision applications such as object detection, object segmentation and 6D object pose estimation. Domain randomization hereby plays an important role in reducing the simulation to reality gap. However, this generalization might not be effective in specialized domains like a production environment involving complex assemblies. Either the individual parts, trained with synthetic images, are integrated in much larger assemblies making them indistinguishable from their counterparts and result in false positives or are partially occluded just enough to give rise to false negatives. Domain knowledge is vital in these cases and if conceived effectively while generating synthetic data, can show a considerable improvement in bridging the simulation to reality gap. This paper focuses on synthetic data generation procedures for parts and assemblies used in a production environment. The basic procedures for synthetic data generation and their various combinations are evaluated and compared on images captured in a production environment, where results show up to 15% improvement using combinations of basic procedures. Reducing the simulation to reality gap in this way can aid to utilize the true potential of robot assisted production using artificial intelligence.","creator":"Parth Rawal, Mrunal Sompura, Wolfgang Hintze"},{"id":"2311.11045","slug":"orca-2-teaching-small-language-models-how-to-reason-arxiv-2311-11045v1-cs-ai","title":"Orca 2: Teaching Small Language Models How to Reason.","link":"http://arxiv.org/abs/2311.11045","abstract":"Orca 1 learns from rich signals, such as explanation traces, allowing it to outperform conventional instruction-tuned models on benchmarks like BigBench Hard and AGIEval. In Orca 2, we continue exploring how improved training signals can enhance smaller LMs' reasoning abilities. Research on training small LMs has often relied on imitation learning to replicate the output of more capable models. We contend that excessive emphasis on imitation may restrict the potential of smaller models. We seek to teach small LMs to employ different solution strategies for different tasks, potentially different from the one used by the larger model. For example, while larger models might provide a direct answer to a complex task, smaller models may not have the same capacity. In Orca 2, we teach the model various reasoning techniques (step-by-step, recall then generate, recall-reason-generate, direct answer, etc.). More crucially, we aim to help the model learn to determine the most effective solution strategy for each task. We evaluate Orca 2 using a comprehensive set of 15 diverse benchmarks (corresponding to approximately 100 tasks and over 36,000 unique prompts). Orca 2 significantly surpasses models of similar size and attains performance levels similar or better to those of models 5-10x larger, as assessed on complex tasks that test advanced reasoning abilities in zero-shot settings. We open-source Orca 2 to encourage further research on the development, evaluation, and alignment of smaller LMs.","creator":"Arindam Mitra, Luciano Del Corro, Shweti Mahajan, Andres Codas, Clarisse Simoes, Sahaj Agrawal, Xuxi Chen, Anastasia Razdaibiedina, Erik Jones, Kriti Aggarwal, Hamid Palangi, Guoqing Zheng, Corby Rosset, Hamed Khanpour, Ahmed Awadallah"},{"id":"2311.11055","slug":"designing-interpretable-ml-system-to-enhance-trustworthy-ai-in-healthcare-a-systematic-review-of-the-last-decade-to-a-proposed-robust-framework-arxiv-2311-11055v1-cs-ai","title":"Designing Interpretable ML System to Enhance Trustworthy AI in Healthcare: A Systematic Review of the Last Decade to A Proposed Robust Framework.","link":"http://arxiv.org/abs/2311.11055","abstract":"AI-based medical technologies, including wearables, telemedicine, LLMs, and digital care twins, significantly impact healthcare. Ensuring AI results are accurate and interpretable is crucial, especially for clinicians. This paper reviews processes and challenges of interpretable ML (IML) and explainable AI (XAI) in healthcare. Objectives include reviewing XAI processes, methods, applications, and challenges, with a focus on quality control. The IML process is classified into data pre-processing interpretability, interpretable modeling, and post-processing interpretability. The paper aims to establish the importance of robust interpretability in healthcare through experimental results, providing insights for creating communicable clinician-AI tools. Research questions, eligibility criteria, and goals were identified following PRISMA and PICO methods. PubMed, Scopus, and Web of Science were systematically searched using specific strings. The survey introduces a step-by-step roadmap for implementing XAI in clinical applications, addressing existing gaps and acknowledging XAI model limitations.","creator":"Elham Nasarian, Roohallah Alizadehsani, U. Rajendra Acharyac, d Kwok-Leung Tsui"},{"id":"1904.10552","slug":"ml-kfhe-multi-label-ensemble-classification-algorithm-exploiting-sensor-fusion-properties-of-the-kalman-filter-arxiv-1904-10552v4-cs-lg-updated","title":"ML-KFHE: Multi-label ensemble classification algorithm exploiting sensor fusion properties of the Kalman filter.","link":"http://arxiv.org/abs/1904.10552","abstract":"Despite the success of ensemble classification methods in multi-class classification problems, ensemble methods based on approaches other than bagging have not been widely explored for multi-label classification problems. The Kalman Filter-based Heuristic Ensemble (KFHE) is an ensemble method that exploits the sensor fusion properties of the Kalman filter to combine several classifier models, and that has been shown to be very effective. This work proposes a multi-label version of KFHE, ML-KFHE, demonstrating the effectiveness of the KFHE method on multi-label datasets. Two variants are introduced based on the underlying component classifier algorithm, ML-KFHE-HOMER, and ML-KFHE-CC which uses HOMER and Classifier Chain (CC) as the underlying multi-label algorithms respectively. ML-KFHE-HOMER and ML-KFHE-CC sequentially train multiple HOMER and CC multi-label classifiers and aggregate their outputs using the sensor fusion properties of the Kalman filter. Extensive experiments and detailed analysis were performed on thirteen multi-label datasets and eight other algorithms, which included state-of-the-art ensemble methods. The results show, for both versions, the ML-KFHE framework improves the predictive performance significantly with respect to bagged combinations of HOMER (named E-HOMER), also introduced in this paper, and bagged combination of CC, Ensemble Classifier Chains (ECC), thus demonstrating the effectiveness of ML-KFHE. Also, the ML-KFHE-HOMER variant was found to perform consistently and significantly better than the compared multi-label methods including existing approaches based on ensembles.","creator":"Arjun Pakrashi, Brian Mac Namee"},{"id":"2009.07448","slug":"question-directed-graph-attention-network-for-numerical-reasoning-over-text-arxiv-2009-07448v2-cs-ai-updated","title":"Question Directed Graph Attention Network for Numerical Reasoning over Text.","link":"http://arxiv.org/abs/2009.07448","abstract":"Numerical reasoning over texts, such as addition, subtraction, sorting and counting, is a challenging machine reading comprehension task, since it requires both natural language understanding and arithmetic computation. To address this challenge, we propose a heterogeneous graph representation for the context of the passage and question needed for such reasoning, and design a question directed graph attention network to drive multi-step numerical reasoning over this context graph. The code link is at: https://github.com/emnlp2020qdgat/QDGAT","creator":"Kunlong Chen, Weidi Xu, Xingyi Cheng, Zou Xiaochuan, Yuyu Zhang, Le Song, Taifeng Wang, Yuan Qi, Wei Chu"},{"id":"2109.00388","slug":"boolean-proportions-arxiv-2109-00388v5-cs-ai-updated","title":"Boolean proportions.","link":"http://arxiv.org/abs/2109.00388","abstract":"The author has recently introduced an abstract algebraic framework of analogical proportions within the general setting of universal algebra. This paper studies analogical proportions in the boolean domain consisting of two elements 0 and 1 within his framework. It turns out that our notion of boolean proportions coincides with two prominent models from the literature in different settings. This means that we can capture two separate modellings of boolean proportions within a single framework which is mathematically appealing and provides further evidence for its robustness and applicability.","creator":"Christian Anti&#x107;"},{"id":"2110.11482","slug":"representations-of-epistemic-uncertainty-and-awareness-in-data-driven-strategies-arxiv-2110-11482v7-cs-ai-updated","title":"Representations of epistemic uncertainty and awareness in data-driven strategies.","link":"http://arxiv.org/abs/2110.11482","abstract":"The diffusion of AI and big data is reshaping decision-making processes by increasing the amount of information that supports decisions while reducing direct interaction with data and empirical evidence. This paradigm shift introduces new sources of uncertainty, as limited data observability results in ambiguity and a lack of interpretability. The need for the proper analysis of data-driven strategies motivates the search for new models that can describe this type of bounded access to knowledge. This contribution presents a novel theoretical model for uncertainty in knowledge representation and its transfer mediated by agents. We provide a dynamical description of knowledge states by endowing our model with a structure to compare and combine them. Specifically, an update is represented through combinations, and its explainability is based on its consistency in different dimensional representations. We look at inequivalent knowledge representations in terms of multiplicity of inferences, preference relations, and information measures. Furthermore, we define a formal analogy with two scenarios that illustrate non-classical uncertainty in terms of ambiguity (Ellsberg's model) and reasoning about knowledge mediated by other agents observing data (Wigner's friend). Finally, we discuss some implications of the proposed model for data-driven strategies, with special attention to reasoning under uncertainty about business value dimensions and the design of measurement tools for their assessment.","creator":"Mario Angelelli, Massimiliano Gervasi"},{"id":"2201.11239","slug":"diagnosing-ai-explanation-methods-with-folk-concepts-of-behavior-arxiv-2201-11239v6-cs-ai-updated","title":"Diagnosing AI Explanation Methods with Folk Concepts of Behavior.","link":"http://arxiv.org/abs/2201.11239","abstract":"We investigate a formalism for the conditions of a successful explanation of AI. We consider \"success\" to depend not only on what information the explanation contains, but also on what information the human explainee understands from it. Theory of mind literature discusses the folk concepts that humans use to understand and generalize behavior. We posit that folk concepts of behavior provide us with a \"language\" that humans understand behavior with. We use these folk concepts as a framework of social attribution by the human explainee - the information constructs that humans are likely to comprehend from explanations - by introducing a blueprint for an explanatory narrative (Figure 1) that explains AI behavior with these constructs. We then demonstrate that many XAI methods today can be mapped to folk concepts of behavior in a qualitative evaluation. This allows us to uncover their failure modes that prevent current methods from explaining successfully - i.e., the information constructs that are missing for any given XAI method, and whose inclusion can decrease the likelihood of misunderstanding AI behavior.","creator":"Alon Jacovi, Jasmijn Bastings, Sebastian Gehrmann, Yoav Goldberg, Katja Filippova"},{"id":"2207.02249","slug":"learning-task-embeddings-for-teamwork-adaptation-in-multi-agent-reinforcement-learning-arxiv-2207-02249v2-cs-ma-updated","title":"Learning Task Embeddings for Teamwork Adaptation in Multi-Agent Reinforcement Learning.","link":"http://arxiv.org/abs/2207.02249","abstract":"Successful deployment of multi-agent reinforcement learning often requires agents to adapt their behaviour. In this work, we discuss the problem of teamwork adaptation in which a team of agents needs to adapt their policies to solve novel tasks with limited fine-tuning. Motivated by the intuition that agents need to be able to identify and distinguish tasks in order to adapt their behaviour to the current task, we propose to learn multi-agent task embeddings (MATE). These task embeddings are trained using an encoder-decoder architecture optimised for reconstruction of the transition and reward functions which uniquely identify tasks. We show that a team of agents is able to adapt to novel tasks when provided with task embeddings. We propose three MATE training paradigms: independent MATE, centralised MATE, and mixed MATE which vary in the information used for the task encoding. We show that the embeddings learned by MATE identify tasks and provide useful information which agents leverage during adaptation to novel tasks.","creator":"Lukas Sch&#xe4;fer, Filippos Christianos, Amos Storkey, Stefano V. Albrecht"},{"id":"2208.11349","slug":"dynamic-memory-based-curiosity-a-bootstrap-approach-for-exploration-arxiv-2208-11349v2-cs-ai-updated","title":"Dynamic Memory-based Curiosity: A Bootstrap Approach for Exploration.","link":"http://arxiv.org/abs/2208.11349","abstract":"The sparsity of extrinsic rewards poses a serious challenge for reinforcement learning (RL). Currently, many efforts have been made on curiosity which can provide a representative intrinsic reward for effective exploration. However, the challenge is still far from being solved. In this paper, we present a novel curiosity for RL, named DyMeCu, which stands for Dynamic Memory-based Curiosity. Inspired by human curiosity and information theory, DyMeCu consists of a dynamic memory and dual online learners. The curiosity arouses if memorized information can not deal with the current state, and the information gap between dual learners can be formulated as the intrinsic reward for agents, and then such state information can be consolidated into the dynamic memory. Compared with previous curiosity methods, DyMeCu can better mimic human curiosity with dynamic memory, and the memory module can be dynamically grown based on a bootstrap paradigm with dual learners. On multiple benchmarks including DeepMind Control Suite and Atari Suite, large-scale empirical experiments are conducted and the results demonstrate that DyMeCu outperforms competitive curiosity-based methods with or without extrinsic rewards. We will release the code to enhance reproducibility.","creator":"Zijian Gao, YiYing Li, Kele Xu, Yuanzhao Zhai, Dawei Feng, Bo Ding, XinJun Mao, Huaimin Wang"},{"id":"2211.09124","slug":"a-review-of-intelligent-music-generation-systems-arxiv-2211-09124v3-cs-sd-updated","title":"A Review of Intelligent Music Generation Systems.","link":"http://arxiv.org/abs/2211.09124","abstract":"With the introduction of ChatGPT, the public's perception of AI-generated content (AIGC) has begun to reshape. Artificial intelligence has significantly reduced the barrier to entry for non-professionals in creative endeavors, enhancing the efficiency of content creation. Recent advancements have seen significant improvements in the quality of symbolic music generation, which is enabled by the use of modern generative algorithms to extract patterns implicit in a piece of music based on rule constraints or a musical corpus. Nevertheless, existing literature reviews tend to present a conventional and conservative perspective on future development trajectories, with a notable absence of thorough benchmarking of generative models. This paper provides a survey and analysis of recent intelligent music generation techniques, outlining their respective characteristics and discussing existing methods for evaluation. Additionally, the paper compares the different characteristics of music generation techniques in the East and West as well as analysing the field's development prospects.","creator":"Lei Wang, Ziyi Zhao, Hanwei Liu, Junwei Pang, Yi Qin, Qidi Wu"},{"id":"2212.08966","slug":"graph-learning-and-its-advancements-on-large-language-models-a-holistic-survey-arxiv-2212-08966v4-cs-ai-updated","title":"Graph Learning and Its Advancements on Large Language Models: A Holistic Survey.","link":"http://arxiv.org/abs/2212.08966","abstract":"Graph learning is a prevalent domain that endeavors to learn the intricate relationships among nodes and the topological structure of graphs. Over the years, graph learning has transcended from graph theory to graph data mining. With the advent of representation learning, it has attained remarkable performance in diverse scenarios. Owing to its extensive application prospects, graph learning attracts copious attention. While some researchers have accomplished impressive surveys on graph learning, they failed to connect related objectives, methods, and applications in a more coherent way. As a result, they did not encompass current ample scenarios and challenging problems due to the rapid expansion of graph learning. Particularly, large language models have recently had a disruptive effect on human life, but they also show relative weakness in structured scenarios. The question of how to make these models more powerful with graph learning remains open. Our survey focuses on the most recent advancements in integrating graph learning with pre-trained language models, specifically emphasizing their application within the domain of large language models. Different from previous surveys on graph learning, we provide a holistic review that analyzes current works from the perspective of graph structure, and discusses the latest applications, trends, and challenges in graph learning. Specifically, we commence by proposing a taxonomy and then summarize the methods employed in graph learning. We then provide a detailed elucidation of mainstream applications. Finally, we propose future directions.","creator":"Shaopeng Wei, Yu Zhao, Xingyan Chen, Qing Li, Fuzhen Zhuang, Ji Liu, Fuji Ren, Gang Kou"},{"id":"2302.00111","slug":"learning-universal-policies-via-text-guided-video-generation-arxiv-2302-00111v3-cs-ai-updated","title":"Learning Universal Policies via Text-Guided Video Generation.","link":"http://arxiv.org/abs/2302.00111","abstract":"A goal of artificial intelligence is to construct an agent that can solve a wide variety of tasks. Recent progress in text-guided image synthesis has yielded models with an impressive ability to generate complex novel images, exhibiting combinatorial generalization across domains. Motivated by this success, we investigate whether such tools can be used to construct more general-purpose agents. Specifically, we cast the sequential decision making problem as a text-conditioned video generation problem, where, given a text-encoded specification of a desired goal, a planner synthesizes a set of future frames depicting its planned actions in the future, after which control actions are extracted from the generated video. By leveraging text as the underlying goal specification, we are able to naturally and combinatorially generalize to novel goals. The proposed policy-as-video formulation can further represent environments with different state and action spaces in a unified space of images, which, for example, enables learning and generalization across a variety of robot manipulation tasks. Finally, by leveraging pretrained language embeddings and widely available videos from the internet, the approach enables knowledge transfer through predicting highly realistic video plans for real robots.","creator":"Yilun Du, Mengjiao Yang, Bo Dai, Hanjun Dai, Ofir Nachum, Joshua B. Tenenbaum, Dale Schuurmans, Pieter Abbeel"},{"id":"2302.05507","slug":"language-decision-transformers-with-exponential-tilt-for-interactive-text-environments-arxiv-2302-05507v2-cs-cl-updated","title":"Language Decision Transformers with Exponential Tilt for Interactive Text Environments.","link":"http://arxiv.org/abs/2302.05507","abstract":"Text-based game environments are challenging because agents must deal with long sequences of text, execute compositional actions using text and learn from sparse rewards. We address these challenges by proposing Language Decision Transformers (LDTs), a framework that is based on transformer language models and decision transformers (DTs). Our LDTs extend DTs with 3 components: (1) exponential tilt to guide the agent towards high obtainable goals, (2) novel goal conditioning methods yielding better results than the traditional return-to-go (sum of all future rewards), and (3) a model of future observations that improves agent performance. LDTs are the first to address offline RL with DTs on these challenging games. Our experiments show that LDTs achieve the highest scores among many different types of agents on some of the most challenging Jericho games, such as Enchanter.","creator":"Nicolas Gontier, Pau Rodriguez, Issam Laradji, David Vazquez, Christopher Pal"},{"id":"2302.06476","slug":"is-chatgpt-a-general-purpose-natural-language-processing-task-solver-arxiv-2302-06476v3-cs-cl-updated","title":"Is ChatGPT a General-Purpose Natural Language Processing Task Solver?.","link":"http://arxiv.org/abs/2302.06476","abstract":"Spurred by advancements in scale, large language models (LLMs) have demonstrated the ability to perform a variety of natural language processing (NLP) tasks zero-shot -- i.e., without adaptation on downstream data. Recently, the debut of ChatGPT has drawn a great deal of attention from the natural language processing (NLP) community due to the fact that it can generate high-quality responses to human input and self-correct previous mistakes based on subsequent conversations. However, it is not yet known whether ChatGPT can serve as a generalist model that can perform many NLP tasks zero-shot. In this work, we empirically analyze the zero-shot learning ability of ChatGPT by evaluating it on 20 popular NLP datasets covering 7 representative task categories. With extensive empirical studies, we demonstrate both the effectiveness and limitations of the current version of ChatGPT. We find that ChatGPT performs well on many tasks favoring reasoning capabilities (e.g., arithmetic reasoning) while it still faces challenges when solving specific tasks such as sequence tagging. We additionally provide in-depth analysis through qualitative case studies.","creator":"Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, Diyi Yang"},{"id":"2302.08143","slug":"learning-to-initialize-can-meta-learning-improve-cross-task-generalization-in-prompt-tuning-arxiv-2302-08143v3-cs-cl-updated","title":"Learning to Initialize: Can Meta Learning Improve Cross-task Generalization in Prompt Tuning?.","link":"http://arxiv.org/abs/2302.08143","abstract":"Prompt tuning (PT) which only tunes the embeddings of an additional sequence of tokens per task, keeping the pre-trained language model (PLM) frozen, has shown remarkable performance in few-shot learning. Despite this, PT has been shown to rely heavily on good initialization of the prompt embeddings. In this work, we study meta prompt tuning (MPT) to systematically explore how meta-learning can help improve (if it can) cross-task generalization in PT through learning to initialize the prompt embeddings from other relevant tasks. We empirically analyze a representative set of meta learning algorithms in a wide range of adaptation settings with different source/target task configurations on a large set of few-shot tasks. With extensive experiments and analysis, we demonstrate the effectiveness of MPT. We find the improvement to be significant particularly on classification tasks. For other kinds of tasks such as question answering, we observe that while MPT can outperform PT in most cases, it does not always outperform multi-task learning. We further provide an in-depth analysis from the perspective of task similarity.","creator":"Chengwei Qin, Qian Li, Ruochen Zhao, Shafiq Joty"},{"id":"2302.11552","slug":"reduce-reuse-recycle-compositional-generation-with-energy-based-diffusion-models-and-mcmc-arxiv-2302-11552v4-cs-lg-updated","title":"Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC.","link":"http://arxiv.org/abs/2302.11552","abstract":"Since their introduction, diffusion models have quickly become the prevailing approach to generative modeling in many domains. They can be interpreted as learning the gradients of a time-varying sequence of log-probability density functions. This interpretation has motivated classifier-based and classifier-free guidance as methods for post-hoc control of diffusion models. In this work, we build upon these ideas using the score-based interpretation of diffusion models, and explore alternative ways to condition, modify, and reuse diffusion models for tasks involving compositional generation and guidance. In particular, we investigate why certain types of composition fail using current techniques and present a number of solutions. We conclude that the sampler (not the model) is responsible for this failure and propose new samplers, inspired by MCMC, which enable successful compositional generation. Further, we propose an energy-based parameterization of diffusion models which enables the use of new compositional operators and more sophisticated, Metropolis-corrected samplers. Intriguingly we find these samplers lead to notable improvements in compositional generation across a wide set of problems such as classifier-guided ImageNet modeling and compositional text-to-image generation.","creator":"Yilun Du, Conor Durkan, Robin Strudel, Joshua B. Tenenbaum, Sander Dieleman, Rob Fergus, Jascha Sohl-Dickstein, Arnaud Doucet, Will Grathwohl"},{"id":"2302.13335","slug":"diffusion-model-augmented-behavioral-cloning-arxiv-2302-13335v3-cs-lg-updated","title":"Diffusion Model-Augmented Behavioral Cloning.","link":"http://arxiv.org/abs/2302.13335","abstract":"Imitation learning addresses the challenge of learning by observing an expert's demonstrations without access to reward signals from environments. Most existing imitation learning methods that do not require interacting with environments either model the expert distribution as the conditional probability p(a|s) (e.g., behavioral cloning, BC) or the joint probability p(s, a). Despite its simplicity, modeling the conditional probability with BC usually struggles with generalization. While modeling the joint probability can lead to improved generalization performance, the inference procedure is often time-consuming and the model can suffer from manifold overfitting. This work proposes an imitation learning framework that benefits from modeling both the conditional and joint probability of the expert distribution. Our proposed diffusion model-augmented behavioral cloning (DBC) employs a diffusion model trained to model expert behaviors and learns a policy to optimize both the BC loss (conditional) and our proposed diffusion model loss (joint). DBC outperforms baselines in various continuous control tasks in navigation, robot arm manipulation, dexterous manipulation, and locomotion. We design additional experiments to verify the limitations of modeling either the conditional probability or the joint probability of the expert distribution as well as compare different generative models. Ablation studies justify the effectiveness of our design choices.","creator":"Hsiang-Chun Wang, Shang-Fu Chen, Ming-Hao Hsu, Chun-Mao Lai, Shao-Hua Sun"},{"id":"2303.06597","slug":"non-orthogonal-multiple-access-enhanced-multi-user-semantic-communication-arxiv-2303-06597v2-eess-sp-updated","title":"Non-Orthogonal Multiple Access Enhanced Multi-User Semantic Communication.","link":"http://arxiv.org/abs/2303.06597","abstract":"Semantic communication serves as a novel paradigm and attracts the broad interest of researchers. One critical aspect of it is the multi-user semantic communication theory, which can further promote its application to the practical network environment. While most existing works focused on the design of end-to-end single-user semantic transmission, a novel non-orthogonal multiple access (NOMA)-based multi-user semantic communication system named NOMASC is proposed in this paper. The proposed system can support semantic tranmission of multiple users with diverse modalities of source information. To avoid high demand for hardware, an asymmetric quantizer is employed at the end of the semantic encoder for discretizing the continuous full-resolution semantic feature. In addition, a neural network model is proposed for mapping the discrete feature into self-learned symbols and accomplishing intelligent multi-user detection (MUD) at the receiver. Simulation results demonstrate that the proposed system holds good performance in non-orthogonal transmission of multiple user signals and outperforms the other methods, especially at low-to-medium SNRs. Moreover, it has high robustness under various simulation settings and mismatched test scenarios.","creator":"Weizhi Li, Haotai Liang, Chen Dong, Xiaodong Xu, Ping Zhang, Kaijun Liu"},{"id":"2303.15445","slug":"irfl-image-recognition-of-figurative-language-arxiv-2303-15445v2-cs-cl-updated","title":"IRFL: Image Recognition of Figurative Language.","link":"http://arxiv.org/abs/2303.15445","abstract":"Figures of speech such as metaphors, similes, and idioms are integral parts of human communication. They are ubiquitous in many forms of discourse, allowing people to convey complex, abstract ideas and evoke emotion. As figurative forms are often conveyed through multiple modalities (e.g., both text and images), understanding multimodal figurative language is an important AI challenge, weaving together profound vision, language, commonsense and cultural knowledge.  In this work, we develop the Image Recognition of Figurative Language (IRFL) dataset. We leverage human annotation and an automatic pipeline we created to generate a multimodal dataset, and introduce two novel tasks as a benchmark for multimodal figurative language understanding. We experimented with state-of-the-art vision and language models and found that the best (22%) performed substantially worse than humans (97%). We release our dataset, benchmark, and code, in hopes of driving the development of models that can better understand figurative language.","creator":"Ron Yosef, Yonatan Bitton, Dafna Shahaf"},{"id":"2305.06657","slug":"on-practical-robust-reinforcement-learning-practical-uncertainty-set-and-double-agent-algorithm-arxiv-2305-06657v3-cs-lg-updated","title":"On Practical Robust Reinforcement Learning: Practical Uncertainty Set and Double-Agent Algorithm.","link":"http://arxiv.org/abs/2305.06657","abstract":"Robust reinforcement learning (RRL) aims at seeking a robust policy to optimize the worst case performance over an uncertainty set of Markov decision processes (MDPs). This set contains some perturbed MDPs from a nominal MDP (N-MDP) that generate samples for training, which reflects some potential mismatches between training (i.e., N-MDP) and true environments. In this paper we present an elaborated uncertainty set by excluding some implausible MDPs from the existing sets. Under this uncertainty set, we develop a sample-based RRL algorithm (named ARQ-Learning) for tabular setting and characterize its finite-time error bound. Also, it is proved that ARQ-Learning converges as fast as the standard Q-Learning and robust Q-Learning while ensuring better robustness. We introduce an additional pessimistic agent which can tackle the major bottleneck for the extension of ARQ-Learning into the cases with larger or continuous state spaces. Incorporating this idea into RL algorithms, we propose double-agent algorithms for model-free RRL. Via experiments, we demonstrate the effectiveness of the proposed algorithms.","creator":"Ukjo Hwang, Songnam Hong"},{"id":"2305.11203","slug":"pdp-parameter-free-differentiable-pruning-is-all-you-need-arxiv-2305-11203v3-cs-lg-updated","title":"PDP: Parameter-free Differentiable Pruning is All You Need.","link":"http://arxiv.org/abs/2305.11203","abstract":"DNN pruning is a popular way to reduce the size of a model, improve the inference latency, and minimize the power consumption on DNN accelerators. However, existing approaches might be too complex, expensive or ineffective to apply to a variety of vision/language tasks, DNN architectures and to honor structured pruning constraints. In this paper, we propose an efficient yet effective train-time pruning scheme, Parameter-free Differentiable Pruning (PDP), which offers state-of-the-art qualities in model size, accuracy, and training cost. PDP uses a dynamic function of weights during training to generate soft pruning masks for the weights in a parameter-free manner for a given pruning target. While differentiable, the simplicity and efficiency of PDP make it universal enough to deliver state-of-the-art random/structured/channel pruning results on various vision and natural language tasks. For example, for MobileNet-v1, PDP can achieve 68.2% top-1 ImageNet1k accuracy at 86.6% sparsity, which is 1.7% higher accuracy than those from the state-of-the-art algorithms. Also, PDP yields over 83.1% accuracy on Multi-Genre Natural Language Inference with 90% sparsity for BERT, while the next best from the existing techniques shows 81.5% accuracy. In addition, PDP can be applied to structured pruning, such as N:M pruning and channel pruning. For 1:4 structured pruning of ResNet18, PDP improved the top-1 ImageNet1k accuracy by over 3.6% over the state-of-the-art. For channel pruning of ResNet50, PDP reduced the top-1 ImageNet1k accuracy by 0.6% from the state-of-the-art.","creator":"Minsik Cho, Saurabh Adya, Devang Naik"},{"id":"2305.17010","slug":"let-the-flows-tell-solving-graph-combinatorial-optimization-problems-with-gflownets-arxiv-2305-17010v3-cs-lg-updated","title":"Let the Flows Tell: Solving Graph Combinatorial Optimization Problems with GFlowNets.","link":"http://arxiv.org/abs/2305.17010","abstract":"Combinatorial optimization (CO) problems are often NP-hard and thus out of reach for exact algorithms, making them a tempting domain to apply machine learning methods. The highly structured constraints in these problems can hinder either optimization or sampling directly in the solution space. On the other hand, GFlowNets have recently emerged as a powerful machinery to efficiently sample from composite unnormalized densities sequentially and have the potential to amortize such solution-searching processes in CO, as well as generate diverse solution candidates. In this paper, we design Markov decision processes (MDPs) for different combinatorial problems and propose to train conditional GFlowNets to sample from the solution space. Efficient training techniques are also developed to benefit long-range credit assignment. Through extensive experiments on a variety of different CO tasks with synthetic and realistic data, we demonstrate that GFlowNet policies can efficiently find high-quality solutions. Our implementation is open-sourced at https://github.com/zdhNarsil/GFlowNet-CombOpt.","creator":"Dinghuai Zhang, Hanjun Dai, Nikolay Malkin, Aaron Courville, Yoshua Bengio, Ling Pan"},{"id":"2305.18399","slug":"on-the-impact-of-activation-and-normalization-in-obtaining-isometric-embeddings-at-initialization-arxiv-2305-18399v3-cs-lg-updated","title":"On the impact of activation and normalization in obtaining isometric embeddings at initialization.","link":"http://arxiv.org/abs/2305.18399","abstract":"In this paper, we explore the structure of the penultimate Gram matrix in deep neural networks, which contains the pairwise inner products of outputs corresponding to a batch of inputs. In several architectures it has been observed that this Gram matrix becomes degenerate with depth at initialization, which dramatically slows training. Normalization layers, such as batch or layer normalization, play a pivotal role in preventing the rank collapse issue. Despite promising advances, the existing theoretical results do not extend to layer normalization, which is widely used in transformers, and can not quantitatively characterize the role of non-linear activations. To bridge this gap, we prove that layer normalization, in conjunction with activation layers, biases the Gram matrix of a multilayer perceptron towards the identity matrix at an exponential rate with depth at initialization. We quantify this rate using the Hermite expansion of the activation function.","creator":"Amir Joudaki, Hadi Daneshmand, Francis Bach"},{"id":"2306.06146","slug":"hidden-classification-layers-enhancing-linear-separability-between-classes-in-neural-networks-layers-arxiv-2306-06146v2-cs-lg-updated","title":"Hidden Classification Layers: Enhancing linear separability between classes in neural networks layers.","link":"http://arxiv.org/abs/2306.06146","abstract":"In the context of classification problems, Deep Learning (DL) approaches represent state of art. Many DL approaches are based on variations of standard multi-layer feed-forward neural networks. These are also referred to as deep networks. The basic idea is that each hidden neural layer accomplishes a data transformation which is expected to make the data representation \"somewhat more linearly separable\" than the previous one to obtain a final data representation which is as linearly separable as possible. However, determining the appropriate neural network parameters that can perform these transformations is a critical problem. In this paper, we investigate the impact on deep network classifier performances of a training approach favouring solutions where data representations at the hidden layers have a higher degree of linear separability between the classes with respect to standard methods. To this aim, we propose a neural network architecture which induces an error function involving the outputs of all the network layers. Although similar approaches have already been partially discussed in the past literature, here we propose a new architecture with a novel error function and an extensive experimental analysis. This experimental analysis was made in the context of image classification tasks considering four widely used datasets. The results show that our approach improves the accuracy on the test set in all the considered cases.","creator":"Andrea Apicella, Francesco Isgr&#xf2;, Roberto Prevete"},{"id":"2306.07691","slug":"styletts-2-towards-human-level-text-to-speech-through-style-diffusion-and-adversarial-training-with-large-speech-language-models-arxiv-2306-07691v2-eess-as-updated","title":"StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models.","link":"http://arxiv.org/abs/2306.07691","abstract":"In this paper, we present StyleTTS 2, a text-to-speech (TTS) model that leverages style diffusion and adversarial training with large speech language models (SLMs) to achieve human-level TTS synthesis. StyleTTS 2 differs from its predecessor by modeling styles as a latent random variable through diffusion models to generate the most suitable style for the text without requiring reference speech, achieving efficient latent diffusion while benefiting from the diverse speech synthesis offered by diffusion models. Furthermore, we employ large pre-trained SLMs, such as WavLM, as discriminators with our novel differentiable duration modeling for end-to-end training, resulting in improved speech naturalness. StyleTTS 2 surpasses human recordings on the single-speaker LJSpeech dataset and matches it on the multispeaker VCTK dataset as judged by native English speakers. Moreover, when trained on the LibriTTS dataset, our model outperforms previous publicly available models for zero-shot speaker adaptation. This work achieves the first human-level TTS on both single and multispeaker datasets, showcasing the potential of style diffusion and adversarial training with large SLMs. The audio demos and source code are available at https://styletts2.github.io/.","creator":"Yinghao Aaron Li, Cong Han, Vinay S. Raghavan, Gavin Mischler, Nima Mesgarani"},{"id":"2307.04962","slug":"intrinsically-motivated-graph-exploration-using-network-theories-of-human-curiosity-arxiv-2307-04962v3-cs-lg-updated","title":"Intrinsically motivated graph exploration using network theories of human curiosity.","link":"http://arxiv.org/abs/2307.04962","abstract":"Intrinsically motivated exploration has proven useful for reinforcement learning, even without additional extrinsic rewards. When the environment is naturally represented as a graph, how to guide exploration best remains an open question. In this work, we propose a novel approach for exploring graph-structured data motivated by two theories of human curiosity: the information gap theory and the compression progress theory. The theories view curiosity as an intrinsic motivation to optimize for topological features of subgraphs induced by nodes visited in the environment. We use these proposed features as rewards for graph neural-network-based reinforcement learning. On multiple classes of synthetically generated graphs, we find that trained agents generalize to longer exploratory walks and larger environments than are seen during training. Our method computes more efficiently than the greedy evaluation of the relevant topological properties. The proposed intrinsic motivations bear particular relevance for recommender systems. We demonstrate that next-node recommendations considering curiosity are more predictive of human choices than PageRank centrality in several real-world graph environments, including MovieLens, Amazon Books, and Wikipedia.","creator":"Shubhankar P. Patankar, Mathieu Ouellet, Juan Cervino, Alejandro Ribeiro, Kieran A. Murphy, Dani S. Bassett"},{"id":"2307.05832","slug":"bag-of-views-an-appearance-based-approach-to-next-best-view-planning-for-3d-reconstruction-arxiv-2307-05832v3-cs-cv-updated","title":"Bag of Views: An Appearance-based Approach to Next-Best-View Planning for 3D Reconstruction.","link":"http://arxiv.org/abs/2307.05832","abstract":"UAV-based intelligent data acquisition for 3D reconstruction and monitoring of infrastructure has experienced an increasing surge of interest due to recent advancements in image processing and deep learning-based techniques. View planning is an essential part of this task that dictates the information capture strategy and heavily impacts the quality of the 3D model generated from the captured data. Recent methods have used prior knowledge or partial reconstruction of the target to accomplish view planning for active reconstruction; the former approach poses a challenge for complex or newly identified targets while the latter is computationally expensive. In this work, we present Bag-of-Views (BoV), a fully appearance-based model used to assign utility to the captured views for both offline dataset refinement and online next-best-view (NBV) planning applications targeting the task of 3D reconstruction. With this contribution, we also developed the View Planning Toolbox (VPT), a lightweight package for training and testing machine learning-based view planning frameworks, custom view dataset generation of arbitrary 3D scenes, and 3D reconstruction. Through experiments which pair a BoV-based reinforcement learning model with VPT, we demonstrate the efficacy of our model in reducing the number of required views for high-quality reconstructions in dataset refinement and NBV planning.","creator":"Sara Hatami Gazani, Matthew Tucsok, Iraj Mantegh, Homayoun Najjaran"},{"id":"2307.14669","slug":"fuzzy-order-sorted-feature-logic-arxiv-2307-14669v2-cs-ai-updated","title":"Fuzzy order-sorted feature logic.","link":"http://arxiv.org/abs/2307.14669","abstract":"Order-Sorted Feature (OSF) logic is a knowledge representation and reasoning language based on function-denoting feature symbols and set-denoting sort symbols ordered in a subsumption lattice. OSF logic allows the construction of record-like terms that represent classes of entities and that are themselves ordered in a subsumption relation. The unification algorithm for such structures provides an efficient calculus of type subsumption, which has been applied in computational linguistics and implemented in constraint logic programming languages such as LOGIN and LIFE and automated reasoners such as CEDAR. This work generalizes OSF logic to a fuzzy setting. We give a flexible definition of a fuzzy subsumption relation which generalizes Zadeh's inclusion between fuzzy sets. Based on this definition we define a fuzzy semantics of OSF logic where sort symbols and OSF terms denote fuzzy sets. We extend the subsumption relation to OSF terms and prove that it constitutes a fuzzy partial order with the property that two OSF terms are subsumed by one another in the crisp sense if and only if their subsumption degree is greater than 0. We show how to find the greatest lower bound of two OSF terms by unifying them and how to compute the subsumption degree between two OSF terms, and we provide the complexity of these operations.","creator":"Gian Carlo Milanese, Gabriella Pasi"},{"id":"2307.15244","slug":"bourne-bootstrapped-self-supervised-learning-framework-for-unified-graph-anomaly-detection-arxiv-2307-15244v2-cs-si-updated","title":"BOURNE: Bootstrapped Self-supervised Learning Framework for Unified Graph Anomaly Detection.","link":"http://arxiv.org/abs/2307.15244","abstract":"Graph anomaly detection (GAD) has gained increasing attention in recent years due to its critical application in a wide range of domains, such as social networks, financial risk management, and traffic analysis. Existing GAD methods can be categorized into node and edge anomaly detection models based on the type of graph objects being detected. However, these methods typically treat node and edge anomalies as separate tasks, overlooking their associations and frequent co-occurrences in real-world graphs. As a result, they fail to leverage the complementary information provided by node and edge anomalies for mutual detection. Additionally, state-of-the-art GAD methods, such as CoLA and SL-GAD, heavily rely on negative pair sampling in contrastive learning, which incurs high computational costs, hindering their scalability to large graphs. To address these limitations, we propose a novel unified graph anomaly detection framework based on bootstrapped self-supervised learning (named BOURNE). We extract a subgraph (graph view) centered on each target node as node context and transform it into a dual hypergraph (hypergraph view) as edge context. These views are encoded using graph and hypergraph neural networks to capture the representations of nodes, edges, and their associated contexts. By swapping the context embeddings between nodes and edges and measuring the agreement in the embedding space, we enable the mutual detection of node and edge anomalies. Furthermore, BOURNE can eliminate the need for negative sampling, thereby enhancing its efficiency in handling large graphs. Extensive experiments conducted on six benchmark datasets demonstrate the superior effectiveness and efficiency of BOURNE in detecting both node and edge anomalies.","creator":"Jie Liu, Mengting He, Xuequn Shang, Jieming Shi, Bin Cui, Hongzhi Yin"},{"id":"2307.16387","slug":"relation-oriented-toward-causal-knowledge-aligned-agi-arxiv-2307-16387v10-cs-ai-updated","title":"Relation-Oriented: Toward Causal Knowledge-Aligned AGI.","link":"http://arxiv.org/abs/2307.16387","abstract":"The current relationship modeling paradigm, grounded in the observational i.i.d assumption, fundamentally misaligns with our causal knowledge understanding due to two key oversights: 1) the unobservable relations, which lead to undetectable hierarchical levels of knowledge, driving the need for model generalizability; 2) the cognitive relative timings, which crucially support our structural knowledge comprehension, resulting in inherent biases within the present Observation-Oriented paradigm. Adopting a novel Relation-Oriented perspective, this paper proposes a new framework to unify the various confusions surrounding causality learning, ranging from traditional causal inference to modern language models.  Also, relation-indexed representation learning (RIRL) is raised as a baseline implementation method of the proposed new paradigm, alongside comprehensive experiments demonstrating its efficacy in autonomously identifying dynamical effects in relationship learning.","creator":"Jia Li, Xiang Li"},{"id":"2308.01098","slug":"towards-better-query-classification-with-multi-expert-knowledge-condensation-in-jd-ads-search-arxiv-2308-01098v3-cs-ir-updated","title":"Towards Better Query Classification with Multi-Expert Knowledge Condensation in JD Ads Search.","link":"http://arxiv.org/abs/2308.01098","abstract":"Search query classification, as an effective way to understand user intents, is of great importance in real-world online ads systems. To ensure a lower latency, a shallow model (e.g. FastText) is widely used for efficient online inference. However, the representation ability of the FastText model is insufficient, resulting in poor classification performance, especially on some low-frequency queries and tailed categories. Using a deeper and more complex model (e.g. BERT) is an effective solution, but it will cause a higher online inference latency and more expensive computing costs. Thus, how to juggle both inference efficiency and classification performance is obviously of great practical importance. To overcome this challenge, in this paper, we propose knowledge condensation (KC), a simple yet effective knowledge distillation framework to boost the classification performance of the online FastText model under strict low latency constraints. Specifically, we propose to train an offline BERT model to retrieve more potentially relevant data. Benefiting from its powerful semantic representation, more relevant labels not exposed in the historical data will be added into the training set for better FastText model training. Moreover, a novel distribution-diverse multi-expert learning strategy is proposed to further improve the mining ability of relevant data. By training multiple BERT models from different data distributions, it can respectively perform better at high, middle, and low-frequency search queries. The model ensemble from multi-distribution makes its retrieval ability more powerful. We have deployed two versions of this framework in JD search, and both offline experiments and online A/B testing from multiple datasets have validated the effectiveness of the proposed approach.","creator":"Kun-Peng Ning, Ming Pang, Zheng Fang, Xue Jiang, Xi-Wei Zhao, Chang-Ping Peng, Zhan-Gang Lin, Jing-He Hu, Jing-Ping Shao"},{"id":"2308.10974","slug":"guinea-pig-trials-utilizing-gpt-a-novel-smart-agent-based-modeling-approach-for-studying-firm-competition-and-collusion-arxiv-2308-10974v3-cs-ai-updated","title":"\"Guinea Pig Trials\" Utilizing GPT: A Novel Smart Agent-Based Modeling Approach for Studying Firm Competition and Collusion.","link":"http://arxiv.org/abs/2308.10974","abstract":"Firm competition and collusion involve complex dynamics, particularly when considering communication among firms. Such issues can be modeled as problems of complex systems, traditionally approached through experiments involving human subjects or agent-based modeling methods. We propose an innovative framework called Smart Agent-Based Modeling (SABM), wherein smart agents, supported by GPT-4 technologies, represent firms, and interact with one another. We conducted a controlled experiment to study firm price competition and collusion behaviors under various conditions. SABM is more cost-effective and flexible compared to conducting experiments with human subjects. Smart agents possess an extensive knowledge base for decision-making and exhibit human-like strategic abilities, surpassing traditional ABM agents. Furthermore, smart agents can simulate human conversation and be personalized, making them ideal for studying complex situations involving communication. Our results demonstrate that, in the absence of communication, smart agents consistently reach tacit collusion, leading to prices converging at levels higher than the Bertrand equilibrium price but lower than monopoly or cartel prices. When communication is allowed, smart agents achieve a higher-level collusion with prices close to cartel prices. Collusion forms more quickly with communication, while price convergence is smoother without it. These results indicate that communication enhances trust between firms, encouraging frequent small price deviations to explore opportunities for a higher-level win-win situation and reducing the likelihood of triggering a price war. We also assigned different personas to firms to analyze behavioral differences and tested variant models under diverse market structures. The findings showcase the effectiveness and robustness of SABM and provide intriguing insights into competition and collusion.","creator":"Xu Han, Zengqing Wu, Chuan Xiao"},{"id":"2308.12634","slug":"towards-hierarchical-regional-transformer-based-multiple-instance-learning-arxiv-2308-12634v2-cs-cv-updated","title":"Towards Hierarchical Regional Transformer-based Multiple Instance Learning.","link":"http://arxiv.org/abs/2308.12634","abstract":"The classification of gigapixel histopathology images with deep multiple instance learning models has become a critical task in digital pathology and precision medicine. In this work, we propose a Transformer-based multiple instance learning approach that replaces the traditional learned attention mechanism with a regional, Vision Transformer inspired self-attention mechanism. We present a method that fuses regional patch information to derive slide-level predictions and show how this regional aggregation can be stacked to hierarchically process features on different distance levels. To increase predictive accuracy, especially for datasets with small, local morphological features, we introduce a method to focus the image processing on high attention regions during inference. Our approach is able to significantly improve performance over the baseline on two histopathology datasets and points towards promising directions for further research.","creator":"Josef Cersovsky, Sadegh Mohammadi, Dagmar Kainmueller, Johannes Hoehne"},{"id":"2309.07053","slug":"pearl-s-and-jeffrey-s-update-as-modes-of-learning-in-probabilistic-programming-arxiv-2309-07053v2-cs-lo-updated","title":"Pearl's and Jeffrey's Update as Modes of Learning in Probabilistic Programming.","link":"http://arxiv.org/abs/2309.07053","abstract":"The concept of updating a probability distribution in the light of new evidence lies at the heart of statistics and machine learning. Pearl's and Jeffrey's rule are two natural update mechanisms which lead to different outcomes, yet the similarities and differences remain mysterious. This paper clarifies their relationship in several ways: via separate descriptions of the two update mechanisms in terms of probabilistic programs and sampling semantics, and via different notions of likelihood (for Pearl and for Jeffrey). Moreover, it is shown that Jeffrey's update rule arises via variational inference. In terms of categorical probability theory, this amounts to an analysis of the situation in terms of the behaviour of the multiset functor, extended to the Kleisli category of the distribution monad.","creator":"Bart Jacobs, Dario Stein"},{"id":"2309.07510","slug":"learning-environment-aware-affordance-for-3d-articulated-object-manipulation-under-occlusions-arxiv-2309-07510v4-cs-ro-updated","title":"Learning Environment-Aware Affordance for 3D Articulated Object Manipulation under Occlusions.","link":"http://arxiv.org/abs/2309.07510","abstract":"Perceiving and manipulating 3D articulated objects in diverse environments is essential for home-assistant robots. Recent studies have shown that point-level affordance provides actionable priors for downstream manipulation tasks. However, existing works primarily focus on single-object scenarios with homogeneous agents, overlooking the realistic constraints imposed by the environment and the agent's morphology, e.g., occlusions and physical limitations. In this paper, we propose an environment-aware affordance framework that incorporates both object-level actionable priors and environment constraints. Unlike object-centric affordance approaches, learning environment-aware affordance faces the challenge of combinatorial explosion due to the complexity of various occlusions, characterized by their quantities, geometries, positions and poses. To address this and enhance data efficiency, we introduce a novel contrastive affordance learning framework capable of training on scenes containing a single occluder and generalizing to scenes with complex occluder combinations. Experiments demonstrate the effectiveness of our proposed approach in learning affordance considering environment constraints. Project page at https://chengkaiacademycity.github.io/EnvAwareAfford/","creator":"Kai Cheng, Ruihai Wu, Yan Shen, Chuanruo Ning, Guanqi Zhan, Hao Dong"},{"id":"2309.12253","slug":"salsa-clrs-a-sparse-and-scalable-benchmark-for-algorithmic-reasoning-arxiv-2309-12253v2-cs-lg-updated","title":"SALSA-CLRS: A Sparse and Scalable Benchmark for Algorithmic Reasoning.","link":"http://arxiv.org/abs/2309.12253","abstract":"We introduce an extension to the CLRS algorithmic learning benchmark, prioritizing scalability and the utilization of sparse representations. Many algorithms in CLRS require global memory or information exchange, mirrored in its execution model, which constructs fully connected (not sparse) graphs based on the underlying problem. Despite CLRS's aim of assessing how effectively learned algorithms can generalize to larger instances, the existing execution model becomes a significant constraint due to its demanding memory requirements and runtime (hard to scale). However, many important algorithms do not demand a fully connected graph; these algorithms, primarily distributed in nature, align closely with the message-passing paradigm employed by Graph Neural Networks. Hence, we propose SALSA-CLRS, an extension of the current CLRS benchmark specifically with scalability and sparseness in mind. Our approach includes adapted algorithms from the original CLRS benchmark and introduces new problems from distributed and randomized algorithms. Moreover, we perform a thorough empirical evaluation of our benchmark. Code is publicly available at https://github.com/jkminder/SALSA-CLRS.","creator":"Julian Minder, Florian Gr&#xf6;tschla, Jo&#xeb;l Mathys, Roger Wattenhofer"},{"id":"2309.13409","slug":"time-series-forecasting-unleashing-long-term-dependencies-with-fractionally-differenced-data-arxiv-2309-13409v3-cs-lg-updated","title":"Time-Series Forecasting: Unleashing Long-Term Dependencies with Fractionally Differenced Data.","link":"http://arxiv.org/abs/2309.13409","abstract":"This study introduces a novel forecasting strategy that leverages the power of fractional differencing (FD) to capture both short- and long-term dependencies in time series data. Unlike traditional integer differencing methods, FD preserves memory in series while stabilizing it for modeling purposes. By applying FD to financial data from the SPY index and incorporating sentiment analysis from news reports, this empirical analysis explores the effectiveness of FD in conjunction with binary classification of target variables. Supervised classification algorithms were employed to validate the performance of FD series. The results demonstrate the superiority of FD over integer differencing, as confirmed by Receiver Operating Characteristic/Area Under the Curve (ROCAUC) and Mathews Correlation Coefficient (MCC) evaluations.","creator":"Sarit Maitra, Vivek Mishra, Srashti Dwivedi, Sukanya Kundu, Goutam Kumar Kundu"},{"id":"2309.16661","slug":"sa2-net-scale-aware-attention-network-for-microscopic-image-segmentation-arxiv-2309-16661v3-cs-cv-updated","title":"SA2-Net: Scale-aware Attention Network for Microscopic Image Segmentation.","link":"http://arxiv.org/abs/2309.16661","abstract":"Microscopic image segmentation is a challenging task, wherein the objective is to assign semantic labels to each pixel in a given microscopic image. While convolutional neural networks (CNNs) form the foundation of many existing frameworks, they often struggle to explicitly capture long-range dependencies. Although transformers were initially devised to address this issue using self-attention, it has been proven that both local and global features are crucial for addressing diverse challenges in microscopic images, including variations in shape, size, appearance, and target region density. In this paper, we introduce SA2-Net, an attention-guided method that leverages multi-scale feature learning to effectively handle diverse structures within microscopic images. Specifically, we propose scale-aware attention (SA2) module designed to capture inherent variations in scales and shapes of microscopic regions, such as cells, for accurate segmentation. This module incorporates local attention at each level of multi-stage features, as well as global attention across multiple resolutions. Furthermore, we address the issue of blurred region boundaries (e.g., cell boundaries) by introducing a novel upsampling strategy called the Adaptive Up-Attention (AuA) module. This module enhances the discriminative ability for improved localization of microscopic regions using an explicit attention mechanism. Extensive experiments on five challenging datasets demonstrate the benefits of our SA2-Net model. Our source code is publicly available at \\url{https://github.com/mustansarfiaz/SA2-Net}.","creator":"Mustansar Fiaz, Moein Heidari, Rao Muhammad Anwer, Hisham Cholakkal"},{"id":"2309.17113","slug":"meta-path-learning-for-multi-relational-graph-neural-networks-arxiv-2309-17113v2-cs-lg-updated","title":"Meta-Path Learning for Multi-relational Graph Neural Networks.","link":"http://arxiv.org/abs/2309.17113","abstract":"Existing multi-relational graph neural networks use one of two strategies for identifying informative relations: either they reduce this problem to low-level weight learning, or they rely on handcrafted chains of relational dependencies, called meta-paths. However, the former approach faces challenges in the presence of many relations (e.g., knowledge graphs), while the latter requires substantial domain expertise to identify relevant meta-paths. In this work we propose a novel approach to learn meta-paths and meta-path GNNs that are highly accurate based on a small number of informative meta-paths. Key element of our approach is a scoring function for measuring the potential informativeness of a relation in the incremental construction of the meta-path. Our experimental evaluation shows that the approach manages to correctly identify relevant meta-paths even with a large number of relations, and substantially outperforms existing multi-relational GNNs on synthetic and real-world experiments.","creator":"Francesco Ferrini, Antonio Longa, Andrea Passerini, Manfred Jaeger"},{"id":"2310.01827","slug":"learning-and-reusing-primitive-behaviours-to-improve-hindsight-experience-replay-sample-efficiency-arxiv-2310-01827v2-cs-ro-updated","title":"Learning and reusing primitive behaviours to improve Hindsight Experience Replay sample efficiency.","link":"http://arxiv.org/abs/2310.01827","abstract":"Hindsight Experience Replay (HER) is a technique used in reinforcement learning (RL) that has proven to be very efficient for training off-policy RL-based agents to solve goal-based robotic manipulation tasks using sparse rewards. Even though HER improves the sample efficiency of RL-based agents by learning from mistakes made in past experiences, it does not provide any guidance while exploring the environment. This leads to very large training times due to the volume of experience required to train an agent using this replay strategy. In this paper, we propose a method that uses primitive behaviours that have been previously learned to solve simple tasks in order to guide the agent toward more rewarding actions during exploration while learning other more complex tasks. This guidance, however, is not executed by a manually designed curriculum, but rather using a critic network to decide at each timestep whether or not to use the actions proposed by the previously-learned primitive policies. We evaluate our method by comparing its performance against HER and other more efficient variations of this algorithm in several block manipulation tasks. We demonstrate the agents can learn a successful policy faster when using our proposed method, both in terms of sample efficiency and computation time. Code is available at https://github.com/franroldans/qmp-her.","creator":"Francisco Roldan Sanchez, Qiang Wang, David Cordova Bulens, Kevin McGuinness, Stephen Redmond, Noel O&#x27;Connor"},{"id":"2310.02230","slug":"leveraging-diffusion-disentangled-representations-to-mitigate-shortcuts-in-underspecified-visual-tasks-arxiv-2310-02230v5-cs-cv-updated","title":"Leveraging Diffusion Disentangled Representations to Mitigate Shortcuts in Underspecified Visual Tasks.","link":"http://arxiv.org/abs/2310.02230","abstract":"Spurious correlations in the data, where multiple cues are predictive of the target labels, often lead to shortcut learning phenomena, where a model may rely on erroneous, easy-to-learn, cues while ignoring reliable ones. In this work, we propose an ensemble diversification framework exploiting the generation of synthetic counterfactuals using Diffusion Probabilistic Models (DPMs). We discover that DPMs have the inherent capability to represent multiple visual cues independently, even when they are largely correlated in the training data. We leverage this characteristic to encourage model diversity and empirically show the efficacy of the approach with respect to several diversification objectives. We show that diffusion-guided diversification can lead models to avert attention from shortcut cues, achieving ensemble diversity performance comparable to previous methods requiring additional data collection.","creator":"Luca Scimeca, Alexander Rubinstein, Armand Mihai Nicolicioiu, Damien Teney, Yoshua Bengio"},{"id":"2310.03358","slug":"enhancing-robust-representation-in-adversarial-training-alignment-and-exclusion-criteria-arxiv-2310-03358v2-cs-cv-updated","title":"Enhancing Robust Representation in Adversarial Training: Alignment and Exclusion Criteria.","link":"http://arxiv.org/abs/2310.03358","abstract":"Deep neural networks are vulnerable to adversarial noise. Adversarial Training (AT) has been demonstrated to be the most effective defense strategy to protect neural networks from being fooled. However, we find AT omits to learning robust features, resulting in poor performance of adversarial robustness. To address this issue, we highlight two criteria of robust representation: (1) Exclusion: \\emph{the feature of examples keeps away from that of other classes}; (2) Alignment: \\emph{the feature of natural and corresponding adversarial examples is close to each other}. These motivate us to propose a generic framework of AT to gain robust representation, by the asymmetric negative contrast and reverse attention. Specifically, we design an asymmetric negative contrast based on predicted probabilities, to push away examples of different classes in the feature space. Moreover, we propose to weight feature by parameters of the linear classifier as the reverse attention, to obtain class-aware feature and pull close the feature of the same class. Empirical evaluations on three benchmark datasets show our methods greatly advance the robustness of AT and achieve state-of-the-art performance.","creator":"Nuoyan Zhou, Nannan Wang, Decheng Liu, Dawei Zhou, Xinbo Gao"},{"id":"2310.04918","slug":"robust-network-pruning-with-sparse-entropic-wasserstein-regression-arxiv-2310-04918v2-cs-ai-updated","title":"Robust Network Pruning With Sparse Entropic Wasserstein Regression.","link":"http://arxiv.org/abs/2310.04918","abstract":"This study tackles the issue of neural network pruning that inaccurate gradients exist when computing the empirical Fisher Information Matrix (FIM). We introduce an entropic Wasserstein regression (EWR) formulation, capitalizing on the geometric attributes of the optimal transport (OT) problem. This is analytically showcased to excel in noise mitigation by adopting neighborhood interpolation across data points. The unique strength of the Wasserstein distance is its intrinsic ability to strike a balance between noise reduction and covariance information preservation. Extensive experiments performed on various networks show comparable performance of the proposed method with state-of-the-art (SoTA) network pruning algorithms. Our proposed method outperforms the SoTA when the network size or the target sparsity is large, the gain is even larger with the existence of noisy gradients, possibly from noisy data, analog memory, or adversarial attacks. Notably, our proposed method achieves a gain of 6% improvement in accuracy and 8% improvement in testing loss for MobileNetV1 with less than one-fourth of the network parameters remaining.","creator":"Lei You, Hei Victor Cheng"},{"id":"2310.08278","slug":"lag-llama-towards-foundation-models-for-time-series-forecasting-arxiv-2310-08278v2-cs-lg-updated","title":"Lag-Llama: Towards Foundation Models for Time Series Forecasting.","link":"http://arxiv.org/abs/2310.08278","abstract":"Aiming to build foundation models for time-series forecasting and study their scaling behavior, we present here our work-in-progress on Lag-Llama, a general-purpose univariate probabilistic time-series forecasting model trained on a large collection of time-series data. The model shows good zero-shot prediction capabilities on unseen \"out-of-distribution\" time-series datasets, outperforming supervised baselines. We use smoothly broken power-laws to fit and predict model scaling behavior. The open source code is made available at https://github.com/kashif/pytorch-transformer-ts.","creator":"Kashif Rasul, Arjun Ashok, Andrew Robert Williams, Arian Khorasani, George Adamopoulos, Rishika Bhagwatkar, Marin Bilo&#x161;, Hena Ghonia, Nadhir Vincent Hassen, Anderson Schneider, Sahil Garg, Alexandre Drouin, Nicolas Chapados, Yuriy Nevmyvaka, Irina Rish"},{"id":"2310.08782","slug":"selectivity-drives-productivity-efficient-dataset-pruning-for-enhanced-transfer-learning-arxiv-2310-08782v3-cs-lg-updated","title":"Selectivity Drives Productivity: Efficient Dataset Pruning for Enhanced Transfer Learning.","link":"http://arxiv.org/abs/2310.08782","abstract":"Massive data is often considered essential for deep learning applications, but it also incurs significant computational and infrastructural costs. Therefore, dataset pruning (DP) has emerged as an effective way to improve data efficiency by identifying and removing redundant training samples without sacrificing performance. In this work, we aim to address the problem of DP for transfer learning, i.e., how to prune a source dataset for improved pretraining efficiency and lossless finetuning accuracy on downstream target tasks. To our best knowledge, the problem of DP for transfer learning remains open, as previous studies have primarily addressed DP and transfer learning as separate problems. By contrast, we establish a unified viewpoint to integrate DP with transfer learning and find that existing DP methods are not suitable for the transfer learning paradigm. We then propose two new DP methods, label mapping and feature mapping, for supervised and self-supervised pretraining settings respectively, by revisiting the DP problem through the lens of source-target domain mapping. Furthermore, we demonstrate the effectiveness of our approach on numerous transfer learning tasks. We show that source data classes can be pruned by up to 40% ~ 80% without sacrificing downstream performance, resulting in a significant 2 ~ 5 times speed-up during the pretraining stage. Besides, our proposal exhibits broad applicability and can improve other computationally intensive transfer learning techniques, such as adversarial pretraining. Codes are available at https://github.com/OPTML-Group/DP4TL.","creator":"Yihua Zhang, Yimeng Zhang, Aochuan Chen, Jinghan Jia, Jiancheng Liu, Gaowen Liu, Mingyi Hong, Shiyu Chang, Sijia Liu"},{"id":"2310.09590","slug":"solving-math-word-problems-with-reexamination-arxiv-2310-09590v2-cs-cl-updated","title":"Solving Math Word Problems with Reexamination.","link":"http://arxiv.org/abs/2310.09590","abstract":"Math word problem (MWP) solving aims to understand the descriptive math problem and calculate the result, for which previous efforts are mostly devoted to upgrade different technical modules. This paper brings a different perspective of \\textit{reexamination process} during training by introducing a pseudo-dual task to enhance the MWP solving. We propose a pseudo-dual (PseDual) learning scheme to model such process, which is model-agnostic thus can be adapted to any existing MWP solvers. The pseudo-dual task is specifically defined as filling the numbers in the expression back into the original word problem with numbers masked. To facilitate the effective joint learning of the two tasks, we further design a scheduled fusion strategy for the number infilling task, which smoothly switches the input from the ground-truth math expressions to the predicted ones. Our pseudo-dual learning scheme has been tested and proven effective when being equipped in several representative MWP solvers through empirical studies. \\textit{The codes and trained models are available at:} \\url{https://github.com/steven640pixel/PsedualMWP}. \\end{abstract}","creator":"Yi Bin, Wenhao Shi, Yujuan Ding, Yang Yang, See-Kiong Ng"},{"id":"2310.09886","slug":"lifelong-sequence-generation-with-dynamic-module-expansion-and-adaptation-arxiv-2310-09886v3-cs-cl-updated","title":"Lifelong Sequence Generation with Dynamic Module Expansion and Adaptation.","link":"http://arxiv.org/abs/2310.09886","abstract":"Lifelong sequence generation (LSG), a problem in continual learning, aims to continually train a model on a sequence of generation tasks to learn constantly emerging new generation patterns while avoiding the forgetting of previous knowledge. Existing LSG methods mainly focus on maintaining old knowledge while paying little attention to knowledge transfer across tasks. In contrast, humans can better learn new tasks by leveraging previously acquired knowledge from similar tasks. Inspired by the learning paradigm of humans, we propose Dynamic Module Expansion and Adaptation (DMEA), which enables the model to dynamically determine the architecture for acquiring new knowledge based on task correlation and select the most similar previous tasks to facilitate adaptation to new tasks. In addition, as the learning process can easily be biased towards the current task which might cause more severe forgetting of previously learned knowledge, we propose dynamic gradient scaling to balance the learning of the current task and replayed tasks. With extensive experiments, we demonstrate that DMEA can consistently outperform existing methods in different LSG settings.","creator":"Chengwei Qin, Chen Chen, Shafiq Joty"},{"id":"2310.10348","slug":"attribution-patching-outperforms-automated-circuit-discovery-arxiv-2310-10348v2-cs-lg-updated","title":"Attribution Patching Outperforms Automated Circuit Discovery.","link":"http://arxiv.org/abs/2310.10348","abstract":"Automated interpretability research has recently attracted attention as a potential research direction that could scale explanations of neural network behavior to large models. Existing automated circuit discovery work applies activation patching to identify subnetworks responsible for solving specific tasks (circuits). In this work, we show that a simple method based on attribution patching outperforms all existing methods while requiring just two forward passes and a backward pass. We apply a linear approximation to activation patching to estimate the importance of each edge in the computational subgraph. Using this approximation, we prune the least important edges of the network. We survey the performance and limitations of this method, finding that averaged over all tasks our method has greater AUC from circuit recovery than other methods.","creator":"Aaquib Syed, Can Rager, Arthur Conmy"},{"id":"2310.15127","slug":"open-ended-instructable-embodied-agents-with-memory-augmented-large-language-models-arxiv-2310-15127v2-cs-ai-updated","title":"Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models.","link":"http://arxiv.org/abs/2310.15127","abstract":"Pre-trained and frozen large language models (LLMs) can effectively map simple scene rearrangement instructions to programs over a robot's visuomotor functions through appropriate few-shot example prompting. To parse open-domain natural language and adapt to a user's idiosyncratic procedures, not known during prompt engineering time, fixed prompts fall short. In this paper, we introduce HELPER, an embodied agent equipped with an external memory of language-program pairs that parses free-form human-robot dialogue into action programs through retrieval-augmented LLM prompting: relevant memories are retrieved based on the current dialogue, instruction, correction, or VLM description, and used as in-context prompt examples for LLM querying. The memory is expanded during deployment to include pairs of user's language and action plans, to assist future inferences and personalize them to the user's language and routines. HELPER sets a new state-of-the-art in the TEACh benchmark in both Execution from Dialog History (EDH) and Trajectory from Dialogue (TfD), with a 1.7x improvement over the previous state-of-the-art for TfD. Our models, code, and video results can be found in our project's website: https://helper-agent-llm.github.io.","creator":"Gabriel Sarch, Yue Wu, Michael J. Tarr, Katerina Fragkiadaki"},{"id":"2310.15778","slug":"preserving-patient-privacy-in-mri-scans-a-comprehensive-approach-with-3d-masked-autoencoders-arxiv-2310-15778v2-cs-cv-updated","title":"Preserving Patient Privacy in MRI Scans: A Comprehensive Approach with 3D Masked Autoencoders.","link":"http://arxiv.org/abs/2310.15778","abstract":"MRI scans provide valuable medical information, however they also contain sensitive and personally identifiable information (PII) that needs to be protected. Whereas MRI metadata is easily sanitized, MRI image data is a privacy risk because it contains information to render highly-realistic 3D visualizations of a patient's head, enabling malicious actors to possibly identify the subject by cross-referencing a database. Data anonymization and de-identification is concerned with ensuring the privacy and confidentiality of individuals' personal information. Traditional MRI de-identification methods remove privacy-sensitive parts (e.g. eyes, nose etc.) from a given scan. This comes at the expense of introducing a domain shift that can throw off downstream analyses. Recently, a GAN-based approach was proposed to de-identify a patient's scan by remodeling it (\\eg changing the face) rather than by removing parts. In this work, we propose CP-MAE, a model that de-identifies the face using masked autoencoders and that outperforms all previous approaches in terms of downstream task performance as well as de-identification. With our method we are able to synthesize scans of resolution up to $256^3$ (previously $128^3$) which constitutes an eight-fold increase in the number of voxels. Using our construction we were able to design a system that exhibits a highly robust training stage, making it easy to fit the network on novel data.","creator":"Lennart Alexander Van der Goten, Kevin Smith"},{"id":"2310.18365","slug":"using-gpt-4-to-augment-unbalanced-data-for-automatic-scoring-arxiv-2310-18365v2-cs-cl-updated","title":"Using GPT-4 to Augment Unbalanced Data for Automatic Scoring.","link":"http://arxiv.org/abs/2310.18365","abstract":"Machine learning-based automatic scoring can be challenging if students' responses are unbalanced across scoring categories, as it introduces uncertainty in the machine training process. To meet this challenge, we introduce a novel text data augmentation framework using GPT-4, a generative large language model, specifically tailored for unbalanced datasets in automatic scoring. Our experimental dataset comprised student-written responses to two science items. We crafted prompts for GPT-4 to generate responses resembling student-written answers, particularly for the minority scoring classes, to augment the data. We then finetuned DistillBERT for automatic scoring based on the augmented and original datasets. Model performance was assessed using accuracy, precision, recall, and F1 score. We incorporate varied amounts of augmented data to examine scoring performance, and our findings revealed remarkedly improved model performance. The average maximum increase observed across two items is: 3.5% for accuracy, 30.6% for precision, 21.1% for recall, and 24.2% for F1 score. Notably, using just 5% of the augmented data led to substantial improvements: 2.6%, 29.2%, 15.1%, and 19.6%. Interestingly, the extent of improvement varied depending on specific datasets. Moreover, we found that a varying amount of augmented data (5%-40%) was needed to obtain a stable improvement. We also compare models trained with GPT-4 augmented data and those trained with additional student-written responses. The findings indicate that former ones match or even exceed the performance of the latter. Specifically, there is an average difference of 1.7%, 1.9%, 11.0%, and 7.8% for four metrics separately. This research underscores the potential and effectiveness of data augmentation techniques utilizing GPT-4 in addressing unbalanced datasets within automated assessment.","creator":"Luyang Fang, Gyeong-Geon Lee, Xiaoming Zhai"},{"id":"2310.18534","slug":"multi-time-scale-world-models-arxiv-2310-18534v2-cs-lg-updated","title":"Multi Time Scale World Models.","link":"http://arxiv.org/abs/2310.18534","abstract":"Intelligent agents use internal world models to reason and make predictions about different courses of their actions at many scales. Devising learning paradigms and architectures that allow machines to learn world models that operate at multiple levels of temporal abstractions while dealing with complex uncertainty predictions is a major technical hurdle. In this work, we propose a probabilistic formalism to learn multi-time scale world models which we call the Multi Time Scale State Space (MTS3) model. Our model uses a computationally efficient inference scheme on multiple time scales for highly accurate long-horizon predictions and uncertainty estimates over several seconds into the future. Our experiments, which focus on action conditional long horizon future predictions, show that MTS3 outperforms recent methods on several system identification benchmarks including complex simulated and real-world dynamical systems.","creator":"Vaisakh Shaj, Saleh Gholam Zadeh, Ozan Demir, Luiz Ricardo Douat, Gerhard Neumann"},{"id":"2310.18948","slug":"building-a-safer-maritime-environment-through-multi-path-long-term-vessel-trajectory-forecasting-arxiv-2310-18948v2-cs-lg-updated","title":"Building a Safer Maritime Environment Through Multi-Path Long-Term Vessel Trajectory Forecasting.","link":"http://arxiv.org/abs/2310.18948","abstract":"Maritime transportation is paramount in achieving global economic growth, entailing concurrent ecological obligations in sustainability and safeguarding endangered marine species, most notably preserving large whale populations. In this regard, the Automatic Identification System (AIS) data plays a significant role by offering real-time streaming data on vessel movement, allowing enhanced traffic monitoring. This study explores using AIS data to prevent vessel-to-whale collisions by forecasting long-term vessel trajectories from engineered AIS data sequences. For such a task, we have developed an encoder-decoder model architecture using Bidirectional Long Short-Term Memory Networks (Bi-LSTM) to predict the next 12 hours of vessel trajectories using 1 to 3 hours of AIS data as input. We feed the model with probabilistic features engineered from historical AIS data that refer to each trajectory's potential route and destination. The model then predicts the vessel's trajectory, considering these additional features by leveraging convolutional layers for spatial feature learning and a position-aware attention mechanism that increases the importance of recent timesteps of a sequence during temporal feature learning. The probabilistic features have an F1 Score of approximately 85% and 75% for each feature type, respectively, demonstrating their effectiveness in augmenting information to the neural network. We test our model on the Gulf of St. Lawrence, a region known to be the habitat of North Atlantic Right Whales (NARW). Our model achieved a high R2 score of over 98% using various techniques and features. It stands out among other approaches as it can make complex decisions during turnings and path selection. Our study highlights the potential of data engineering and trajectory forecasting models for marine life species preservation.","creator":"Gabriel Spadon, Jay Kumar, Matthew Smith, Sarah Vela, Romina Gehrmann, Derek Eden, Joshua van Berkel, Amilcar Soares, Ronan Fablet, Ronald Pelot, Stan Matwin"},{"id":"2310.19727","slug":"generating-medical-prescriptions-with-conditional-transformer-arxiv-2310-19727v2-cs-cl-updated","title":"Generating Medical Prescriptions with Conditional Transformer.","link":"http://arxiv.org/abs/2310.19727","abstract":"Access to real-world medication prescriptions is essential for medical research and healthcare quality improvement. However, access to real medication prescriptions is often limited due to the sensitive nature of the information expressed. Additionally, manually labelling these instructions for training and fine-tuning Natural Language Processing (NLP) models can be tedious and expensive. We introduce a novel task-specific model architecture, Label-To-Text-Transformer (\\textbf{LT3}), tailored to generate synthetic medication prescriptions based on provided labels, such as a vocabulary list of medications and their attributes. LT3 is trained on a set of around 2K lines of medication prescriptions extracted from the MIMIC-III database, allowing the model to produce valuable synthetic medication prescriptions. We evaluate LT3's performance by contrasting it with a state-of-the-art Pre-trained Language Model (PLM), T5, analysing the quality and diversity of generated texts. We deploy the generated synthetic data to train the SpacyNER model for the Named Entity Recognition (NER) task over the n2c2-2018 dataset. The experiments show that the model trained on synthetic data can achieve a 96-98\\% F1 score at Label Recognition on Drug, Frequency, Route, Strength, and Form. LT3 codes and data will be shared at \\url{https://github.com/HECTA-UoM/Label-To-Text-Transformer}","creator":"Samuel Belkadi, Nicolo Micheletti, Lifeng Han, Warren Del-Pinto, Goran Nenadic"},{"id":"2310.20049","slug":"surf-a-generalization-benchmark-for-gnns-predicting-fluid-dynamics-arxiv-2310-20049v3-cs-lg-updated","title":"SURF: A Generalization Benchmark for GNNs Predicting Fluid Dynamics.","link":"http://arxiv.org/abs/2310.20049","abstract":"Simulating fluid dynamics is crucial for the design and development process, ranging from simple valves to complex turbomachinery. Accurately solving the underlying physical equations is computationally expensive. Therefore, learning-based solvers that model interactions on meshes have gained interest due to their promising speed-ups. However, it is unknown to what extent these models truly understand the underlying physical principles and can generalize rather than interpolate. Generalization is a key requirement for a general-purpose fluid simulator, which should adapt to different topologies, resolutions, or thermodynamic ranges. We propose SURF, a benchmark designed to test the $\\textit{generalization}$ of learned graph-based fluid simulators. SURF comprises individual datasets and provides specific performance and generalization metrics for evaluating and comparing different models. We empirically demonstrate the applicability of SURF by thoroughly investigating the two state-of-the-art graph-based models, yielding new insights into their generalization.","creator":"Stefan K&#xfc;nzli, Florian Gr&#xf6;tschla, Jo&#xeb;l Mathys, Roger Wattenhofer"},{"id":"2310.20327","slug":"improving-entropy-based-test-time-adaptation-from-a-clustering-view-arxiv-2310-20327v4-cs-ai-updated","title":"Improving Entropy-Based Test-Time Adaptation from a Clustering View.","link":"http://arxiv.org/abs/2310.20327","abstract":"Domain shift is a common problem in the realistic world, where training data and test data follow different data distributions. To deal with this problem, fully test-time adaptation (TTA) leverages the unlabeled data encountered during test time to adapt the model. In particular, Entropy-Based TTA (EBTTA) methods, which minimize the prediction's entropy on test samples, have shown great success. In this paper, we introduce a new perspective on the EBTTA, which interprets these methods from a view of clustering. It is an iterative algorithm: 1) in the assignment step, the forward process of the EBTTA models is the assignment of labels for these test samples, and 2) in the updating step, the backward process is the update of the model via the assigned samples. Based on the interpretation, we can gain a deeper understanding of EBTTA, where we show that the entropy loss would further increase the largest probability. Accordingly, we offer an alternative explanation for why existing EBTTA methods are sensitive to initial assignments, outliers, and batch size. This observation can guide us to put forward the improvement of EBTTA. We propose robust label assignment, weight adjustment, and gradient accumulation to alleviate the above problems. Experimental results demonstrate that our method can achieve consistent improvements on various datasets. Code is provided in the supplementary material.","creator":"Guoliang Lin, Hanjiang Lai, Yan Pan, Jian Yin"},{"id":"2311.00530","slug":"the-development-of-llms-for-embodied-navigation-arxiv-2311-00530v3-cs-ai-updated","title":"The Development of LLMs for Embodied Navigation.","link":"http://arxiv.org/abs/2311.00530","abstract":"In recent years, the rapid advancement of Large Language Models (LLMs) such as the Generative Pre-trained Transformer (GPT) has attracted increasing attention due to their potential in a variety of practical applications. The application of LLMs with Embodied Intelligence has emerged as a significant area of focus. Among the myriad applications of LLMs, navigation tasks are particularly noteworthy because they demand a deep understanding of the environment and quick, accurate decision-making. LLMs can augment embodied intelligence systems with sophisticated environmental perception and decision-making support, leveraging their robust language and image-processing capabilities. This article offers an exhaustive summary of the symbiosis between LLMs and embodied intelligence with a focus on navigation. It reviews state-of-the-art models, research methodologies, and assesses the advantages and disadvantages of existing embodied navigation models and datasets. Finally, the article elucidates the role of LLMs in embodied intelligence, based on current research, and forecasts future directions in the field. A comprehensive list of studies in this survey is available at https://github.com/Rongtao-Xu/Awesome-LLM-EN","creator":"Jinzhou Lin, Han Gao, Xuxiang Feng, Rongtao Xu, Changwei Wang, Man Zhang, Li Guo, Shibiao Xu"},{"id":"2311.01310","slug":"scattering-vision-transformer-spectral-mixing-matters-arxiv-2311-01310v2-cs-cv-updated","title":"Scattering Vision Transformer: Spectral Mixing Matters.","link":"http://arxiv.org/abs/2311.01310","abstract":"Vision transformers have gained significant attention and achieved state-of-the-art performance in various computer vision tasks, including image classification, instance segmentation, and object detection. However, challenges remain in addressing attention complexity and effectively capturing fine-grained information within images. Existing solutions often resort to down-sampling operations, such as pooling, to reduce computational cost. Unfortunately, such operations are non-invertible and can result in information loss. In this paper, we present a novel approach called Scattering Vision Transformer (SVT) to tackle these challenges. SVT incorporates a spectrally scattering network that enables the capture of intricate image details. SVT overcomes the invertibility issue associated with down-sampling operations by separating low-frequency and high-frequency components. Furthermore, SVT introduces a unique spectral gating network utilizing Einstein multiplication for token and channel mixing, effectively reducing complexity. We show that SVT achieves state-of-the-art performance on the ImageNet dataset with a significant reduction in a number of parameters and FLOPS. SVT shows 2\\% improvement over LiTv2 and iFormer. SVT-H-S reaches 84.2\\% top-1 accuracy, while SVT-H-B reaches 85.2\\% (state-of-art for base versions) and SVT-H-L reaches 85.7\\% (again state-of-art for large versions). SVT also shows comparable results in other vision tasks such as instance segmentation. SVT also outperforms other transformers in transfer learning on standard datasets such as CIFAR10, CIFAR100, Oxford Flower, and Stanford Car datasets. The project page is available on this webpage.\\url{https://badripatro.github.io/svt/}.","creator":"Badri N. Patro, Vijay Srinivas Agneeswaran"},{"id":"2311.02651","slug":"compute-at-scale-a-broad-investigation-into-the-data-center-industry-arxiv-2311-02651v3-cs-cy-updated","title":"Compute at Scale -- A Broad Investigation into the Data Center Industry.","link":"http://arxiv.org/abs/2311.02651","abstract":"This report characterizes the data center industry and its importance for AI development. Data centers are industrial facilities that efficiently provide compute at scale and thus constitute the engine rooms of today's digital economy. As large-scale AI training and inference become increasingly computationally expensive, they are dominantly executed from this designated infrastructure. Key features of data centers include large-scale compute clusters that require extensive cooling and consume large amounts of power, the need for fast connectivity both within the data center and to the internet, and an emphasis on security and reliability. The global industry is valued at approximately $250B and is expected to double over the next seven years. There are likely about 500 large (above 10 MW) data centers globally, with the US, Europe, and China constituting the most important markets. The report further covers important actors, business models, main inputs, and typical locations of data centers.","creator":"Konstantin Pilz, Lennart Heim"},{"id":"2311.04666","slug":"pre-training-llms-using-human-like-development-data-corpus-arxiv-2311-04666v2-cs-cl-updated","title":"Pre-training LLMs using human-like development data corpus.","link":"http://arxiv.org/abs/2311.04666","abstract":"Pre-trained Large Language Models (LLMs) have shown success in a diverse set of language inference and understanding tasks. The pre-training stage of LLMs looks at a large corpus of raw textual data. The BabyLM shared task compares LLM pre-training to human language acquisition, where the number of tokens seen by 13-year-old kids is magnitudes smaller than the number of tokens seen by LLMs. In this work, we pre-train and evaluate LLMs on their ability to learn contextual word representations using roughly the same number of tokens as seen by children. We provide a strong set of baselines; with different architectures, evaluation of changes in performance across epochs, and reported pre-training metrics for the strict small and strict tracks of the task. We also try to loosely replicate the RoBERTa baseline given by the task organizers to observe the training robustness to hyperparameter selection and replicability. We provide the submission details to the strict and strict-small tracks in this report.","creator":"Khushi Bhardwaj, Raj Sanjay Shah, Sashank Varma"},{"id":"2311.05659","slug":"enhancing-instance-level-image-classification-with-set-level-labels-arxiv-2311-05659v2-cs-lg-updated","title":"Enhancing Instance-Level Image Classification with Set-Level Labels.","link":"http://arxiv.org/abs/2311.05659","abstract":"Instance-level image classification tasks have traditionally relied on single-instance labels to train models, e.g., few-shot learning and transfer learning. However, set-level coarse-grained labels that capture relationships among instances can provide richer information in real-world scenarios. In this paper, we present a novel approach to enhance instance-level image classification by leveraging set-level labels. We provide a theoretical analysis of the proposed method, including recognition conditions for fast excess risk rate, shedding light on the theoretical foundations of our approach. We conducted experiments on two distinct categories of datasets: natural image datasets and histopathology image datasets. Our experimental results demonstrate the effectiveness of our approach, showcasing improved classification performance compared to traditional single-instance label-based methods. Notably, our algorithm achieves 13% improvement in classification accuracy compared to the strongest baseline on the histopathology image classification benchmarks. Importantly, our experimental findings align with the theoretical analysis, reinforcing the robustness and reliability of our proposed method. This work bridges the gap between instance-level and set-level image classification, offering a promising avenue for advancing the capabilities of image classification models with set-level coarse-grained labels.","creator":"Renyu Zhang, Aly A. Khan, Yuxin Chen, Robert L. Grossman"},{"id":"2311.06310","slug":"textit-labor-space-a-unifying-representation-of-the-labor-market-via-large-language-models-arxiv-2311-06310v2-physics-soc-ph-updated","title":"$\\textit{Labor Space}$: A Unifying Representation of the Labor Market via Large Language Models.","link":"http://arxiv.org/abs/2311.06310","abstract":"The labor market is a complex ecosystem comprising diverse, interconnected entities, such as industries, occupations, skills, and firms. Due to the lack of a systematic method to map these heterogeneous entities together, each entity has been analyzed in isolation or only through pairwise relationships, inhibiting comprehensive understanding of the whole ecosystem. Here, we introduce $\\textit{Labor Space}$, a vector-space embedding of heterogeneous labor market entities, derived through applying a large language model with fine-tuning. Labor Space exposes the complex relational fabric of various labor market constituents, facilitating coherent integrative analysis of industries, occupations, skills, and firms, while retaining type-specific clustering. We demonstrate its unprecedented analytical capacities, including positioning heterogeneous entities on an economic axes, such as `Manufacturing--Healthcare'. Furthermore, by allowing vector arithmetic of these entities, Labor Space enables the exploration of complex inter-unit relations, and subsequently the estimation of the ramifications of economic shocks on individual units and their ripple effect across the labor market. We posit that Labor Space provides policymakers and business leaders with a comprehensive unifying framework for labor market analysis and simulation, fostering more nuanced and effective strategic decision-making.","creator":"Seongwoon Kim, Yong-Yeol Ahn, Jaehyuk Park"},{"id":"2311.07127","slug":"untargeted-black-box-attacks-for-social-recommendations-arxiv-2311-07127v2-cs-si-updated","title":"Untargeted Black-box Attacks for Social Recommendations.","link":"http://arxiv.org/abs/2311.07127","abstract":"The rise of online social networks has facilitated the evolution of social recommender systems, which incorporate social relations to enhance users' decision-making process. With the great success of Graph Neural Networks in learning node representations, GNN-based social recommendations have been widely studied to model user-item interactions and user-user social relations simultaneously. Despite their great successes, recent studies have shown that these advanced recommender systems are highly vulnerable to adversarial attacks, in which attackers can inject well-designed fake user profiles to disrupt recommendation performances. While most existing studies mainly focus on targeted attacks to promote target items on vanilla recommender systems, untargeted attacks to degrade the overall prediction performance are less explored on social recommendations under a black-box scenario. To perform untargeted attacks on social recommender systems, attackers can construct malicious social relationships for fake users to enhance the attack performance. However, the coordination of social relations and item profiles is challenging for attacking black-box social recommendations. To address this limitation, we first conduct several preliminary studies to demonstrate the effectiveness of cross-community connections and cold-start items in degrading recommendations performance. Specifically, we propose a novel framework Multiattack based on multi-agent reinforcement learning to coordinate the generation of cold-start item profiles and cross-community social relations for conducting untargeted attacks on black-box social recommendations. Comprehensive experiments on various real-world datasets demonstrate the effectiveness of our proposed attacking framework under the black-box setting.","creator":"Wenqi Fan, Shijie Wang, Xiao-yong Wei, Xiaowei Mei, Qing Li"},{"id":"2311.07633","slug":"rethinking-and-benchmarking-predict-then-optimize-paradigm-for-combinatorial-optimization-problems-arxiv-2311-07633v2-cs-lg-updated","title":"Rethinking and Benchmarking Predict-then-Optimize Paradigm for Combinatorial Optimization Problems.","link":"http://arxiv.org/abs/2311.07633","abstract":"Numerous web applications rely on solving combinatorial optimization problems, such as energy cost-aware scheduling, budget allocation on web advertising, and graph matching on social networks. However, many optimization problems involve unknown coefficients, and improper predictions of these factors may lead to inferior decisions which may cause energy wastage, inefficient resource allocation, inappropriate matching in social networks, etc. Such a research topic is referred to as \"Predict-Then-Optimize (PTO)\" which considers the performance of prediction and decision-making in a unified system. A noteworthy recent development is the end-to-end methods by directly optimizing the ultimate decision quality which claims to yield better results in contrast to the traditional two-stage approach. However, the evaluation benchmarks in this field are fragmented and the effectiveness of various models in different scenarios remains unclear, hindering the comprehensive assessment and fast deployment of these methods. To address these issues, we provide a comprehensive categorization of current approaches and integrate existing experimental scenarios to establish a unified benchmark, elucidating the circumstances under which end-to-end training yields improvements, as well as the contexts in which it performs ineffectively. We also introduce a new dataset for the industrial combinatorial advertising problem for inclusive finance to open-source. We hope the rethinking and benchmarking of PTO could facilitate more convenient evaluation and deployment, and inspire further improvements both in the academy and industry within this field.","creator":"Haoyu Geng, Hang Ruan, Runzhong Wang, Yang Li, Yang Wang, Lei Chen, Junchi Yan"},{"id":"2311.07723","slug":"generalization-analogies-a-testbed-for-generalizing-ai-oversight-to-hard-to-measure-domains-arxiv-2311-07723v2-cs-ai-updated","title":"Generalization Analogies: A Testbed for Generalizing AI Oversight to Hard-To-Measure Domains.","link":"http://arxiv.org/abs/2311.07723","abstract":"As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable. To better understand how reward models generalize, we craft 69 distribution shifts spanning 8 categories. We find that reward models do not learn to evaluate `instruction-following' by default and instead favor personas that resemble internet text. Techniques for interpreting reward models' internal representations achieve better generalization than standard fine-tuning, but still frequently fail to distinguish instruction-following from conflated behaviors. We consolidate the 15 most challenging distribution shifts into the GENeralization analogIES (GENIES) benchmark, which we hope will enable progress toward controlling reward model generalization.","creator":"Joshua Clymer, Garrett Baker, Rohan Subramani, Sam Wang"},{"id":"2311.07750","slug":"synthensemble-a-fusion-of-cnn-vision-transformer-and-hybrid-models-for-multi-label-chest-x-ray-classification-arxiv-2311-07750v2-cs-cv-updated","title":"SynthEnsemble: A Fusion of CNN, Vision Transformer, and Hybrid Models for Multi-Label Chest X-Ray Classification.","link":"http://arxiv.org/abs/2311.07750","abstract":"Chest X-rays are widely used to diagnose thoracic diseases, but the lack of detailed information about these abnormalities makes it challenging to develop accurate automated diagnosis systems, which is crucial for early detection and effective treatment. To address this challenge, we employed deep learning techniques to identify patterns in chest X-rays that correspond to different diseases. We conducted experiments on the \"ChestX-ray14\" dataset using various pre-trained CNNs, transformers, hybrid(CNN+Transformer) models and classical models. The best individual model was the CoAtNet, which achieved an area under the receiver operating characteristic curve (AUROC) of 84.2%. By combining the predictions of all trained models using a weighted average ensemble where the weight of each model was determined using differential evolution, we further improved the AUROC to 85.4%, outperforming other state-of-the-art methods in this field. Our findings demonstrate the potential of deep learning techniques, particularly ensemble deep learning, for improving the accuracy of automatic diagnosis of thoracic diseases from chest X-rays.","creator":"S.M. Nabil Ashraf, Md. Adyelullahil Mamun, Hasnat Md. Abdullah, Md. Golam Rabiul Alam"},{"id":"2311.07780","slug":"parrot-trained-adversarial-examples-pushing-the-practicality-of-black-box-audio-attacks-against-speaker-recognition-models-arxiv-2311-07780v2-cs-sd-updated","title":"Parrot-Trained Adversarial Examples: Pushing the Practicality of Black-Box Audio Attacks against Speaker Recognition Models.","link":"http://arxiv.org/abs/2311.07780","abstract":"Audio adversarial examples (AEs) have posed significant security challenges to real-world speaker recognition systems. Most black-box attacks still require certain information from the speaker recognition model to be effective (e.g., keeping probing and requiring the knowledge of similarity scores). This work aims to push the practicality of the black-box attacks by minimizing the attacker's knowledge about a target speaker recognition model. Although it is not feasible for an attacker to succeed with completely zero knowledge, we assume that the attacker only knows a short (or a few seconds) speech sample of a target speaker. Without any probing to gain further knowledge about the target model, we propose a new mechanism, called parrot training, to generate AEs against the target model. Motivated by recent advancements in voice conversion (VC), we propose to use the one short sentence knowledge to generate more synthetic speech samples that sound like the target speaker, called parrot speech. Then, we use these parrot speech samples to train a parrot-trained(PT) surrogate model for the attacker. Under a joint transferability and perception framework, we investigate different ways to generate AEs on the PT model (called PT-AEs) to ensure the PT-AEs can be generated with high transferability to a black-box target model with good human perceptual quality. Real-world experiments show that the resultant PT-AEs achieve the attack success rates of 45.8% - 80.8% against the open-source models in the digital-line scenario and 47.9% - 58.3% against smart devices, including Apple HomePod (Siri), Amazon Echo, and Google Home, in the over-the-air scenario.","creator":"Rui Duan, Zhe Qu, Leah Ding, Yao Liu, Zhuo Lu"},{"id":"2311.07989","slug":"a-survey-on-language-models-for-code-arxiv-2311-07989v2-cs-cl-updated","title":"A Survey on Language Models for Code.","link":"http://arxiv.org/abs/2311.07989","abstract":"In this work we systematically review the recent advancements in code processing with language models, covering 50+ models, 30+ evaluation tasks, 150+ datasets, and 550 related works. We break down code processing models into general language models represented by the GPT family and specialized models that are specifically pretrained on code, often with tailored objectives. We discuss the relations and differences between these models, and highlight the historical transition of code modeling from statistical models and RNNs to pretrained Transformers and LLMs, which is exactly the same course that had been taken by NLP. We also discuss code-specific features such as AST, CFG, and unit tests, along with their application in training code language models, and identify key challenges and potential future directions in this domain. We keep the survey open and updated on GitHub repository at https://github.com/codefuse-ai/Awesome-Code-LLM.","creator":"Ziyin Zhang, Chaoyu Chen, Bingchang Liu, Cong Liao, Zi Gong, Hang Yu, Jianguo Li, Rui Wang"},{"id":"2311.08393","slug":"mvsa-net-multi-view-state-action-recognition-for-robust-and-deployable-trajectory-generation-arxiv-2311-08393v2-cs-cv-updated","title":"MVSA-Net: Multi-View State-Action Recognition for Robust and Deployable Trajectory Generation.","link":"http://arxiv.org/abs/2311.08393","abstract":"The learn-from-observation (LfO) paradigm is a human-inspired mode for a robot to learn to perform a task simply by watching it being performed. LfO can facilitate robot integration on factory floors by minimizing disruption and reducing tedious programming. A key component of the LfO pipeline is a transformation of the depth camera frames to the corresponding task state and action pairs, which are then relayed to learning techniques such as imitation or inverse reinforcement learning for understanding the task parameters. While several existing computer vision models analyze videos for activity recognition, SA-Net specifically targets robotic LfO from RGB-D data. However, SA-Net and many other models analyze frame data captured from a single viewpoint. Their analysis is therefore highly sensitive to occlusions of the observed task, which are frequent in deployments. An obvious way of reducing occlusions is to simultaneously observe the task from multiple viewpoints and synchronously fuse the multiple streams in the model. Toward this, we present multi-view SA-Net, which generalizes the SA-Net model to allow the perception of multiple viewpoints of the task activity, integrate them, and better recognize the state and action in each frame. Performance evaluations on two distinct domains establish that MVSA-Net recognizes the state-action pairs under occlusion more accurately compared to single-view MVSA-Net and other baselines. Our ablation studies further evaluate its performance under different ambient conditions and establish the contribution of the architecture components. As such, MVSA-Net offers a significantly more robust and deployable state-action trajectory generation compared to previous methods.","creator":"Ehsan Asali, Prashant Doshi, Jin Sun"},{"id":"2311.08427","slug":"towards-a-transportable-causal-network-model-based-on-observational-healthcare-data-arxiv-2311-08427v2-cs-lg-updated","title":"Towards a Transportable Causal Network Model Based on Observational Healthcare Data.","link":"http://arxiv.org/abs/2311.08427","abstract":"Over the last decades, many prognostic models based on artificial intelligence techniques have been used to provide detailed predictions in healthcare. Unfortunately, the real-world observational data used to train and validate these models are almost always affected by biases that can strongly impact the outcomes validity: two examples are values missing not-at-random and selection bias. Addressing them is a key element in achieving transportability and in studying the causal relationships that are critical in clinical decision making, going beyond simpler statistical approaches based on probabilistic association.  In this context, we propose a novel approach that combines selection diagrams, missingness graphs, causal discovery and prior knowledge into a single graphical model to estimate the cardiovascular risk of adolescent and young females who survived breast cancer. We learn this model from data comprising two different cohorts of patients. The resulting causal network model is validated by expert clinicians in terms of risk assessment, accuracy and explainability, and provides a prognostic model that outperforms competing machine learning methods.","creator":"Alice Bernasconi, Alessio Zanga, Peter J.F. Lucas, Marco Scutari, Fabio Stella"},{"id":"2311.09115","slug":"healnet-hybrid-multi-modal-fusion-for-heterogeneous-biomedical-data-arxiv-2311-09115v2-cs-lg-updated","title":"HEALNet -- Hybrid Multi-Modal Fusion for Heterogeneous Biomedical Data.","link":"http://arxiv.org/abs/2311.09115","abstract":"Technological advances in medical data collection such as high-resolution histopathology and high-throughput genomic sequencing have contributed to the rising requirement for multi-modal biomedical modelling, specifically for image, tabular, and graph data. Most multi-modal deep learning approaches use modality-specific architectures that are trained separately and cannot capture the crucial cross-modal information that motivates the integration of different data sources. This paper presents the Hybrid Early-fusion Attention Learning Network (HEALNet): a flexible multi-modal fusion architecture, which a) preserves modality-specific structural information, b) captures the cross-modal interactions and structural information in a shared latent space, c) can effectively handle missing modalities during training and inference, and d) enables intuitive model inspection by learning on the raw data input instead of opaque embeddings. We conduct multi-modal survival analysis on Whole Slide Images and Multi-omic data on four cancer cohorts of The Cancer Genome Atlas (TCGA). HEALNet achieves state-of-the-art performance, substantially improving over both uni-modal and recent multi-modal baselines, whilst being robust in scenarios with missing modalities.","creator":"Konstantin Hemker, Nikola Simidjievski, Mateja Jamnik"},{"id":"2311.09574","slug":"lymphoml-an-interpretable-artificial-intelligence-based-method-identifies-morphologic-features-that-correlate-with-lymphoma-subtype-arxiv-2311-09574v3-cs-lg-updated","title":"LymphoML: An interpretable artificial intelligence-based method identifies morphologic features that correlate with lymphoma subtype.","link":"http://arxiv.org/abs/2311.09574","abstract":"The accurate classification of lymphoma subtypes using hematoxylin and eosin (H&amp;E)-stained tissue is complicated by the wide range of morphological features these cancers can exhibit. We present LymphoML - an interpretable machine learning method that identifies morphologic features that correlate with lymphoma subtypes. Our method applies steps to process H&amp;E-stained tissue microarray cores, segment nuclei and cells, compute features encompassing morphology, texture, and architecture, and train gradient-boosted models to make diagnostic predictions. LymphoML's interpretable models, developed on a limited volume of H&amp;E-stained tissue, achieve non-inferior diagnostic accuracy to pathologists using whole-slide images and outperform black box deep-learning on a dataset of 670 cases from Guatemala spanning 8 lymphoma subtypes. Using SHapley Additive exPlanation (SHAP) analysis, we assess the impact of each feature on model prediction and find that nuclear shape features are most discriminative for DLBCL (F1-score: 78.7%) and classical Hodgkin lymphoma (F1-score: 74.5%). Finally, we provide the first demonstration that a model combining features from H&amp;E-stained tissue with features from a standardized panel of 6 immunostains results in a similar diagnostic accuracy (85.3%) to a 46-stain panel (86.1%).","creator":"Vivek Shankar, Xiaoli Yang, Vrishab Krishna, Brent Tan, Oscar Silva, Rebecca Rojansky, Andrew Ng, Fabiola Valvert, Edward Briercheck, David Weinstock, Yasodha Natkunam, Sebastian Fernandez-Pol, Pranav Rajpurkar"},{"id":"2311.09680","slug":"trustworthy-large-models-in-vision-a-survey-arxiv-2311-09680v2-cs-cv-updated","title":"Trustworthy Large Models in Vision: A Survey.","link":"http://arxiv.org/abs/2311.09680","abstract":"The rapid progress of Large Models (LMs) has recently revolutionized various fields of deep learning with remarkable grades, ranging from Natural Language Processing (NLP) to Computer Vision (CV). However, LMs are increasingly challenged and criticized by academia and industry due to their powerful performance but untrustworthy behavior, which urgently needs to be alleviated by reliable methods. Despite the abundance of literature on trustworthy LMs in NLP, a systematic survey specifically delving into the trustworthiness of LMs in CV remains absent. In order to mitigate this gap, we summarize four relevant concerns that obstruct the trustworthy usage in vision of LMs in this survey, including 1) human misuse, 2) vulnerability, 3) inherent issue and 4) interpretability. By highlighting corresponding challenge, countermeasures, and discussion in each topic, we hope this survey will facilitate readers' understanding of this field, promote alignment of LMs with human expectations and enable trustworthy LMs to serve as welfare rather than disaster for human society.","creator":"Ziyan Guo, Jun Liu"},{"id":"2311.10057","slug":"the-song-describer-dataset-a-corpus-of-audio-captions-for-music-and-language-evaluation-arxiv-2311-10057v2-cs-sd-updated","title":"The Song Describer Dataset: a Corpus of Audio Captions for Music-and-Language Evaluation.","link":"http://arxiv.org/abs/2311.10057","abstract":"We introduce the Song Describer dataset (SDD), a new crowdsourced corpus of high-quality audio-caption pairs, designed for the evaluation of music-and-language models. The dataset consists of 1.1k human-written natural language descriptions of 706 music recordings, all publicly accessible and released under Creative Common licenses. To showcase the use of our dataset, we benchmark popular models on three key music-and-language tasks (music captioning, text-to-music generation and music-language retrieval). Our experiments highlight the importance of cross-dataset evaluation and offer insights into how researchers can use SDD to gain a broader understanding of model performance.","creator":"Ilaria Manco, Benno Weck, SeungHeon Doh, Minz Won, Yixiao Zhang, Dmitry Bodganov, Yusong Wu, Ke Chen, Philip Tovstogan, Emmanouil Benetos, Elio Quinton, Gy&#xf6;rgy Fazekas, Juhan Nam"},{"id":"2311.10090","slug":"jaxmarl-multi-agent-rl-environments-in-jax-arxiv-2311-10090v3-cs-lg-updated","title":"JaxMARL: Multi-Agent RL Environments in JAX.","link":"http://arxiv.org/abs/2311.10090","abstract":"Benchmarks play an important role in the development of machine learning algorithms. For example, research in reinforcement learning (RL) has been heavily influenced by available environments and benchmarks. However, RL environments are traditionally run on the CPU, limiting their scalability with typical academic compute. Recent advancements in JAX have enabled the wider use of hardware acceleration to overcome these computational hurdles, enabling massively parallel RL training pipelines and environments. This is particularly useful for multi-agent reinforcement learning (MARL) research. First of all, multiple agents must be considered at each environment step, adding computational burden, and secondly, the sample complexity is increased due to non-stationarity, decentralised partial observability, or other MARL challenges. In this paper, we present JaxMARL, the first open-source code base that combines ease-of-use with GPU enabled efficiency, and supports a large number of commonly used MARL environments as well as popular baseline algorithms. When considering wall clock time, our experiments show that per-run our JAX-based training pipeline is up to 12500x faster than existing approaches. This enables efficient and thorough evaluations, with the potential to alleviate the evaluation crisis of the field. We also introduce and benchmark SMAX, a vectorised, simplified version of the popular StarCraft Multi-Agent Challenge, which removes the need to run the StarCraft II game engine. This not only enables GPU acceleration, but also provides a more flexible MARL environment, unlocking the potential for self-play, meta-learning, and other future applications in MARL. We provide code at https://github.com/flairox/jaxmarl.","creator":"Alexander Rutherford, Benjamin Ellis, Matteo Gallici, Jonathan Cook, Andrei Lupu, Gardar Ingvarsson, Timon Willi, Akbir Khan, Christian Schroeder de Witt, Alexandra Souly, Saptarashmi Bandyopadhyay, Mikayel Samvelyan, Minqi Jiang, Robert Tjarko Lange, Shimon Whiteson, Bruno Lacerda, Nick Hawes, Tim Rocktaschel, Chris Lu, Jakob Nicolaus Foerster"},{"id":"2311.10217","slug":"a-language-and-its-dimensions-intrinsic-dimensions-of-language-fractal-structures-arxiv-2311-10217v2-cs-cl-updated","title":"A Language and Its Dimensions: Intrinsic Dimensions of Language Fractal Structures.","link":"http://arxiv.org/abs/2311.10217","abstract":"The present paper introduces a novel object of study - a language fractal structure. We hypothesize that a set of embeddings of all $n$-grams of a natural language constitutes a representative sample of this fractal set. (We use the term Hailonakea to refer to the sum total of all language fractal structures, over all $n$). The paper estimates intrinsic (genuine) dimensions of language fractal structures for the Russian and English languages. To this end, we employ methods based on (1) topological data analysis and (2) a minimum spanning tree of a data graph for a cloud of points considered (Steele theorem). For both languages, for all $n$, the intrinsic dimensions appear to be non-integer values (typical for fractal sets), close to 9 for both of the Russian and English language.","creator":"Vasilii A. Gromov, Nikita S. Borodin, Asel S. Yerbolova"},{"id":"2310.19845","slug":"modified-genetic-algorithm-for-feature-selection-and-hyper-parameter-optimization-case-of-xgboost-in-spam-prediction-arxiv-2310-19845v1-cs-lg-cross-listed","title":"Modified Genetic Algorithm for Feature Selection and Hyper Parameter Optimization: Case of XGBoost in Spam Prediction.","link":"http://arxiv.org/abs/2310.19845","abstract":"Recently, spam on online social networks has attracted attention in the research and business world. Twitter has become the preferred medium to spread spam content. Many research efforts attempted to encounter social networks spam. Twitter brought extra challenges represented by the feature space size, and imbalanced data distributions. Usually, the related research works focus on part of these main challenges or produce black-box models. In this paper, we propose a modified genetic algorithm for simultaneous dimensionality reduction and hyper parameter optimization over imbalanced datasets. The algorithm initialized an eXtreme Gradient Boosting classifier and reduced the features space of tweets dataset; to generate a spam prediction model. The model is validated using a 50 times repeated 10-fold stratified cross-validation, and analyzed using nonparametric statistical tests. The resulted prediction model attains on average 82.32\\% and 92.67\\% in terms of geometric mean and accuracy respectively, utilizing less than 10\\% of the total feature space. The empirical results show that the modified genetic algorithm outperforms $Chi^2$ and $PCA$ feature selection methods. In addition, eXtreme Gradient Boosting outperforms many machine learning algorithms, including BERT-based deep learning model, in spam prediction. Furthermore, the proposed approach is applied to SMS spam modeling and compared to related works.","creator":"Nazeeh Ghatasheh, Ismail Altaharwa, Khaled Aldebei"}]},{"name":"Plant Biology","feed":[{"id":"2023.11.20.567890v1","slug":"designer-antisense-circrnagfp-reduces-gfp-protein-abundance-in-transgenic-arabidopsis-protoplasts-in-a-sequence-specific-manner-independent-of-rnai-pathways","title":"Designer antisense circRNAGFP reduces GFP protein abundance in transgenic Arabidopsis protoplasts in a sequence-specific manner, independent of RNAi pathways","link":"http://biorxiv.org/cgi/content/short/2023.11.20.567890v1?rss=1","abstract":"Circular RNAs (circRNAs) are single-stranded molecules that have attracted increasing attention in recent years due to their covalently closed structure and their diverse functional roles in mammalian cells, where they are involved in the regulation of gene expression and protein function. Increasing evidence suggests that circRNAs have similar functions in plants, where they play a role in plant development, resistance to biotic stress, and abiotic stress tolerance. Here, we investigated the agronomically relevant question of whether synthetic designer circRNAs can be used to modulate in a sequence-specific manner gene expression in plants. We show that treatment of GFP-expressing Arabidopsis protoplasts with designer 50 nt GFP antisense circRNA (circRNAGFP) reduces the cellular accumulation of the reporter protein in a sequence-specific and dose-dependent manner. This inhibitory activity of circRNAGFP was not abolished in various Arabidopsis ago and dcl mutants with defective RNAi pathways. Moreover, and in contrast to other types of RNA such as double-stranded (ds)RNA, circRNAs did not induce a PTI response in plant leaves. We discuss the possibility that circRNA may be applied to regulate endogenous plant genes and thus may have future potential as a novel bioherbicide.","creator":"Hossain, M., Pfafenroth, C., Imani, J., Secic, E., Sede, A. R., Galli, M., Heinlein, M., Bindereif, A., Ladera, M., Kogel, K.-H."},{"id":"2023.11.20.567875v1","slug":"mechanisms-of-infection-and-response-of-the-fungal-wheat-pathogen-zymoseptoria-tritici-during-compatible-incompatible-and-non-host-interactions","title":"Mechanisms of infection and response of the fungal wheat pathogen Zymoseptoria tritici during compatible, incompatible and non-host interactions","link":"http://biorxiv.org/cgi/content/short/2023.11.20.567875v1?rss=1","abstract":"Zymoseptoria tritici incites Septoria tritici blotch, a disease causing significant annual yield losses in wheat. To investigate infection phase-specific gene expression in the pathogen we analyzed gene expression during infection of susceptible (Taichung 29) and resistant (Veranopolis and Israel 493) wheat cultivars, plus the non-host species barley at 1, 3, 6, 10, 17 and 23 days post-inoculation (DPI). There were dramatic differences in pathogen gene expression at 10 DPI in the compatible compared to both incompatible interactions. The largest differences in pathogen gene expression occurred at 3 DPI in both compatible and incompatible interactions compared to the non-host interaction. Thirty-one putative effectors had early expression in the compatible interaction. Subsequent subcellular localization studies using Agrobacterium-mediated transient expression in Nicotiana benthamiana revealed that most candidate effectors localized to the nucleus and cytosol, and two localized to mobile cytosolic bodies, suggesting involvement in intracellular signaling or host gene regulation. Mycgr3109710, which localized to cytosolic bodies, belongs to the non-plant PR-1-like protein family implicated in virulence in other pathogens. Comparison of pathogen gene expression in resistant and susceptible hosts, in which an initial colonization is established, versus in the non-host species, allowed us to identify genes involved in establishing infection. Comparison of the compatible and incompatible interactions identified pathogen genes involved in transition from biotrophic to necrotrophic growth at 10 DPI. In addition, we contribute to the understanding of candidate effectors that are activated early during infection and might be involved in the initial plant immunity suppression.","creator":"Gomez-Gutierrez, S. V., Million, C. R., Jaiswal, N., Gribskov, M., Helm, M., Goodwin, S. B."},{"id":"2023.11.18.567672v1","slug":"comparative-cytogenetics-of-kenaf-hibiscus-cannabinus-l-breeding-lines-reveal-chromosomal-variability-and-instability","title":"Comparative cytogenetics of kenaf (Hibiscus cannabinus L.) breeding lines reveal chromosomal variability and instability","link":"http://biorxiv.org/cgi/content/short/2023.11.18.567672v1?rss=1","abstract":"Kenaf (Hibiscus cannabinus), a native warm-seasonal crop in Africa, is being considered for genetic improvement for local bast fiber production. To expedite its genetic improvement through breeding, kenaf genotypes from Ghana were assessed for genomic diversity regarding their chromosomal composition and ploidy levels. To gain insight into the repetitive DNA fractions in kenaf, the organization of 5S and 35S rRNA genes, as well as telomeric signal patterns were studied by a molecular cytogenetic approach. Using multi-color fluorescent in situ hybridization, distinct rDNA loci and Arabidopsis-type telomeres were revealed. The 5S rRNA genes were conserved in kenaf and localized in interstitial regions of two chromosomes across all accessions. The 35S rRNA genes were variable across the kenaf accessions and localized at sub-terminal ends and rarely interstitially in eight or six chromosome arms. Telomeric signals were observed at terminal ends of all chromosomes, with smaller signals also interstitially. The chromosome configuration of Ghana kenaf accessions was confirmed to be 2n=2x=36, each. We discuss the chromosomal variability and the likely genomic instability in the kenaf breeding lines from Ghana. To our knowledge, this is the first report on molecular cytogenetics on kenaf and thus, provides valuable insights into the genome of kenaf that will be useful for breeding. Additionally, this study provides a basis for further studies to analyze the repetitive DNA sequences and develop reference karyotypes to reveal genetic and evolutionary relationships between cultivated and wild Hibiscus species.","creator":"Ankrah, N.-A., El-nagish, A., Breitenbach, S., Tetteh, A., Heitkam, T."},{"id":"2023.11.18.567481v1","slug":"guanylate-cyclase-activity-of-tir1-afb-auxin-receptorsin-rapid-auxin-responses","title":"Guanylate cyclase activity of TIR1/AFB auxin receptorsin rapid auxin responses","link":"http://biorxiv.org/cgi/content/short/2023.11.18.567481v1?rss=1","abstract":"The major developmental signal in plants, auxin is perceived by TIR1/AFB receptors. It triggers transcriptional reprogramming via well-established canonical mechanism but also elusive rapid, non-transcriptional responses. Here we demonstrate that TIR1/AFB receptors have, next to recently identified adenylate cyclase, also guanylate cyclase activity. Auxin perception activates independently the cAMP and cGMP production by TIR1/AFBs in vitro and increases cAMP and cGMP levels in planta with a slow and fast dynamics, respectively. Exogenous cGMP but not cAMP application induces rapid cytosolic Ca2+ transients and root growth inhibition, suggesting that TIR1/AFB-derived cGMP mediates rapid auxin responses. This unprecedented combination of adenylate and guanylate cyclase activities in a hormone receptor provides a new paradigm for how a single perception mechanism can mediate a multitude of diverse downstream responses.","creator":"Qi, L., Kwiatkowski, M., Kulich, I., Chen, H., Gao, Y., Yun, P., Li, L., Shabala, S., Farmer, E., Jaworski, K., Friml, J."},{"id":"2023.11.17.567642v1","slug":"conservation-of-heat-stress-acclimation-by-the-inositol-polyphosphate-multikinase-ipmk-responsible-for-4-6-insp7-production-in-land-plants","title":"Conservation of heat stress acclimation by the inositol polyphosphate multikinase, IPMK responsible for 4/6-InsP7 production in land plants","link":"http://biorxiv.org/cgi/content/short/2023.11.17.567642v1?rss=1","abstract":"Inositol pyrophosphates (PP-InsPs) are soluble cellular messengers that integrate environmental cues to induce adaptive responses in eukaryotes. In plants, the biological functions of various PP-InsP species are poorly understood, largely due to the absence of canonical enzymes present in other eukaryotes. The recent identification of a new PP-InsP isomer with yet unknown enantiomeric identity, 4/6-InsP7 in the eudicot Arabidopsis thaliana, further highlights the intricate PP-InsP signalling network employed by plants. The abundance of 4/6-InsP7 in land plants, the enzyme(s) responsible for its synthesis, and the physiological functions of this species are all currently unknown. In this study, we show that 4/6-InsP7 is the major PP-InsP species present across land plants. Our findings demonstrate that the Arabidopsis inositol polyphosphate multikinase (IPMK) homolog, AtIPK2 generates 4/6-InsP7 in vitro. Furthermore, the cellular level of 4/6-InsP7 is controlled by the two Arabidopsis IPMK isoforms, AtIPK2 and AtIPK2{beta}. Notably, the activity of these IPMK proteins is critical for heat stress acclimation in Arabidopsis. During heat stress, the expression of genes encoding various heat shock proteins controlled by the heat shock factors (HSFs) is affected in the AtIPK2-deficient plants. Furthermore, we show that the transcription activity of HSF is regulated by the AtIPK2 proteins. Our parallel investigations using the liverwort Marchantia polymorpha suggest that the InsP6 kinase activity of IPMK and the role of IPMK in regulating the heat stress response are evolutionarily conserved. Collectively, our study indicates that IPMK has played a critical role in transducing environmental cues for biological processes during land plant evolution.","creator":"Yadav, R., Liu, G., Rana, P., Pullagurla, N. J., Qiu, D., Jessen, H. J., Laha, D."},{"id":"2023.11.16.567443v1","slug":"inositolphosphate-glycans-accumulate-and-suppress-plant-defense-during-arabidopsis-botrytis-interaction","title":"Inositolphosphate glycans accumulate and suppress plant defense during Arabidopsis/Botrytis interaction","link":"http://biorxiv.org/cgi/content/short/2023.11.16.567443v1?rss=1","abstract":"This study investigates the presence and significance of previously undiscovered oligosaccharides that accumulate during the interaction between Arabidopsis thaliana and Botrytis cinerea, a pathogenic fungus. Initially focused on characterizing cell wall-derived oligosaccharides, the research uncovered inositol phosphate glycans (IPGs) originating from plant sphingolipids, specifically glycosylinositol phosphorylceramides. Advanced chromatography, mass spectrometry techniques and molecular biology were employed to identify these IPGs, determine their origins, and study their role in the A. thaliana-B. cinerea interaction. Contrary to the conventional belief that oligosaccharides trigger plant defense, this research suggests that B. cinerea releases IPGs identical to those generated by host plant to actually downregulate plant defense mechanisms. This discovery offers insight into the dynamic strategies used by B. cinerea to evade plant defenses and establish successful infections.","creator":"Lelas, L., Rouffet, J., Filachet, A., Sechet, J., Akary, E., Desprez, T., Vernhettes, S., Voxeur, A."},{"id":"2023.11.17.567530v1","slug":"the-cuticular-wax-compositions-and-crystal-coverage-of-leaves-and-petals-differ-in-a-consistent-manner-between-plant-species","title":"The cuticular wax compositions and crystal coverage of leaves and petals differ in a consistent manner between plant species","link":"http://biorxiv.org/cgi/content/short/2023.11.17.567530v1?rss=1","abstract":"Both leaves and petals are covered in a cuticle, which itself contains and is covered by, cuticular waxes. The waxes perform various roles in plants' lives, and the cuticular composition of leaves has received much attention. To date, the cuticular composition of petals has been largely ignored. Being the outermost boundary between the plant and the environment, the cuticle is the first point of contact between a flower and a pollinator, yet we know little about how plant-pollinator interactions shape its chemical composition. Here, we investigate the general structure and composition of floral cuticular waxes by analysing the cuticular composition of leaves and petals of 49 plant species, representing 19 orders and 27 families. We show that the flowers of plants from across the phylogenetic range are nearly devoid of wax crystals, and that the total wax load of leaves in 90% of the species is higher than that of petals. The proportion of alkanes is higher, and the chain-lengths of the aliphatic compounds are shorter in petals than in leaves. We argue these differences are a result of the adaptation to the different roles leaves and petals play in plant biology.","creator":"Tunstad, S. A., Bull, I. D., Rands, S. A., Whitney, H. M."},{"id":"2023.11.17.567553v1","slug":"pseudomonas-syringae-pv-tomato-dc3000-induces-defense-responses-in-diverse-maize-inbred-lines","title":"Pseudomonas syringae pv. tomato DC3000 induces defense responses in diverse maize inbred lines","link":"http://biorxiv.org/cgi/content/short/2023.11.17.567553v1?rss=1","abstract":"Many phytopathogens translocate virulence (effector) proteins into plant cells to circumvent host immune responses during infection. One such pathogen is Pseudomonas syringae pv. tomato DC3000, which secretes at least twenty-nine effectors into host cells, of which a subset elicits host defense responses in crop plant species. However, it is unknown whether P. syringae pv. tomato DC3000 activates immune responses in diverse maize inbreds. Here, we screened a diverse maize germplasm collection for effector-dependent recognition of this bacterial pathogen. As a control, we infiltrated Pseudomonas syringae DC3000(D36E), a derivative of P. syringae pv. tomato DC3000 that lacks all endogenous effectors. In our evaluations, we observed a variety of responses to P. syringae pv. tomato DC3000 in maize and scored the phenotypes as either no observable response (N) or as one of three responses: weak chlorosis (WC), chlorosis (C) with minimal cell death, and hypersensitive reaction (HR)-like cell death. Of the twenty-six maize inbreds screened, 13 were scored as N, 2 as WC, 2 as C, and 9 as HR-like cell death. Importantly, no maize line responded to P. syringae DC3000(D36E), demonstrating the responses observed are likely dependent upon recognition of one or more Pseudomonas effectors. Importantly, maize inbreds that recognize P. syringae pv. tomato DC3000 accumulated detectable hydrogen peroxide as well as an increase in transcript expression of a subset of maize defense genes. Collectively, our results will likely stimulate new research aimed at identifying the cognate maize disease resistance proteins that recognize the activities of one or more bacterial effectors.","creator":"Jaiswal, N., Helm, M."},{"id":"2023.11.15.567278v1","slug":"influence-of-mixed-and-single-infection-of-grapevine-leafroll-associated-virus-and-viral-load-on-berry-quality","title":"Influence of mixed and single infection of grapevine leafroll-associated virus and viral load on berry quality","link":"http://biorxiv.org/cgi/content/short/2023.11.15.567278v1?rss=1","abstract":"1Grapevine leafroll disease (GLD) is a viral disease that affects grapevines (Vitis vinifera L.) and has a severe economic impact on viticulture. In this study, the effect of grapevine leafroll-associated viruses (GLRaV) on berry quality was investigated in clones of cultivar cv. Crimson Seedless table grapes infected with GLRaV. RT-PCR confirmed the identity of the clones: clone 3236, infected only with GLRaV-3 (termed Single); clone 3215, infected with GLRaV-3, GLRaV-4 strain 9 and grapevine virus A (termed Mixed), and a viral free clone of the same genetic background of the infected clones (termed Control). The berry quality indices of size, sugar, acidity, and anthocyanin content were measured at harvest maturity. RT-qPCR was used to determine viral load. The study was repeated over two years. A two-way, multivariate analysis of variance (MANOVA) was applied with clone and season as independent variables and the measured berry quality parameters as a dependent variable. All dependent variables were significantly affected by viral infection (Wilks, {lambda}, [2,33] = 0.033895, p-value < 0.001), while only titratable acidity (TA) was affected by season. Average berry dry mass decreased (p-value < 0.001). The water content of both infected clones was greater than that of the control (p-value < 0.001). Both infected clones displayed reduced sugar content as a fraction of the berry dry mass (p-value < 0.001). The anthocyanin and the phenol content of the infected clones were significantly reduced compared to the control clone (p < 0.001, p < 0.05, clone 3236 and clone 3215, respectively). Finally, the viral load was highly variable, and no quantitative relationship between viral load and berry composition was found.","creator":"Salo, W., Considine, J. A., Considine, M. J."},{"id":"2023.11.16.567332v1","slug":"guidelines-for-performing-ribosome-profiling-in-plants-including-structural-analysis-of-rrna-fragments","title":"Guidelines for performing ribosome profiling in plants including structural analysis of rRNA fragments","link":"http://biorxiv.org/cgi/content/short/2023.11.16.567332v1?rss=1","abstract":"Ribosome profiling (or Ribo-seq) is a technique that provides genome-wide information on the translational landscape (translatome). Across different plant studies, variable methodological setups have been described which raises questions about the general comparability of data that were generated from diverging methodologies. Furthermore, a common problem when performing Ribo-seq are abundant rRNA fragments that are wastefully incorporated into the libraries and dramatically reduce sequencing depth. To remove these rRNA contaminants, it is common to perform preliminary trials to identify these fragments because they are thought to vary depending on nuclease treatment, tissue source, and plant species. Here, we compile valuable insights gathered over years of generating Ribo-seq datasets from different species and experimental setups. We highlight which technical steps are important for maintaining cross experiment comparability and describe a highly efficient approach for rRNA removal. Furthermore, we provide evidence that many rRNA fragments are structurally preserved over diverse nuclease regimes, as well as across plant species. Using a recently published cryo-electron microscopy (cryo-EM) structure of the tobacco 80S ribosome, we show that the most abundant rRNA fragments are spatially derived from the solvent-exposed surface of the ribosome. The guidelines presented here shall aid newcomers in establishing ribosome profiling in new plant species and provide insights that will help in customizing the methodology for individual research goals.","creator":"Ting, M. K. Y., Gao, Y., Barahimipour, R., Ghandour, R., Liu, J., Martinez-Seidel, F., Smirnova, J., Gotsmann, V. L., Fischer, A., Haydon, M. J., Willmund, F., Zoschke, R."},{"id":"2023.11.15.565111v1","slug":"distinct-mechanisms-of-plant-immune-resilience-revealed-by-natural-variation-in-warm-temperature-modulated-disease-resistance-among-arabidopsis-accessions","title":"Distinct mechanisms of plant immune resilience revealed by natural variation in warm temperature-modulated disease resistance among Arabidopsis accessions","link":"http://biorxiv.org/cgi/content/short/2023.11.15.565111v1?rss=1","abstract":"Elevated temperature suppresses production of the key plant defence hormone salicylic acid (SA). Heat-mediated SA suppression and resulting plant vulnerability are due to downregulated expression of CALMODULIN BINDING PROTEIN 60-LIKE G (CBP60g) and SYSTEMIC ACQUIRED RESISTANCE DEFICIENT 1 (SARD1), which encode master regulators of plant immunity. However, previous studies in Arabidopsis thaliana plants have primarily focused on the accession Columbia-0 (Col-0), while the mechanisms governing the intraspecific variation in Arabidopsis immunity under elevated temperature have remained unknown. Here we show that BASIC HELIX LOOP HELIX 059 (bHLH059), a thermosensitive SA regulator at non-stress temperatures, does not regulate immune suppression under warmer temperatures. In agreement, temperature-resilient and -sensitive Arabidopsis accessions based on disease resistance to the bacterial pathogen Pseudomonas syringae pv. tomato (Pst) DC3000 did not correlate with bHLH059 sequence polymorphisms. Instead, we found that different temperature-resilient accessions exhibit varying CBP60g and SARD1 expression profiles, potentially revealing both CBP60g/SARD1-dependent and independent mechanisms of plant immune resilience to warming temperature. Collectively, this study has unveiled the intraspecific diversity of Arabidopsis immune responses under warm temperatures. Our dissection of mechanisms underlying temperature-modulated plant immunity could aid in predicting plant responses to climate change and provide foundational knowledge for climate-resilient crop engineering.","creator":"Rossi, C. A. M., Patel, D. N., Castroverde, C. D. M."},{"id":"2023.11.15.567221v1","slug":"bacterial-assembly-in-the-switchgrass-rhizosphere-is-shaped-by-phylogeny-host-genotype-and-growing-site","title":"Bacterial assembly in the switchgrass rhizosphere is shaped by phylogeny, host genotype, and growing site.","link":"http://biorxiv.org/cgi/content/short/2023.11.15.567221v1?rss=1","abstract":"Since microbial traits are conserved at different taxonomic levels, plant hosts may influence microbiome composition differently at different levels to broadly promote or resist microbiota with traits that impact host fitness. We tested this hypothesis by assessing signals of host genetic influence on bacterial composition in the switchgrass rhizosphere using 128 genotypes in dissimilar growing sites. We employed three common gardens, combined with host genetic mapping, 16S rRNA gene sequence analysis, hierarchical modeling, tests of phylogenetic conservation of host influence, and genome-wide association analyses to determine the contributions of host genetics in shaping rhizosphere bacterial composition at different taxonomic levels. Modeling bacterial assembly showed that growing site was a strong factor shaping bacterial composition in the rhizosphere, though host genetic influence played a significant role. The heritability of bacterial abundance was strongest at the genus level. Phylogenetic signal for heritability was detected within the bacterial phylogeny but conserved clades differed between common gardens. We identified shared host genetic variants associated with bacterial abundance and host traits related to plant metabolism. Our results suggest further investigation is required regarding the genotype-by-environment-by-microbiome relationship to elucidate the factors shaping rhizosphere microbiome composition and the agroecological dynamics shaping plant phenotype.","creator":"Sutherland, J., Bell, T. H., Bonos, S., Tkach, C., Hansen, J., Crawford, R., Carlson, J. E., Lasky, J. R."},{"id":"2023.11.14.564028v1","slug":"xanthomonas-citri-subsp-citri-type-iii-effector-ptha4-directs-the-dynamical-expression-of-a-putative-citrus-carbohydrate-binding-gene-for-canker-formation","title":"Xanthomonas citri subsp. citri type III effector PthA4 directs the dynamical expression of a putative citrus carbohydrate-binding gene for canker formation","link":"http://biorxiv.org/cgi/content/short/2023.11.14.564028v1?rss=1","abstract":"Xanthomonas citri subsp. citri (Xcc), the causal agent of citrus bacterial canker, elicits canker symptoms in citrus plants because of the transcriptional activator-like (TAL) effector PthA4, which activates the expression of the citrus susceptibility gene CsLOB1. This study reports the regulation of the putative carbohydrate-binding protein gene Cs9g12620 by the PthA4-CsLOB1 module during Xcc infection. We found that the transcription of Cs9g12620 was induced by infection with Xcc in a PthA4-dependent manner. Even though it specifically bound to a putative TAL effector-binding element in the Cs9g12620 promoter, PthA4 exerted a suppressive effect on the promoter activity. In contrast, CsLOB1 bound to the Cs9g12620 promoter to activate its activity. The silencing of CsLOB1 significantly reduced the level of expression of Cs9g12620, which demonstrated that Cs9g12620 was directly regulated by CsLOB1. Intriguingly, PhtA4 interacted with CsLOB1 and exerted feedback control that suppressed the induction of expression of Cs9g12620 by CsLOB1. Transient overexpression and gene silencing revealed that Cs9g12620 was required for the optimal development of canker symptoms. These results support the hypothesis that the expression of Cs9g12620 is dynamically directed by PthA4 for canker formation through the PthA4-CsLOB1 regulatory module.","creator":"Chen, X., Zou, H., Zhuo, T., Rou, W., Wu, W., Fan, X."},{"id":"2023.11.15.567147v1","slug":"identification-of-a-putative-rhamnogalacturonan-ii-cmp-beta-kdo-transferase-through-a-callus-based-gene-editing-method-which-overcomes-embryo-lethality","title":"Identification of a putative rhamnogalacturonan-II CMP-beta-Kdo transferase through a callus-based gene editing method which overcomes embryo lethality.","link":"http://biorxiv.org/cgi/content/short/2023.11.15.567147v1?rss=1","abstract":"The pectin rhamnogalacturonan II (RG-II) is an extraordinarily complex plant carbohydrate, crucial for developmental processes. RG-II contains over 20 distinct glycosidic linkages involving 12 distinct sugars; its biosynthesis is predicted to require numerous glycosyltransferases (GTs). RG-IIs low abundance in the plant cell wall belies its vital role in plant development. Minor structural modifications lead to lethality or severe growth impairment, posing significant challenges for GT identification via reverse genetics. Here we developed a novel method to generate viable loss-of-function Arabidopsis mutants in callus tissue via gene editing. We combined this with a candidate gene approach to characterize the GT29 RCKT1/MGP2. Analysis of rckt1 callus revealed a loss of 3-deoxy-D-manno-octulosonic acid (Kdo) from RG-II sidechain C, suggesting RCKT1s role as the RG-II CMP-{beta}-Kdo transferase1. RCKT1 becomes only the second confirmed GT implicated in RG-II biosynthesis. This discovery provides insight into RG-IIs structural impact on plant cell walls, as well as a method to further uncover the machinery required for the synthesis of this enigmatic polymer.","creator":"Zhang, Y., Sharma, D., Liang, Y., Downs, N., Dolman, F., Thorne, K., Pereira, J. H., Adams, P. D., Scheller, H., O'Neill, M., Urbanowicz, B. R., Mortimer, J. C."},{"id":"2023.11.15.567161v1","slug":"the-polyamines-spermine-and-spermidine-inhibit-or-induce-programmed-cell-death-in-arabidopsis-thaliana-in-vitro-and-in-vivo-in-a-dose-dependent-manner","title":"The polyamines spermine and spermidine inhibit or induce programmed cell death in Arabidopsis thaliana in vitro and in vivo in a dose dependent manner.","link":"http://biorxiv.org/cgi/content/short/2023.11.15.567161v1?rss=1","abstract":"Polyamines are ubiquitous biomolecules with a number of established functions in eukaryotic cells. In plant cells, polyamines have previously been linked to abiotic and biotic stress tolerance, as well as to the modulation of programmed cell death (PCD), with contrasting reports on their pro-PCD and pro-survival effects. Here, we used two well established platforms for the study of plant PCD; Arabidopsis thaliana suspension cultures cells and the root hair assay, to examine the roles of the polyamines spermine and spermidine in the regulation of PCD. We demonstrate that both polyamines can trigger PCD when applied exogenously at higher doses, whereas at lower concentrations they inhibit PCD induced by both biotic and abiotic stimuli. Furthermore, we show that concentrations of polyamines resulting in inhibition of PCD generated a transient ROS burst in our experimental system, and activated the expression of oxidative stress- and pathogen response-associated genes. Finally, we examined PCD responses in existing Arabidopsis polyamine synthesis mutants, and identified a subtle PCD phenotype in Arabidopsis seedlings deficient in thermo-spermine. The presented data show that polyamines can have a role in PCD regulation, however that role is dose-dependent and consequently they may act as either inhibitors, or inducers, of PCD in Arabidopsis.","creator":"Burke, R., Nicotra, D., Phelan, J., McCabe, P. F., Kacprzyk, J."},{"id":"2023.11.15.567154v1","slug":"integrating-annual-radial-growth-analyses-and-carbon-isotope-discrimination-to-forecast-early-warning-of-beech-forest-dieback-across-the-italian-peninsula","title":"Integrating annual radial growth analyses and carbon isotope discrimination to forecast early warning of beech forest dieback across the Italian Peninsula","link":"http://biorxiv.org/cgi/content/short/2023.11.15.567154v1?rss=1","abstract":"Tree mortality and forest dieback episodes are increasing due to drought and heat stress. However, a comprehensive understanding of the mechanisms enabling trees to cope with droughts remains lacking. Here, we employed a multi-proxy method utilizing tree-ring width, basal area increment (BAI) trends, and {delta}13C-derived intrinsic water-use-efficiency (iWUE) to unravel beech resilience against drought stress. We selected four sites spanning the latitudinal gradient and beech distribution in northern (Trentino-TRE), central (Lazio-LAZ), southern (Campania-CAM) and southernmost Italy (Calabria-CAL) with different climate conditions and soil water availability.  First-order autocorrelation (AR1) analysis was performed to detect early warning signals for potential tree dieback risks during extreme drought events. Results revealed a negative correlation between vapour pressure deficit (VPD) and BAI, especially at southern latitudes. GAMM analysis showed a negative trend in BAI across most sites, stronger at the TRE site following the 2003 drought event. During this event, {delta}13C and iWUE increased with rising VPD, indicative of conservative water-use (lower stomatal conductance) and contributing to the decline in BAI. Conversely, CAM exhibited a steady increase in BAI and iWUE, likely influenced by rising atmospheric CO2 and water availability. LAZ site exhibited a decrease in {delta}13C, attributed to greater soil water holding capacity, enabling it to sustain higher transpiration rates. Conversely, southern sites presented higher iWUE, likely as high VPD initially reduces stomatal conductance but not the net assimilation rate, resulting in increased iWUE. Nevertheless, almost all sites exhibited a co-occurrence of increase in AR1 (except for CAM) and standard deviation, suggesting a reduction of resilience to future extreme events.  Overall, multi-proxy, retrospective quantifications of BAI, iWUE and resilience provide a robust and complementary tool for differentiating water-use strategies and predicting tree growth decline and dieback, as well as identifying those that have the potential to survive in warmer and drier future conditions.","creator":"Puchi, P. F., Dalmonech, D., Vangi, E., Battipaglia, G., Tognetti, R., Collalti, A."},{"id":"2023.11.12.566746v1","slug":"a-transcriptomic-dataset-for-investigating-the-arabidopsis-unfolded-protein-response-under-chronic-proteotoxic-endoplasmic-reticulum-stress","title":"A transcriptomic dataset for investigating the Arabidopsis Unfolded Protein Response under chronic, proteotoxic endoplasmic reticulum stress","link":"http://biorxiv.org/cgi/content/short/2023.11.12.566746v1?rss=1","abstract":"The Unfolded Protein Response (UPR) is a retrograde, ER-to-nucleus, signalling pathway which is conserved across kingdoms. In plants, it contributes to development, reproduction, immunity and tolerance to abiotic stress. This RNA sequencing dataset was produced from 14-day-old Arabidopsis thaliana seedlings challenged by tunicamycin (Tm), an antibiotic inhibiting Asn-linked glycosylation in the endoplasmic reticulum (ER), causing an ER stress and eventually activating the UPR. Wild-type (WT) and a double mutant deficient for two main actors of the UPR (INOSITOL-REQUIRING ENZYME 1A and INOSITOL-REQUIRING ENZYME 1B) were used as genetic backgrounds in our experimental setup, allowing to distinguish among differentially-expressed genes (DEGs) which ones are dependent on or independent on IRE1s. Also, shoots and roots were harvested separately to determine organ-specific transcriptomic responses to Tm. Library and sequencing were performed using DNBseq technology by the Beijing Genomics Institute. Reads were mapped and quantified against the Arabidopsis genome. Differentially-expressed genes were identified using Rflomics upon filtering and normalization by the Trimmed Mean of M-value (TMM) method. While the genotype effect was weak under mock conditions (with a total of 182 DEGs in shoots and 195 DEGs in roots), the tunicamycin effect on each genotype was characterized by several hundred of DEGs in both shoots and roots. Among these genes, 872 and 563 genes were statistically up- and down-regulated in the shoot tissues of the double mutant when compared to those of WT, respectively. In roots of Tm-challenged seedlings, 425 and 439 genes were significantly up- and down-regulated in mutants with respect to WT. We believe that our dataset could be reused for investigating any biological questions linked to ER homeostasis and its role in plant physiology.  SPECIFICATIONS TABLE  O_TBL View this table: org.highwire.dtl.DTLVardef@14f84beorg.highwire.dtl.DTLVardef@193f66aorg.highwire.dtl.DTLVardef@116e98eorg.highwire.dtl.DTLVardef@13fa9caorg.highwire.dtl.DTLVardef@a443c8_HPS_FORMAT_FIGEXP  M_TBL C_TBL","creator":"Ducloy, A., Azzopardi, M., Ivsic, C., Cueff, G., Sourdeval, D., Charif, D., Cacas, J.-L."},{"id":"2023.11.12.566724v1","slug":"photobodies-enable-the-phase-separation-and-counterbalance-of-phytochrome-b-mediated-pif5-degradation-and-stabilization","title":"Photobodies enable the phase-separation and counterbalance of phytochrome B mediated PIF5 degradation and stabilization","link":"http://biorxiv.org/cgi/content/short/2023.11.12.566724v1?rss=1","abstract":"Photoactivation of the plant photoreceptor and thermosensor phytochrome B (PHYB) triggers its condensation into subnuclear photobodies (PBs). However, the function of PBs remains frustratingly elusive. Here, we show that PHYB condensation enables the co-occurrence and competition of two antagonistic phase-separated signaling actions. We found that PHYB recruits PHYTOCHROME-INTERACTING FACTOR5 (PIF5) to PBs and, surprisingly, that PHYB exerts opposing roles in degrading and stabilizing PIF5. Perturbing PB size by overproducing PHYB provoked a biphasic PIF5 response: while a moderate increase in PHYB enhanced PIF5 degradation, further elevating the PHYB level stabilized PIF5 by retaining more of it in enlarged PBs. Our results support a model in which PHYB condensation stabilizes PIF5 in PBs to counteract PIF5 degradation in the surrounding nucleoplasm, thereby enabling an environmentally sensitive counterbalancing mechanism to titrate nucleoplasmic PIF5 and its transcriptional output. This PB-enabled signaling mechanism provides a framework for regulating a plethora of PHYB-interacting signaling molecules in diverse plant environmental responses. We propose that this function of PBs represents a general function of biomolecular condensates to allow distinct variations of a cellular process or signaling pathway to coexist and interact to generate dynamically adjustable integrated outputs within a single subcellular space.","creator":"Kim, R. J. A., Fan, D., He, J., Kim, K., Du, J., Chen, M."},{"id":"2023.11.10.566533v1","slug":"a-multiscale-approach-to-investigate-fluorescence-and-ndvi-imaging-as-proxy-of-photosynthetic-traits-in-wheat","title":"A multiscale approach to investigate fluorescence and NDVI imaging as proxy of photosynthetic traits in wheat","link":"http://biorxiv.org/cgi/content/short/2023.11.10.566533v1?rss=1","abstract":"With the development of the digital phenotyping, repeated measurements of agronomic traits over time are easily accessible, notably for morphological and phenological traits. However high throughput methods for estimating physiological traits such as photosynthesis are lacking. This study demonstrates the links of fluorescence and reflectance imaging with photosynthetic traits. Two wheat cultivars were grown in pots in a controlled environment. Photosynthesis was characterised by gas-exchange and biochemical analysis at five time points, from booting to 21 days post anthesis. On the same days imaging was performed on the same pots, at leaf and plant scale, using indoor and outdoor phenotyping platforms, respectively. Five image variables (Fv/Fm and NDVI at the whole plant level and Fv/Fm, {Phi}(II)532 and {Phi}(NPQ)1077 at the leaf scale) were compared to variables from A-Ci and A-Par curves, biochemical analysis, and fluorescence instruments. The results suggested that the image variables are robust estimators of photosynthetic traits, as long as senescence is driving the variability. Despite contrasting cultivar behaviour, linear regression models which account for the cultivar and the interaction effects, further improved the modelling of photosynthesis indicators. Finally, the results highlight the challenge of discriminating functional to cosmetic stay green genotypes using digital imaging.  HighlightA temporal and multi-scale study of fluorescence and NDVI imaging used as a proxy for photosynthetic parameters","creator":"Virlet, N., Pennacchi, J. P., Sadeghi-Tehran, P., Ashfield, T., Orr, D., Carmo-Silva, E., Hawkesford, M."},{"id":"2023.11.14.566975v1","slug":"plant-pathogenic-fungi-hijack-phosphate-starvation-signaling-with-conserved-enzymatic-effectors","title":"Plant pathogenic fungi hijack phosphate starvation signaling with conserved enzymatic effectors","link":"http://biorxiv.org/cgi/content/short/2023.11.14.566975v1?rss=1","abstract":"Phosphate availability modulates plant immune function and regulates interactions with beneficial, phosphate-providing, microbes. Here, we describe the hijacking of plant phosphate sensing by a family of Nudix hydrolase effectors from pathogenic Magnaporthe oryzae and Colletotrichum fungi. Structural and enzymatic analyses of the Nudix effector family demonstrate that they selectively hydrolyze inositol pyrophosphates, a molecule used by plants to monitor phosphate status and regulate starvation responses. In M. oryzae, gene deletion and complementation experiments reveal that the enzymatic activity of a Nudix effector significantly contributes to pathogen virulence. Further, we show that this conserved effector family induces phosphate starvation signaling in plants. Our study elucidates a molecular mechanism, utilized by multiple phytopathogenic fungi, that manipulates the highly conserved plant phosphate sensing pathway to exacerbate disease.  One-Sentence SummaryA family of conserved enzyme effectors from pathogenic fungi manipulate plant phosphate sensing to promote infection.","creator":"McCombe, C. L., Wegner, A., Zamora, C. S., Casanova, F., Aditya, S., Greenwood, J. R., Wirtz, L., de Paula, S., England, E., Shang, S., Ericsson, D. J., Oliveira-Garcia, E., Williams, S. J., Schaffrath, U."},{"id":"2023.11.14.567017v1","slug":"evidence-that-variation-in-root-anatomy-contributes-to-local-adaptation-in-mexican-native-maize","title":"Evidence that variation in root anatomy contributes to local adaptation in Mexican native maize","link":"http://biorxiv.org/cgi/content/short/2023.11.14.567017v1?rss=1","abstract":"Mexican native maize (Zea mays ssp. mays) is adapted to a wide range of climatic and edaphic conditions. Here, we focus specifically on the potential role of root anatomical variation in this adaptation. In light of the investment required to characterize root anatomy, we present a machine learning approach using environmental descriptors to project trait variation from a relatively small training panel onto a larger panel of genotyped and georeferenced Mexican maize accessions. The resulting models defined potential biologically relevant clines across a complex environment and were used subsequently in genotype-environment association. We found evidence of systematic variation in maize root anatomy across Mexico, notably a prevalence of trait combinations favoring a reduction in axial conductance in cooler, drier highland areas. We discuss our results in the context of previously described water-banking strategies and present candidate genes that are associated with both root anatomical and environmental variation. Our strategy is a refinement of standard environmental genome wide association analysis that is applicable whenever a training set of georeferenced phenotypic data is available.","creator":"McLaughlin, C., Li, M., Perryman, M., Heymans, A., Schneider, H., Lasky, J., Sawers, R."},{"id":"2023.11.14.567013v1","slug":"primary-multistep-phosphorelay-activation-comprises-both-cytokinin-and-abiotic-stress-responses-in-brassicaceae","title":"Primary multistep phosphorelay activation comprises both cytokinin and abiotic stress responses in Brassicaceae","link":"http://biorxiv.org/cgi/content/short/2023.11.14.567013v1?rss=1","abstract":"Multistep phosphorelay (MSP) signaling integrates hormonal and environmental signals to control plant development and adaptive responses. The type-A RESPONSE REGULATORs (RRAs), the downstream members of the MSP cascade and cytokinin primary response genes, are supposed to mediate primarily the negative feedback regulation of (cytokinin-induced) MSP signaling. However, the transcriptional data suggest the involvement of RRAs in stress-related responses as well. By employing evolutionary conservation with the well-characterized Arabidopsis thaliana RRAs, we identified 5 and 38 novel putative RRAs in Brassica oleracea and Brassica napus, respectively. Our phylogenetic analysis suggests the existence of gene-specific selective pressure, maintaining the homologs of ARR3, ARR6, and ARR16 as singletons during the evolution of Brassica oleracea and Brassica rapa. We categorized RRAs based on the kinetics of their cytokinin-mediated upregulation and observed both similarities and specificities in this type of response across Brassicaceae. Using bioinformatic analysis and experimental data demonstrating the cytokinin responsiveness of Arabidopsis-derived TCSv2 reporter, we unveil the mechanistic conservation of cytokinin-mediated upregulation of RRAs in Brassica rapa and Brassica napus. Notably, we identify partial cytokinin dependency of cold stress-induced RRA transcription, thus corroborating the role of cytokinin signaling in the crop adaptive responses.  HighlightsWe identified Brassica homologs of Arabidopsis type-A response regulators (RRAs), demonstrate existence of selective pressure preventing several RRAs multiplication during Brassicaceae evolution and describe cytokinin dependency of cold-induced RRAs upregulation.","creator":"Nicolas Mala, K. L., Skalak, J., Zemlyanskaya, E., Dolgikh, V., Jedlickova, V., Robert-Boisivon, H., Havlickova, L., Panzarova, K., Trtilek, M., Bancroft, I., Hejatko, J."},{"id":"2023.11.13.566960v1","slug":"does-stomatal-patterning-in-amphistomatous-leavesminimize-the-co2-diffusion-path-length-withinleaves","title":"Does stomatal patterning in amphistomatous leavesminimize the CO2 diffusion path length withinleaves?","link":"http://biorxiv.org/cgi/content/short/2023.11.13.566960v1?rss=1","abstract":"Photosynthesis is co-limited by multiple factors depending on the plant and its environment. These include biochemical rate limitations, internal and external water potentials, temperature, irradiance, and carbon dioxide (CO2). Amphistomatous leaves have stomata on both abaxial and adaxial leaf surfaces. This feature is considered an adaptation to alleviate CO2 diffusion limitations in productive environments where other factors are not limiting as the diffusion path length from stomate to chloroplast is effectively halved. Plants can also reduce CO2 limitations through other aspects of optimal stomatal anatomy: stomatal density, distribution, patterning, and size. A number of studies have demonstrated that stomata are overdispersed on a single leaf surface; however, much less is known about stomatal anatomy in amphistomatous leaves, especially the coordination between leaf surfaces, despite their prevelance in nature and near ubiquity among crop species. Here we use novel spatial statistics based on simulations and photosynthesis modeling to test hypotheses about how amphistomatous plants may optimize CO2 limitations in the model angiosperm Arabidopsis thaliana grown in different light environments. We find that 1) stomata are overdispersed, but not ideally dispersed, on both leaf surfaces across all light treatments; 2) abaxial and adaxial leaf surface patterning are independent; and 3) the theoretical improvements to photosynthesis from abaxial-adaxial stomatal coordination are miniscule (<< 1%) across the range of feasible parameter space. However, we also find that 4) stomatal size is correlated with the mesophyll volume that it supplies with CO2, suggesting that plants may optimize CO2 diffusion limitations through alternative pathways other than ideal, uniform stomatal spacing. We discuss the developmental, physical, and evolutionary constraits which may prohibit plants from reaching the theoretical adaptive peak of uniform stomatal spacing and inter-surface stomatal coordination. These findings contribute to our understanding of variation in the anatomy of amphistomatous leaves.","creator":"Watts, J. L., Dow, G. J., Buckley, T. N., Muir, C. D."},{"id":"2023.11.14.566984v1","slug":"a-tomato-ethylene-insensitive-mutant-displays-altered-growth-and-higher-carotene-levels-in-fruit","title":"A tomato ethylene-insensitive mutant displays altered growth and higher -carotene levels in fruit","link":"http://biorxiv.org/cgi/content/short/2023.11.14.566984v1?rss=1","abstract":"The mutants insensitive to ethylene are helpful in deciphering the role of ethylene in plant development. We isolated an ethylene-insensitive tomato (Solanum lycopersicum) mutant by screening for acetylene-resistant (atr-1) seedlings. The atr-1 mutant displayed resistance to kinetin, suggesting attenuation of the ethylene sensing response. atr-1 also exhibited resistance to ABA- and glucose-mediated inhibition of seed germination. Unlike the Never- ripe (Nr) mutant, atr-1 seedlings were resistant to glucose, indicating ethylene sensing in atr-1 is located in a component distinct from Nr. Metabolically, atr-1 seedlings had lower levels of amino acids but higher levels of several phytohormones, including ABA. atr-1 plants grew faster and produced more flowers, leading to a higher fruit set. However, the atr- 1 fruits took a longer duration to reach the red-ripe (RR) stage. The ripened atr-1 fruits had higher {beta}-carotene levels, retained high {beta}-carotene and lycopene levels post-RR stage. The metabolome profiles of post-RR stage atr-1 fruits revealed increased levels of sugars. The atr-1 had a P279L mutation in the GAF domain of the ETR4, a key ethylene receptor regulating tomato ripening. Our study highlights that novel alleles in ethylene receptors may aid in enhancing the nutritional quality of tomato.","creator":"Gupta, S. K., Santisree, P., Gupta, P., Kilambi, H. V., Sreelakshmi, Y., Sharma, R."},{"id":"2023.11.13.566818v1","slug":"transcriptomic-landscape-of-seedstick-in-arabidopsis-thaliana-funiculus-after-fertilisation","title":"Transcriptomic landscape of seedstick in Arabidopsis thaliana funiculus after fertilisation","link":"http://biorxiv.org/cgi/content/short/2023.11.13.566818v1?rss=1","abstract":"In Angiosperms, the continuation of plant species is intricately dependent on the funiculus multifaceted role in nutrient transport, mechanical support, and dehiscence of seeds. SEEDSTICK (STK) is a MADS-box transcription factor involved in seed size and dehiscence, and one of the few genes identified as affecting funiculus growth. Given the importance of the funiculus to a correct seed development, allied with previous phenotypic observations of stk mutants, we performed a transcriptomic analysis of stk funiculi, using RNA-sequencing, to infer on the deregulated networks of genes. The generated dataset of differentially expressed genes was enriched with cell wall biogenesis, cell cycle, sugar metabolism and transport terms, all in accordance with stk phenotype. We selected eight differentially expressed genes involved with abscission, seed development or novel functions in stk funiculus, such as hormones/secondary metabolites transport, for transcriptome validation using qPCR and/or promoter reporter lines. Overall, the analysis performed in this study allowed delving into the STK-network established in Arabidopsis funiculus, fulfilling a literature gap. Simultaneously, our findings reinforced the reliability of the transcriptome, and identified processes and new candidate genes that will enable a better understanding on the role of this sporophytic structure and how seed development may be affected by it.","creator":"Ferreira, M. J., Silva, J., Takeuchi, H., Suzuki, T., Higashiyama, T., Coimbra, S. V. d. A."},{"id":"2023.11.14.567063v1","slug":"comparing-hormone-dynamics-in-cereal-crops-via-transient-expression-of-hormone-sensors","title":"Comparing hormone dynamics in cereal crops via transient expression of hormone sensors","link":"http://biorxiv.org/cgi/content/short/2023.11.14.567063v1?rss=1","abstract":"Plant hormones are small molecules which elicit profound physiological responses. Although plant hormone biosynthesis and response genes have been critical for agricultural improvement, it has been difficult to experimentally compare hormone biology across species because of complex phenotypic outputs. We used transient expression of genetic hormone sensors and transcriptomics to quantify tissue-specific gibberellic acid (GA) and auxin responses across tissues and genotypes in cereal crops. We found that the FRET-based GPS2 biosensor detects exogenous GA treatments in maize, barley, sorghum, and wheat, in both vegetative and floral tissues. Measuring GPS2 output across GA dosages revealed tissue- and genotype-specific differences in GA sensor response. We observed marked differences in maize vs barley leaves and floral tissues and an unexpected drop in GPS2 output in the maize d1 GA biosynthesis mutant after GA treatment, likely reflecting differences in bioactive GA content, GA transport, and mechanisms of GA response. We then used RNAseq to measure transcriptional responses to GA treatment in leaves from maize wildtype, d1, and barley as well as floral tissues from maize and barley for a cross-tissue, cross-genotype, and cross-species GA-response comparison. After orthology prediction and analysis of within- and cross-species GO-term enrichment, we identified core sets of GA-responsive genes in each species as well as maize- barley orthogroups. Our analysis suggests that downregulation of GA-INSENSITIVE DWARF1 (GID1) and upregulation of -Expansin1 (EXPA1) orthologs comprises a universal GA-response mechanism that is independent of GA biosynthesis, and identifies F-Box proteins, hexokinase, and AMPK/SNF1 protein kinase orthologs as unexpected cross-tissue, cross-genotype, and cross-species GA-responsive genes. We then compared the transient expression of the DR5, DR5v2, and DII-mDII auxin reporters in barley and maize and find that although DR5 did not respond to exogenous auxin in barley, DR5v2 responded to auxin treatment with a similar magnitude as in maize. Both species display auxin-mediated DII degradation that requires the 26S proteasome.","creator":"Dao, T. Q., Drapek, C., Jones, A. M., Leiboff, S."},{"id":"2023.11.11.566720v1","slug":"sucrose-or-starch-the-influence-of-tonoplast-sucrose-transporter-perturbation-on-carbon-partitioning-for-growth-defense-and-winter-protection-in-coppiced-poplar","title":"Sucrose or starch? The influence of tonoplast sucrose transporter perturbation on carbon partitioning for growth, defense, and winter protection in coppiced poplar","link":"http://biorxiv.org/cgi/content/short/2023.11.11.566720v1?rss=1","abstract":"Non-structural carbohydrate reserves of stems and roots underpin overall tree fitness as well as productivity under short-rotation management practices such as coppicing for bioenergy. While both sucrose and starch comprise the predominant carbohydrate reserves of Populus, utilization is understood primarily in terms of starch turnover. The tonoplast sucrose transport protein SUT4 modulates sucrose export to distant sinks, but the possibility of its involvement in sink tissue carbohydrate remobilization has not been explored. Here, we used PtaSUT4-knockout mutants of Populus tremula x alba (INRA 717-1B4) in winter and summer glasshouse coppicing experiments to strain carbon demand and test for SUT4 involvement in reserve utilization. We show that epicormic bud emergence was delayed and subsequent growth reduced in sut4 mutants following winter but not summer coppicing. Reserve depletion during post-coppice regrowth was not impaired in the sut4 mutants under winter or summer glasshouse conditions. Interestingly, xylem hexose increased during post-coppice growth exclusively in the winter when osmoprotection is critical, and the increase was attenuated in sut4 mutants. Accrual of abundant defense metabolites, including salicinoids, chlorogenic acids, and flavonoid products was prioritized in the summer, but conspicuously lower in sut4 mutants than controls. Together, our results point to shifting priorities for SUT4 function from support for osmoprotection in winter to chemical defense in summer. Delayed bud release and growth following winter but not summer coppicing in the sut4 mutants demonstrate the importance of SUT4 in modulating trade-offs between growth and the other priorities during reserve utilization in Populus.","creator":"Tuma, T. T., Nyamdari, B., Hsieh, C., Chen, Y.-H., Harding, S. A., Tsai, C.-J."},{"id":"2023.11.11.566685v1","slug":"robust-organ-size-in-arabidopsis-is-primarily-governed-by-cell-growth-rather-than-cell-division-patterns","title":"Robust organ size in Arabidopsis is primarily governed by cell growth rather than cell division patterns","link":"http://biorxiv.org/cgi/content/short/2023.11.11.566685v1?rss=1","abstract":"Organ sizes and shapes are highly reproducible, or robust, within a species and individuals. Arabidopsis thaliana sepals, which are the leaf-like organs that enclose flower buds, have consistent size and shape, which indicates robust development. Counterintuitively, variability in cell growth rate over time and between cells facilitates robust development because cumulative cell growth averages to a uniform rate. Here we investigate how sepal morphogenesis is robust to changes in cell division but not robust to changes in cell growth variability. We live image and quantitatively compare the development of sepals with increased or decreased cell division rate (lgo mutant and LGO overexpression, respectively), a mutant with altered cell growth variability (ftsh4), and double mutants combining these. We find that robustness is preserved when cell division rate changes because there is no change in the spatial pattern of growth. Meanwhile when robustness is lost in ftsh4 mutants, cell growth accumulates unevenly, and cells have disorganized growth directions. Thus, we demonstrate in vivo that both cell growth rate and direction average in robust development, preserving robustness despite changes in cell division.  Summary statementRobust sepal development is preserved despite changes in cell division rate and is characterized by spatiotemporal averaging of heterogeneity in cell growth rate and direction.","creator":"Burda, I., Li, C.-B., Clark, F. K., Roeder, A. H."},{"id":"2023.11.09.566501v1","slug":"genetic-factors-acting-prior-to-dormancy-in-sour-cherry-influence-bloom-time-the-following-spring","title":"Genetic factors acting prior to dormancy in sour cherry influence bloom time the following spring","link":"http://biorxiv.org/cgi/content/short/2023.11.09.566501v1?rss=1","abstract":"Bloom time is central to tree fruit production, and for Prunus species floral development leading up to bloom spans four seasons. Understanding this entire process is crucial for developing strategies to manipulate bloom time to prevent crop loss due to climate change. Here, we present a detailed examination of flower development from initiation until bloom for early- and late-blooming sour cherries (Prunus cerasus) from a population segregating for a major bloom time QTL on chromosome 4. Using a new staging system, we identified floral buds from early-blooming trees were persistently more advanced than those from late-blooming siblings. A gDNA coverage analysis revealed the late-blooming haplotype of this QTL, k, is located on a subgenome originating from the late-blooming P. fruticosa progenitor. Transcriptome analyses identified a large number of genes within this QTL as differentially expressed between early- and late-blooming trees during the vegetative-to-floral transition. From these, we identified candidate genes for the late bloom phenotype, including multiple transcription factors homologous to REproductive Meristem (REM) B3 domain-containing proteins. Additionally, we determined the basis of k in sour cherry is likely separate from candidate genes found in sweet cherry - suggesting several major regulators of bloom time are located on Prunus chromosome 4.  HIGHLIGHTDormancy is a main effector of bloom time in fruit trees. However, developmental, genetic, and transcriptomic analyses indicate differences in flower development before dormancy significantly influence flowering time in cherry.","creator":"Goeckeritz, C. Z., Grabb, C., Grumet, R., Iezzoni, A. F., Hollender, C. A."},{"id":"2023.11.10.566572v1","slug":"an-arabidopsis-leaf-expression-atlas-across-diurnal-and-developmental-scales","title":"An Arabidopsis leaf expression atlas across diurnal and developmental scales","link":"http://biorxiv.org/cgi/content/short/2023.11.10.566572v1?rss=1","abstract":"Mature plant leaves are a composite of distinct cell types, including epidermal, mesophyll and vascular cells. Notably the proportion of these cells, and the relative transcript concentrations within different cell types may change over time. While gene expression data at a single-cell level can provide cell-type specific expression values, it is often too expensive to perform this on high resolution time series. Although bulk RNA-seq can be performed in a high resolution time series, the RNA-seq in whole leaves measures the average gene expression values across all cell types in each sample. In this study, we combined single cell RNA-seq data with time-series data from whole leaves to infer an atlas of cell type-specific gene expression changes over time for Arabidopsis thaliana. We inferred how relative transcript concentrations of cell types vary across diurnal and developmental time scales. Importantly this analysis revealed three sub-groups of mesophyll cells that have distinct temporal profiles of expression. Finally, we develop tissue-specific gene networks that form a new community resource: An Arabidopsis Leaf Time-Dependent Atlas (AraLeTa), which allows users to extract gene networks that are confirmed by transcription factor binding data and specific to certain cell types, at certain times of day and certain developmental stages, which is available at: https://regulatorynet.shinyapps.io/araleta/.","creator":"Vong, G., McCarthy, K., Claydon, W., Davis, S. J., Redmond, E. J., Ezer, D."}]},{"name":"Economics","feed":[{"id":"2311.10716","slug":"the-independence-of-central-banks-a-reductio-ad-impossibile-arxiv-2311-10716v1-econ-gn","title":"The independence of Central Banks, a reductio ad impossibile.","link":"http://arxiv.org/abs/2311.10716","abstract":"This paper testifies to the fact that the independence of the Central Banks, as stated by its founding fathers, is nothing more than a chimera. We demonstrate that the hypothesis inflation is a purely monetary phenomenon does not support the plea for independence. Moreover, we show that the conservative central banker, the imaginary Principal-Agent contract, the alleged financial autonomy, just like the ban on budgetary financing, are all arguments that lack logic. We equally show that the idea of independence is not convincing because its operational toolbox, as well as the system of rules it relies on, lack well-defined outlines.","creator":"Ion Pohoata, Delia-Elena Diaconasu, Ioana Negru"},{"id":"2311.10742","slug":"ai-ethics-and-ordoliberalism-2-0-towards-a-digital-bill-of-rights-arxiv-2311-10742v1-cs-cy","title":"AI Ethics and Ordoliberalism 2.0: Towards A 'Digital Bill of Rights'.","link":"http://arxiv.org/abs/2311.10742","abstract":"This article analyzes AI ethics from a distinct business ethics perspective, i.e., 'ordoliberalism 2.0.' It argues that the ongoing discourse on (generative) AI relies too much on corporate self-regulation and voluntary codes of conduct and thus lacks adequate governance mechanisms. To address these issues, the paper suggests not only introducing hard-law legislation with a more effective oversight structure but also merging already existing AI guidelines with an ordoliberal-inspired regulatory and competition policy. However, this link between AI ethics, regulation, and antitrust is not yet adequately discussed in the academic literature and beyond. The paper thus closes a significant gap in the academic literature and adds to the predominantly legal-political and philosophical discourse on AI governance. The paper's research questions and goals are twofold: First, it identifies ordoliberal-inspired AI ethics principles that could serve as the foundation for a 'digital bill of rights.' Second, it shows how those principles could be implemented at the macro level with the help of ordoliberal competition and regulatory policy.","creator":"Manuel Woersdoerfer"},{"id":"2311.10831","slug":"religious-competition-culture-and-domestic-violence-evidence-from-colombia-arxiv-2311-10831v1-econ-gn","title":"Religious Competition, Culture and Domestic Violence: Evidence from Colombia.","link":"http://arxiv.org/abs/2311.10831","abstract":"This paper studies how religious competition, as measured by the emergence of religious organizations with innovative worship styles and cultural practices, impacts domestic violence. Using data from Colombia, the study estimates a two-way fixed-effects model and reveals that the establishment of the first non-Catholic church in a predominantly Catholic municipality leads to a significant decrease in reported cases of domestic violence. This effect persists in the long run, indicating that religious competition introduces values and practices that discourage domestic violence, such as household stability and reduced male dominance. Additionally, the effect is more pronounced in municipalities with less clustered social networks, suggesting the diffusion of these values and practices through social connections. This research contributes to the understanding of how culture influences domestic violence, emphasizing the role of religious competition as a catalyst for cultural change.","creator":"Hector Galindo-Silva, Guy Tchuente"},{"id":"2311.10861","slug":"first-do-no-harm-algorithms-ai-and-digital-product-liability-arxiv-2311-10861v1-econ-gn","title":"First, Do No Harm: Algorithms, AI, and Digital Product Liability.","link":"http://arxiv.org/abs/2311.10861","abstract":"The ethical imperative for technology should be first, do no harm. But digital innovations like AI and social media increasingly enable societal harms, from bias to misinformation. As these technologies grow ubiquitous, we need solutions to address unintended consequences. This report proposes a model to incentivize developers to prevent foreseeable algorithmic harms. It does this by expanding negligence and product liability laws. Digital product developers would be incentivized to mitigate potential algorithmic risks before deployment to protect themselves and investors. Standards and penalties would be set proportional to harm. Insurers would require harm mitigation during development in order to obtain coverage. This shifts tech ethics from move fast and break things to first, do no harm. Details would need careful refinement between stakeholders to enact reasonable guardrails without stifling innovation. Policy and harm prevention frameworks would likely evolve over time. Similar accountability schemes have helped address workplace, environmental, and product safety. Introducing algorithmic harm negligence liability would acknowledge the real societal costs of unethical tech. The timing is right for reform. This proposal provides a model to steer the digital revolution toward human rights and dignity. Harm prevention must be prioritized over reckless growth. Vigorous liability policies are essential to stop technologists from breaking things","creator":"Marc J. Pfeiffer"},{"id":"2311.10917","slug":"modeling-trading-games-in-a-stochastic-non-life-insurance-market-arxiv-2311-10917v1-econ-th","title":"Modeling trading games in a stochastic non-life insurance market.","link":"http://arxiv.org/abs/2311.10917","abstract":"We studied the behavior and variation of utility between the two conflicting players in a closed Nash-equilibrium loop. Our modeling approach also captured the nexus between optimal premium strategizing and firm performance using the Lotka-Volterra completion model. Our model robustly modeled the two main cases, insurer-insurer and insurer-policyholder, which we accompanied by numerical examples of premium movements and their relationship to the market equilibrium point. We found that insurers with high claim exposures tend to set high premiums. The other competitors either set a competitive premium or adopt the fixed premium charge to remain in the game; otherwise, they will operate below the optimal point. We also noted an inverse link between trading premiums and claims in general insurance games due to self-interest and utility indifferences. We concluded that while an insurer aims to charge high premiums to enjoy more, policyholders are willing to avoid these charges by paying less.","creator":"Leonard Mushunje, David Edmund Allen"},{"id":"2311.10987","slug":"research-on-the-dynamic-evolution-and-influencing-factors-of-energy-resilience-in-china-arxiv-2311-10987v1-econ-gn","title":"Research on the Dynamic Evolution and Influencing Factors of Energy Resilience in China.","link":"http://arxiv.org/abs/2311.10987","abstract":"Energy security is the guarantee for achieving the goal of carbon peaking and carbon neutrality, and exploring energy resilience is one of the important ways to promote energy security transition and adapt to changes in international and domestic energy markets. This paper applies the combined dynamic evaluation method to measure China's energy resilience level from 2004-2021, analyses the spatio-temporal dynamic evolution of China's energy resilience through the center of gravity-standard deviation ellipse and kernel density estimation, and employs geo-detectors to detect the main influencing factors and interactions of China's energy resilience. The study finds that:(1)China's energy resilience level generally shows a zigzagging forward development trend, and the spatial imbalance characteristic of China's energy resilience is more obvious.(2)The spatial dynamics of China's energy resilience level evolves in a northeast-southwest direction, and the whole moves towards the southwest, with an overall counterclockwise trend of constant offset.(3)When the energy resilience level of neighboring provinces is too low or too high, it has little effect on the improvement of the energy resilience level of the province; when the energy resilience level of neighboring provinces is 1-1.4, it has a positive spatial correlation with the energy resilience level of the province, and the synergistic development of the provinces can improve the energy resilience level together.(4)GDP, the number of employees, the number of employees enrolled in basic pension and medical insurance, and the number of patent applications in high-tech industries have a more significant impact on China's energy resilience, while China's energy resilience is affected by the interaction of multiple factors.","creator":"Tie Wei, Youqi Chen, Zhicheng Duan"},{"id":"2311.11231","slug":"workforce-pdei-productivity-coupled-with-dei-arxiv-2311-11231v1-econ-gn","title":"Workforce pDEI: Productivity Coupled with DEI.","link":"http://arxiv.org/abs/2311.11231","abstract":"Ranking pertaining to the human-centered tasks -- underscoring their paramount significance in these domains such as evaluation and hiring process -- exhibits widespread prevalence across various industries. Consequently, decision-makers are taking proactive measurements to promote diversity, underscore equity, and advance inclusion. Their unwavering commitment to these ideals emanates from the following convictions: (i) Diversity encompasses a broad spectrum of differences; (ii) Equity involves the assurance of equitable opportunities; and (iii) Inclusion revolves around the cultivation of a sense of value and impartiality, concurrently empowering individuals. Data-driven AI tools have been used for screening and ranking processes. However, there is a growing concern that the presence of pre-existing biases in databases may be exacerbated, particularly in the context of imbalanced datasets or the black-box-schema. In this research, we propose a model-driven recruitment decision support tool that addresses fairness together with equity in the screening phase. We introduce the term ``pDEI\" to represent the output-input oriented production efficiency adjusted by socioeconomic disparity. Taking into account various aspects of interpreting socioeconomic disparity, our goals are (i) maximizing the relative efficiency of underrepresented groups and (ii) understanding how socioeconomic disparity affects the cultivation of a DEI-positive workplace.","creator":"Lanqing Du, Jinwook Lee"},{"id":"2311.11366","slug":"ambiguity-aversion-as-a-route-to-randomness-in-a-duopoly-game-arxiv-2311-11366v1-econ-th","title":"Ambiguity aversion as a route to randomness in a duopoly game.","link":"http://arxiv.org/abs/2311.11366","abstract":"The global dynamics is investigated for a duopoly game where the perfect foresight hypothesis is relaxed and firms are worst-case maximizers. Overlooking the degree of product substitutability as well as the sensitivity of price to quantity, the unique and globally stable Cournot-Nash equilibrium of the complete-information duopoly game, loses stability when firms are not aware if they are playing a duopoly game, as it is, or an oligopoly game with more than two competitors. This finding resembles Theocharis' condition for the stability of the Cournot-Nash equilibrium in oligopolies without uncertainty. As opposed to complete-information oligopoly games, coexisting attractors, disconnected basins of attractions and chaotic dynamics emerge when the Cournot-Nash equilibrium loses stability. This difference in the global dynamics is due to the nonlinearities introduced by the worst-case approach to uncertainty, which mirror in bimodal best-reply functions. Conducted with techniques that require a symmetric setting of the game, the investigation of the dynamics reveals that a chaotic regime prevents firms from being ambiguity averse, that is, firms are worst-case maximizers only in the quantity-expectation space. Therefore, chaotic dynamics are the result and at the same time the source of profit uncertainty.","creator":"Davide Radi, Laura Gardini"},{"id":"2311.11406","slug":"architecting-the-future-a-model-for-enterprise-integration-in-the-metaverse-arxiv-2311-11406v1-cs-cy","title":"Architecting the Future: A Model for Enterprise Integration in the Metaverse.","link":"http://arxiv.org/abs/2311.11406","abstract":"Although it has a history that goes back about three decades, Metaverse has grown to be one of the most talked-about subjects today. Metaverse gradually increased its influence in the realm of business discourse after initially being restricted to discussions about entertainment. Before getting deep into the Metaverse, it should be noted that failure and deviating from the business path are highly likely for an enterprise that relies heavily on information technology (IT) because of improper use and thinking about IT. The idea of enterprise architecture (EA) emerged as a management strategy to address this issue. As the first school of thought of EA, it sought to transform IT from an unnecessary burden in an enterprise to a guiding and supporting force. Then an extended EA model is suggested as a result of the attempt made in this paper to use the idea of EA to steer virtual enterprises on Metaverse-based platforms. Finally, to evaluate the conceptual model and demonstrate that the Metaverse can support businesses, three case studies Decentraland, Battle Infinity, and Rooom were utilized.","creator":"Amirmohammad Nateghi, Maedeh Mosharraf"},{"id":"2311.11526","slug":"benefiting-from-bias-delegating-to-encourage-information-acquisition-arxiv-2311-11526v1-econ-th","title":"Benefiting from Bias: Delegating to Encourage Information Acquisition.","link":"http://arxiv.org/abs/2311.11526","abstract":"A principal delegates decisions to a biased agent. Payoffs depend on a state that the principal cannot observe. Initially, the agent does not observe the state, but he can acquire information about it at a cost. We characterize the principal's optimal delegation set. This set features a cap on high decisions and a gap around the agent's ex ante favorite decision. It may even induce ex-post Pareto-dominated decisions. Under certain conditions on the cost of information acquisition, we show that the principal prefers delegating to an agent with a small bias than to an unbiased agent.","creator":"Ian Ball, Xin Gao"},{"id":"2311.11576","slug":"multi-stage-optimisation-towards-transformation-pathways-for-municipal-energy-systems-arxiv-2311-11576v1-eess-sy","title":"Multi-stage optimisation towards transformation pathways for municipal energy systems.","link":"http://arxiv.org/abs/2311.11576","abstract":"An essential facet of achieving climate neutrality by 2045 is the decarbonization of municipal energy systems. To accomplish this, it is necessary to establish implementation concepts that detail the timing, location, and specific measures required to achieve decarbonization. This restructuring process involves identifying the measures that offer the most compelling techno-economic and ecological advantages. In particular, measures that contribute to the interconnection of energy vectors and domains, e.g. heating, cooling, and electricity supply, in the sense of decentralized multi-energy systems are a promising future development option. Due to the high complexity resulting from a multitude of decision options as well as a temporal coupling across the transformation path, the use of optimization methods is required, which enable a bottom-up identification of suitable transformation solutions in a high spatial resolution. For the design of reasonable concepts, we develop a multistage optimization problem for the derivation of transformation pathways in the context of a multi-location structure, expansion, and operation problem. The results show that the heat supply in the future will mainly be provided by heat pumps with a share of 60%. It can also be shown that an early dismantling of the gas network will lead to the need for transitional technologies such as pellet heating. Overall, the conversion of the municipal energy system can significantly reduce emissions (97%).","creator":"Paul Maximilian R&#xf6;hrig, Nils K&#xf6;rber, Julius Zocher, Andreas Ulbig"},{"id":"2311.11637","slug":"modeling-economies-of-scope-in-joint-production-convex-regression-of-input-distance-function-arxiv-2311-11637v1-stat-me","title":"Modeling economies of scope in joint production: Convex regression of input distance function.","link":"http://arxiv.org/abs/2311.11637","abstract":"Modeling of joint production has proved a vexing problem. This paper develops a radial convex nonparametric least squares (CNLS) approach to estimate the input distance function with multiple outputs. We document the correct input distance function transformation and prove that the necessary orthogonality conditions can be satisfied in radial CNLS. A Monte Carlo study is performed to compare the finite sample performance of radial CNLS and other deterministic and stochastic frontier approaches in terms of the input distance function estimation. We apply our novel approach to the Finnish electricity distribution network regulation and empirically confirm that the input isoquants become more curved. In addition, we introduce the weight restriction to radial CNLS to mitigate the potential overfitting and increase the out-of-sample performance in energy regulation.","creator":"Timo Kuosmanen, Sheng Dai"},{"id":"2311.11828","slug":"would-monetary-incentives-to-covid-19-vaccination-reduce-motivation-arxiv-2311-11828v1-econ-gn","title":"Would Monetary Incentives to COVID-19 vaccination reduce motivation?.","link":"http://arxiv.org/abs/2311.11828","abstract":"Some people did not get the COVID-19 vaccine even though it was offered at no cost. A monetary incentive might lead people to vaccinate, although existing studies have provided different findings about this effect. We investigate how monetary incentives differ according to individual characteristics. Using panel data with online experiments, we found that (1) subsidies reduced vaccine intention but increased it after controlling heterogeneity; (2) the stronger the social image against the vaccination, the lower the monetary incentive; and (3) persistently unvaccinated people would intend to be vaccinated only if a large subsidy was provided.","creator":"Eiji Yamamura, Yoshiro Tsutsui, Fumio Ohtake"},{"id":"2311.11858","slug":"theory-coherent-shrinkage-of-time-varying-parameters-in-vars-arxiv-2311-11858v1-econ-em","title":"Theory coherent shrinkage of Time-Varying Parameters in VARs.","link":"http://arxiv.org/abs/2311.11858","abstract":"Time-Varying Parameters Vector Autoregressive (TVP-VAR) models are frequently used in economics to capture evolving relationships among the macroeconomic variables. However, TVP-VARs have the tendency of overfitting the data, resulting in inaccurate forecasts and imprecise estimates of typical objects of interests such as the impulse response functions. This paper introduces a Theory Coherent Time-Varying Parameters Vector Autoregressive Model (TC-TVP-VAR), which leverages on an arbitrary theoretical framework derived by an underlying economic theory to form a prior for the time varying parameters. This \"theory coherent\" shrinkage prior significantly improves inference precision and forecast accuracy over the standard TVP-VAR. Furthermore, the TC-TVP-VAR can be used to perform indirect posterior inference on the deep parameters of the underlying economic theory. The paper reveals that using the classical 3-equation New Keynesian block to form a prior for the TVP- VAR substantially enhances forecast accuracy of output growth and of the inflation rate in a standard model of monetary policy. Additionally, the paper shows that the TC-TVP-VAR can be used to address the inferential challenges during the Zero Lower Bound period.","creator":"Andrea Renzetti"},{"id":"2007.07842","slug":"persistence-in-financial-connectedness-and-systemic-risk-arxiv-2007-07842v4-econ-em-updated","title":"Persistence in Financial Connectedness and Systemic Risk.","link":"http://arxiv.org/abs/2007.07842","abstract":"This paper characterises dynamic linkages arising from shocks with heterogeneous degrees of persistence. Using frequency domain techniques, we introduce measures that identify smoothly varying links of a transitory and persistent nature. Our approach allows us to test for statistical differences in such dynamic links. We document substantial differences in transitory and persistent linkages among US financial industry volatilities, argue that they track heterogeneously persistent sources of systemic risk, and thus may serve as a useful tool for market participants.","creator":"Jozef Barunik, Michael Ellington"},{"id":"2010.01249","slug":"optimal-echo-chambers-arxiv-2010-01249v9-econ-th-updated","title":"Optimal Echo Chambers.","link":"http://arxiv.org/abs/2010.01249","abstract":"When learning from others, people tend to focus their attention on those with similar views. This is often attributed to flawed reasoning, and thought to slow learning and polarize beliefs. However, we show that echo chambers are a rational response to uncertainty about the accuracy of information sources, and can improve learning and reduce disagreement. Furthermore, overextending the range of views someone is exposed to can backfire, slowing their learning by making them less responsive to information from others. We model a Bayesian decision maker who chooses a set of information sources and then observes a signal from one. With uncertainty about which sources are accurate, focusing attention on signals close to one's own expectation can be beneficial, as their expected accuracy is higher. The optimal echo chamber balances the credibility of views similar to one's own against the usefulness of those further away.","creator":"Gabriel Martinez, Nicholas H. Tenev"},{"id":"2104.10657","slug":"a-rational-inattention-theory-of-echo-chamber-arxiv-2104-10657v7-econ-th-updated","title":"A Rational Inattention Theory of Echo Chamber.","link":"http://arxiv.org/abs/2104.10657","abstract":"We develop a rational inattention theory of echo chamber, whereby players gather information about an uncertain state by allocating limited attention capacities across biased primary sources and other players. The resulting Poisson attention network transmits information from the primary source to a player either directly, or indirectly through the other players. Rational inattention generates heterogeneous demands for information among players who are biased toward different decisions. In an echo chamber equilibrium, each player restricts attention to his own-biased source and like-minded friends, as the latter attend to the same primary source as his, and so could serve as secondary sources in case the information transmission from the primary source to him is disrupted. We provide sufficient conditions that give rise to echo chamber equilibria, characterize the attention networks inside echo chambers, and use our results to inform the design and regulation of information platforms.","creator":"Lin Hu, Anqi Li, Xu Tan"},{"id":"2112.14265","slug":"learning-in-repeated-interactions-on-networks-arxiv-2112-14265v4-econ-th-updated","title":"Learning in Repeated Interactions on Networks.","link":"http://arxiv.org/abs/2112.14265","abstract":"We study how long-lived, rational agents learn in a social network. In every period, after observing the past actions of his neighbors, each agent receives a private signal, and chooses an action whose payoff depends only on the state. Since equilibrium actions depend on higher order beliefs, it is difficult to characterize behavior. Nevertheless, we show that regardless of the size and shape of the network, the utility function, and the patience of the agents, the speed of learning in any equilibrium is bounded from above by a constant that only depends on the private signal distribution.","creator":"Wanying Huang, Philipp Strack, Omer Tamuz"},{"id":"2204.00347","slug":"insuring-uninsurable-income-arxiv-2204-00347v5-econ-th-updated","title":"Insuring uninsurable income.","link":"http://arxiv.org/abs/2204.00347","abstract":"This paper presents a method to avoid the ominous prediction of the previous work: if insured incomes of infinitely lived individuals are unobservable, then efficient allocations lead to welfare inequality between individuals and immiseration of society. The proposed mechanism (i) promises full insurance in each period with varying inter-period allocation weights; (ii) these insurance contracts are actuarially fair; (iii) it does not easily induce parmanent inequality and is sustainable.","creator":"Michiko Ogaku"},{"id":"2205.11365","slug":"graph-based-methods-for-discrete-choice-arxiv-2205-11365v2-cs-lg-updated","title":"Graph-Based Methods for Discrete Choice.","link":"http://arxiv.org/abs/2205.11365","abstract":"Choices made by individuals have widespread impacts--for instance, people choose between political candidates to vote for, between social media posts to share, and between brands to purchase--moreover, data on these choices are increasingly abundant. Discrete choice models are a key tool for learning individual preferences from such data. Additionally, social factors like conformity and contagion influence individual choice. Traditional methods for incorporating these factors into choice models do not account for the entire social network and require hand-crafted features. To overcome these limitations, we use graph learning to study choice in networked contexts. We identify three ways in which graph learning techniques can be used for discrete choice: learning chooser representations, regularizing choice model parameters, and directly constructing predictions from a network. We design methods in each category and test them on real-world choice datasets, including county-level 2016 US election results and Android app installation and usage data. We show that incorporating social network structure can improve the predictions of the standard econometric choice model, the multinomial logit. We provide evidence that app installations are influenced by social context, but we find no such effect on app usage among the same participants, which instead is habit-driven. In the election data, we highlight the additional insights a discrete choice framework provides over classification or regression, the typical approaches. On synthetic data, we demonstrate the sample complexity benefit of using social information in choice models.","creator":"Kiran Tomlinson, Austin R. Benson"},{"id":"2210.00815","slug":"measurement-of-trustworthiness-of-the-online-reviews-arxiv-2210-00815v2-econ-th-updated","title":"Measurement of Trustworthiness of the Online Reviews.","link":"http://arxiv.org/abs/2210.00815","abstract":"In electronic commerce (e-commerce)markets, a decision-maker faces a sequential choice problem. Third-party intervention plays an important role in making purchase decisions in this choice process. For instance, while purchasing products/services online, a buyer's choice or behavior is often affected by the overall reviewers' ratings, feedback, etc. Moreover, the reviewer is also a decision-maker. After purchase, the decision-maker would put forth their reviews for the product, online. Such reviews would affect the purchase decision of another potential buyer, who would read the reviews before conforming to his/her final purchase. The question that arises is \\textit{how trustworthy are these review reports and ratings?} The trustworthiness of these review reports and ratings is based on whether the reviewer is a rational or an irrational person. Indexing the reviewer's rationality could be a way to quantify a reviewer's rationality but it does not communicate the history of his/her behavior. In this article, the researcher aims at formally deriving a rationality pattern function and thereby, the degree of rationality of the decision-maker or the reviewer in the sequential choice problem in the e-commerce markets. Applying such a rationality pattern function could make it easier to quantify the rational behavior of an agent who participates in the digital markets. This, in turn, is expected to minimize the information asymmetry within the decision-making process and identify the paid reviewers or manipulative reviews.","creator":"Dipankar Das"},{"id":"2303.14263","slug":"the-effect-of-product-recommendations-on-online-investor-behaviors-arxiv-2303-14263v2-econ-gn-updated","title":"The Effect of Product Recommendations on Online Investor Behaviors.","link":"http://arxiv.org/abs/2303.14263","abstract":"Despite the popularity of product recommendations on online investment platforms, few studies have explored their impact on investor behaviors. Using data from a global e-commerce platform, we apply regression discontinuity design to causally examine the effects of product recommendations on online investors' mutual fund investments. Our findings indicate that recommended funds experience a significant rise in purchases, especially among low socioeconomic status investors who are most influenced by these recommendations. However, investors tend to suffer significantly worse investment returns after purchasing recommended funds, and this negative impact is also most significant for investors with low socioeconomic status. To explain this disparity, we find investors tend to gather less information and expend reduced effort in fund research when buying recommended funds. Furthermore, investors' redemption timing of recommended funds is less optimal than non-recommended funds. We also find that recommended funds experience a larger return reversal than non-recommended funds. In conclusion, product recommendations make investors behave more irrationally and these negative consequences are most significant for investors with low socioeconomic status, which can amplify wealth inequality among investors in financial markets.","creator":"Ruiqi Rich Zhu, Cheng He, Yu Jeffrey Hu"},{"id":"2306.09287","slug":"modelling-and-forecasting-macroeconomic-risk-with-time-varying-skewness-stochastic-volatility-models-arxiv-2306-09287v2-econ-em-updated","title":"Modelling and Forecasting Macroeconomic Risk with Time Varying Skewness Stochastic Volatility Models.","link":"http://arxiv.org/abs/2306.09287","abstract":"Monitoring downside risk and upside risk to the key macroeconomic indicators is critical for effective policymaking aimed at maintaining economic stability. In this paper I propose a parametric framework for modelling and forecasting macroeconomic risk based on stochastic volatility models with Skew-Normal and Skew-t shocks featuring time varying skewness. Exploiting a mixture stochastic representation of the Skew-Normal and Skew-t random variables, in the paper I develop efficient posterior simulation samplers for Bayesian estimation of both univariate and VAR models of this type. In an application, I use the models to predict downside risk to GDP growth in the US and I show that these models represent a competitive alternative to semi-parametric approaches such as quantile regression. Finally, estimating a medium scale VAR on US data I show that time varying skewness is a relevant feature of macroeconomic and financial shocks.","creator":"Andrea Renzetti"},{"id":"2308.10974","slug":"guinea-pig-trials-utilizing-gpt-a-novel-smart-agent-based-modeling-approach-for-studying-firm-competition-and-collusion-arxiv-2308-10974v3-cs-ai-updated","title":"\"Guinea Pig Trials\" Utilizing GPT: A Novel Smart Agent-Based Modeling Approach for Studying Firm Competition and Collusion.","link":"http://arxiv.org/abs/2308.10974","abstract":"Firm competition and collusion involve complex dynamics, particularly when considering communication among firms. Such issues can be modeled as problems of complex systems, traditionally approached through experiments involving human subjects or agent-based modeling methods. We propose an innovative framework called Smart Agent-Based Modeling (SABM), wherein smart agents, supported by GPT-4 technologies, represent firms, and interact with one another. We conducted a controlled experiment to study firm price competition and collusion behaviors under various conditions. SABM is more cost-effective and flexible compared to conducting experiments with human subjects. Smart agents possess an extensive knowledge base for decision-making and exhibit human-like strategic abilities, surpassing traditional ABM agents. Furthermore, smart agents can simulate human conversation and be personalized, making them ideal for studying complex situations involving communication. Our results demonstrate that, in the absence of communication, smart agents consistently reach tacit collusion, leading to prices converging at levels higher than the Bertrand equilibrium price but lower than monopoly or cartel prices. When communication is allowed, smart agents achieve a higher-level collusion with prices close to cartel prices. Collusion forms more quickly with communication, while price convergence is smoother without it. These results indicate that communication enhances trust between firms, encouraging frequent small price deviations to explore opportunities for a higher-level win-win situation and reducing the likelihood of triggering a price war. We also assigned different personas to firms to analyze behavioral differences and tested variant models under diverse market structures. The findings showcase the effectiveness and robustness of SABM and provide intriguing insights into competition and collusion.","creator":"Xu Han, Zengqing Wu, Chuan Xiao"},{"id":"2309.07476","slug":"causal-inference-in-network-experiments-regression-based-analysis-and-design-based-properties-arxiv-2309-07476v2-econ-em-updated","title":"Causal inference in network experiments: regression-based analysis and design-based properties.","link":"http://arxiv.org/abs/2309.07476","abstract":"Investigating interference or spillover effects among units is a central task in many social science problems. Network experiments are powerful tools for this task, which avoids endogeneity by randomly assigning treatments to units over networks. However, it is non-trivial to analyze network experiments properly without imposing strong modeling assumptions. Previously, many researchers have proposed sophisticated point estimators and standard errors for causal effects under network experiments. We further show that regression-based point estimators and standard errors can have strong theoretical guarantees if the regression functions and robust standard errors are carefully specified to accommodate the interference patterns under network experiments. We first recall a well-known result that the Hajek estimator is numerically identical to the coefficient from the weighted-least-squares fit based on the inverse probability of the exposure mapping. Moreover, we demonstrate that the regression-based approach offers three notable advantages: its ease of implementation, the ability to derive standard errors through the same weighted-least-squares fit, and the capacity to integrate covariates into the analysis, thereby enhancing estimation efficiency. Furthermore, we analyze the asymptotic bias of the regression-based network-robust standard errors. Recognizing that the covariance estimator can be anti-conservative, we propose an adjusted covariance estimator to improve the empirical coverage rates. Although we focus on regression-based point estimators and standard errors, our theory holds under the design-based framework, which assumes that the randomness comes solely from the design of network experiments and allows for arbitrary misspecification of the regression models.","creator":"Mengsi Gao, Peng Ding"},{"id":"2310.14590","slug":"can-the-black-lives-matter-movement-reduce-racial-disparities-evidence-from-medical-crowdfunding-arxiv-2310-14590v2-econ-gn-updated","title":"Can the Black Lives Matter Movement Reduce Racial Disparities? Evidence from Medical Crowdfunding.","link":"http://arxiv.org/abs/2310.14590","abstract":"Using high-frequency donation records from a major medical crowdfunding site and careful difference-in-difference analysis, we demonstrate that the 2020 BLM surge decreased the fundraising gap between Black and non-Black beneficiaries by around 50\\%. The reduction is largely attributed to non-Black donors. Those beneficiaries in counties with moderate BLM activities were most impacted. We construct innovative instrumental variable approaches that utilize weekends and rainfall to identify the global and local effects of BLM protests. Results suggest a broad social movement has a greater influence on charitable-giving behavior than a local event. Social media significantly magnifies the impact of protests.","creator":"Kaixin Liu, Jiwei Zhou, Junda Wang"},{"id":"2310.18836","slug":"design-of-cluster-randomized-trials-with-cross-cluster-interference-arxiv-2310-18836v2-stat-me-updated","title":"Design of Cluster-Randomized Trials with Cross-Cluster Interference.","link":"http://arxiv.org/abs/2310.18836","abstract":"Cluster-randomized trials often involve units that are irregularly distributed in space without well-separated communities. In these settings, cluster construction is a critical aspect of the design due to the potential for cross-cluster interference. The existing literature relies on partial interference models, which take clusters as given and assume no cross-cluster interference. We relax this assumption by allowing interference to decay with geographic distance between units. This induces a bias-variance trade-off: constructing fewer, larger clusters reduces bias due to interference but increases variance. We propose new estimators that exclude units most potentially impacted by cross-cluster interference and show that this substantially reduces asymptotic bias relative to conventional difference-in-means estimators. We provide formal justification for a new design that chooses the number of clusters to balance the asymptotic bias and variance of our estimators and uses unsupervised learning to automate cluster construction.","creator":"Michael P. Leung"},{"id":"2311.03195","slug":"some-coordination-problems-are-harder-than-others-arxiv-2311-03195v2-econ-th-updated","title":"Some coordination problems are harder than others.","link":"http://arxiv.org/abs/2311.03195","abstract":"In order to coordinate players in a game must first identify a target pattern of behaviour. In this paper we investigate the difficulty of identifying prominent outcomes in two kinds of binary action coordination problems in social networks: pure coordination games and anti-coordination games. For both environments, we determine the computational complexity of finding a strategy profile that (i) maximises welfare, (ii) maximises welfare subject to being an equilibrium, and (iii) maximises potential. We show that the complexity of these objectives can vary with the type of coordination problem. Objectives (i) and (iii) are tractable problems in pure coordination games, but for anti-coordination games are NP-hard. Objective (ii), finding the best Nash equilibrium, is NP-hard for both. Our results support the idea that environments in which actions are strategic complements (e.g., technology adoption) facilitate successful coordination more readily than those in which actions are strategic substitutes (e.g., public good provision).","creator":"Argyrios Deligkas, Eduard Eiben, Gregory Gutin, Philip R. Neary, Anders Yeo"}]}]